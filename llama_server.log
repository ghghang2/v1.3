ggml_cuda_init: found 1 CUDA devices:
  Device 0: Tesla T4, compute capability 7.5, VMM: yes
common_download_file_single_online: no previous model file found /root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_preset.ini
common_download_file_single_online: HEAD invalid http status code received: 404
no remote preset found, skipping
common_download_file_single_online: no previous model file found /root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-F16.gguf
common_download_file_single_online: trying to download model from https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-F16.gguf to /root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-F16.gguf.downloadInProgress (etag:"78f73a4ef91c8f92d4df971f570ff3719007201f6d955b8695384a1b21b04a80")...
main: n_parallel is set to auto, using n_parallel = 4 and kv_unified = true
build: 7772 (287a33017) with GNU 11.4.0 for Linux x86_64
system info: n_threads = 1, n_threads_batch = 1, total_threads = 2

system_info: n_threads = 1 (n_threads_batch = 1) / 2 | CUDA : ARCHS = 750 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | 

Running without SSL
init: using 6 threads for HTTP server
start: binding port with default address family
main: loading model
srv    load_model: loading model '/root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-F16.gguf'
common_init_result: fitting params to device memory, for bugs during this step try to reproduce them with -fit off, or provide --verbose logs if the bug only occurs with -fit on
srv  log_server_r: request: GET /health 127.0.0.1 503
llama_params_fit_impl: projected to use 15546 MiB of device memory vs. 14807 MiB of free device memory
llama_params_fit_impl: cannot meet free memory target of 1024 MiB, need to reduce device memory by 1763 MiB
srv  log_server_r: request: GET /health 127.0.0.1 503
llama_params_fit_impl: context size reduced from 131072 to 56064 -> need 1767 MiB less memory in total
llama_params_fit_impl: entire model can be fit by reducing context
llama_params_fit: successfully fit params to free device memory
llama_params_fit: fitting params to free memory took 1.89 seconds
llama_model_load_from_file_impl: using device CUDA0 (Tesla T4) (0000:00:04.0) - 14807 MiB free
llama_model_loader: direct I/O is enabled, disabling mmap
llama_model_loader: loaded meta data with 37 key-value pairs and 459 tensors from /root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-F16.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = gpt-oss
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Gpt-Oss-20B
llama_model_loader: - kv   3:                           general.basename str              = Gpt-Oss-20B
llama_model_loader: - kv   4:                       general.quantized_by str              = Unsloth
llama_model_loader: - kv   5:                         general.size_label str              = 20B
llama_model_loader: - kv   6:                            general.license str              = apache-2.0
llama_model_loader: - kv   7:                           general.repo_url str              = https://huggingface.co/unsloth
llama_model_loader: - kv   8:                               general.tags arr[str,2]       = ["vllm", "text-generation"]
llama_model_loader: - kv   9:                        gpt-oss.block_count u32              = 24
llama_model_loader: - kv  10:                     gpt-oss.context_length u32              = 131072
llama_model_loader: - kv  11:                   gpt-oss.embedding_length u32              = 2880
llama_model_loader: - kv  12:                gpt-oss.feed_forward_length u32              = 2880
llama_model_loader: - kv  13:               gpt-oss.attention.head_count u32              = 64
llama_model_loader: - kv  14:            gpt-oss.attention.head_count_kv u32              = 8
llama_model_loader: - kv  15:                     gpt-oss.rope.freq_base f32              = 150000.000000
llama_model_loader: - kv  16:   gpt-oss.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  17:                       gpt-oss.expert_count u32              = 32
llama_model_loader: - kv  18:                  gpt-oss.expert_used_count u32              = 4
llama_model_loader: - kv  19:               gpt-oss.attention.key_length u32              = 64
llama_model_loader: - kv  20:             gpt-oss.attention.value_length u32              = 64
llama_model_loader: - kv  21:                          general.file_type u32              = 1
llama_model_loader: - kv  22:           gpt-oss.attention.sliding_window u32              = 128
llama_model_loader: - kv  23:         gpt-oss.expert_feed_forward_length u32              = 2880
llama_model_loader: - kv  24:                  gpt-oss.rope.scaling.type str              = yarn
llama_model_loader: - kv  25:                gpt-oss.rope.scaling.factor f32              = 32.000000
llama_model_loader: - kv  26: gpt-oss.rope.scaling.original_context_length u32              = 4096
llama_model_loader: - kv  27:               general.quantization_version u32              = 2
llama_model_loader: - kv  28:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  29:                         tokenizer.ggml.pre str              = gpt-4o
llama_model_loader: - kv  30:                      tokenizer.ggml.tokens arr[str,201088]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  31:                  tokenizer.ggml.token_type arr[i32,201088]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  32:                      tokenizer.ggml.merges arr[str,446189]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  33:                tokenizer.ggml.bos_token_id u32              = 199998
llama_model_loader: - kv  34:                tokenizer.ggml.eos_token_id u32              = 200002
llama_model_loader: - kv  35:            tokenizer.ggml.padding_token_id u32              = 200017
llama_model_loader: - kv  36:                    tokenizer.chat_template str              = {# Chat template fixes by Unsloth #}\n...
llama_model_loader: - type  f32:  289 tensors
llama_model_loader: - type  f16:   98 tensors
llama_model_loader: - type mxfp4:   72 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = F16
print_info: file size   = 12.83 GiB (5.27 BPW) 
load: 0 unused tokens
load: setting token '<|message|>' (200008) attribute to USER_DEFINED (16), old attributes: 8
load: setting token '<|start|>' (200006) attribute to USER_DEFINED (16), old attributes: 8
load: setting token '<|constrain|>' (200003) attribute to USER_DEFINED (16), old attributes: 8
load: setting token '<|channel|>' (200005) attribute to USER_DEFINED (16), old attributes: 8
load: printing all EOG tokens:
load:   - 199999 ('<|endoftext|>')
load:   - 200002 ('<|return|>')
load:   - 200007 ('<|end|>')
load:   - 200012 ('<|call|>')
load: special_eog_ids contains both '<|return|>' and '<|call|>', or '<|calls|>' and '<|flush|>' tokens, removing '<|end|>' token from EOG list
load: special tokens cache size = 21
load: token to piece cache size = 1.3332 MB
print_info: arch                  = gpt-oss
print_info: vocab_only            = 0
print_info: no_alloc              = 0
print_info: n_ctx_train           = 131072
print_info: n_embd                = 2880
print_info: n_embd_inp            = 2880
print_info: n_layer               = 24
print_info: n_head                = 64
print_info: n_head_kv             = 8
print_info: n_rot                 = 64
print_info: n_swa                 = 128
print_info: is_swa_any            = 1
print_info: n_embd_head_k         = 64
print_info: n_embd_head_v         = 64
print_info: n_gqa                 = 8
print_info: n_embd_k_gqa          = 512
print_info: n_embd_v_gqa          = 512
print_info: f_norm_eps            = 0.0e+00
print_info: f_norm_rms_eps        = 1.0e-05
print_info: f_clamp_kqv           = 0.0e+00
print_info: f_max_alibi_bias      = 0.0e+00
print_info: f_logit_scale         = 0.0e+00
print_info: f_attn_scale          = 0.0e+00
print_info: n_ff                  = 2880
print_info: n_expert              = 32
print_info: n_expert_used         = 4
print_info: n_expert_groups       = 0
print_info: n_group_used          = 0
print_info: causal attn           = 1
print_info: pooling type          = 0
print_info: rope type             = 2
print_info: rope scaling          = yarn
print_info: freq_base_train       = 150000.0
print_info: freq_scale_train      = 0.03125
print_info: freq_base_swa         = 150000.0
print_info: freq_scale_swa        = 0.03125
print_info: n_ctx_orig_yarn       = 4096
print_info: rope_yarn_log_mul     = 0.0000
print_info: rope_finetuned        = unknown
print_info: model type            = 20B
print_info: model params          = 20.91 B
print_info: general.name          = Gpt-Oss-20B
print_info: n_ff_exp              = 2880
print_info: vocab type            = BPE
print_info: n_vocab               = 201088
print_info: n_merges              = 446189
print_info: BOS token             = 199998 '<|startoftext|>'
print_info: EOS token             = 200002 '<|return|>'
print_info: EOT token             = 199999 '<|endoftext|>'
print_info: PAD token             = 200017 '<|reserved_200017|>'
print_info: LF token              = 198 'Ċ'
print_info: EOG token             = 199999 '<|endoftext|>'
print_info: EOG token             = 200002 '<|return|>'
print_info: EOG token             = 200012 '<|call|>'
print_info: max token length      = 256
load_tensors: loading model tensors, this can take a while... (mmap = false, direct_io = true)
srv  log_server_r: request: GET /health 127.0.0.1 503
load_tensors: offloading output layer to GPU
load_tensors: offloading 23 repeating layers to GPU
load_tensors: offloaded 25/25 layers to GPU
load_tensors:        CUDA0 model buffer size = 12036.68 MiB
load_tensors:    CUDA_Host model buffer size =  1104.61 MiB
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
srv  log_server_r: request: GET /health 127.0.0.1 503
srv  log_server_r: request: GET /health 127.0.0.1 503
srv  log_server_r: request: GET /health 127.0.0.1 503
srv  log_server_r: request: GET /health 127.0.0.1 503
.
common_init_result: added <|endoftext|> logit bias = -inf
common_init_result: added <|return|> logit bias = -inf
common_init_result: added <|call|> logit bias = -inf
llama_context: constructing llama_context
llama_context: n_seq_max     = 4
llama_context: n_ctx         = 56064
llama_context: n_ctx_seq     = 56064
llama_context: n_batch       = 2048
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = auto
llama_context: kv_unified    = true
llama_context: freq_base     = 150000.0
llama_context: freq_scale    = 0.03125
llama_context: n_ctx_seq (56064) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_context:  CUDA_Host  output buffer size =     3.07 MiB
llama_kv_cache_iswa: creating non-SWA KV cache, size = 56064 cells
llama_kv_cache:      CUDA0 KV buffer size =  1314.00 MiB
llama_kv_cache: size = 1314.00 MiB ( 56064 cells,  12 layers,  4/1 seqs), K (f16):  657.00 MiB, V (f16):  657.00 MiB
llama_kv_cache_iswa: creating     SWA KV cache, size = 1024 cells
llama_kv_cache:      CUDA0 KV buffer size =    24.00 MiB
llama_kv_cache: size =   24.00 MiB (  1024 cells,  12 layers,  4/1 seqs), K (f16):   12.00 MiB, V (f16):   12.00 MiB
sched_reserve: reserving ...
sched_reserve: Flash Attention was auto, set to enabled
sched_reserve:      CUDA0 compute buffer size =   398.38 MiB
sched_reserve:  CUDA_Host compute buffer size =   117.15 MiB
sched_reserve: graph nodes  = 1352
sched_reserve: graph splits = 2
sched_reserve: reserve took 58.76 ms, sched copies = 1
common_init_from_params: warming up the model with an empty run - please wait ... (--no-warmup to disable)
srv  log_server_r: request: GET /health 127.0.0.1 503
srv    load_model: initializing slots, n_slots = 4
slot   load_model: id  0 | task -1 | new slot, n_ctx = 56064
slot   load_model: id  1 | task -1 | new slot, n_ctx = 56064
slot   load_model: id  2 | task -1 | new slot, n_ctx = 56064
slot   load_model: id  3 | task -1 | new slot, n_ctx = 56064
srv    load_model: prompt cache is enabled, size limit: 8192 MiB
srv    load_model: use `--cache-ram 0` to disable the prompt cache
srv    load_model: for more info see https://github.com/ggml-org/llama.cpp/pull/16391
srv    load_model: thinking = 0
load_model: chat template, example_format: '<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2026-02-22

Reasoning: medium

# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions

You are a helpful assistant<|end|><|start|>user<|message|>Hello<|end|><|start|>assistant<|channel|>final<|message|>Hi there<|end|><|start|>user<|message|>How are you?<|end|><|start|>assistant'
main: model loaded
main: server is listening on http://127.0.0.1:8000
main: starting the main loop...
srv  update_slots: all slots are idle
srv  log_server_r: request: GET /health 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LRU, t_last = -1
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 0 | processing task, is_child = 0
slot update_slots: id  3 | task 0 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 921
slot update_slots: id  3 | task 0 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  3 | task 0 | prompt processing progress, n_tokens = 857, batch.n_tokens = 857, progress = 0.930510
slot update_slots: id  3 | task 0 | n_tokens = 857, memory_seq_rm [857, end)
slot update_slots: id  3 | task 0 | prompt processing progress, n_tokens = 921, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 0 | prompt done, n_tokens = 921, batch.n_tokens = 64
slot init_sampler: id  3 | task 0 | init sampler, took 0.13 ms, tokens: text = 921, total = 921
slot update_slots: id  3 | task 0 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 856, size = 20.096 MiB)
slot print_timing: id  3 | task 0 | 
prompt eval time =    1348.03 ms /   921 tokens (    1.46 ms per token,   683.22 tokens per second)
       eval time =    2447.63 ms /   105 tokens (   23.31 ms per token,    42.90 tokens per second)
      total time =    3795.66 ms /  1026 tokens
slot      release: id  3 | task 0 | stop processing: n_tokens = 1025, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.673 (> 0.100 thold), f_keep = 0.978
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 107 | processing task, is_child = 0
slot update_slots: id  3 | task 107 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1488
slot update_slots: id  3 | task 107 | n_tokens = 1002, memory_seq_rm [1002, end)
slot update_slots: id  3 | task 107 | prompt processing progress, n_tokens = 1424, batch.n_tokens = 422, progress = 0.956989
slot update_slots: id  3 | task 107 | n_tokens = 1424, memory_seq_rm [1424, end)
slot update_slots: id  3 | task 107 | prompt processing progress, n_tokens = 1488, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 107 | prompt done, n_tokens = 1488, batch.n_tokens = 64
slot init_sampler: id  3 | task 107 | init sampler, took 0.21 ms, tokens: text = 1488, total = 1488
slot update_slots: id  3 | task 107 | created context checkpoint 2 of 8 (pos_min = 422, pos_max = 1423, size = 23.496 MiB)
slot print_timing: id  3 | task 107 | 
prompt eval time =     551.06 ms /   486 tokens (    1.13 ms per token,   881.94 tokens per second)
       eval time =   11827.42 ms /   496 tokens (   23.85 ms per token,    41.94 tokens per second)
      total time =   12378.48 ms /   982 tokens
slot      release: id  3 | task 107 | stop processing: n_tokens = 1983, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.742 (> 0.100 thold), f_keep = 0.759
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 605 | processing task, is_child = 0
slot update_slots: id  3 | task 605 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2029
slot update_slots: id  3 | task 605 | n_tokens = 1505, memory_seq_rm [1505, end)
slot update_slots: id  3 | task 605 | prompt processing progress, n_tokens = 1965, batch.n_tokens = 460, progress = 0.968457
slot update_slots: id  3 | task 605 | n_tokens = 1965, memory_seq_rm [1965, end)
slot update_slots: id  3 | task 605 | prompt processing progress, n_tokens = 2029, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 605 | prompt done, n_tokens = 2029, batch.n_tokens = 64
slot init_sampler: id  3 | task 605 | init sampler, took 0.29 ms, tokens: text = 2029, total = 2029
slot update_slots: id  3 | task 605 | created context checkpoint 3 of 8 (pos_min = 981, pos_max = 1964, size = 23.074 MiB)
slot print_timing: id  3 | task 605 | 
prompt eval time =     627.63 ms /   524 tokens (    1.20 ms per token,   834.89 tokens per second)
       eval time =    1206.03 ms /    49 tokens (   24.61 ms per token,    40.63 tokens per second)
      total time =    1833.66 ms /   573 tokens
slot      release: id  3 | task 605 | stop processing: n_tokens = 2077, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.953 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 656 | processing task, is_child = 0
slot update_slots: id  3 | task 656 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2146
slot update_slots: id  3 | task 656 | n_tokens = 2046, memory_seq_rm [2046, end)
slot update_slots: id  3 | task 656 | prompt processing progress, n_tokens = 2082, batch.n_tokens = 36, progress = 0.970177
slot update_slots: id  3 | task 656 | n_tokens = 2082, memory_seq_rm [2082, end)
slot update_slots: id  3 | task 656 | prompt processing progress, n_tokens = 2146, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 656 | prompt done, n_tokens = 2146, batch.n_tokens = 64
slot init_sampler: id  3 | task 656 | init sampler, took 0.41 ms, tokens: text = 2146, total = 2146
slot update_slots: id  3 | task 656 | created context checkpoint 4 of 8 (pos_min = 1058, pos_max = 2081, size = 24.012 MiB)
slot print_timing: id  3 | task 656 | 
prompt eval time =     308.12 ms /   100 tokens (    3.08 ms per token,   324.55 tokens per second)
       eval time =   18429.61 ms /   737 tokens (   25.01 ms per token,    39.99 tokens per second)
      total time =   18737.72 ms /   837 tokens
slot      release: id  3 | task 656 | stop processing: n_tokens = 2882, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.378 (> 0.100 thold), f_keep = 0.320
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 2882, total state size = 91.592 MiB
srv          load:  - looking for better prompt, base f_keep = 0.320, sim = 0.378
srv        update:  - cache state: 1 prompts, 182.270 MiB (limits: 8192.000 MiB, 56064 tokens, 129529 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv  get_availabl: prompt cache update took 147.91 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1395 | processing task, is_child = 0
slot update_slots: id  3 | task 1395 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2435
slot update_slots: id  3 | task 1395 | n_past = 921, slot.prompt.tokens.size() = 2882, seq_id = 3, pos_min = 1858, n_swa = 128
slot update_slots: id  3 | task 1395 | restored context checkpoint (pos_min = 422, pos_max = 1423, size = 23.496 MiB)
slot update_slots: id  3 | task 1395 | erased invalidated context checkpoint (pos_min = 981, pos_max = 1964, n_swa = 128, size = 23.074 MiB)
slot update_slots: id  3 | task 1395 | erased invalidated context checkpoint (pos_min = 1058, pos_max = 2081, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 1395 | n_tokens = 921, memory_seq_rm [921, end)
slot update_slots: id  3 | task 1395 | prompt processing progress, n_tokens = 2371, batch.n_tokens = 1450, progress = 0.973717
slot update_slots: id  3 | task 1395 | n_tokens = 2371, memory_seq_rm [2371, end)
slot update_slots: id  3 | task 1395 | prompt processing progress, n_tokens = 2435, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 1395 | prompt done, n_tokens = 2435, batch.n_tokens = 64
slot init_sampler: id  3 | task 1395 | init sampler, took 0.37 ms, tokens: text = 2435, total = 2435
slot update_slots: id  3 | task 1395 | created context checkpoint 3 of 8 (pos_min = 1347, pos_max = 2370, size = 24.012 MiB)
slot print_timing: id  3 | task 1395 | 
prompt eval time =    1669.82 ms /  1514 tokens (    1.10 ms per token,   906.68 tokens per second)
       eval time =    3809.53 ms /   153 tokens (   24.90 ms per token,    40.16 tokens per second)
      total time =    5479.36 ms /  1667 tokens
slot      release: id  3 | task 1395 | stop processing: n_tokens = 2587, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.939 (> 0.100 thold), f_keep = 0.942
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1550 | processing task, is_child = 0
slot update_slots: id  3 | task 1550 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2593
slot update_slots: id  3 | task 1550 | n_tokens = 2436, memory_seq_rm [2436, end)
slot update_slots: id  3 | task 1550 | prompt processing progress, n_tokens = 2529, batch.n_tokens = 93, progress = 0.975318
slot update_slots: id  3 | task 1550 | n_tokens = 2529, memory_seq_rm [2529, end)
slot update_slots: id  3 | task 1550 | prompt processing progress, n_tokens = 2593, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 1550 | prompt done, n_tokens = 2593, batch.n_tokens = 64
slot init_sampler: id  3 | task 1550 | init sampler, took 0.59 ms, tokens: text = 2593, total = 2593
slot update_slots: id  3 | task 1550 | created context checkpoint 4 of 8 (pos_min = 1563, pos_max = 2528, size = 22.652 MiB)
slot print_timing: id  3 | task 1550 | 
prompt eval time =     515.72 ms /   157 tokens (    3.28 ms per token,   304.43 tokens per second)
       eval time =    3855.40 ms /   158 tokens (   24.40 ms per token,    40.98 tokens per second)
      total time =    4371.12 ms /   315 tokens
slot      release: id  3 | task 1550 | stop processing: n_tokens = 2750, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.591 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1710 | processing task, is_child = 0
slot update_slots: id  3 | task 1710 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 4595
slot update_slots: id  3 | task 1710 | n_tokens = 2716, memory_seq_rm [2716, end)
slot update_slots: id  3 | task 1710 | prompt processing progress, n_tokens = 4531, batch.n_tokens = 1815, progress = 0.986072
slot update_slots: id  3 | task 1710 | n_tokens = 4531, memory_seq_rm [4531, end)
slot update_slots: id  3 | task 1710 | prompt processing progress, n_tokens = 4595, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 1710 | prompt done, n_tokens = 4595, batch.n_tokens = 64
slot init_sampler: id  3 | task 1710 | init sampler, took 0.74 ms, tokens: text = 4595, total = 4595
slot update_slots: id  3 | task 1710 | created context checkpoint 5 of 8 (pos_min = 3507, pos_max = 4530, size = 24.012 MiB)
slot print_timing: id  3 | task 1710 | 
prompt eval time =    2046.15 ms /  1879 tokens (    1.09 ms per token,   918.31 tokens per second)
       eval time =    1094.75 ms /    44 tokens (   24.88 ms per token,    40.19 tokens per second)
      total time =    3140.90 ms /  1923 tokens
slot      release: id  3 | task 1710 | stop processing: n_tokens = 4638, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.922 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1756 | processing task, is_child = 0
slot update_slots: id  3 | task 1756 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 5000
slot update_slots: id  3 | task 1756 | n_tokens = 4610, memory_seq_rm [4610, end)
slot update_slots: id  3 | task 1756 | prompt processing progress, n_tokens = 4936, batch.n_tokens = 326, progress = 0.987200
slot update_slots: id  3 | task 1756 | n_tokens = 4936, memory_seq_rm [4936, end)
slot update_slots: id  3 | task 1756 | prompt processing progress, n_tokens = 5000, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 1756 | prompt done, n_tokens = 5000, batch.n_tokens = 64
slot init_sampler: id  3 | task 1756 | init sampler, took 0.84 ms, tokens: text = 5000, total = 5000
slot update_slots: id  3 | task 1756 | created context checkpoint 6 of 8 (pos_min = 3912, pos_max = 4935, size = 24.012 MiB)
slot print_timing: id  3 | task 1756 | 
prompt eval time =     561.23 ms /   390 tokens (    1.44 ms per token,   694.90 tokens per second)
       eval time =    1025.60 ms /    41 tokens (   25.01 ms per token,    39.98 tokens per second)
      total time =    1586.84 ms /   431 tokens
slot      release: id  3 | task 1756 | stop processing: n_tokens = 5040, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.639 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1799 | processing task, is_child = 0
slot update_slots: id  3 | task 1799 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 7839
slot update_slots: id  3 | task 1799 | n_tokens = 5010, memory_seq_rm [5010, end)
slot update_slots: id  3 | task 1799 | prompt processing progress, n_tokens = 7058, batch.n_tokens = 2048, progress = 0.900370
slot update_slots: id  3 | task 1799 | n_tokens = 7058, memory_seq_rm [7058, end)
slot update_slots: id  3 | task 1799 | prompt processing progress, n_tokens = 7775, batch.n_tokens = 717, progress = 0.991836
slot update_slots: id  3 | task 1799 | n_tokens = 7775, memory_seq_rm [7775, end)
slot update_slots: id  3 | task 1799 | prompt processing progress, n_tokens = 7839, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 1799 | prompt done, n_tokens = 7839, batch.n_tokens = 64
slot init_sampler: id  3 | task 1799 | init sampler, took 1.52 ms, tokens: text = 7839, total = 7839
slot update_slots: id  3 | task 1799 | created context checkpoint 7 of 8 (pos_min = 6751, pos_max = 7774, size = 24.012 MiB)
slot print_timing: id  3 | task 1799 | 
prompt eval time =    3237.71 ms /  2829 tokens (    1.14 ms per token,   873.77 tokens per second)
       eval time =   19910.77 ms /   750 tokens (   26.55 ms per token,    37.67 tokens per second)
      total time =   23148.48 ms /  3579 tokens
slot      release: id  3 | task 1799 | stop processing: n_tokens = 8588, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.962 (> 0.100 thold), f_keep = 0.967
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 2552 | processing task, is_child = 0
slot update_slots: id  3 | task 2552 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 8632
slot update_slots: id  3 | task 2552 | n_tokens = 8306, memory_seq_rm [8306, end)
slot update_slots: id  3 | task 2552 | prompt processing progress, n_tokens = 8568, batch.n_tokens = 262, progress = 0.992586
slot update_slots: id  3 | task 2552 | n_tokens = 8568, memory_seq_rm [8568, end)
slot update_slots: id  3 | task 2552 | prompt processing progress, n_tokens = 8632, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 2552 | prompt done, n_tokens = 8632, batch.n_tokens = 64
slot init_sampler: id  3 | task 2552 | init sampler, took 1.80 ms, tokens: text = 8632, total = 8632
slot update_slots: id  3 | task 2552 | created context checkpoint 8 of 8 (pos_min = 7564, pos_max = 8567, size = 23.543 MiB)
slot print_timing: id  3 | task 2552 | 
prompt eval time =     577.35 ms /   326 tokens (    1.77 ms per token,   564.65 tokens per second)
       eval time =    1411.24 ms /    53 tokens (   26.63 ms per token,    37.56 tokens per second)
      total time =    1988.59 ms /   379 tokens
slot      release: id  3 | task 2552 | stop processing: n_tokens = 8684, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 2607 | processing task, is_child = 0
slot update_slots: id  3 | task 2607 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 8737
slot update_slots: id  3 | task 2607 | n_tokens = 8654, memory_seq_rm [8654, end)
slot update_slots: id  3 | task 2607 | prompt processing progress, n_tokens = 8673, batch.n_tokens = 19, progress = 0.992675
slot update_slots: id  3 | task 2607 | n_tokens = 8673, memory_seq_rm [8673, end)
slot update_slots: id  3 | task 2607 | prompt processing progress, n_tokens = 8737, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 2607 | prompt done, n_tokens = 8737, batch.n_tokens = 64
slot init_sampler: id  3 | task 2607 | init sampler, took 1.25 ms, tokens: text = 8737, total = 8737
slot update_slots: id  3 | task 2607 | erasing old context checkpoint (pos_min = 0, pos_max = 856, size = 20.096 MiB)
slot update_slots: id  3 | task 2607 | created context checkpoint 8 of 8 (pos_min = 7660, pos_max = 8672, size = 23.754 MiB)
slot print_timing: id  3 | task 2607 | 
prompt eval time =     312.06 ms /    83 tokens (    3.76 ms per token,   265.97 tokens per second)
       eval time =    5492.79 ms /   202 tokens (   27.19 ms per token,    36.78 tokens per second)
      total time =    5804.85 ms /   285 tokens
slot      release: id  3 | task 2607 | stop processing: n_tokens = 8938, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.975 (> 0.100 thold), f_keep = 0.980
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 2811 | processing task, is_child = 0
slot update_slots: id  3 | task 2811 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 8985
slot update_slots: id  3 | task 2811 | n_tokens = 8757, memory_seq_rm [8757, end)
slot update_slots: id  3 | task 2811 | prompt processing progress, n_tokens = 8921, batch.n_tokens = 164, progress = 0.992877
slot update_slots: id  3 | task 2811 | n_tokens = 8921, memory_seq_rm [8921, end)
slot update_slots: id  3 | task 2811 | prompt processing progress, n_tokens = 8985, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 2811 | prompt done, n_tokens = 8985, batch.n_tokens = 64
slot init_sampler: id  3 | task 2811 | init sampler, took 1.36 ms, tokens: text = 8985, total = 8985
slot update_slots: id  3 | task 2811 | erasing old context checkpoint (pos_min = 422, pos_max = 1423, size = 23.496 MiB)
slot update_slots: id  3 | task 2811 | created context checkpoint 8 of 8 (pos_min = 7914, pos_max = 8920, size = 23.613 MiB)
slot print_timing: id  3 | task 2811 | 
prompt eval time =     518.23 ms /   228 tokens (    2.27 ms per token,   439.96 tokens per second)
       eval time =    2256.08 ms /    83 tokens (   27.18 ms per token,    36.79 tokens per second)
      total time =    2774.31 ms /   311 tokens
slot      release: id  3 | task 2811 | stop processing: n_tokens = 9067, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.961 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 2896 | processing task, is_child = 0
slot update_slots: id  3 | task 2896 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 9400
slot update_slots: id  3 | task 2896 | n_tokens = 9036, memory_seq_rm [9036, end)
slot update_slots: id  3 | task 2896 | prompt processing progress, n_tokens = 9336, batch.n_tokens = 300, progress = 0.993191
slot update_slots: id  3 | task 2896 | n_tokens = 9336, memory_seq_rm [9336, end)
slot update_slots: id  3 | task 2896 | prompt processing progress, n_tokens = 9400, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 2896 | prompt done, n_tokens = 9400, batch.n_tokens = 64
slot init_sampler: id  3 | task 2896 | init sampler, took 1.38 ms, tokens: text = 9400, total = 9400
slot update_slots: id  3 | task 2896 | erasing old context checkpoint (pos_min = 1347, pos_max = 2370, size = 24.012 MiB)
slot update_slots: id  3 | task 2896 | created context checkpoint 8 of 8 (pos_min = 8312, pos_max = 9335, size = 24.012 MiB)
slot print_timing: id  3 | task 2896 | 
prompt eval time =     628.74 ms /   364 tokens (    1.73 ms per token,   578.94 tokens per second)
       eval time =     685.71 ms /    24 tokens (   28.57 ms per token,    35.00 tokens per second)
      total time =    1314.45 ms /   388 tokens
slot      release: id  3 | task 2896 | stop processing: n_tokens = 9423, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 2922 | processing task, is_child = 0
slot update_slots: id  3 | task 2922 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 9474
slot update_slots: id  3 | task 2922 | n_tokens = 9414, memory_seq_rm [9414, end)
slot update_slots: id  3 | task 2922 | prompt processing progress, n_tokens = 9474, batch.n_tokens = 60, progress = 1.000000
slot update_slots: id  3 | task 2922 | prompt done, n_tokens = 9474, batch.n_tokens = 60
slot init_sampler: id  3 | task 2922 | init sampler, took 1.32 ms, tokens: text = 9474, total = 9474
slot update_slots: id  3 | task 2922 | erasing old context checkpoint (pos_min = 1563, pos_max = 2528, size = 22.652 MiB)
slot update_slots: id  3 | task 2922 | created context checkpoint 8 of 8 (pos_min = 8399, pos_max = 9413, size = 23.801 MiB)
slot print_timing: id  3 | task 2922 | 
prompt eval time =     206.77 ms /    60 tokens (    3.45 ms per token,   290.18 tokens per second)
       eval time =    7743.62 ms /   272 tokens (   28.47 ms per token,    35.13 tokens per second)
      total time =    7950.39 ms /   332 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 2922 | stop processing: n_tokens = 9745, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.981 (> 0.100 thold), f_keep = 0.090
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 9745, total state size = 252.522 MiB
srv          load:  - looking for better prompt, base f_keep = 0.090, sim = 0.981
srv        update:  - cache state: 2 prompts, 625.552 MiB (limits: 8192.000 MiB, 56064 tokens, 165358 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv  get_availabl: prompt cache update took 466.13 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3195 | processing task, is_child = 0
slot update_slots: id  3 | task 3195 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 898
slot update_slots: id  3 | task 3195 | n_past = 881, slot.prompt.tokens.size() = 9745, seq_id = 3, pos_min = 8721, n_swa = 128
slot update_slots: id  3 | task 3195 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  3 | task 3195 | erased invalidated context checkpoint (pos_min = 3507, pos_max = 4530, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 3195 | erased invalidated context checkpoint (pos_min = 3912, pos_max = 4935, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 3195 | erased invalidated context checkpoint (pos_min = 6751, pos_max = 7774, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 3195 | erased invalidated context checkpoint (pos_min = 7564, pos_max = 8567, n_swa = 128, size = 23.543 MiB)
slot update_slots: id  3 | task 3195 | erased invalidated context checkpoint (pos_min = 7660, pos_max = 8672, n_swa = 128, size = 23.754 MiB)
slot update_slots: id  3 | task 3195 | erased invalidated context checkpoint (pos_min = 7914, pos_max = 8920, n_swa = 128, size = 23.613 MiB)
slot update_slots: id  3 | task 3195 | erased invalidated context checkpoint (pos_min = 8312, pos_max = 9335, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 3195 | erased invalidated context checkpoint (pos_min = 8399, pos_max = 9413, n_swa = 128, size = 23.801 MiB)
slot update_slots: id  3 | task 3195 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  3 | task 3195 | prompt processing progress, n_tokens = 834, batch.n_tokens = 834, progress = 0.928730
slot update_slots: id  3 | task 3195 | n_tokens = 834, memory_seq_rm [834, end)
slot update_slots: id  3 | task 3195 | prompt processing progress, n_tokens = 898, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3195 | prompt done, n_tokens = 898, batch.n_tokens = 64
slot init_sampler: id  3 | task 3195 | init sampler, took 0.13 ms, tokens: text = 898, total = 898
slot update_slots: id  3 | task 3195 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 833, size = 19.557 MiB)
slot print_timing: id  3 | task 3195 | 
prompt eval time =    1121.51 ms /   898 tokens (    1.25 ms per token,   800.70 tokens per second)
       eval time =    2964.07 ms /   112 tokens (   26.46 ms per token,    37.79 tokens per second)
      total time =    4085.58 ms /  1010 tokens
slot      release: id  3 | task 3195 | stop processing: n_tokens = 1009, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.857 (> 0.100 thold), f_keep = 0.982
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3309 | processing task, is_child = 0
slot update_slots: id  3 | task 3309 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1156
slot update_slots: id  3 | task 3309 | n_tokens = 991, memory_seq_rm [991, end)
slot update_slots: id  3 | task 3309 | prompt processing progress, n_tokens = 1092, batch.n_tokens = 101, progress = 0.944637
slot update_slots: id  3 | task 3309 | n_tokens = 1092, memory_seq_rm [1092, end)
slot update_slots: id  3 | task 3309 | prompt processing progress, n_tokens = 1156, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3309 | prompt done, n_tokens = 1156, batch.n_tokens = 64
slot init_sampler: id  3 | task 3309 | init sampler, took 0.19 ms, tokens: text = 1156, total = 1156
slot update_slots: id  3 | task 3309 | created context checkpoint 2 of 8 (pos_min = 68, pos_max = 1091, size = 24.012 MiB)
slot print_timing: id  3 | task 3309 | 
prompt eval time =     434.35 ms /   165 tokens (    2.63 ms per token,   379.88 tokens per second)
       eval time =    2739.51 ms /   102 tokens (   26.86 ms per token,    37.23 tokens per second)
      total time =    3173.86 ms /   267 tokens
slot      release: id  3 | task 3309 | stop processing: n_tokens = 1257, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.876 (> 0.100 thold), f_keep = 0.979
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3413 | processing task, is_child = 0
slot update_slots: id  3 | task 3413 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1404
slot update_slots: id  3 | task 3413 | n_tokens = 1230, memory_seq_rm [1230, end)
slot update_slots: id  3 | task 3413 | prompt processing progress, n_tokens = 1340, batch.n_tokens = 110, progress = 0.954416
slot update_slots: id  3 | task 3413 | n_tokens = 1340, memory_seq_rm [1340, end)
slot update_slots: id  3 | task 3413 | prompt processing progress, n_tokens = 1404, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3413 | prompt done, n_tokens = 1404, batch.n_tokens = 64
slot init_sampler: id  3 | task 3413 | init sampler, took 0.23 ms, tokens: text = 1404, total = 1404
slot update_slots: id  3 | task 3413 | created context checkpoint 3 of 8 (pos_min = 316, pos_max = 1339, size = 24.012 MiB)
slot print_timing: id  3 | task 3413 | 
prompt eval time =     458.73 ms /   174 tokens (    2.64 ms per token,   379.31 tokens per second)
       eval time =    2731.53 ms /    99 tokens (   27.59 ms per token,    36.24 tokens per second)
      total time =    3190.26 ms /   273 tokens
slot      release: id  3 | task 3413 | stop processing: n_tokens = 1502, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.879 (> 0.100 thold), f_keep = 0.961
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3514 | processing task, is_child = 0
slot update_slots: id  3 | task 3514 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1642
slot update_slots: id  3 | task 3514 | n_tokens = 1443, memory_seq_rm [1443, end)
slot update_slots: id  3 | task 3514 | prompt processing progress, n_tokens = 1578, batch.n_tokens = 135, progress = 0.961023
slot update_slots: id  3 | task 3514 | n_tokens = 1578, memory_seq_rm [1578, end)
slot update_slots: id  3 | task 3514 | prompt processing progress, n_tokens = 1642, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3514 | prompt done, n_tokens = 1642, batch.n_tokens = 64
slot init_sampler: id  3 | task 3514 | init sampler, took 0.28 ms, tokens: text = 1642, total = 1642
slot update_slots: id  3 | task 3514 | created context checkpoint 4 of 8 (pos_min = 554, pos_max = 1577, size = 24.012 MiB)
slot print_timing: id  3 | task 3514 | 
prompt eval time =     478.88 ms /   199 tokens (    2.41 ms per token,   415.55 tokens per second)
       eval time =    1568.21 ms /    56 tokens (   28.00 ms per token,    35.71 tokens per second)
      total time =    2047.10 ms /   255 tokens
slot      release: id  3 | task 3514 | stop processing: n_tokens = 1697, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.906 (> 0.100 thold), f_keep = 0.984
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3572 | processing task, is_child = 0
slot update_slots: id  3 | task 3572 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1844
slot update_slots: id  3 | task 3572 | n_tokens = 1670, memory_seq_rm [1670, end)
slot update_slots: id  3 | task 3572 | prompt processing progress, n_tokens = 1780, batch.n_tokens = 110, progress = 0.965293
slot update_slots: id  3 | task 3572 | n_tokens = 1780, memory_seq_rm [1780, end)
slot update_slots: id  3 | task 3572 | prompt processing progress, n_tokens = 1844, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3572 | prompt done, n_tokens = 1844, batch.n_tokens = 64
slot init_sampler: id  3 | task 3572 | init sampler, took 0.29 ms, tokens: text = 1844, total = 1844
slot update_slots: id  3 | task 3572 | created context checkpoint 5 of 8 (pos_min = 756, pos_max = 1779, size = 24.012 MiB)
slot print_timing: id  3 | task 3572 | 
prompt eval time =     474.77 ms /   174 tokens (    2.73 ms per token,   366.50 tokens per second)
       eval time =    1236.65 ms /    43 tokens (   28.76 ms per token,    34.77 tokens per second)
      total time =    1711.42 ms /   217 tokens
slot      release: id  3 | task 3572 | stop processing: n_tokens = 1886, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.914 (> 0.100 thold), f_keep = 0.986
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3617 | processing task, is_child = 0
slot update_slots: id  3 | task 3617 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2033
slot update_slots: id  3 | task 3617 | n_tokens = 1859, memory_seq_rm [1859, end)
slot update_slots: id  3 | task 3617 | prompt processing progress, n_tokens = 1969, batch.n_tokens = 110, progress = 0.968519
slot update_slots: id  3 | task 3617 | n_tokens = 1969, memory_seq_rm [1969, end)
slot update_slots: id  3 | task 3617 | prompt processing progress, n_tokens = 2033, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3617 | prompt done, n_tokens = 2033, batch.n_tokens = 64
slot init_sampler: id  3 | task 3617 | init sampler, took 0.33 ms, tokens: text = 2033, total = 2033
slot update_slots: id  3 | task 3617 | created context checkpoint 6 of 8 (pos_min = 945, pos_max = 1968, size = 24.012 MiB)
slot print_timing: id  3 | task 3617 | 
prompt eval time =     464.40 ms /   174 tokens (    2.67 ms per token,   374.68 tokens per second)
       eval time =    1168.58 ms /    41 tokens (   28.50 ms per token,    35.09 tokens per second)
      total time =    1632.98 ms /   215 tokens
slot      release: id  3 | task 3617 | stop processing: n_tokens = 2073, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.922 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3660 | processing task, is_child = 0
slot update_slots: id  3 | task 3660 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2220
slot update_slots: id  3 | task 3660 | n_tokens = 2046, memory_seq_rm [2046, end)
slot update_slots: id  3 | task 3660 | prompt processing progress, n_tokens = 2156, batch.n_tokens = 110, progress = 0.971171
slot update_slots: id  3 | task 3660 | n_tokens = 2156, memory_seq_rm [2156, end)
slot update_slots: id  3 | task 3660 | prompt processing progress, n_tokens = 2220, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3660 | prompt done, n_tokens = 2220, batch.n_tokens = 64
slot init_sampler: id  3 | task 3660 | init sampler, took 0.46 ms, tokens: text = 2220, total = 2220
slot update_slots: id  3 | task 3660 | created context checkpoint 7 of 8 (pos_min = 1134, pos_max = 2155, size = 23.965 MiB)
slot print_timing: id  3 | task 3660 | 
prompt eval time =     481.45 ms /   174 tokens (    2.77 ms per token,   361.41 tokens per second)
       eval time =    1195.43 ms /    41 tokens (   29.16 ms per token,    34.30 tokens per second)
      total time =    1676.88 ms /   215 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 3660 | stop processing: n_tokens = 2260, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.928 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3703 | processing task, is_child = 0
slot update_slots: id  3 | task 3703 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2407
slot update_slots: id  3 | task 3703 | n_tokens = 2233, memory_seq_rm [2233, end)
slot update_slots: id  3 | task 3703 | prompt processing progress, n_tokens = 2343, batch.n_tokens = 110, progress = 0.973411
slot update_slots: id  3 | task 3703 | n_tokens = 2343, memory_seq_rm [2343, end)
slot update_slots: id  3 | task 3703 | prompt processing progress, n_tokens = 2407, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3703 | prompt done, n_tokens = 2407, batch.n_tokens = 64
slot init_sampler: id  3 | task 3703 | init sampler, took 0.53 ms, tokens: text = 2407, total = 2407
slot update_slots: id  3 | task 3703 | created context checkpoint 8 of 8 (pos_min = 1321, pos_max = 2342, size = 23.965 MiB)
slot print_timing: id  3 | task 3703 | 
prompt eval time =     472.16 ms /   174 tokens (    2.71 ms per token,   368.52 tokens per second)
       eval time =   10728.10 ms /   357 tokens (   30.05 ms per token,    33.28 tokens per second)
      total time =   11200.26 ms /   531 tokens
slot      release: id  3 | task 3703 | stop processing: n_tokens = 2763, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.374 (> 0.100 thold), f_keep = 0.325
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 2763, total state size = 88.755 MiB
srv          load:  - looking for better prompt, base f_keep = 0.325, sim = 0.374
srv        update:  - cache state: 3 prompts, 901.854 MiB (limits: 8192.000 MiB, 56064 tokens, 139795 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv  get_availabl: prompt cache update took 200.11 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4062 | processing task, is_child = 0
slot update_slots: id  3 | task 4062 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2403
slot update_slots: id  3 | task 4062 | n_past = 898, slot.prompt.tokens.size() = 2763, seq_id = 3, pos_min = 1741, n_swa = 128
slot update_slots: id  3 | task 4062 | restored context checkpoint (pos_min = 756, pos_max = 1779, size = 24.012 MiB)
slot update_slots: id  3 | task 4062 | erased invalidated context checkpoint (pos_min = 945, pos_max = 1968, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 4062 | erased invalidated context checkpoint (pos_min = 1134, pos_max = 2155, n_swa = 128, size = 23.965 MiB)
slot update_slots: id  3 | task 4062 | erased invalidated context checkpoint (pos_min = 1321, pos_max = 2342, n_swa = 128, size = 23.965 MiB)
slot update_slots: id  3 | task 4062 | n_tokens = 898, memory_seq_rm [898, end)
slot update_slots: id  3 | task 4062 | prompt processing progress, n_tokens = 2339, batch.n_tokens = 1441, progress = 0.973367
slot update_slots: id  3 | task 4062 | n_tokens = 2339, memory_seq_rm [2339, end)
slot update_slots: id  3 | task 4062 | prompt processing progress, n_tokens = 2403, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4062 | prompt done, n_tokens = 2403, batch.n_tokens = 64
slot init_sampler: id  3 | task 4062 | init sampler, took 0.36 ms, tokens: text = 2403, total = 2403
slot update_slots: id  3 | task 4062 | created context checkpoint 6 of 8 (pos_min = 1315, pos_max = 2338, size = 24.012 MiB)
slot print_timing: id  3 | task 4062 | 
prompt eval time =    1678.68 ms /  1505 tokens (    1.12 ms per token,   896.54 tokens per second)
       eval time =   12765.60 ms /   474 tokens (   26.93 ms per token,    37.13 tokens per second)
      total time =   14444.28 ms /  1979 tokens
slot      release: id  3 | task 4062 | stop processing: n_tokens = 2876, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.836
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4538 | processing task, is_child = 0
slot update_slots: id  3 | task 4538 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2435
slot update_slots: id  3 | task 4538 | n_tokens = 2404, memory_seq_rm [2404, end)
slot update_slots: id  3 | task 4538 | prompt processing progress, n_tokens = 2435, batch.n_tokens = 31, progress = 1.000000
slot update_slots: id  3 | task 4538 | prompt done, n_tokens = 2435, batch.n_tokens = 31
slot init_sampler: id  3 | task 4538 | init sampler, took 0.34 ms, tokens: text = 2435, total = 2435
slot update_slots: id  3 | task 4538 | created context checkpoint 7 of 8 (pos_min = 1852, pos_max = 2403, size = 12.944 MiB)
slot print_timing: id  3 | task 4538 | 
prompt eval time =     184.12 ms /    31 tokens (    5.94 ms per token,   168.37 tokens per second)
       eval time =    1610.42 ms /    57 tokens (   28.25 ms per token,    35.39 tokens per second)
      total time =    1794.54 ms /    88 tokens
slot      release: id  3 | task 4538 | stop processing: n_tokens = 2491, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.481 (> 0.100 thold), f_keep = 0.986
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4596 | processing task, is_child = 0
slot update_slots: id  3 | task 4596 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 5101
slot update_slots: id  3 | task 4596 | n_tokens = 2455, memory_seq_rm [2455, end)
slot update_slots: id  3 | task 4596 | prompt processing progress, n_tokens = 4503, batch.n_tokens = 2048, progress = 0.882768
slot update_slots: id  3 | task 4596 | n_tokens = 4503, memory_seq_rm [4503, end)
slot update_slots: id  3 | task 4596 | prompt processing progress, n_tokens = 5037, batch.n_tokens = 534, progress = 0.987453
slot update_slots: id  3 | task 4596 | n_tokens = 5037, memory_seq_rm [5037, end)
slot update_slots: id  3 | task 4596 | prompt processing progress, n_tokens = 5101, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4596 | prompt done, n_tokens = 5101, batch.n_tokens = 64
slot init_sampler: id  3 | task 4596 | init sampler, took 0.71 ms, tokens: text = 5101, total = 5101
slot update_slots: id  3 | task 4596 | created context checkpoint 8 of 8 (pos_min = 4013, pos_max = 5036, size = 24.012 MiB)
slot print_timing: id  3 | task 4596 | 
prompt eval time =    3140.13 ms /  2646 tokens (    1.19 ms per token,   842.64 tokens per second)
       eval time =     778.72 ms /    27 tokens (   28.84 ms per token,    34.67 tokens per second)
      total time =    3918.85 ms /  2673 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 4596 | stop processing: n_tokens = 5127, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.946 (> 0.100 thold), f_keep = 0.172
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 5127, total state size = 144.235 MiB
srv          load:  - looking for better prompt, base f_keep = 0.172, sim = 0.946
srv        update:  - cache state: 4 prompts, 1222.662 MiB (limits: 8192.000 MiB, 56064 tokens, 137466 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv        update:    - prompt 0x58dc3fb8c770:    5127 tokens, checkpoints:  8,   320.808 MiB
srv  get_availabl: prompt cache update took 226.07 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4626 | processing task, is_child = 0
slot update_slots: id  3 | task 4626 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 931
slot update_slots: id  3 | task 4626 | n_past = 881, slot.prompt.tokens.size() = 5127, seq_id = 3, pos_min = 4103, n_swa = 128
slot update_slots: id  3 | task 4626 | restored context checkpoint (pos_min = 554, pos_max = 1577, size = 24.012 MiB)
slot update_slots: id  3 | task 4626 | erased invalidated context checkpoint (pos_min = 756, pos_max = 1779, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 4626 | erased invalidated context checkpoint (pos_min = 1315, pos_max = 2338, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 4626 | erased invalidated context checkpoint (pos_min = 1852, pos_max = 2403, n_swa = 128, size = 12.944 MiB)
slot update_slots: id  3 | task 4626 | erased invalidated context checkpoint (pos_min = 4013, pos_max = 5036, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 4626 | n_tokens = 881, memory_seq_rm [881, end)
slot update_slots: id  3 | task 4626 | prompt processing progress, n_tokens = 931, batch.n_tokens = 50, progress = 1.000000
slot update_slots: id  3 | task 4626 | prompt done, n_tokens = 931, batch.n_tokens = 50
slot init_sampler: id  3 | task 4626 | init sampler, took 0.16 ms, tokens: text = 931, total = 931
slot print_timing: id  3 | task 4626 | 
prompt eval time =     264.31 ms /    50 tokens (    5.29 ms per token,   189.17 tokens per second)
       eval time =     967.31 ms /    41 tokens (   23.59 ms per token,    42.39 tokens per second)
      total time =    1231.62 ms /    91 tokens
slot      release: id  3 | task 4626 | stop processing: n_tokens = 971, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.641 (> 0.100 thold), f_keep = 0.977
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4668 | processing task, is_child = 0
slot update_slots: id  3 | task 4668 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1480
slot update_slots: id  3 | task 4668 | n_tokens = 949, memory_seq_rm [949, end)
slot update_slots: id  3 | task 4668 | prompt processing progress, n_tokens = 1416, batch.n_tokens = 467, progress = 0.956757
slot update_slots: id  3 | task 4668 | n_tokens = 1416, memory_seq_rm [1416, end)
slot update_slots: id  3 | task 4668 | prompt processing progress, n_tokens = 1480, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4668 | prompt done, n_tokens = 1480, batch.n_tokens = 64
slot init_sampler: id  3 | task 4668 | init sampler, took 0.40 ms, tokens: text = 1480, total = 1480
slot print_timing: id  3 | task 4668 | 
prompt eval time =     601.07 ms /   531 tokens (    1.13 ms per token,   883.43 tokens per second)
       eval time =    9524.93 ms /   393 tokens (   24.24 ms per token,    41.26 tokens per second)
      total time =   10126.00 ms /   924 tokens
slot      release: id  3 | task 4668 | stop processing: n_tokens = 1872, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.761 (> 0.100 thold), f_keep = 0.798
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5063 | processing task, is_child = 0
slot update_slots: id  3 | task 5063 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1961
slot update_slots: id  3 | task 5063 | n_tokens = 1493, memory_seq_rm [1493, end)
slot update_slots: id  3 | task 5063 | prompt processing progress, n_tokens = 1897, batch.n_tokens = 404, progress = 0.967364
slot update_slots: id  3 | task 5063 | n_tokens = 1897, memory_seq_rm [1897, end)
slot update_slots: id  3 | task 5063 | prompt processing progress, n_tokens = 1961, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5063 | prompt done, n_tokens = 1961, batch.n_tokens = 64
slot init_sampler: id  3 | task 5063 | init sampler, took 0.29 ms, tokens: text = 1961, total = 1961
slot update_slots: id  3 | task 5063 | created context checkpoint 5 of 8 (pos_min = 881, pos_max = 1896, size = 23.824 MiB)
slot print_timing: id  3 | task 5063 | 
prompt eval time =     586.92 ms /   468 tokens (    1.25 ms per token,   797.39 tokens per second)
       eval time =    1146.76 ms /    46 tokens (   24.93 ms per token,    40.11 tokens per second)
      total time =    1733.68 ms /   514 tokens
slot      release: id  3 | task 5063 | stop processing: n_tokens = 2006, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.512 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5111 | processing task, is_child = 0
slot update_slots: id  3 | task 5111 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 3854
slot update_slots: id  3 | task 5111 | n_tokens = 1975, memory_seq_rm [1975, end)
slot update_slots: id  3 | task 5111 | prompt processing progress, n_tokens = 3790, batch.n_tokens = 1815, progress = 0.983394
slot update_slots: id  3 | task 5111 | n_tokens = 3790, memory_seq_rm [3790, end)
slot update_slots: id  3 | task 5111 | prompt processing progress, n_tokens = 3854, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5111 | prompt done, n_tokens = 3854, batch.n_tokens = 64
slot init_sampler: id  3 | task 5111 | init sampler, took 0.54 ms, tokens: text = 3854, total = 3854
slot update_slots: id  3 | task 5111 | created context checkpoint 6 of 8 (pos_min = 2766, pos_max = 3789, size = 24.012 MiB)
slot print_timing: id  3 | task 5111 | 
prompt eval time =    2022.79 ms /  1879 tokens (    1.08 ms per token,   928.92 tokens per second)
       eval time =    1110.61 ms /    44 tokens (   25.24 ms per token,    39.62 tokens per second)
      total time =    3133.40 ms /  1923 tokens
slot      release: id  3 | task 5111 | stop processing: n_tokens = 3897, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.654 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5157 | processing task, is_child = 0
slot update_slots: id  3 | task 5157 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 5915
slot update_slots: id  3 | task 5157 | n_tokens = 3866, memory_seq_rm [3866, end)
slot update_slots: id  3 | task 5157 | prompt processing progress, n_tokens = 5851, batch.n_tokens = 1985, progress = 0.989180
slot update_slots: id  3 | task 5157 | n_tokens = 5851, memory_seq_rm [5851, end)
slot update_slots: id  3 | task 5157 | prompt processing progress, n_tokens = 5915, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5157 | prompt done, n_tokens = 5915, batch.n_tokens = 64
slot init_sampler: id  3 | task 5157 | init sampler, took 1.25 ms, tokens: text = 5915, total = 5915
slot update_slots: id  3 | task 5157 | created context checkpoint 7 of 8 (pos_min = 4827, pos_max = 5850, size = 24.012 MiB)
slot print_timing: id  3 | task 5157 | 
prompt eval time =    2246.09 ms /  2049 tokens (    1.10 ms per token,   912.25 tokens per second)
       eval time =    1002.06 ms /    40 tokens (   25.05 ms per token,    39.92 tokens per second)
      total time =    3248.15 ms /  2089 tokens
slot      release: id  3 | task 5157 | stop processing: n_tokens = 5954, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.957 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5199 | processing task, is_child = 0
slot update_slots: id  3 | task 5199 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 6191
slot update_slots: id  3 | task 5199 | n_tokens = 5923, memory_seq_rm [5923, end)
slot update_slots: id  3 | task 5199 | prompt processing progress, n_tokens = 6127, batch.n_tokens = 204, progress = 0.989662
slot update_slots: id  3 | task 5199 | n_tokens = 6127, memory_seq_rm [6127, end)
slot update_slots: id  3 | task 5199 | prompt processing progress, n_tokens = 6191, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5199 | prompt done, n_tokens = 6191, batch.n_tokens = 64
slot init_sampler: id  3 | task 5199 | init sampler, took 0.87 ms, tokens: text = 6191, total = 6191
slot update_slots: id  3 | task 5199 | created context checkpoint 8 of 8 (pos_min = 5103, pos_max = 6126, size = 24.012 MiB)
slot print_timing: id  3 | task 5199 | 
prompt eval time =     488.62 ms /   268 tokens (    1.82 ms per token,   548.48 tokens per second)
       eval time =    1267.67 ms /    50 tokens (   25.35 ms per token,    39.44 tokens per second)
      total time =    1756.29 ms /   318 tokens
slot      release: id  3 | task 5199 | stop processing: n_tokens = 6240, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.803 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5251 | processing task, is_child = 0
slot update_slots: id  3 | task 5251 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 7729
slot update_slots: id  3 | task 5251 | n_tokens = 6209, memory_seq_rm [6209, end)
slot update_slots: id  3 | task 5251 | prompt processing progress, n_tokens = 7665, batch.n_tokens = 1456, progress = 0.991719
slot update_slots: id  3 | task 5251 | n_tokens = 7665, memory_seq_rm [7665, end)
slot update_slots: id  3 | task 5251 | prompt processing progress, n_tokens = 7729, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5251 | prompt done, n_tokens = 7729, batch.n_tokens = 64
slot init_sampler: id  3 | task 5251 | init sampler, took 1.06 ms, tokens: text = 7729, total = 7729
slot update_slots: id  3 | task 5251 | erasing old context checkpoint (pos_min = 0, pos_max = 833, size = 19.557 MiB)
slot update_slots: id  3 | task 5251 | created context checkpoint 8 of 8 (pos_min = 6641, pos_max = 7664, size = 24.012 MiB)
slot print_timing: id  3 | task 5251 | 
prompt eval time =    1774.43 ms /  1520 tokens (    1.17 ms per token,   856.61 tokens per second)
       eval time =    1042.06 ms /    41 tokens (   25.42 ms per token,    39.35 tokens per second)
      total time =    2816.49 ms /  1561 tokens
slot      release: id  3 | task 5251 | stop processing: n_tokens = 7769, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.790 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5294 | processing task, is_child = 0
slot update_slots: id  3 | task 5294 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 9795
slot update_slots: id  3 | task 5294 | n_tokens = 7739, memory_seq_rm [7739, end)
slot update_slots: id  3 | task 5294 | prompt processing progress, n_tokens = 9731, batch.n_tokens = 1992, progress = 0.993466
slot update_slots: id  3 | task 5294 | n_tokens = 9731, memory_seq_rm [9731, end)
slot update_slots: id  3 | task 5294 | prompt processing progress, n_tokens = 9795, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5294 | prompt done, n_tokens = 9795, batch.n_tokens = 64
slot init_sampler: id  3 | task 5294 | init sampler, took 1.35 ms, tokens: text = 9795, total = 9795
slot update_slots: id  3 | task 5294 | erasing old context checkpoint (pos_min = 68, pos_max = 1091, size = 24.012 MiB)
slot update_slots: id  3 | task 5294 | created context checkpoint 8 of 8 (pos_min = 8707, pos_max = 9730, size = 24.012 MiB)
slot print_timing: id  3 | task 5294 | 
prompt eval time =    2440.68 ms /  2056 tokens (    1.19 ms per token,   842.39 tokens per second)
       eval time =    2701.13 ms /   102 tokens (   26.48 ms per token,    37.76 tokens per second)
      total time =    5141.81 ms /  2158 tokens
slot      release: id  3 | task 5294 | stop processing: n_tokens = 9896, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.800 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5398 | processing task, is_child = 0
slot update_slots: id  3 | task 5398 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 12332
slot update_slots: id  3 | task 5398 | n_tokens = 9866, memory_seq_rm [9866, end)
slot update_slots: id  3 | task 5398 | prompt processing progress, n_tokens = 11914, batch.n_tokens = 2048, progress = 0.966104
slot update_slots: id  3 | task 5398 | n_tokens = 11914, memory_seq_rm [11914, end)
slot update_slots: id  3 | task 5398 | prompt processing progress, n_tokens = 12268, batch.n_tokens = 354, progress = 0.994810
slot update_slots: id  3 | task 5398 | n_tokens = 12268, memory_seq_rm [12268, end)
slot update_slots: id  3 | task 5398 | prompt processing progress, n_tokens = 12332, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5398 | prompt done, n_tokens = 12332, batch.n_tokens = 64
slot init_sampler: id  3 | task 5398 | init sampler, took 1.72 ms, tokens: text = 12332, total = 12332
slot update_slots: id  3 | task 5398 | erasing old context checkpoint (pos_min = 316, pos_max = 1339, size = 24.012 MiB)
slot update_slots: id  3 | task 5398 | created context checkpoint 8 of 8 (pos_min = 11244, pos_max = 12267, size = 24.012 MiB)
slot print_timing: id  3 | task 5398 | 
prompt eval time =    3131.10 ms /  2466 tokens (    1.27 ms per token,   787.58 tokens per second)
       eval time =    1142.24 ms /    43 tokens (   26.56 ms per token,    37.65 tokens per second)
      total time =    4273.34 ms /  2509 tokens
slot      release: id  3 | task 5398 | stop processing: n_tokens = 12374, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5444 | processing task, is_child = 0
slot update_slots: id  3 | task 5444 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 12428
slot update_slots: id  3 | task 5444 | n_tokens = 12340, memory_seq_rm [12340, end)
slot update_slots: id  3 | task 5444 | prompt processing progress, n_tokens = 12364, batch.n_tokens = 24, progress = 0.994850
slot update_slots: id  3 | task 5444 | n_tokens = 12364, memory_seq_rm [12364, end)
slot update_slots: id  3 | task 5444 | prompt processing progress, n_tokens = 12428, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5444 | prompt done, n_tokens = 12428, batch.n_tokens = 64
slot init_sampler: id  3 | task 5444 | init sampler, took 2.03 ms, tokens: text = 12428, total = 12428
slot update_slots: id  3 | task 5444 | erasing old context checkpoint (pos_min = 554, pos_max = 1577, size = 24.012 MiB)
slot update_slots: id  3 | task 5444 | created context checkpoint 8 of 8 (pos_min = 11350, pos_max = 12363, size = 23.778 MiB)
slot print_timing: id  3 | task 5444 | 
prompt eval time =     303.66 ms /    88 tokens (    3.45 ms per token,   289.80 tokens per second)
       eval time =    1701.01 ms /    63 tokens (   27.00 ms per token,    37.04 tokens per second)
      total time =    2004.67 ms /   151 tokens
slot      release: id  3 | task 5444 | stop processing: n_tokens = 12490, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.964 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5509 | processing task, is_child = 0
slot update_slots: id  3 | task 5509 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 12928
slot update_slots: id  3 | task 5509 | n_tokens = 12461, memory_seq_rm [12461, end)
slot update_slots: id  3 | task 5509 | prompt processing progress, n_tokens = 12864, batch.n_tokens = 403, progress = 0.995049
slot update_slots: id  3 | task 5509 | n_tokens = 12864, memory_seq_rm [12864, end)
slot update_slots: id  3 | task 5509 | prompt processing progress, n_tokens = 12928, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5509 | prompt done, n_tokens = 12928, batch.n_tokens = 64
slot init_sampler: id  3 | task 5509 | init sampler, took 1.81 ms, tokens: text = 12928, total = 12928
slot update_slots: id  3 | task 5509 | erasing old context checkpoint (pos_min = 881, pos_max = 1896, size = 23.824 MiB)
slot update_slots: id  3 | task 5509 | created context checkpoint 8 of 8 (pos_min = 11840, pos_max = 12863, size = 24.012 MiB)
slot print_timing: id  3 | task 5509 | 
prompt eval time =     725.43 ms /   467 tokens (    1.55 ms per token,   643.75 tokens per second)
       eval time =    1073.38 ms /    40 tokens (   26.83 ms per token,    37.27 tokens per second)
      total time =    1798.81 ms /   507 tokens
slot      release: id  3 | task 5509 | stop processing: n_tokens = 12967, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.973 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5551 | processing task, is_child = 0
slot update_slots: id  3 | task 5551 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13299
slot update_slots: id  3 | task 5551 | n_tokens = 12937, memory_seq_rm [12937, end)
slot update_slots: id  3 | task 5551 | prompt processing progress, n_tokens = 13235, batch.n_tokens = 298, progress = 0.995188
slot update_slots: id  3 | task 5551 | n_tokens = 13235, memory_seq_rm [13235, end)
slot update_slots: id  3 | task 5551 | prompt processing progress, n_tokens = 13299, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5551 | prompt done, n_tokens = 13299, batch.n_tokens = 64
slot init_sampler: id  3 | task 5551 | init sampler, took 1.86 ms, tokens: text = 13299, total = 13299
slot update_slots: id  3 | task 5551 | erasing old context checkpoint (pos_min = 2766, pos_max = 3789, size = 24.012 MiB)
slot update_slots: id  3 | task 5551 | created context checkpoint 8 of 8 (pos_min = 12211, pos_max = 13234, size = 24.012 MiB)
slot print_timing: id  3 | task 5551 | 
prompt eval time =     642.13 ms /   362 tokens (    1.77 ms per token,   563.75 tokens per second)
       eval time =   13801.62 ms /   488 tokens (   28.28 ms per token,    35.36 tokens per second)
      total time =   14443.75 ms /   850 tokens
slot      release: id  3 | task 5551 | stop processing: n_tokens = 13786, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 6041 | processing task, is_child = 0
slot update_slots: id  3 | task 6041 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13843
slot update_slots: id  3 | task 6041 | n_tokens = 13727, memory_seq_rm [13727, end)
slot update_slots: id  3 | task 6041 | prompt processing progress, n_tokens = 13779, batch.n_tokens = 52, progress = 0.995377
slot update_slots: id  3 | task 6041 | n_tokens = 13779, memory_seq_rm [13779, end)
slot update_slots: id  3 | task 6041 | prompt processing progress, n_tokens = 13843, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 6041 | prompt done, n_tokens = 13843, batch.n_tokens = 64
slot init_sampler: id  3 | task 6041 | init sampler, took 1.91 ms, tokens: text = 13843, total = 13843
slot update_slots: id  3 | task 6041 | erasing old context checkpoint (pos_min = 4827, pos_max = 5850, size = 24.012 MiB)
slot update_slots: id  3 | task 6041 | created context checkpoint 8 of 8 (pos_min = 12762, pos_max = 13778, size = 23.848 MiB)
slot print_timing: id  3 | task 6041 | 
prompt eval time =     391.30 ms /   116 tokens (    3.37 ms per token,   296.45 tokens per second)
       eval time =    9397.49 ms /   311 tokens (   30.22 ms per token,    33.09 tokens per second)
      total time =    9788.78 ms /   427 tokens
slot      release: id  3 | task 6041 | stop processing: n_tokens = 14153, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 6354 | processing task, is_child = 0
slot update_slots: id  3 | task 6354 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 14281
slot update_slots: id  3 | task 6354 | n_tokens = 14090, memory_seq_rm [14090, end)
slot update_slots: id  3 | task 6354 | prompt processing progress, n_tokens = 14217, batch.n_tokens = 127, progress = 0.995519
slot update_slots: id  3 | task 6354 | n_tokens = 14217, memory_seq_rm [14217, end)
slot update_slots: id  3 | task 6354 | prompt processing progress, n_tokens = 14281, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 6354 | prompt done, n_tokens = 14281, batch.n_tokens = 64
slot init_sampler: id  3 | task 6354 | init sampler, took 1.98 ms, tokens: text = 14281, total = 14281
slot update_slots: id  3 | task 6354 | erasing old context checkpoint (pos_min = 5103, pos_max = 6126, size = 24.012 MiB)
slot update_slots: id  3 | task 6354 | created context checkpoint 8 of 8 (pos_min = 13193, pos_max = 14216, size = 24.012 MiB)
slot print_timing: id  3 | task 6354 | 
prompt eval time =     587.16 ms /   191 tokens (    3.07 ms per token,   325.29 tokens per second)
       eval time =   31298.63 ms /  1021 tokens (   30.65 ms per token,    32.62 tokens per second)
      total time =   31885.79 ms /  1212 tokens
slot      release: id  3 | task 6354 | stop processing: n_tokens = 15301, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 7377 | processing task, is_child = 0
slot update_slots: id  3 | task 7377 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 15376
slot update_slots: id  3 | task 7377 | n_tokens = 15248, memory_seq_rm [15248, end)
slot update_slots: id  3 | task 7377 | prompt processing progress, n_tokens = 15312, batch.n_tokens = 64, progress = 0.995838
slot update_slots: id  3 | task 7377 | n_tokens = 15312, memory_seq_rm [15312, end)
slot update_slots: id  3 | task 7377 | prompt processing progress, n_tokens = 15376, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 7377 | prompt done, n_tokens = 15376, batch.n_tokens = 64
slot init_sampler: id  3 | task 7377 | init sampler, took 2.11 ms, tokens: text = 15376, total = 15376
slot update_slots: id  3 | task 7377 | erasing old context checkpoint (pos_min = 6641, pos_max = 7664, size = 24.012 MiB)
slot update_slots: id  3 | task 7377 | created context checkpoint 8 of 8 (pos_min = 14288, pos_max = 15311, size = 24.012 MiB)
slot print_timing: id  3 | task 7377 | 
prompt eval time =     429.75 ms /   128 tokens (    3.36 ms per token,   297.84 tokens per second)
       eval time =    2228.83 ms /    77 tokens (   28.95 ms per token,    34.55 tokens per second)
      total time =    2658.58 ms /   205 tokens
slot      release: id  3 | task 7377 | stop processing: n_tokens = 15452, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 7456 | processing task, is_child = 0
slot update_slots: id  3 | task 7456 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 15626
slot update_slots: id  3 | task 7456 | n_tokens = 15393, memory_seq_rm [15393, end)
slot update_slots: id  3 | task 7456 | prompt processing progress, n_tokens = 15562, batch.n_tokens = 169, progress = 0.995904
slot update_slots: id  3 | task 7456 | n_tokens = 15562, memory_seq_rm [15562, end)
slot update_slots: id  3 | task 7456 | prompt processing progress, n_tokens = 15626, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 7456 | prompt done, n_tokens = 15626, batch.n_tokens = 64
slot init_sampler: id  3 | task 7456 | init sampler, took 2.15 ms, tokens: text = 15626, total = 15626
slot update_slots: id  3 | task 7456 | erasing old context checkpoint (pos_min = 8707, pos_max = 9730, size = 24.012 MiB)
slot update_slots: id  3 | task 7456 | created context checkpoint 8 of 8 (pos_min = 14538, pos_max = 15561, size = 24.012 MiB)
slot print_timing: id  3 | task 7456 | 
prompt eval time =     521.04 ms /   233 tokens (    2.24 ms per token,   447.18 tokens per second)
       eval time =   16600.22 ms /   586 tokens (   28.33 ms per token,    35.30 tokens per second)
      total time =   17121.26 ms /   819 tokens
slot      release: id  3 | task 7456 | stop processing: n_tokens = 16211, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.979 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8044 | processing task, is_child = 0
slot update_slots: id  3 | task 8044 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 16441
slot update_slots: id  3 | task 8044 | n_tokens = 16091, memory_seq_rm [16091, end)
slot update_slots: id  3 | task 8044 | prompt processing progress, n_tokens = 16377, batch.n_tokens = 286, progress = 0.996107
slot update_slots: id  3 | task 8044 | n_tokens = 16377, memory_seq_rm [16377, end)
slot update_slots: id  3 | task 8044 | prompt processing progress, n_tokens = 16441, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 8044 | prompt done, n_tokens = 16441, batch.n_tokens = 64
slot init_sampler: id  3 | task 8044 | init sampler, took 2.65 ms, tokens: text = 16441, total = 16441
slot update_slots: id  3 | task 8044 | erasing old context checkpoint (pos_min = 11244, pos_max = 12267, size = 24.012 MiB)
slot update_slots: id  3 | task 8044 | created context checkpoint 8 of 8 (pos_min = 15353, pos_max = 16376, size = 24.012 MiB)
slot print_timing: id  3 | task 8044 | 
prompt eval time =     649.41 ms /   350 tokens (    1.86 ms per token,   538.95 tokens per second)
       eval time =   17387.62 ms /   592 tokens (   29.37 ms per token,    34.05 tokens per second)
      total time =   18037.03 ms /   942 tokens
slot      release: id  3 | task 8044 | stop processing: n_tokens = 17032, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8638 | processing task, is_child = 0
slot update_slots: id  3 | task 8638 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 17076
slot update_slots: id  3 | task 8638 | n_tokens = 16973, memory_seq_rm [16973, end)
slot update_slots: id  3 | task 8638 | prompt processing progress, n_tokens = 17012, batch.n_tokens = 39, progress = 0.996252
slot update_slots: id  3 | task 8638 | n_tokens = 17012, memory_seq_rm [17012, end)
slot update_slots: id  3 | task 8638 | prompt processing progress, n_tokens = 17076, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 8638 | prompt done, n_tokens = 17076, batch.n_tokens = 64
slot init_sampler: id  3 | task 8638 | init sampler, took 2.38 ms, tokens: text = 17076, total = 17076
slot update_slots: id  3 | task 8638 | erasing old context checkpoint (pos_min = 11350, pos_max = 12363, size = 23.778 MiB)
slot update_slots: id  3 | task 8638 | created context checkpoint 8 of 8 (pos_min = 16008, pos_max = 17011, size = 23.543 MiB)
slot print_timing: id  3 | task 8638 | 
prompt eval time =     369.43 ms /   103 tokens (    3.59 ms per token,   278.81 tokens per second)
       eval time =   10956.56 ms /   362 tokens (   30.27 ms per token,    33.04 tokens per second)
      total time =   11325.99 ms /   465 tokens
slot      release: id  3 | task 8638 | stop processing: n_tokens = 17437, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9002 | processing task, is_child = 0
slot update_slots: id  3 | task 9002 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 17481
slot update_slots: id  3 | task 9002 | n_tokens = 17209, memory_seq_rm [17209, end)
slot update_slots: id  3 | task 9002 | prompt processing progress, n_tokens = 17417, batch.n_tokens = 208, progress = 0.996339
slot update_slots: id  3 | task 9002 | n_tokens = 17417, memory_seq_rm [17417, end)
slot update_slots: id  3 | task 9002 | prompt processing progress, n_tokens = 17481, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9002 | prompt done, n_tokens = 17481, batch.n_tokens = 64
slot init_sampler: id  3 | task 9002 | init sampler, took 2.39 ms, tokens: text = 17481, total = 17481
slot update_slots: id  3 | task 9002 | erasing old context checkpoint (pos_min = 11840, pos_max = 12863, size = 24.012 MiB)
slot update_slots: id  3 | task 9002 | created context checkpoint 8 of 8 (pos_min = 16449, pos_max = 17416, size = 22.699 MiB)
slot print_timing: id  3 | task 9002 | 
prompt eval time =     653.13 ms /   272 tokens (    2.40 ms per token,   416.46 tokens per second)
       eval time =    2489.50 ms /    82 tokens (   30.36 ms per token,    32.94 tokens per second)
      total time =    3142.63 ms /   354 tokens
slot      release: id  3 | task 9002 | stop processing: n_tokens = 17562, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.980 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9086 | processing task, is_child = 0
slot update_slots: id  3 | task 9086 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 17881
slot update_slots: id  3 | task 9086 | n_tokens = 17527, memory_seq_rm [17527, end)
slot update_slots: id  3 | task 9086 | prompt processing progress, n_tokens = 17817, batch.n_tokens = 290, progress = 0.996421
slot update_slots: id  3 | task 9086 | n_tokens = 17817, memory_seq_rm [17817, end)
slot update_slots: id  3 | task 9086 | prompt processing progress, n_tokens = 17881, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9086 | prompt done, n_tokens = 17881, batch.n_tokens = 64
slot init_sampler: id  3 | task 9086 | init sampler, took 3.53 ms, tokens: text = 17881, total = 17881
slot update_slots: id  3 | task 9086 | erasing old context checkpoint (pos_min = 12211, pos_max = 13234, size = 24.012 MiB)
slot update_slots: id  3 | task 9086 | created context checkpoint 8 of 8 (pos_min = 16849, pos_max = 17816, size = 22.699 MiB)
slot print_timing: id  3 | task 9086 | 
prompt eval time =     717.20 ms /   354 tokens (    2.03 ms per token,   493.59 tokens per second)
       eval time =   19854.25 ms /   655 tokens (   30.31 ms per token,    32.99 tokens per second)
      total time =   20571.44 ms /  1009 tokens
slot      release: id  3 | task 9086 | stop processing: n_tokens = 18535, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.964 (> 0.100 thold), f_keep = 0.967
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9743 | processing task, is_child = 0
slot update_slots: id  3 | task 9743 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 18590
slot update_slots: id  3 | task 9743 | n_tokens = 17923, memory_seq_rm [17923, end)
slot update_slots: id  3 | task 9743 | prompt processing progress, n_tokens = 18526, batch.n_tokens = 603, progress = 0.996557
slot update_slots: id  3 | task 9743 | n_tokens = 18526, memory_seq_rm [18526, end)
slot update_slots: id  3 | task 9743 | prompt processing progress, n_tokens = 18590, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9743 | prompt done, n_tokens = 18590, batch.n_tokens = 64
slot init_sampler: id  3 | task 9743 | init sampler, took 2.59 ms, tokens: text = 18590, total = 18590
slot update_slots: id  3 | task 9743 | erasing old context checkpoint (pos_min = 12762, pos_max = 13778, size = 23.848 MiB)
slot update_slots: id  3 | task 9743 | created context checkpoint 8 of 8 (pos_min = 17812, pos_max = 18525, size = 16.743 MiB)
slot print_timing: id  3 | task 9743 | 
prompt eval time =    1205.43 ms /   667 tokens (    1.81 ms per token,   553.33 tokens per second)
       eval time =    1645.56 ms /    55 tokens (   29.92 ms per token,    33.42 tokens per second)
      total time =    2850.99 ms /   722 tokens
slot      release: id  3 | task 9743 | stop processing: n_tokens = 18644, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.916 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9800 | processing task, is_child = 0
slot update_slots: id  3 | task 9800 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 20329
slot update_slots: id  3 | task 9800 | n_tokens = 18614, memory_seq_rm [18614, end)
slot update_slots: id  3 | task 9800 | prompt processing progress, n_tokens = 20265, batch.n_tokens = 1651, progress = 0.996852
slot update_slots: id  3 | task 9800 | n_tokens = 20265, memory_seq_rm [20265, end)
slot update_slots: id  3 | task 9800 | prompt processing progress, n_tokens = 20329, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9800 | prompt done, n_tokens = 20329, batch.n_tokens = 64
slot init_sampler: id  3 | task 9800 | init sampler, took 3.89 ms, tokens: text = 20329, total = 20329
slot update_slots: id  3 | task 9800 | erasing old context checkpoint (pos_min = 13193, pos_max = 14216, size = 24.012 MiB)
slot update_slots: id  3 | task 9800 | created context checkpoint 8 of 8 (pos_min = 19241, pos_max = 20264, size = 24.012 MiB)
slot print_timing: id  3 | task 9800 | 
prompt eval time =    2787.19 ms /  1715 tokens (    1.63 ms per token,   615.32 tokens per second)
       eval time =    1235.56 ms /    41 tokens (   30.14 ms per token,    33.18 tokens per second)
      total time =    4022.75 ms /  1756 tokens
slot      release: id  3 | task 9800 | stop processing: n_tokens = 20369, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.927 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9843 | processing task, is_child = 0
slot update_slots: id  3 | task 9843 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 21952
slot update_slots: id  3 | task 9843 | n_tokens = 20339, memory_seq_rm [20339, end)
slot update_slots: id  3 | task 9843 | prompt processing progress, n_tokens = 21888, batch.n_tokens = 1549, progress = 0.997085
slot update_slots: id  3 | task 9843 | n_tokens = 21888, memory_seq_rm [21888, end)
slot update_slots: id  3 | task 9843 | prompt processing progress, n_tokens = 21952, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9843 | prompt done, n_tokens = 21952, batch.n_tokens = 64
slot init_sampler: id  3 | task 9843 | init sampler, took 3.03 ms, tokens: text = 21952, total = 21952
slot update_slots: id  3 | task 9843 | erasing old context checkpoint (pos_min = 14288, pos_max = 15311, size = 24.012 MiB)
slot update_slots: id  3 | task 9843 | created context checkpoint 8 of 8 (pos_min = 20864, pos_max = 21887, size = 24.012 MiB)
slot print_timing: id  3 | task 9843 | 
prompt eval time =    2593.21 ms /  1613 tokens (    1.61 ms per token,   622.01 tokens per second)
       eval time =   10141.18 ms /   335 tokens (   30.27 ms per token,    33.03 tokens per second)
      total time =   12734.39 ms /  1948 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 9843 | stop processing: n_tokens = 22286, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10180 | processing task, is_child = 0
slot update_slots: id  3 | task 10180 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 22330
slot update_slots: id  3 | task 10180 | n_tokens = 22173, memory_seq_rm [22173, end)
slot update_slots: id  3 | task 10180 | prompt processing progress, n_tokens = 22266, batch.n_tokens = 93, progress = 0.997134
slot update_slots: id  3 | task 10180 | n_tokens = 22266, memory_seq_rm [22266, end)
slot update_slots: id  3 | task 10180 | prompt processing progress, n_tokens = 22330, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 10180 | prompt done, n_tokens = 22330, batch.n_tokens = 64
slot init_sampler: id  3 | task 10180 | init sampler, took 3.06 ms, tokens: text = 22330, total = 22330
slot update_slots: id  3 | task 10180 | erasing old context checkpoint (pos_min = 14538, pos_max = 15561, size = 24.012 MiB)
slot update_slots: id  3 | task 10180 | created context checkpoint 8 of 8 (pos_min = 21262, pos_max = 22265, size = 23.543 MiB)
slot print_timing: id  3 | task 10180 | 
prompt eval time =     515.31 ms /   157 tokens (    3.28 ms per token,   304.67 tokens per second)
       eval time =    3739.71 ms /   124 tokens (   30.16 ms per token,    33.16 tokens per second)
      total time =    4255.02 ms /   281 tokens
slot      release: id  3 | task 10180 | stop processing: n_tokens = 22453, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10306 | processing task, is_child = 0
slot update_slots: id  3 | task 10306 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 22493
slot update_slots: id  3 | task 10306 | n_tokens = 22340, memory_seq_rm [22340, end)
slot update_slots: id  3 | task 10306 | prompt processing progress, n_tokens = 22429, batch.n_tokens = 89, progress = 0.997155
slot update_slots: id  3 | task 10306 | n_tokens = 22429, memory_seq_rm [22429, end)
slot update_slots: id  3 | task 10306 | prompt processing progress, n_tokens = 22493, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 10306 | prompt done, n_tokens = 22493, batch.n_tokens = 64
slot init_sampler: id  3 | task 10306 | init sampler, took 3.08 ms, tokens: text = 22493, total = 22493
slot update_slots: id  3 | task 10306 | erasing old context checkpoint (pos_min = 15353, pos_max = 16376, size = 24.012 MiB)
slot update_slots: id  3 | task 10306 | created context checkpoint 8 of 8 (pos_min = 21429, pos_max = 22428, size = 23.449 MiB)
slot print_timing: id  3 | task 10306 | 
prompt eval time =     504.46 ms /   153 tokens (    3.30 ms per token,   303.29 tokens per second)
       eval time =    3674.87 ms /   122 tokens (   30.12 ms per token,    33.20 tokens per second)
      total time =    4179.34 ms /   275 tokens
slot      release: id  3 | task 10306 | stop processing: n_tokens = 22614, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10430 | processing task, is_child = 0
slot update_slots: id  3 | task 10430 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 22658
slot update_slots: id  3 | task 10430 | n_tokens = 22505, memory_seq_rm [22505, end)
slot update_slots: id  3 | task 10430 | prompt processing progress, n_tokens = 22594, batch.n_tokens = 89, progress = 0.997175
slot update_slots: id  3 | task 10430 | n_tokens = 22594, memory_seq_rm [22594, end)
slot update_slots: id  3 | task 10430 | prompt processing progress, n_tokens = 22658, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 10430 | prompt done, n_tokens = 22658, batch.n_tokens = 64
slot init_sampler: id  3 | task 10430 | init sampler, took 4.27 ms, tokens: text = 22658, total = 22658
slot update_slots: id  3 | task 10430 | erasing old context checkpoint (pos_min = 16008, pos_max = 17011, size = 23.543 MiB)
slot update_slots: id  3 | task 10430 | created context checkpoint 8 of 8 (pos_min = 21590, pos_max = 22593, size = 23.543 MiB)
slot print_timing: id  3 | task 10430 | 
prompt eval time =     498.25 ms /   153 tokens (    3.26 ms per token,   307.08 tokens per second)
       eval time =    3714.16 ms /   122 tokens (   30.44 ms per token,    32.85 tokens per second)
      total time =    4212.41 ms /   275 tokens
slot      release: id  3 | task 10430 | stop processing: n_tokens = 22779, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10554 | processing task, is_child = 0
slot update_slots: id  3 | task 10554 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 22823
slot update_slots: id  3 | task 10554 | n_tokens = 22670, memory_seq_rm [22670, end)
slot update_slots: id  3 | task 10554 | prompt processing progress, n_tokens = 22759, batch.n_tokens = 89, progress = 0.997196
slot update_slots: id  3 | task 10554 | n_tokens = 22759, memory_seq_rm [22759, end)
slot update_slots: id  3 | task 10554 | prompt processing progress, n_tokens = 22823, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 10554 | prompt done, n_tokens = 22823, batch.n_tokens = 64
slot init_sampler: id  3 | task 10554 | init sampler, took 3.13 ms, tokens: text = 22823, total = 22823
slot update_slots: id  3 | task 10554 | erasing old context checkpoint (pos_min = 16449, pos_max = 17416, size = 22.699 MiB)
slot update_slots: id  3 | task 10554 | created context checkpoint 8 of 8 (pos_min = 21755, pos_max = 22758, size = 23.543 MiB)
slot print_timing: id  3 | task 10554 | 
prompt eval time =     498.72 ms /   153 tokens (    3.26 ms per token,   306.78 tokens per second)
       eval time =    3655.55 ms /   121 tokens (   30.21 ms per token,    33.10 tokens per second)
      total time =    4154.27 ms /   274 tokens
slot      release: id  3 | task 10554 | stop processing: n_tokens = 22943, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10677 | processing task, is_child = 0
slot update_slots: id  3 | task 10677 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 22983
slot update_slots: id  3 | task 10677 | n_tokens = 22834, memory_seq_rm [22834, end)
slot update_slots: id  3 | task 10677 | prompt processing progress, n_tokens = 22919, batch.n_tokens = 85, progress = 0.997215
slot update_slots: id  3 | task 10677 | n_tokens = 22919, memory_seq_rm [22919, end)
slot update_slots: id  3 | task 10677 | prompt processing progress, n_tokens = 22983, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 10677 | prompt done, n_tokens = 22983, batch.n_tokens = 64
slot init_sampler: id  3 | task 10677 | init sampler, took 3.14 ms, tokens: text = 22983, total = 22983
slot update_slots: id  3 | task 10677 | erasing old context checkpoint (pos_min = 16849, pos_max = 17816, size = 22.699 MiB)
slot update_slots: id  3 | task 10677 | created context checkpoint 8 of 8 (pos_min = 21919, pos_max = 22918, size = 23.449 MiB)
slot print_timing: id  3 | task 10677 | 
prompt eval time =     540.93 ms /   149 tokens (    3.63 ms per token,   275.45 tokens per second)
       eval time =    1862.70 ms /    62 tokens (   30.04 ms per token,    33.28 tokens per second)
      total time =    2403.63 ms /   211 tokens
slot      release: id  3 | task 10677 | stop processing: n_tokens = 23044, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10741 | processing task, is_child = 0
slot update_slots: id  3 | task 10741 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 23366
slot update_slots: id  3 | task 10741 | n_tokens = 22992, memory_seq_rm [22992, end)
slot update_slots: id  3 | task 10741 | prompt processing progress, n_tokens = 23302, batch.n_tokens = 310, progress = 0.997261
slot update_slots: id  3 | task 10741 | n_tokens = 23302, memory_seq_rm [23302, end)
slot update_slots: id  3 | task 10741 | prompt processing progress, n_tokens = 23366, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 10741 | prompt done, n_tokens = 23366, batch.n_tokens = 64
slot init_sampler: id  3 | task 10741 | init sampler, took 3.19 ms, tokens: text = 23366, total = 23366
slot update_slots: id  3 | task 10741 | erasing old context checkpoint (pos_min = 17812, pos_max = 18525, size = 16.743 MiB)
slot update_slots: id  3 | task 10741 | created context checkpoint 8 of 8 (pos_min = 22329, pos_max = 23301, size = 22.816 MiB)
slot print_timing: id  3 | task 10741 | 
prompt eval time =     772.10 ms /   374 tokens (    2.06 ms per token,   484.40 tokens per second)
       eval time =    4808.80 ms /   158 tokens (   30.44 ms per token,    32.86 tokens per second)
      total time =    5580.89 ms /   532 tokens
slot      release: id  3 | task 10741 | stop processing: n_tokens = 23523, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10901 | processing task, is_child = 0
slot update_slots: id  3 | task 10901 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 23563
slot update_slots: id  3 | task 10901 | n_tokens = 23410, memory_seq_rm [23410, end)
slot update_slots: id  3 | task 10901 | prompt processing progress, n_tokens = 23499, batch.n_tokens = 89, progress = 0.997284
slot update_slots: id  3 | task 10901 | n_tokens = 23499, memory_seq_rm [23499, end)
slot update_slots: id  3 | task 10901 | prompt processing progress, n_tokens = 23563, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 10901 | prompt done, n_tokens = 23563, batch.n_tokens = 64
slot init_sampler: id  3 | task 10901 | init sampler, took 3.26 ms, tokens: text = 23563, total = 23563
slot update_slots: id  3 | task 10901 | erasing old context checkpoint (pos_min = 19241, pos_max = 20264, size = 24.012 MiB)
slot update_slots: id  3 | task 10901 | created context checkpoint 8 of 8 (pos_min = 22550, pos_max = 23498, size = 22.253 MiB)
slot print_timing: id  3 | task 10901 | 
prompt eval time =     521.84 ms /   153 tokens (    3.41 ms per token,   293.19 tokens per second)
       eval time =    3606.01 ms /   120 tokens (   30.05 ms per token,    33.28 tokens per second)
      total time =    4127.85 ms /   273 tokens
slot      release: id  3 | task 10901 | stop processing: n_tokens = 23682, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11023 | processing task, is_child = 0
slot update_slots: id  3 | task 11023 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 23726
slot update_slots: id  3 | task 11023 | n_tokens = 23573, memory_seq_rm [23573, end)
slot update_slots: id  3 | task 11023 | prompt processing progress, n_tokens = 23662, batch.n_tokens = 89, progress = 0.997303
slot update_slots: id  3 | task 11023 | n_tokens = 23662, memory_seq_rm [23662, end)
slot update_slots: id  3 | task 11023 | prompt processing progress, n_tokens = 23726, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11023 | prompt done, n_tokens = 23726, batch.n_tokens = 64
slot init_sampler: id  3 | task 11023 | init sampler, took 3.28 ms, tokens: text = 23726, total = 23726
slot update_slots: id  3 | task 11023 | erasing old context checkpoint (pos_min = 20864, pos_max = 21887, size = 24.012 MiB)
slot update_slots: id  3 | task 11023 | created context checkpoint 8 of 8 (pos_min = 22709, pos_max = 23661, size = 22.347 MiB)
slot print_timing: id  3 | task 11023 | 
prompt eval time =     513.29 ms /   153 tokens (    3.35 ms per token,   298.08 tokens per second)
       eval time =    3736.94 ms /   124 tokens (   30.14 ms per token,    33.18 tokens per second)
      total time =    4250.23 ms /   277 tokens
slot      release: id  3 | task 11023 | stop processing: n_tokens = 23849, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11149 | processing task, is_child = 0
slot update_slots: id  3 | task 11149 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 23889
slot update_slots: id  3 | task 11149 | n_tokens = 23736, memory_seq_rm [23736, end)
slot update_slots: id  3 | task 11149 | prompt processing progress, n_tokens = 23825, batch.n_tokens = 89, progress = 0.997321
slot update_slots: id  3 | task 11149 | n_tokens = 23825, memory_seq_rm [23825, end)
slot update_slots: id  3 | task 11149 | prompt processing progress, n_tokens = 23889, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11149 | prompt done, n_tokens = 23889, batch.n_tokens = 64
slot init_sampler: id  3 | task 11149 | init sampler, took 4.75 ms, tokens: text = 23889, total = 23889
slot update_slots: id  3 | task 11149 | erasing old context checkpoint (pos_min = 21262, pos_max = 22265, size = 23.543 MiB)
slot update_slots: id  3 | task 11149 | created context checkpoint 8 of 8 (pos_min = 22876, pos_max = 23824, size = 22.253 MiB)
slot print_timing: id  3 | task 11149 | 
prompt eval time =     520.48 ms /   153 tokens (    3.40 ms per token,   293.96 tokens per second)
       eval time =    3777.38 ms /   125 tokens (   30.22 ms per token,    33.09 tokens per second)
      total time =    4297.87 ms /   278 tokens
slot      release: id  3 | task 11149 | stop processing: n_tokens = 24013, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 1.000
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11276 | processing task, is_child = 0
slot update_slots: id  3 | task 11276 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 24064
slot update_slots: id  3 | task 11276 | n_tokens = 24004, memory_seq_rm [24004, end)
slot update_slots: id  3 | task 11276 | prompt processing progress, n_tokens = 24064, batch.n_tokens = 60, progress = 1.000000
slot update_slots: id  3 | task 11276 | prompt done, n_tokens = 24064, batch.n_tokens = 60
slot init_sampler: id  3 | task 11276 | init sampler, took 3.32 ms, tokens: text = 24064, total = 24064
slot update_slots: id  3 | task 11276 | erasing old context checkpoint (pos_min = 21429, pos_max = 22428, size = 23.449 MiB)
slot update_slots: id  3 | task 11276 | created context checkpoint 8 of 8 (pos_min = 22992, pos_max = 24003, size = 23.731 MiB)
slot print_timing: id  3 | task 11276 | 
prompt eval time =     223.45 ms /    60 tokens (    3.72 ms per token,   268.52 tokens per second)
       eval time =    2408.84 ms /    80 tokens (   30.11 ms per token,    33.21 tokens per second)
      total time =    2632.28 ms /   140 tokens
slot      release: id  3 | task 11276 | stop processing: n_tokens = 24143, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11357 | processing task, is_child = 0
slot update_slots: id  3 | task 11357 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 24285
slot update_slots: id  3 | task 11357 | n_tokens = 24091, memory_seq_rm [24091, end)
slot update_slots: id  3 | task 11357 | prompt processing progress, n_tokens = 24221, batch.n_tokens = 130, progress = 0.997365
slot update_slots: id  3 | task 11357 | n_tokens = 24221, memory_seq_rm [24221, end)
slot update_slots: id  3 | task 11357 | prompt processing progress, n_tokens = 24285, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11357 | prompt done, n_tokens = 24285, batch.n_tokens = 64
slot init_sampler: id  3 | task 11357 | init sampler, took 3.37 ms, tokens: text = 24285, total = 24285
slot update_slots: id  3 | task 11357 | erasing old context checkpoint (pos_min = 21590, pos_max = 22593, size = 23.543 MiB)
slot update_slots: id  3 | task 11357 | created context checkpoint 8 of 8 (pos_min = 23197, pos_max = 24220, size = 24.012 MiB)
slot print_timing: id  3 | task 11357 | 
prompt eval time =     569.75 ms /   194 tokens (    2.94 ms per token,   340.50 tokens per second)
       eval time =    5233.83 ms /   174 tokens (   30.08 ms per token,    33.25 tokens per second)
      total time =    5803.58 ms /   368 tokens
slot      release: id  3 | task 11357 | stop processing: n_tokens = 24458, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11533 | processing task, is_child = 0
slot update_slots: id  3 | task 11533 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 24625
slot update_slots: id  3 | task 11533 | n_tokens = 24399, memory_seq_rm [24399, end)
slot update_slots: id  3 | task 11533 | prompt processing progress, n_tokens = 24561, batch.n_tokens = 162, progress = 0.997401
slot update_slots: id  3 | task 11533 | n_tokens = 24561, memory_seq_rm [24561, end)
slot update_slots: id  3 | task 11533 | prompt processing progress, n_tokens = 24625, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11533 | prompt done, n_tokens = 24625, batch.n_tokens = 64
slot init_sampler: id  3 | task 11533 | init sampler, took 3.36 ms, tokens: text = 24625, total = 24625
slot update_slots: id  3 | task 11533 | erasing old context checkpoint (pos_min = 21755, pos_max = 22758, size = 23.543 MiB)
slot update_slots: id  3 | task 11533 | created context checkpoint 8 of 8 (pos_min = 23537, pos_max = 24560, size = 24.012 MiB)
slot print_timing: id  3 | task 11533 | 
prompt eval time =     583.67 ms /   226 tokens (    2.58 ms per token,   387.21 tokens per second)
       eval time =    4103.54 ms /   136 tokens (   30.17 ms per token,    33.14 tokens per second)
      total time =    4687.21 ms /   362 tokens
slot      release: id  3 | task 11533 | stop processing: n_tokens = 24760, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11671 | processing task, is_child = 0
slot update_slots: id  3 | task 11671 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 24797
slot update_slots: id  3 | task 11671 | n_tokens = 24722, memory_seq_rm [24722, end)
slot update_slots: id  3 | task 11671 | prompt processing progress, n_tokens = 24733, batch.n_tokens = 11, progress = 0.997419
slot update_slots: id  3 | task 11671 | n_tokens = 24733, memory_seq_rm [24733, end)
slot update_slots: id  3 | task 11671 | prompt processing progress, n_tokens = 24797, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11671 | prompt done, n_tokens = 24797, batch.n_tokens = 64
slot init_sampler: id  3 | task 11671 | init sampler, took 3.39 ms, tokens: text = 24797, total = 24797
slot update_slots: id  3 | task 11671 | erasing old context checkpoint (pos_min = 21919, pos_max = 22918, size = 23.449 MiB)
slot update_slots: id  3 | task 11671 | created context checkpoint 8 of 8 (pos_min = 23736, pos_max = 24732, size = 23.379 MiB)
slot print_timing: id  3 | task 11671 | 
prompt eval time =     322.22 ms /    75 tokens (    4.30 ms per token,   232.76 tokens per second)
       eval time =    2064.45 ms /    69 tokens (   29.92 ms per token,    33.42 tokens per second)
      total time =    2386.67 ms /   144 tokens
slot      release: id  3 | task 11671 | stop processing: n_tokens = 24865, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.035
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 24865, total state size = 607.070 MiB
srv          load:  - looking for better prompt, base f_keep = 0.035, sim = 0.984
srv        update:  - cache state: 5 prompts, 2014.536 MiB (limits: 8192.000 MiB, 56064 tokens, 184543 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv        update:    - prompt 0x58dc3fb8c770:    5127 tokens, checkpoints:  8,   320.808 MiB
srv        update:    - prompt 0x58dc3f318830:   24865 tokens, checkpoints:  8,   791.874 MiB
srv  get_availabl: prompt cache update took 632.17 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11742 | processing task, is_child = 0
slot update_slots: id  3 | task 11742 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 895
slot update_slots: id  3 | task 11742 | n_past = 881, slot.prompt.tokens.size() = 24865, seq_id = 3, pos_min = 23841, n_swa = 128
slot update_slots: id  3 | task 11742 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  3 | task 11742 | erased invalidated context checkpoint (pos_min = 22329, pos_max = 23301, n_swa = 128, size = 22.816 MiB)
slot update_slots: id  3 | task 11742 | erased invalidated context checkpoint (pos_min = 22550, pos_max = 23498, n_swa = 128, size = 22.253 MiB)
slot update_slots: id  3 | task 11742 | erased invalidated context checkpoint (pos_min = 22709, pos_max = 23661, n_swa = 128, size = 22.347 MiB)
slot update_slots: id  3 | task 11742 | erased invalidated context checkpoint (pos_min = 22876, pos_max = 23824, n_swa = 128, size = 22.253 MiB)
slot update_slots: id  3 | task 11742 | erased invalidated context checkpoint (pos_min = 22992, pos_max = 24003, n_swa = 128, size = 23.731 MiB)
slot update_slots: id  3 | task 11742 | erased invalidated context checkpoint (pos_min = 23197, pos_max = 24220, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 11742 | erased invalidated context checkpoint (pos_min = 23537, pos_max = 24560, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 11742 | erased invalidated context checkpoint (pos_min = 23736, pos_max = 24732, n_swa = 128, size = 23.379 MiB)
slot update_slots: id  3 | task 11742 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  3 | task 11742 | prompt processing progress, n_tokens = 831, batch.n_tokens = 831, progress = 0.928492
slot update_slots: id  3 | task 11742 | n_tokens = 831, memory_seq_rm [831, end)
slot update_slots: id  3 | task 11742 | prompt processing progress, n_tokens = 895, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11742 | prompt done, n_tokens = 895, batch.n_tokens = 64
slot init_sampler: id  3 | task 11742 | init sampler, took 0.13 ms, tokens: text = 895, total = 895
slot update_slots: id  3 | task 11742 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 830, size = 19.486 MiB)
slot print_timing: id  3 | task 11742 | 
prompt eval time =    1105.05 ms /   895 tokens (    1.23 ms per token,   809.92 tokens per second)
       eval time =    1583.35 ms /    61 tokens (   25.96 ms per token,    38.53 tokens per second)
      total time =    2688.39 ms /   956 tokens
slot      release: id  3 | task 11742 | stop processing: n_tokens = 955, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.637 (> 0.100 thold), f_keep = 0.976
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11805 | processing task, is_child = 0
slot update_slots: id  3 | task 11805 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1463
slot update_slots: id  3 | task 11805 | n_tokens = 932, memory_seq_rm [932, end)
slot update_slots: id  3 | task 11805 | prompt processing progress, n_tokens = 1399, batch.n_tokens = 467, progress = 0.956254
slot update_slots: id  3 | task 11805 | n_tokens = 1399, memory_seq_rm [1399, end)
slot update_slots: id  3 | task 11805 | prompt processing progress, n_tokens = 1463, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11805 | prompt done, n_tokens = 1463, batch.n_tokens = 64
slot init_sampler: id  3 | task 11805 | init sampler, took 0.21 ms, tokens: text = 1463, total = 1463
slot update_slots: id  3 | task 11805 | created context checkpoint 2 of 8 (pos_min = 375, pos_max = 1398, size = 24.012 MiB)
slot print_timing: id  3 | task 11805 | 
prompt eval time =     661.08 ms /   531 tokens (    1.24 ms per token,   803.23 tokens per second)
       eval time =    2347.45 ms /    87 tokens (   26.98 ms per token,    37.06 tokens per second)
      total time =    3008.54 ms /   618 tokens
slot      release: id  3 | task 11805 | stop processing: n_tokens = 1549, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.933 (> 0.100 thold), f_keep = 0.958
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11894 | processing task, is_child = 0
slot update_slots: id  3 | task 11894 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1590
slot update_slots: id  3 | task 11894 | n_tokens = 1484, memory_seq_rm [1484, end)
slot update_slots: id  3 | task 11894 | prompt processing progress, n_tokens = 1526, batch.n_tokens = 42, progress = 0.959748
slot update_slots: id  3 | task 11894 | n_tokens = 1526, memory_seq_rm [1526, end)
slot update_slots: id  3 | task 11894 | prompt processing progress, n_tokens = 1590, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11894 | prompt done, n_tokens = 1590, batch.n_tokens = 64
slot init_sampler: id  3 | task 11894 | init sampler, took 0.22 ms, tokens: text = 1590, total = 1590
slot update_slots: id  3 | task 11894 | created context checkpoint 3 of 8 (pos_min = 525, pos_max = 1525, size = 23.473 MiB)
slot print_timing: id  3 | task 11894 | 
prompt eval time =     351.20 ms /   106 tokens (    3.31 ms per token,   301.82 tokens per second)
       eval time =    1239.96 ms /    46 tokens (   26.96 ms per token,    37.10 tokens per second)
      total time =    1591.16 ms /   152 tokens
slot      release: id  3 | task 11894 | stop processing: n_tokens = 1635, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.513 (> 0.100 thold), f_keep = 0.979
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11942 | processing task, is_child = 0
slot update_slots: id  3 | task 11942 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 3120
slot update_slots: id  3 | task 11942 | n_tokens = 1600, memory_seq_rm [1600, end)
slot update_slots: id  3 | task 11942 | prompt processing progress, n_tokens = 3056, batch.n_tokens = 1456, progress = 0.979487
slot update_slots: id  3 | task 11942 | n_tokens = 3056, memory_seq_rm [3056, end)
slot update_slots: id  3 | task 11942 | prompt processing progress, n_tokens = 3120, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11942 | prompt done, n_tokens = 3120, batch.n_tokens = 64
slot init_sampler: id  3 | task 11942 | init sampler, took 0.44 ms, tokens: text = 3120, total = 3120
slot update_slots: id  3 | task 11942 | created context checkpoint 4 of 8 (pos_min = 2032, pos_max = 3055, size = 24.012 MiB)
slot print_timing: id  3 | task 11942 | 
prompt eval time =    1824.75 ms /  1520 tokens (    1.20 ms per token,   832.99 tokens per second)
       eval time =    1481.06 ms /    52 tokens (   28.48 ms per token,    35.11 tokens per second)
      total time =    3305.81 ms /  1572 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 11942 | stop processing: n_tokens = 3171, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.604 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11996 | processing task, is_child = 0
slot update_slots: id  3 | task 11996 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 5200
slot update_slots: id  3 | task 11996 | n_tokens = 3141, memory_seq_rm [3141, end)
slot update_slots: id  3 | task 11996 | prompt processing progress, n_tokens = 5136, batch.n_tokens = 1995, progress = 0.987692
slot update_slots: id  3 | task 11996 | n_tokens = 5136, memory_seq_rm [5136, end)
slot update_slots: id  3 | task 11996 | prompt processing progress, n_tokens = 5200, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11996 | prompt done, n_tokens = 5200, batch.n_tokens = 64
slot init_sampler: id  3 | task 11996 | init sampler, took 0.72 ms, tokens: text = 5200, total = 5200
slot update_slots: id  3 | task 11996 | created context checkpoint 5 of 8 (pos_min = 4112, pos_max = 5135, size = 24.012 MiB)
slot print_timing: id  3 | task 11996 | 
prompt eval time =    2583.12 ms /  2059 tokens (    1.25 ms per token,   797.10 tokens per second)
       eval time =    1274.02 ms /    43 tokens (   29.63 ms per token,    33.75 tokens per second)
      total time =    3857.13 ms /  2102 tokens
slot      release: id  3 | task 11996 | stop processing: n_tokens = 5242, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.678 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12041 | processing task, is_child = 0
slot update_slots: id  3 | task 12041 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 7685
slot update_slots: id  3 | task 12041 | n_tokens = 5208, memory_seq_rm [5208, end)
slot update_slots: id  3 | task 12041 | prompt processing progress, n_tokens = 7256, batch.n_tokens = 2048, progress = 0.944177
slot update_slots: id  3 | task 12041 | n_tokens = 7256, memory_seq_rm [7256, end)
slot update_slots: id  3 | task 12041 | prompt processing progress, n_tokens = 7621, batch.n_tokens = 365, progress = 0.991672
slot update_slots: id  3 | task 12041 | n_tokens = 7621, memory_seq_rm [7621, end)
slot update_slots: id  3 | task 12041 | prompt processing progress, n_tokens = 7685, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12041 | prompt done, n_tokens = 7685, batch.n_tokens = 64
slot init_sampler: id  3 | task 12041 | init sampler, took 1.06 ms, tokens: text = 7685, total = 7685
slot update_slots: id  3 | task 12041 | created context checkpoint 6 of 8 (pos_min = 6597, pos_max = 7620, size = 24.012 MiB)
slot print_timing: id  3 | task 12041 | 
prompt eval time =    3353.57 ms /  2477 tokens (    1.35 ms per token,   738.62 tokens per second)
       eval time =    1284.91 ms /    43 tokens (   29.88 ms per token,    33.47 tokens per second)
      total time =    4638.48 ms /  2520 tokens
slot      release: id  3 | task 12041 | stop processing: n_tokens = 7727, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12087 | processing task, is_child = 0
slot update_slots: id  3 | task 12087 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 7820
slot update_slots: id  3 | task 12087 | n_tokens = 7693, memory_seq_rm [7693, end)
slot update_slots: id  3 | task 12087 | prompt processing progress, n_tokens = 7756, batch.n_tokens = 63, progress = 0.991816
slot update_slots: id  3 | task 12087 | n_tokens = 7756, memory_seq_rm [7756, end)
slot update_slots: id  3 | task 12087 | prompt processing progress, n_tokens = 7820, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12087 | prompt done, n_tokens = 7820, batch.n_tokens = 64
slot init_sampler: id  3 | task 12087 | init sampler, took 1.09 ms, tokens: text = 7820, total = 7820
slot update_slots: id  3 | task 12087 | created context checkpoint 7 of 8 (pos_min = 6732, pos_max = 7755, size = 24.012 MiB)
slot print_timing: id  3 | task 12087 | 
prompt eval time =     424.46 ms /   127 tokens (    3.34 ms per token,   299.21 tokens per second)
       eval time =    1762.26 ms /    58 tokens (   30.38 ms per token,    32.91 tokens per second)
      total time =    2186.72 ms /   185 tokens
slot      release: id  3 | task 12087 | stop processing: n_tokens = 7877, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.807 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12147 | processing task, is_child = 0
slot update_slots: id  3 | task 12147 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 9725
slot update_slots: id  3 | task 12147 | n_tokens = 7846, memory_seq_rm [7846, end)
slot update_slots: id  3 | task 12147 | prompt processing progress, n_tokens = 9661, batch.n_tokens = 1815, progress = 0.993419
slot update_slots: id  3 | task 12147 | n_tokens = 9661, memory_seq_rm [9661, end)
slot update_slots: id  3 | task 12147 | prompt processing progress, n_tokens = 9725, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12147 | prompt done, n_tokens = 9725, batch.n_tokens = 64
slot init_sampler: id  3 | task 12147 | init sampler, took 1.88 ms, tokens: text = 9725, total = 9725
slot update_slots: id  3 | task 12147 | created context checkpoint 8 of 8 (pos_min = 8637, pos_max = 9660, size = 24.012 MiB)
slot print_timing: id  3 | task 12147 | 
prompt eval time =    2736.06 ms /  1879 tokens (    1.46 ms per token,   686.75 tokens per second)
       eval time =    1441.95 ms /    46 tokens (   31.35 ms per token,    31.90 tokens per second)
      total time =    4178.01 ms /  1925 tokens
slot      release: id  3 | task 12147 | stop processing: n_tokens = 9770, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.826 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12195 | processing task, is_child = 0
slot update_slots: id  3 | task 12195 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 11788
slot update_slots: id  3 | task 12195 | n_tokens = 9739, memory_seq_rm [9739, end)
slot update_slots: id  3 | task 12195 | prompt processing progress, n_tokens = 11724, batch.n_tokens = 1985, progress = 0.994571
slot update_slots: id  3 | task 12195 | n_tokens = 11724, memory_seq_rm [11724, end)
slot update_slots: id  3 | task 12195 | prompt processing progress, n_tokens = 11788, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12195 | prompt done, n_tokens = 11788, batch.n_tokens = 64
slot init_sampler: id  3 | task 12195 | init sampler, took 1.63 ms, tokens: text = 11788, total = 11788
slot update_slots: id  3 | task 12195 | erasing old context checkpoint (pos_min = 0, pos_max = 830, size = 19.486 MiB)
slot update_slots: id  3 | task 12195 | created context checkpoint 8 of 8 (pos_min = 10700, pos_max = 11723, size = 24.012 MiB)
slot print_timing: id  3 | task 12195 | 
prompt eval time =    3020.61 ms /  2049 tokens (    1.47 ms per token,   678.34 tokens per second)
       eval time =    1384.16 ms /    44 tokens (   31.46 ms per token,    31.79 tokens per second)
      total time =    4404.77 ms /  2093 tokens
slot      release: id  3 | task 12195 | stop processing: n_tokens = 11831, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.978 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12241 | processing task, is_child = 0
slot update_slots: id  3 | task 12241 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 12064
slot update_slots: id  3 | task 12241 | n_tokens = 11796, memory_seq_rm [11796, end)
slot update_slots: id  3 | task 12241 | prompt processing progress, n_tokens = 12000, batch.n_tokens = 204, progress = 0.994695
slot update_slots: id  3 | task 12241 | n_tokens = 12000, memory_seq_rm [12000, end)
slot update_slots: id  3 | task 12241 | prompt processing progress, n_tokens = 12064, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12241 | prompt done, n_tokens = 12064, batch.n_tokens = 64
slot init_sampler: id  3 | task 12241 | init sampler, took 1.66 ms, tokens: text = 12064, total = 12064
slot update_slots: id  3 | task 12241 | erasing old context checkpoint (pos_min = 375, pos_max = 1398, size = 24.012 MiB)
slot update_slots: id  3 | task 12241 | created context checkpoint 8 of 8 (pos_min = 10976, pos_max = 11999, size = 24.012 MiB)
slot print_timing: id  3 | task 12241 | 
prompt eval time =     612.30 ms /   268 tokens (    2.28 ms per token,   437.69 tokens per second)
       eval time =   11476.49 ms /   379 tokens (   30.28 ms per token,    33.02 tokens per second)
      total time =   12088.79 ms /   647 tokens
slot      release: id  3 | task 12241 | stop processing: n_tokens = 12442, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12622 | processing task, is_child = 0
slot update_slots: id  3 | task 12622 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 12471
slot update_slots: id  3 | task 12622 | n_tokens = 12412, memory_seq_rm [12412, end)
slot update_slots: id  3 | task 12622 | prompt processing progress, n_tokens = 12471, batch.n_tokens = 59, progress = 1.000000
slot update_slots: id  3 | task 12622 | prompt done, n_tokens = 12471, batch.n_tokens = 59
slot init_sampler: id  3 | task 12622 | init sampler, took 2.46 ms, tokens: text = 12471, total = 12471
slot update_slots: id  3 | task 12622 | erasing old context checkpoint (pos_min = 525, pos_max = 1525, size = 23.473 MiB)
slot update_slots: id  3 | task 12622 | created context checkpoint 8 of 8 (pos_min = 11418, pos_max = 12411, size = 23.309 MiB)
slot print_timing: id  3 | task 12622 | 
prompt eval time =     292.28 ms /    59 tokens (    4.95 ms per token,   201.86 tokens per second)
       eval time =    1514.78 ms /    56 tokens (   27.05 ms per token,    36.97 tokens per second)
      total time =    1807.06 ms /   115 tokens
slot      release: id  3 | task 12622 | stop processing: n_tokens = 12526, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.983 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12679 | processing task, is_child = 0
slot update_slots: id  3 | task 12679 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 12712
slot update_slots: id  3 | task 12679 | n_tokens = 12499, memory_seq_rm [12499, end)
slot update_slots: id  3 | task 12679 | prompt processing progress, n_tokens = 12648, batch.n_tokens = 149, progress = 0.994965
slot update_slots: id  3 | task 12679 | n_tokens = 12648, memory_seq_rm [12648, end)
slot update_slots: id  3 | task 12679 | prompt processing progress, n_tokens = 12712, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12679 | prompt done, n_tokens = 12712, batch.n_tokens = 64
slot init_sampler: id  3 | task 12679 | init sampler, took 1.87 ms, tokens: text = 12712, total = 12712
slot update_slots: id  3 | task 12679 | erasing old context checkpoint (pos_min = 2032, pos_max = 3055, size = 24.012 MiB)
slot update_slots: id  3 | task 12679 | created context checkpoint 8 of 8 (pos_min = 11624, pos_max = 12647, size = 24.012 MiB)
slot print_timing: id  3 | task 12679 | 
prompt eval time =     467.48 ms /   213 tokens (    2.19 ms per token,   455.63 tokens per second)
       eval time =   12393.72 ms /   450 tokens (   27.54 ms per token,    36.31 tokens per second)
      total time =   12861.20 ms /   663 tokens
slot      release: id  3 | task 12679 | stop processing: n_tokens = 13161, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 13131 | processing task, is_child = 0
slot update_slots: id  3 | task 13131 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13212
slot update_slots: id  3 | task 13131 | n_tokens = 13152, memory_seq_rm [13152, end)
slot update_slots: id  3 | task 13131 | prompt processing progress, n_tokens = 13212, batch.n_tokens = 60, progress = 1.000000
slot update_slots: id  3 | task 13131 | prompt done, n_tokens = 13212, batch.n_tokens = 60
slot init_sampler: id  3 | task 13131 | init sampler, took 1.83 ms, tokens: text = 13212, total = 13212
slot update_slots: id  3 | task 13131 | erasing old context checkpoint (pos_min = 4112, pos_max = 5135, size = 24.012 MiB)
slot update_slots: id  3 | task 13131 | created context checkpoint 8 of 8 (pos_min = 12137, pos_max = 13151, size = 23.801 MiB)
slot print_timing: id  3 | task 13131 | 
prompt eval time =     206.81 ms /    60 tokens (    3.45 ms per token,   290.13 tokens per second)
       eval time =    9667.36 ms /   322 tokens (   30.02 ms per token,    33.31 tokens per second)
      total time =    9874.16 ms /   382 tokens
slot      release: id  3 | task 13131 | stop processing: n_tokens = 13533, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.899 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 13454 | processing task, is_child = 0
slot update_slots: id  3 | task 13454 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 15026
slot update_slots: id  3 | task 13454 | n_tokens = 13505, memory_seq_rm [13505, end)
slot update_slots: id  3 | task 13454 | prompt processing progress, n_tokens = 14962, batch.n_tokens = 1457, progress = 0.995741
slot update_slots: id  3 | task 13454 | n_tokens = 14962, memory_seq_rm [14962, end)
slot update_slots: id  3 | task 13454 | prompt processing progress, n_tokens = 15026, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 13454 | prompt done, n_tokens = 15026, batch.n_tokens = 64
slot init_sampler: id  3 | task 13454 | init sampler, took 2.07 ms, tokens: text = 15026, total = 15026
slot update_slots: id  3 | task 13454 | erasing old context checkpoint (pos_min = 6597, pos_max = 7620, size = 24.012 MiB)
slot update_slots: id  3 | task 13454 | created context checkpoint 8 of 8 (pos_min = 13938, pos_max = 14961, size = 24.012 MiB)
slot print_timing: id  3 | task 13454 | 
prompt eval time =    2259.58 ms /  1521 tokens (    1.49 ms per token,   673.14 tokens per second)
       eval time =   32613.27 ms /  1055 tokens (   30.91 ms per token,    32.35 tokens per second)
      total time =   34872.85 ms /  2576 tokens
slot      release: id  3 | task 13454 | stop processing: n_tokens = 16080, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LRU, t_last = -1
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 14511 | processing task, is_child = 0
slot update_slots: id  2 | task 14511 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 14235
slot update_slots: id  2 | task 14511 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 14511 | prompt processing progress, n_tokens = 2048, batch.n_tokens = 2048, progress = 0.143871
slot update_slots: id  2 | task 14511 | n_tokens = 2048, memory_seq_rm [2048, end)
slot update_slots: id  2 | task 14511 | prompt processing progress, n_tokens = 4096, batch.n_tokens = 2048, progress = 0.287741
slot update_slots: id  2 | task 14511 | n_tokens = 4096, memory_seq_rm [4096, end)
slot update_slots: id  2 | task 14511 | prompt processing progress, n_tokens = 6144, batch.n_tokens = 2048, progress = 0.431612
slot update_slots: id  2 | task 14511 | n_tokens = 6144, memory_seq_rm [6144, end)
slot update_slots: id  2 | task 14511 | prompt processing progress, n_tokens = 8192, batch.n_tokens = 2048, progress = 0.575483
slot update_slots: id  2 | task 14511 | n_tokens = 8192, memory_seq_rm [8192, end)
slot update_slots: id  2 | task 14511 | prompt processing progress, n_tokens = 10240, batch.n_tokens = 2048, progress = 0.719354
slot update_slots: id  2 | task 14511 | n_tokens = 10240, memory_seq_rm [10240, end)
slot update_slots: id  2 | task 14511 | prompt processing progress, n_tokens = 12288, batch.n_tokens = 2048, progress = 0.863224
slot update_slots: id  2 | task 14511 | n_tokens = 12288, memory_seq_rm [12288, end)
slot update_slots: id  2 | task 14511 | prompt processing progress, n_tokens = 14171, batch.n_tokens = 1883, progress = 0.995504
slot update_slots: id  2 | task 14511 | n_tokens = 14171, memory_seq_rm [14171, end)
slot update_slots: id  2 | task 14511 | prompt processing progress, n_tokens = 14235, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 14511 | prompt done, n_tokens = 14235, batch.n_tokens = 64
slot init_sampler: id  2 | task 14511 | init sampler, took 1.95 ms, tokens: text = 14235, total = 14235
slot update_slots: id  2 | task 14511 | created context checkpoint 1 of 8 (pos_min = 13274, pos_max = 14170, size = 21.034 MiB)
slot print_timing: id  2 | task 14511 | 
prompt eval time =   22604.24 ms / 14235 tokens (    1.59 ms per token,   629.75 tokens per second)
       eval time =   35652.67 ms /  1148 tokens (   31.06 ms per token,    32.20 tokens per second)
      total time =   58256.91 ms / 15383 tokens
slot      release: id  2 | task 14511 | stop processing: n_tokens = 15382, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 15667 | processing task, is_child = 0
slot update_slots: id  2 | task 15667 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 15492
slot update_slots: id  2 | task 15667 | n_tokens = 15338, memory_seq_rm [15338, end)
slot update_slots: id  2 | task 15667 | prompt processing progress, n_tokens = 15428, batch.n_tokens = 90, progress = 0.995869
slot update_slots: id  2 | task 15667 | n_tokens = 15428, memory_seq_rm [15428, end)
slot update_slots: id  2 | task 15667 | prompt processing progress, n_tokens = 15492, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 15667 | prompt done, n_tokens = 15492, batch.n_tokens = 64
slot init_sampler: id  2 | task 15667 | init sampler, took 3.04 ms, tokens: text = 15492, total = 15492
slot update_slots: id  2 | task 15667 | created context checkpoint 2 of 8 (pos_min = 14531, pos_max = 15427, size = 21.034 MiB)
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.977 (> 0.100 thold), f_keep = 0.055
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 16080, total state size = 380.038 MiB
srv          load:  - looking for better prompt, base f_keep = 0.055, sim = 0.977
srv        update:  - cache state: 6 prompts, 2585.755 MiB (limits: 8192.000 MiB, 56064 tokens, 194719 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv        update:    - prompt 0x58dc3fb8c770:    5127 tokens, checkpoints:  8,   320.808 MiB
srv        update:    - prompt 0x58dc3f318830:   24865 tokens, checkpoints:  8,   791.874 MiB
srv        update:    - prompt 0x58dc40d3cf50:   16080 tokens, checkpoints:  8,   571.219 MiB
srv  get_availabl: prompt cache update took 442.82 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16066 | processing task, is_child = 0
slot update_slots: id  3 | task 16066 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 902
slot update_slots: id  3 | task 16066 | n_past = 881, slot.prompt.tokens.size() = 16080, seq_id = 3, pos_min = 15953, n_swa = 128
slot update_slots: id  3 | task 16066 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  3 | task 16066 | erased invalidated context checkpoint (pos_min = 6732, pos_max = 7755, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 16066 | erased invalidated context checkpoint (pos_min = 8637, pos_max = 9660, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 16066 | erased invalidated context checkpoint (pos_min = 10700, pos_max = 11723, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 16066 | erased invalidated context checkpoint (pos_min = 10976, pos_max = 11999, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 16066 | erased invalidated context checkpoint (pos_min = 11418, pos_max = 12411, n_swa = 128, size = 23.309 MiB)
slot update_slots: id  3 | task 16066 | erased invalidated context checkpoint (pos_min = 11624, pos_max = 12647, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 16066 | erased invalidated context checkpoint (pos_min = 12137, pos_max = 13151, n_swa = 128, size = 23.801 MiB)
slot update_slots: id  3 | task 16066 | erased invalidated context checkpoint (pos_min = 13938, pos_max = 14961, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 16066 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  3 | task 16066 | prompt processing progress, n_tokens = 838, batch.n_tokens = 839, progress = 0.929047
slot update_slots: id  3 | task 16066 | n_tokens = 838, memory_seq_rm [838, end)
slot update_slots: id  3 | task 16066 | prompt processing progress, n_tokens = 902, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 16066 | prompt done, n_tokens = 902, batch.n_tokens = 65
slot init_sampler: id  3 | task 16066 | init sampler, took 0.16 ms, tokens: text = 902, total = 902
slot update_slots: id  3 | task 16066 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 837, size = 19.651 MiB)
slot print_timing: id  2 | task 15667 | 
prompt eval time =     506.39 ms /   154 tokens (    3.29 ms per token,   304.12 tokens per second)
       eval time =   14297.65 ms /   400 tokens (   35.74 ms per token,    27.98 tokens per second)
      total time =   14804.04 ms /   554 tokens
slot      release: id  2 | task 15667 | stop processing: n_tokens = 15891, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  3 | task 16066 | 
prompt eval time =    1719.20 ms /   902 tokens (    1.91 ms per token,   524.66 tokens per second)
       eval time =    1377.45 ms /    42 tokens (   32.80 ms per token,    30.49 tokens per second)
      total time =    3096.66 ms /   944 tokens
slot      release: id  3 | task 16066 | stop processing: n_tokens = 943, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.633 (> 0.100 thold), f_keep = 0.975
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16110 | processing task, is_child = 0
slot update_slots: id  3 | task 16110 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1452
slot update_slots: id  3 | task 16110 | n_tokens = 919, memory_seq_rm [919, end)
slot update_slots: id  3 | task 16110 | prompt processing progress, n_tokens = 1388, batch.n_tokens = 469, progress = 0.955923
slot update_slots: id  3 | task 16110 | n_tokens = 1388, memory_seq_rm [1388, end)
slot update_slots: id  3 | task 16110 | prompt processing progress, n_tokens = 1452, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 16110 | prompt done, n_tokens = 1452, batch.n_tokens = 64
slot init_sampler: id  3 | task 16110 | init sampler, took 0.28 ms, tokens: text = 1452, total = 1452
srv  params_from_: Chat format: GPT-OSS
slot update_slots: id  3 | task 16110 | created context checkpoint 2 of 8 (pos_min = 493, pos_max = 1387, size = 20.987 MiB)
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 16113 | processing task, is_child = 0
slot update_slots: id  2 | task 16113 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 15934
slot update_slots: id  2 | task 16113 | n_past = 15862, slot.prompt.tokens.size() = 15891, seq_id = 2, pos_min = 15762, n_swa = 128
slot update_slots: id  2 | task 16113 | restored context checkpoint (pos_min = 14531, pos_max = 15427, size = 21.034 MiB)
slot update_slots: id  2 | task 16113 | n_tokens = 15427, memory_seq_rm [15427, end)
slot update_slots: id  2 | task 16113 | prompt processing progress, n_tokens = 15870, batch.n_tokens = 444, progress = 0.995983
slot update_slots: id  2 | task 16113 | n_tokens = 15870, memory_seq_rm [15870, end)
slot update_slots: id  2 | task 16113 | prompt processing progress, n_tokens = 15934, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  2 | task 16113 | prompt done, n_tokens = 15934, batch.n_tokens = 65
slot init_sampler: id  2 | task 16113 | init sampler, took 2.21 ms, tokens: text = 15934, total = 15934
slot update_slots: id  2 | task 16113 | created context checkpoint 3 of 8 (pos_min = 14974, pos_max = 15869, size = 21.011 MiB)
slot print_timing: id  3 | task 16110 | 
prompt eval time =    1050.75 ms /   533 tokens (    1.97 ms per token,   507.26 tokens per second)
       eval time =    4558.55 ms /    65 tokens (   70.13 ms per token,    14.26 tokens per second)
      total time =    5609.30 ms /   598 tokens
slot      release: id  3 | task 16110 | stop processing: n_tokens = 1516, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.905 (> 0.100 thold), f_keep = 0.980
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16183 | processing task, is_child = 0
slot update_slots: id  3 | task 16183 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1641
slot update_slots: id  3 | task 16183 | n_tokens = 1485, memory_seq_rm [1485, end)
slot update_slots: id  3 | task 16183 | prompt processing progress, n_tokens = 1577, batch.n_tokens = 93, progress = 0.960999
slot update_slots: id  3 | task 16183 | n_tokens = 1577, memory_seq_rm [1577, end)
slot update_slots: id  3 | task 16183 | prompt processing progress, n_tokens = 1641, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 16183 | prompt done, n_tokens = 1641, batch.n_tokens = 65
slot init_sampler: id  3 | task 16183 | init sampler, took 0.28 ms, tokens: text = 1641, total = 1641
slot update_slots: id  3 | task 16183 | created context checkpoint 3 of 8 (pos_min = 1325, pos_max = 1576, size = 5.909 MiB)
slot print_timing: id  3 | task 16183 | 
prompt eval time =     644.25 ms /   156 tokens (    4.13 ms per token,   242.14 tokens per second)
       eval time =    2322.35 ms /    42 tokens (   55.29 ms per token,    18.09 tokens per second)
      total time =    2966.60 ms /   198 tokens
slot      release: id  3 | task 16183 | stop processing: n_tokens = 1682, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.701 (> 0.100 thold), f_keep = 0.982
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16232 | processing task, is_child = 0
slot update_slots: id  3 | task 16232 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2354
slot update_slots: id  3 | task 16232 | n_tokens = 1651, memory_seq_rm [1651, end)
slot update_slots: id  3 | task 16232 | prompt processing progress, n_tokens = 2290, batch.n_tokens = 640, progress = 0.972812
slot update_slots: id  3 | task 16232 | n_tokens = 2290, memory_seq_rm [2290, end)
slot update_slots: id  3 | task 16232 | prompt processing progress, n_tokens = 2354, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 16232 | prompt done, n_tokens = 2354, batch.n_tokens = 65
slot init_sampler: id  3 | task 16232 | init sampler, took 0.41 ms, tokens: text = 2354, total = 2354
slot update_slots: id  3 | task 16232 | created context checkpoint 4 of 8 (pos_min = 1453, pos_max = 2289, size = 19.627 MiB)
slot print_timing: id  3 | task 16232 | 
prompt eval time =    1669.06 ms /   703 tokens (    2.37 ms per token,   421.20 tokens per second)
       eval time =    2549.68 ms /    43 tokens (   59.29 ms per token,    16.86 tokens per second)
      total time =    4218.74 ms /   746 tokens
slot      release: id  3 | task 16232 | stop processing: n_tokens = 2396, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.661 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16288 | processing task, is_child = 0
slot update_slots: id  3 | task 16288 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 3576
slot update_slots: id  3 | task 16288 | n_tokens = 2365, memory_seq_rm [2365, end)
slot update_slots: id  3 | task 16288 | prompt processing progress, n_tokens = 3512, batch.n_tokens = 1148, progress = 0.982103
slot update_slots: id  3 | task 16288 | n_tokens = 3512, memory_seq_rm [3512, end)
slot update_slots: id  3 | task 16288 | prompt processing progress, n_tokens = 3576, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 16288 | prompt done, n_tokens = 3576, batch.n_tokens = 65
slot init_sampler: id  3 | task 16288 | init sampler, took 0.67 ms, tokens: text = 3576, total = 3576
slot update_slots: id  3 | task 16288 | created context checkpoint 5 of 8 (pos_min = 2615, pos_max = 3511, size = 21.034 MiB)
slot print_timing: id  3 | task 16288 | 
prompt eval time =    2638.98 ms /  1211 tokens (    2.18 ms per token,   458.89 tokens per second)
       eval time =    2716.70 ms /    46 tokens (   59.06 ms per token,    16.93 tokens per second)
      total time =    5355.67 ms /  1257 tokens
slot      release: id  3 | task 16288 | stop processing: n_tokens = 3621, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.900 (> 0.100 thold), f_keep = 0.990
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16342 | processing task, is_child = 0
slot update_slots: id  3 | task 16342 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 3985
slot update_slots: id  3 | task 16342 | n_tokens = 3586, memory_seq_rm [3586, end)
slot update_slots: id  3 | task 16342 | prompt processing progress, n_tokens = 3921, batch.n_tokens = 336, progress = 0.983940
slot update_slots: id  3 | task 16342 | n_tokens = 3921, memory_seq_rm [3921, end)
slot update_slots: id  3 | task 16342 | prompt processing progress, n_tokens = 3985, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 16342 | prompt done, n_tokens = 3985, batch.n_tokens = 65
slot init_sampler: id  3 | task 16342 | init sampler, took 0.73 ms, tokens: text = 3985, total = 3985
slot update_slots: id  3 | task 16342 | created context checkpoint 6 of 8 (pos_min = 3077, pos_max = 3920, size = 19.791 MiB)
slot print_timing: id  3 | task 16342 | 
prompt eval time =    1021.02 ms /   399 tokens (    2.56 ms per token,   390.79 tokens per second)
       eval time =    2748.80 ms /    47 tokens (   58.49 ms per token,    17.10 tokens per second)
      total time =    3769.82 ms /   446 tokens
slot      release: id  3 | task 16342 | stop processing: n_tokens = 4031, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.975 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16399 | processing task, is_child = 0
slot update_slots: id  3 | task 16399 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 4100
slot update_slots: id  3 | task 16399 | n_tokens = 3999, memory_seq_rm [3999, end)
slot update_slots: id  3 | task 16399 | prompt processing progress, n_tokens = 4036, batch.n_tokens = 38, progress = 0.984390
slot update_slots: id  3 | task 16399 | n_tokens = 4036, memory_seq_rm [4036, end)
slot update_slots: id  3 | task 16399 | prompt processing progress, n_tokens = 4100, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 16399 | prompt done, n_tokens = 4100, batch.n_tokens = 65
slot init_sampler: id  3 | task 16399 | init sampler, took 0.79 ms, tokens: text = 4100, total = 4100
slot update_slots: id  3 | task 16399 | created context checkpoint 7 of 8 (pos_min = 3242, pos_max = 4035, size = 18.619 MiB)
slot print_timing: id  3 | task 16399 | 
prompt eval time =     557.42 ms /   101 tokens (    5.52 ms per token,   181.19 tokens per second)
       eval time =    2733.25 ms /    46 tokens (   59.42 ms per token,    16.83 tokens per second)
      total time =    3290.67 ms /   147 tokens
slot      release: id  3 | task 16399 | stop processing: n_tokens = 4145, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.670 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16464 | processing task, is_child = 0
slot update_slots: id  3 | task 16464 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 6143
slot update_slots: id  3 | task 16464 | n_tokens = 4113, memory_seq_rm [4113, end)
slot update_slots: id  3 | task 16464 | prompt processing progress, n_tokens = 6079, batch.n_tokens = 1967, progress = 0.989582
slot update_slots: id  3 | task 16464 | n_tokens = 6079, memory_seq_rm [6079, end)
slot update_slots: id  3 | task 16464 | prompt processing progress, n_tokens = 6143, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 16464 | prompt done, n_tokens = 6143, batch.n_tokens = 65
slot init_sampler: id  3 | task 16464 | init sampler, took 1.08 ms, tokens: text = 6143, total = 6143
slot update_slots: id  3 | task 16464 | created context checkpoint 8 of 8 (pos_min = 5182, pos_max = 6078, size = 21.034 MiB)
slot print_timing: id  3 | task 16464 | 
prompt eval time =    3660.94 ms /  2030 tokens (    1.80 ms per token,   554.50 tokens per second)
       eval time =    2441.57 ms /    44 tokens (   55.49 ms per token,    18.02 tokens per second)
      total time =    6102.50 ms /  2074 tokens
slot      release: id  3 | task 16464 | stop processing: n_tokens = 6186, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.888 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16523 | processing task, is_child = 0
slot update_slots: id  3 | task 16523 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 6928
slot update_slots: id  3 | task 16523 | n_tokens = 6151, memory_seq_rm [6151, end)
slot update_slots: id  3 | task 16523 | prompt processing progress, n_tokens = 6864, batch.n_tokens = 714, progress = 0.990762
slot update_slots: id  3 | task 16523 | n_tokens = 6864, memory_seq_rm [6864, end)
slot update_slots: id  3 | task 16523 | prompt processing progress, n_tokens = 6928, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 16523 | prompt done, n_tokens = 6928, batch.n_tokens = 65
slot init_sampler: id  3 | task 16523 | init sampler, took 1.36 ms, tokens: text = 6928, total = 6928
slot update_slots: id  3 | task 16523 | erasing old context checkpoint (pos_min = 0, pos_max = 837, size = 19.651 MiB)
slot update_slots: id  3 | task 16523 | created context checkpoint 8 of 8 (pos_min = 5999, pos_max = 6863, size = 20.284 MiB)
slot print_timing: id  3 | task 16523 | 
prompt eval time =    1675.00 ms /   777 tokens (    2.16 ms per token,   463.88 tokens per second)
       eval time =    2350.19 ms /    43 tokens (   54.66 ms per token,    18.30 tokens per second)
      total time =    4025.18 ms /   820 tokens
slot      release: id  3 | task 16523 | stop processing: n_tokens = 6970, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.766 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16589 | processing task, is_child = 0
slot update_slots: id  3 | task 16589 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 9060
slot update_slots: id  3 | task 16589 | n_tokens = 6937, memory_seq_rm [6937, end)
slot update_slots: id  3 | task 16589 | prompt processing progress, n_tokens = 8984, batch.n_tokens = 2048, progress = 0.991611
slot update_slots: id  3 | task 16589 | n_tokens = 8984, memory_seq_rm [8984, end)
slot update_slots: id  3 | task 16589 | prompt processing progress, n_tokens = 8996, batch.n_tokens = 13, progress = 0.992936
slot update_slots: id  3 | task 16589 | n_tokens = 8996, memory_seq_rm [8996, end)
slot update_slots: id  3 | task 16589 | prompt processing progress, n_tokens = 9060, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 16589 | prompt done, n_tokens = 9060, batch.n_tokens = 65
slot init_sampler: id  3 | task 16589 | init sampler, took 1.73 ms, tokens: text = 9060, total = 9060
slot update_slots: id  3 | task 16589 | erasing old context checkpoint (pos_min = 493, pos_max = 1387, size = 20.987 MiB)
slot update_slots: id  3 | task 16589 | created context checkpoint 8 of 8 (pos_min = 8100, pos_max = 8995, size = 21.011 MiB)
slot print_timing: id  3 | task 16589 | 
prompt eval time =    3828.58 ms /  2123 tokens (    1.80 ms per token,   554.51 tokens per second)
       eval time =    5529.35 ms /   102 tokens (   54.21 ms per token,    18.45 tokens per second)
      total time =    9357.93 ms /  2225 tokens
slot      release: id  3 | task 16589 | stop processing: n_tokens = 9161, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.829 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16706 | processing task, is_child = 0
slot update_slots: id  3 | task 16706 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 11009
slot update_slots: id  3 | task 16706 | n_tokens = 9129, memory_seq_rm [9129, end)
slot update_slots: id  3 | task 16706 | prompt processing progress, n_tokens = 10945, batch.n_tokens = 1817, progress = 0.994187
slot update_slots: id  3 | task 16706 | n_tokens = 10945, memory_seq_rm [10945, end)
slot update_slots: id  3 | task 16706 | prompt processing progress, n_tokens = 11009, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 16706 | prompt done, n_tokens = 11009, batch.n_tokens = 65
slot init_sampler: id  3 | task 16706 | init sampler, took 2.00 ms, tokens: text = 11009, total = 11009
slot update_slots: id  3 | task 16706 | erasing old context checkpoint (pos_min = 1325, pos_max = 1576, size = 5.909 MiB)
slot update_slots: id  3 | task 16706 | created context checkpoint 8 of 8 (pos_min = 10048, pos_max = 10944, size = 21.034 MiB)
slot print_timing: id  3 | task 16706 | 
prompt eval time =    3429.70 ms /  1880 tokens (    1.82 ms per token,   548.15 tokens per second)
       eval time =    2482.97 ms /    45 tokens (   55.18 ms per token,    18.12 tokens per second)
      total time =    5912.67 ms /  1925 tokens
slot      release: id  3 | task 16706 | stop processing: n_tokens = 11053, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.843 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16781 | processing task, is_child = 0
slot update_slots: id  3 | task 16781 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13067
slot update_slots: id  3 | task 16781 | n_tokens = 11017, memory_seq_rm [11017, end)
slot update_slots: id  3 | task 16781 | prompt processing progress, n_tokens = 13003, batch.n_tokens = 1987, progress = 0.995102
slot update_slots: id  3 | task 16781 | n_tokens = 13003, memory_seq_rm [13003, end)
slot update_slots: id  3 | task 16781 | prompt processing progress, n_tokens = 13067, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 16781 | prompt done, n_tokens = 13067, batch.n_tokens = 65
slot init_sampler: id  3 | task 16781 | init sampler, took 2.88 ms, tokens: text = 13067, total = 13067
slot update_slots: id  3 | task 16781 | erasing old context checkpoint (pos_min = 1453, pos_max = 2289, size = 19.627 MiB)
slot update_slots: id  3 | task 16781 | created context checkpoint 8 of 8 (pos_min = 12106, pos_max = 13002, size = 21.034 MiB)
slot print_timing: id  3 | task 16781 | 
prompt eval time =    3663.12 ms /  2050 tokens (    1.79 ms per token,   559.63 tokens per second)
       eval time =    2444.99 ms /    45 tokens (   54.33 ms per token,    18.40 tokens per second)
      total time =    6108.11 ms /  2095 tokens
slot      release: id  3 | task 16781 | stop processing: n_tokens = 13111, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.980 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16850 | processing task, is_child = 0
slot update_slots: id  3 | task 16850 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13344
slot update_slots: id  3 | task 16850 | n_tokens = 13075, memory_seq_rm [13075, end)
slot update_slots: id  3 | task 16850 | prompt processing progress, n_tokens = 13280, batch.n_tokens = 206, progress = 0.995204
slot update_slots: id  3 | task 16850 | n_tokens = 13280, memory_seq_rm [13280, end)
slot update_slots: id  3 | task 16850 | prompt processing progress, n_tokens = 13344, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 16850 | prompt done, n_tokens = 13344, batch.n_tokens = 65
slot init_sampler: id  3 | task 16850 | init sampler, took 2.49 ms, tokens: text = 13344, total = 13344
slot update_slots: id  3 | task 16850 | erasing old context checkpoint (pos_min = 2615, pos_max = 3511, size = 21.034 MiB)
slot update_slots: id  3 | task 16850 | created context checkpoint 8 of 8 (pos_min = 12451, pos_max = 13279, size = 19.439 MiB)
slot print_timing: id  3 | task 16850 | 
prompt eval time =     784.25 ms /   269 tokens (    2.92 ms per token,   343.00 tokens per second)
       eval time =    2844.80 ms /    52 tokens (   54.71 ms per token,    18.28 tokens per second)
      total time =    3629.05 ms /   321 tokens
slot      release: id  3 | task 16850 | stop processing: n_tokens = 13395, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.959 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16935 | processing task, is_child = 0
slot update_slots: id  3 | task 16935 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13936
slot update_slots: id  3 | task 16935 | n_tokens = 13363, memory_seq_rm [13363, end)
slot update_slots: id  3 | task 16935 | prompt processing progress, n_tokens = 13872, batch.n_tokens = 510, progress = 0.995408
slot update_slots: id  3 | task 16935 | n_tokens = 13872, memory_seq_rm [13872, end)
slot update_slots: id  3 | task 16935 | prompt processing progress, n_tokens = 13936, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 16935 | prompt done, n_tokens = 13936, batch.n_tokens = 65
slot init_sampler: id  3 | task 16935 | init sampler, took 2.65 ms, tokens: text = 13936, total = 13936
slot update_slots: id  3 | task 16935 | erasing old context checkpoint (pos_min = 3077, pos_max = 3920, size = 19.791 MiB)
slot update_slots: id  3 | task 16935 | created context checkpoint 8 of 8 (pos_min = 13000, pos_max = 13871, size = 20.448 MiB)
slot print_timing: id  3 | task 16935 | 
prompt eval time =    1187.33 ms /   573 tokens (    2.07 ms per token,   482.59 tokens per second)
       eval time =    2421.77 ms /    43 tokens (   56.32 ms per token,    17.76 tokens per second)
      total time =    3609.11 ms /   616 tokens
slot      release: id  3 | task 16935 | stop processing: n_tokens = 13978, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.902 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 17004 | processing task, is_child = 0
slot update_slots: id  3 | task 17004 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 15467
slot update_slots: id  3 | task 17004 | n_tokens = 13946, memory_seq_rm [13946, end)
slot update_slots: id  3 | task 17004 | prompt processing progress, n_tokens = 15403, batch.n_tokens = 1458, progress = 0.995862
slot update_slots: id  3 | task 17004 | n_tokens = 15403, memory_seq_rm [15403, end)
slot update_slots: id  3 | task 17004 | prompt processing progress, n_tokens = 15467, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 17004 | prompt done, n_tokens = 15467, batch.n_tokens = 65
slot init_sampler: id  3 | task 17004 | init sampler, took 2.88 ms, tokens: text = 15467, total = 15467
slot update_slots: id  3 | task 17004 | erasing old context checkpoint (pos_min = 3242, pos_max = 4035, size = 18.619 MiB)
slot update_slots: id  3 | task 17004 | created context checkpoint 8 of 8 (pos_min = 14506, pos_max = 15402, size = 21.034 MiB)
slot print_timing: id  3 | task 17004 | 
prompt eval time =    2765.29 ms /  1521 tokens (    1.82 ms per token,   550.03 tokens per second)
       eval time =    2163.33 ms /    41 tokens (   52.76 ms per token,    18.95 tokens per second)
      total time =    4928.63 ms /  1562 tokens
slot      release: id  3 | task 17004 | stop processing: n_tokens = 15507, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.883 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 17061 | processing task, is_child = 0
slot update_slots: id  3 | task 17061 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 17518
slot update_slots: id  3 | task 17061 | n_tokens = 15476, memory_seq_rm [15476, end)
slot update_slots: id  3 | task 17061 | prompt processing progress, n_tokens = 17454, batch.n_tokens = 1979, progress = 0.996347
slot update_slots: id  3 | task 17061 | n_tokens = 17454, memory_seq_rm [17454, end)
slot update_slots: id  3 | task 17061 | prompt processing progress, n_tokens = 17518, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 17061 | prompt done, n_tokens = 17518, batch.n_tokens = 65
slot init_sampler: id  3 | task 17061 | init sampler, took 3.23 ms, tokens: text = 17518, total = 17518
slot update_slots: id  3 | task 17061 | erasing old context checkpoint (pos_min = 5182, pos_max = 6078, size = 21.034 MiB)
slot update_slots: id  3 | task 17061 | created context checkpoint 8 of 8 (pos_min = 16557, pos_max = 17453, size = 21.034 MiB)
slot print_timing: id  2 | task 16113 | 
prompt eval time =    1198.05 ms /   507 tokens (    2.36 ms per token,   423.19 tokens per second)
       eval time =   77309.85 ms /   936 tokens (   82.60 ms per token,    12.11 tokens per second)
      total time =   78507.90 ms /  1443 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 16113 | stop processing: n_tokens = 16869, truncated = 0
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.970 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 17134 | processing task, is_child = 0
slot update_slots: id  2 | task 17134 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 17357
slot update_slots: id  2 | task 17134 | n_past = 16839, slot.prompt.tokens.size() = 16869, seq_id = 2, pos_min = 16740, n_swa = 128
slot update_slots: id  2 | task 17134 | restored context checkpoint (pos_min = 14974, pos_max = 15869, size = 21.011 MiB)
slot update_slots: id  2 | task 17134 | n_tokens = 15869, memory_seq_rm [15869, end)
slot update_slots: id  2 | task 17134 | prompt processing progress, n_tokens = 17293, batch.n_tokens = 1425, progress = 0.996313
slot update_slots: id  2 | task 17134 | n_tokens = 17293, memory_seq_rm [17293, end)
slot update_slots: id  2 | task 17134 | prompt processing progress, n_tokens = 17357, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  2 | task 17134 | prompt done, n_tokens = 17357, batch.n_tokens = 65
slot init_sampler: id  2 | task 17134 | init sampler, took 3.25 ms, tokens: text = 17357, total = 17357
slot update_slots: id  2 | task 17134 | created context checkpoint 4 of 8 (pos_min = 16396, pos_max = 17292, size = 21.034 MiB)
slot print_timing: id  3 | task 17061 | 
prompt eval time =    3721.21 ms /  2042 tokens (    1.82 ms per token,   548.75 tokens per second)
       eval time =   66161.24 ms /  1158 tokens (   57.13 ms per token,    17.50 tokens per second)
      total time =   69882.45 ms /  3200 tokens
slot      release: id  3 | task 17061 | stop processing: n_tokens = 18675, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  2 | task 17134 | 
prompt eval time =    2982.51 ms /  1488 tokens (    2.00 ms per token,   498.91 tokens per second)
       eval time =   78737.80 ms /  1638 tokens (   48.07 ms per token,    20.80 tokens per second)
      total time =   81720.30 ms /  3126 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 17134 | stop processing: n_tokens = 18994, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.981 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 18774 | processing task, is_child = 0
slot update_slots: id  2 | task 18774 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 19326
slot update_slots: id  2 | task 18774 | n_tokens = 18964, memory_seq_rm [18964, end)
slot update_slots: id  2 | task 18774 | prompt processing progress, n_tokens = 19262, batch.n_tokens = 298, progress = 0.996688
slot update_slots: id  2 | task 18774 | n_tokens = 19262, memory_seq_rm [19262, end)
slot update_slots: id  2 | task 18774 | prompt processing progress, n_tokens = 19326, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 18774 | prompt done, n_tokens = 19326, batch.n_tokens = 64
slot init_sampler: id  2 | task 18774 | init sampler, took 3.96 ms, tokens: text = 19326, total = 19326
slot update_slots: id  2 | task 18774 | created context checkpoint 5 of 8 (pos_min = 18389, pos_max = 19261, size = 20.471 MiB)
slot print_timing: id  2 | task 18774 | 
prompt eval time =     933.89 ms /   362 tokens (    2.58 ms per token,   387.63 tokens per second)
       eval time =   36644.91 ms /  1132 tokens (   32.37 ms per token,    30.89 tokens per second)
      total time =   37578.80 ms /  1494 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 18774 | stop processing: n_tokens = 20457, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 19908 | processing task, is_child = 0
slot update_slots: id  2 | task 19908 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 20500
slot update_slots: id  2 | task 19908 | n_tokens = 20426, memory_seq_rm [20426, end)
slot update_slots: id  2 | task 19908 | prompt processing progress, n_tokens = 20436, batch.n_tokens = 10, progress = 0.996878
slot update_slots: id  2 | task 19908 | n_tokens = 20436, memory_seq_rm [20436, end)
slot update_slots: id  2 | task 19908 | prompt processing progress, n_tokens = 20500, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 19908 | prompt done, n_tokens = 20500, batch.n_tokens = 64
slot init_sampler: id  2 | task 19908 | init sampler, took 3.96 ms, tokens: text = 20500, total = 20500
slot update_slots: id  2 | task 19908 | created context checkpoint 6 of 8 (pos_min = 19560, pos_max = 20435, size = 20.542 MiB)
slot print_timing: id  2 | task 19908 | 
prompt eval time =     396.56 ms /    74 tokens (    5.36 ms per token,   186.61 tokens per second)
       eval time =   18535.60 ms /   569 tokens (   32.58 ms per token,    30.70 tokens per second)
      total time =   18932.15 ms /   643 tokens
slot      release: id  2 | task 19908 | stop processing: n_tokens = 21068, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 20479 | processing task, is_child = 0
slot update_slots: id  2 | task 20479 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 21112
slot update_slots: id  2 | task 20479 | n_tokens = 20915, memory_seq_rm [20915, end)
slot update_slots: id  2 | task 20479 | prompt processing progress, n_tokens = 21048, batch.n_tokens = 133, progress = 0.996969
slot update_slots: id  2 | task 20479 | n_tokens = 21048, memory_seq_rm [21048, end)
slot update_slots: id  2 | task 20479 | prompt processing progress, n_tokens = 21112, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 20479 | prompt done, n_tokens = 21112, batch.n_tokens = 64
slot init_sampler: id  2 | task 20479 | init sampler, took 3.23 ms, tokens: text = 21112, total = 21112
slot update_slots: id  2 | task 20479 | created context checkpoint 7 of 8 (pos_min = 20171, pos_max = 21047, size = 20.565 MiB)
slot print_timing: id  2 | task 20479 | 
prompt eval time =     673.35 ms /   197 tokens (    3.42 ms per token,   292.57 tokens per second)
       eval time =    9240.32 ms /   279 tokens (   33.12 ms per token,    30.19 tokens per second)
      total time =    9913.67 ms /   476 tokens
slot      release: id  2 | task 20479 | stop processing: n_tokens = 21390, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 20760 | processing task, is_child = 0
slot update_slots: id  2 | task 20760 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 21434
slot update_slots: id  2 | task 20760 | n_tokens = 21144, memory_seq_rm [21144, end)
slot update_slots: id  2 | task 20760 | prompt processing progress, n_tokens = 21370, batch.n_tokens = 226, progress = 0.997014
slot update_slots: id  2 | task 20760 | n_tokens = 21370, memory_seq_rm [21370, end)
slot update_slots: id  2 | task 20760 | prompt processing progress, n_tokens = 21434, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 20760 | prompt done, n_tokens = 21434, batch.n_tokens = 64
slot init_sampler: id  2 | task 20760 | init sampler, took 2.93 ms, tokens: text = 21434, total = 21434
slot update_slots: id  2 | task 20760 | created context checkpoint 8 of 8 (pos_min = 20493, pos_max = 21369, size = 20.565 MiB)
slot print_timing: id  2 | task 20760 | 
prompt eval time =     828.69 ms /   290 tokens (    2.86 ms per token,   349.95 tokens per second)
       eval time =   10005.77 ms /   303 tokens (   33.02 ms per token,    30.28 tokens per second)
      total time =   10834.46 ms /   593 tokens
slot      release: id  2 | task 20760 | stop processing: n_tokens = 21736, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 21065 | processing task, is_child = 0
slot update_slots: id  2 | task 21065 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 21773
slot update_slots: id  2 | task 21065 | n_tokens = 21469, memory_seq_rm [21469, end)
slot update_slots: id  2 | task 21065 | prompt processing progress, n_tokens = 21709, batch.n_tokens = 240, progress = 0.997061
slot update_slots: id  2 | task 21065 | n_tokens = 21709, memory_seq_rm [21709, end)
slot update_slots: id  2 | task 21065 | prompt processing progress, n_tokens = 21773, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 21065 | prompt done, n_tokens = 21773, batch.n_tokens = 64
slot init_sampler: id  2 | task 21065 | init sampler, took 3.00 ms, tokens: text = 21773, total = 21773
slot update_slots: id  2 | task 21065 | erasing old context checkpoint (pos_min = 13274, pos_max = 14170, size = 21.034 MiB)
slot update_slots: id  2 | task 21065 | created context checkpoint 8 of 8 (pos_min = 20998, pos_max = 21708, size = 16.672 MiB)
slot print_timing: id  2 | task 21065 | 
prompt eval time =     877.13 ms /   304 tokens (    2.89 ms per token,   346.58 tokens per second)
       eval time =    4392.55 ms /   133 tokens (   33.03 ms per token,    30.28 tokens per second)
      total time =    5269.68 ms /   437 tokens
slot      release: id  2 | task 21065 | stop processing: n_tokens = 21905, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 21200 | processing task, is_child = 0
slot update_slots: id  2 | task 21200 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 21948
slot update_slots: id  2 | task 21200 | n_tokens = 21820, memory_seq_rm [21820, end)
slot update_slots: id  2 | task 21200 | prompt processing progress, n_tokens = 21884, batch.n_tokens = 64, progress = 0.997084
slot update_slots: id  2 | task 21200 | n_tokens = 21884, memory_seq_rm [21884, end)
slot update_slots: id  2 | task 21200 | prompt processing progress, n_tokens = 21948, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 21200 | prompt done, n_tokens = 21948, batch.n_tokens = 64
slot init_sampler: id  2 | task 21200 | init sampler, took 3.00 ms, tokens: text = 21948, total = 21948
slot update_slots: id  2 | task 21200 | erasing old context checkpoint (pos_min = 14531, pos_max = 15427, size = 21.034 MiB)
slot update_slots: id  2 | task 21200 | created context checkpoint 8 of 8 (pos_min = 21194, pos_max = 21883, size = 16.180 MiB)
slot print_timing: id  2 | task 21200 | 
prompt eval time =     599.97 ms /   128 tokens (    4.69 ms per token,   213.34 tokens per second)
       eval time =    1405.02 ms /    43 tokens (   32.67 ms per token,    30.60 tokens per second)
      total time =    2004.99 ms /   171 tokens
slot      release: id  2 | task 21200 | stop processing: n_tokens = 21990, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.965 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 21245 | processing task, is_child = 0
slot update_slots: id  2 | task 21245 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 22764
slot update_slots: id  2 | task 21245 | n_tokens = 21957, memory_seq_rm [21957, end)
slot update_slots: id  2 | task 21245 | prompt processing progress, n_tokens = 22700, batch.n_tokens = 743, progress = 0.997189
slot update_slots: id  2 | task 21245 | n_tokens = 22700, memory_seq_rm [22700, end)
slot update_slots: id  2 | task 21245 | prompt processing progress, n_tokens = 22764, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 21245 | prompt done, n_tokens = 22764, batch.n_tokens = 64
slot init_sampler: id  2 | task 21245 | init sampler, took 4.18 ms, tokens: text = 22764, total = 22764
slot update_slots: id  2 | task 21245 | erasing old context checkpoint (pos_min = 14974, pos_max = 15869, size = 21.011 MiB)
slot update_slots: id  2 | task 21245 | created context checkpoint 8 of 8 (pos_min = 21803, pos_max = 22699, size = 21.034 MiB)
slot print_timing: id  2 | task 21245 | 
prompt eval time =    1840.14 ms /   807 tokens (    2.28 ms per token,   438.55 tokens per second)
       eval time =    7640.99 ms /   234 tokens (   32.65 ms per token,    30.62 tokens per second)
      total time =    9481.12 ms /  1041 tokens
slot      release: id  2 | task 21245 | stop processing: n_tokens = 22997, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 21481 | processing task, is_child = 0
slot update_slots: id  2 | task 21481 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 23035
slot update_slots: id  2 | task 21481 | n_tokens = 22795, memory_seq_rm [22795, end)
slot update_slots: id  2 | task 21481 | prompt processing progress, n_tokens = 22971, batch.n_tokens = 176, progress = 0.997222
slot update_slots: id  2 | task 21481 | n_tokens = 22971, memory_seq_rm [22971, end)
slot update_slots: id  2 | task 21481 | prompt processing progress, n_tokens = 23035, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 21481 | prompt done, n_tokens = 23035, batch.n_tokens = 64
slot init_sampler: id  2 | task 21481 | init sampler, took 3.17 ms, tokens: text = 23035, total = 23035
slot update_slots: id  2 | task 21481 | erasing old context checkpoint (pos_min = 16396, pos_max = 17292, size = 21.034 MiB)
slot update_slots: id  2 | task 21481 | created context checkpoint 8 of 8 (pos_min = 22100, pos_max = 22970, size = 20.424 MiB)
slot print_timing: id  2 | task 21481 | 
prompt eval time =     752.36 ms /   240 tokens (    3.13 ms per token,   319.00 tokens per second)
       eval time =    6461.48 ms /   198 tokens (   32.63 ms per token,    30.64 tokens per second)
      total time =    7213.83 ms /   438 tokens
slot      release: id  2 | task 21481 | stop processing: n_tokens = 23232, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 21681 | processing task, is_child = 0
slot update_slots: id  2 | task 21681 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 23276
slot update_slots: id  2 | task 21681 | n_tokens = 23046, memory_seq_rm [23046, end)
slot update_slots: id  2 | task 21681 | prompt processing progress, n_tokens = 23212, batch.n_tokens = 166, progress = 0.997250
slot update_slots: id  2 | task 21681 | n_tokens = 23212, memory_seq_rm [23212, end)
slot update_slots: id  2 | task 21681 | prompt processing progress, n_tokens = 23276, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 21681 | prompt done, n_tokens = 23276, batch.n_tokens = 64
slot init_sampler: id  2 | task 21681 | init sampler, took 3.17 ms, tokens: text = 23276, total = 23276
slot update_slots: id  2 | task 21681 | erasing old context checkpoint (pos_min = 18389, pos_max = 19261, size = 20.471 MiB)
slot update_slots: id  2 | task 21681 | created context checkpoint 8 of 8 (pos_min = 22335, pos_max = 23211, size = 20.565 MiB)
slot print_timing: id  2 | task 21681 | 
prompt eval time =     712.46 ms /   230 tokens (    3.10 ms per token,   322.83 tokens per second)
       eval time =    5289.32 ms /   162 tokens (   32.65 ms per token,    30.63 tokens per second)
      total time =    6001.77 ms /   392 tokens
slot      release: id  2 | task 21681 | stop processing: n_tokens = 23437, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 21845 | processing task, is_child = 0
slot update_slots: id  2 | task 21845 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 23557
slot update_slots: id  2 | task 21845 | n_tokens = 23396, memory_seq_rm [23396, end)
slot update_slots: id  2 | task 21845 | prompt processing progress, n_tokens = 23493, batch.n_tokens = 97, progress = 0.997283
slot update_slots: id  2 | task 21845 | n_tokens = 23493, memory_seq_rm [23493, end)
slot update_slots: id  2 | task 21845 | prompt processing progress, n_tokens = 23557, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 21845 | prompt done, n_tokens = 23557, batch.n_tokens = 64
slot init_sampler: id  2 | task 21845 | init sampler, took 4.46 ms, tokens: text = 23557, total = 23557
slot update_slots: id  2 | task 21845 | erasing old context checkpoint (pos_min = 19560, pos_max = 20435, size = 20.542 MiB)
slot update_slots: id  2 | task 21845 | created context checkpoint 8 of 8 (pos_min = 22596, pos_max = 23492, size = 21.034 MiB)
slot print_timing: id  2 | task 21845 | 
prompt eval time =     639.16 ms /   161 tokens (    3.97 ms per token,   251.89 tokens per second)
       eval time =    3213.60 ms /    99 tokens (   32.46 ms per token,    30.81 tokens per second)
      total time =    3852.76 ms /   260 tokens
slot      release: id  2 | task 21845 | stop processing: n_tokens = 23655, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 21946 | processing task, is_child = 0
slot update_slots: id  2 | task 21946 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 23800
slot update_slots: id  2 | task 21946 | n_tokens = 23587, memory_seq_rm [23587, end)
slot update_slots: id  2 | task 21946 | prompt processing progress, n_tokens = 23736, batch.n_tokens = 149, progress = 0.997311
slot update_slots: id  2 | task 21946 | n_tokens = 23736, memory_seq_rm [23736, end)
slot update_slots: id  2 | task 21946 | prompt processing progress, n_tokens = 23800, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 21946 | prompt done, n_tokens = 23800, batch.n_tokens = 64
slot init_sampler: id  2 | task 21946 | init sampler, took 3.25 ms, tokens: text = 23800, total = 23800
slot update_slots: id  2 | task 21946 | erasing old context checkpoint (pos_min = 20171, pos_max = 21047, size = 20.565 MiB)
slot update_slots: id  2 | task 21946 | created context checkpoint 8 of 8 (pos_min = 22839, pos_max = 23735, size = 21.034 MiB)
slot print_timing: id  2 | task 21946 | 
prompt eval time =     679.82 ms /   213 tokens (    3.19 ms per token,   313.32 tokens per second)
       eval time =    3436.31 ms /   107 tokens (   32.12 ms per token,    31.14 tokens per second)
      total time =    4116.12 ms /   320 tokens
slot      release: id  2 | task 21946 | stop processing: n_tokens = 23906, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.037
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 23906, total state size = 581.605 MiB
srv          load:  - looking for better prompt, base f_keep = 0.037, sim = 0.985
srv        update:  - cache state: 7 prompts, 3324.868 MiB (limits: 8192.000 MiB, 56064 tokens, 210334 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv        update:    - prompt 0x58dc3fb8c770:    5127 tokens, checkpoints:  8,   320.808 MiB
srv        update:    - prompt 0x58dc3f318830:   24865 tokens, checkpoints:  8,   791.874 MiB
srv        update:    - prompt 0x58dc40d3cf50:   16080 tokens, checkpoints:  8,   571.219 MiB
srv        update:    - prompt 0x58dc4c8ce8a0:   23906 tokens, checkpoints:  8,   739.114 MiB
srv  get_availabl: prompt cache update took 1068.79 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 22055 | processing task, is_child = 0
slot update_slots: id  2 | task 22055 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 895
slot update_slots: id  2 | task 22055 | n_past = 882, slot.prompt.tokens.size() = 23906, seq_id = 2, pos_min = 23009, n_swa = 128
slot update_slots: id  2 | task 22055 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  2 | task 22055 | erased invalidated context checkpoint (pos_min = 20493, pos_max = 21369, n_swa = 128, size = 20.565 MiB)
slot update_slots: id  2 | task 22055 | erased invalidated context checkpoint (pos_min = 20998, pos_max = 21708, n_swa = 128, size = 16.672 MiB)
slot update_slots: id  2 | task 22055 | erased invalidated context checkpoint (pos_min = 21194, pos_max = 21883, n_swa = 128, size = 16.180 MiB)
slot update_slots: id  2 | task 22055 | erased invalidated context checkpoint (pos_min = 21803, pos_max = 22699, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 22055 | erased invalidated context checkpoint (pos_min = 22100, pos_max = 22970, n_swa = 128, size = 20.424 MiB)
slot update_slots: id  2 | task 22055 | erased invalidated context checkpoint (pos_min = 22335, pos_max = 23211, n_swa = 128, size = 20.565 MiB)
slot update_slots: id  2 | task 22055 | erased invalidated context checkpoint (pos_min = 22596, pos_max = 23492, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 22055 | erased invalidated context checkpoint (pos_min = 22839, pos_max = 23735, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 22055 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 22055 | prompt processing progress, n_tokens = 831, batch.n_tokens = 831, progress = 0.928492
slot update_slots: id  2 | task 22055 | n_tokens = 831, memory_seq_rm [831, end)
slot update_slots: id  2 | task 22055 | prompt processing progress, n_tokens = 895, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 22055 | prompt done, n_tokens = 895, batch.n_tokens = 64
slot init_sampler: id  2 | task 22055 | init sampler, took 0.17 ms, tokens: text = 895, total = 895
slot update_slots: id  2 | task 22055 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 830, size = 19.486 MiB)
slot print_timing: id  2 | task 22055 | 
prompt eval time =    1820.63 ms /   895 tokens (    2.03 ms per token,   491.59 tokens per second)
       eval time =   11620.49 ms /   349 tokens (   33.30 ms per token,    30.03 tokens per second)
      total time =   13441.12 ms /  1244 tokens
slot      release: id  2 | task 22055 | stop processing: n_tokens = 1243, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.857 (> 0.100 thold), f_keep = 0.721
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 22406 | processing task, is_child = 0
slot update_slots: id  2 | task 22406 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1045
slot update_slots: id  2 | task 22406 | n_tokens = 896, memory_seq_rm [896, end)
slot update_slots: id  2 | task 22406 | prompt processing progress, n_tokens = 981, batch.n_tokens = 85, progress = 0.938756
slot update_slots: id  2 | task 22406 | n_tokens = 981, memory_seq_rm [981, end)
slot update_slots: id  2 | task 22406 | prompt processing progress, n_tokens = 1045, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 22406 | prompt done, n_tokens = 1045, batch.n_tokens = 64
slot init_sampler: id  2 | task 22406 | init sampler, took 0.15 ms, tokens: text = 1045, total = 1045
slot update_slots: id  2 | task 22406 | created context checkpoint 2 of 8 (pos_min = 346, pos_max = 980, size = 14.890 MiB)
slot print_timing: id  2 | task 22406 | 
prompt eval time =     651.59 ms /   149 tokens (    4.37 ms per token,   228.67 tokens per second)
       eval time =   24653.09 ms /   716 tokens (   34.43 ms per token,    29.04 tokens per second)
      total time =   25304.68 ms /   865 tokens
slot      release: id  2 | task 22406 | stop processing: n_tokens = 1760, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.852 (> 0.100 thold), f_keep = 0.984
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 23124 | processing task, is_child = 0
slot update_slots: id  2 | task 23124 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2033
slot update_slots: id  2 | task 23124 | n_tokens = 1732, memory_seq_rm [1732, end)
slot update_slots: id  2 | task 23124 | prompt processing progress, n_tokens = 1969, batch.n_tokens = 237, progress = 0.968519
slot update_slots: id  2 | task 23124 | n_tokens = 1969, memory_seq_rm [1969, end)
slot update_slots: id  2 | task 23124 | prompt processing progress, n_tokens = 2033, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 23124 | prompt done, n_tokens = 2033, batch.n_tokens = 64
slot init_sampler: id  2 | task 23124 | init sampler, took 0.28 ms, tokens: text = 2033, total = 2033
slot update_slots: id  2 | task 23124 | created context checkpoint 3 of 8 (pos_min = 1072, pos_max = 1968, size = 21.034 MiB)
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.950 (> 0.100 thold), f_keep = 0.047
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 18675, total state size = 440.888 MiB
srv          load:  - looking for better prompt, base f_keep = 0.047, sim = 0.950
srv        update:  - cache state: 8 prompts, 3931.073 MiB (limits: 8192.000 MiB, 56064 tokens, 216816 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv        update:    - prompt 0x58dc3fb8c770:    5127 tokens, checkpoints:  8,   320.808 MiB
srv        update:    - prompt 0x58dc3f318830:   24865 tokens, checkpoints:  8,   791.874 MiB
srv        update:    - prompt 0x58dc40d3cf50:   16080 tokens, checkpoints:  8,   571.219 MiB
srv        update:    - prompt 0x58dc4c8ce8a0:   23906 tokens, checkpoints:  8,   739.114 MiB
srv        update:    - prompt 0x58dc38d9f350:   18675 tokens, checkpoints:  8,   606.205 MiB
srv  get_availabl: prompt cache update took 1417.48 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 23648 | processing task, is_child = 0
slot update_slots: id  3 | task 23648 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 927
slot update_slots: id  3 | task 23648 | n_past = 881, slot.prompt.tokens.size() = 18675, seq_id = 3, pos_min = 18548, n_swa = 128
slot update_slots: id  3 | task 23648 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  3 | task 23648 | erased invalidated context checkpoint (pos_min = 5999, pos_max = 6863, n_swa = 128, size = 20.284 MiB)
slot update_slots: id  3 | task 23648 | erased invalidated context checkpoint (pos_min = 8100, pos_max = 8995, n_swa = 128, size = 21.011 MiB)
slot update_slots: id  3 | task 23648 | erased invalidated context checkpoint (pos_min = 10048, pos_max = 10944, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  3 | task 23648 | erased invalidated context checkpoint (pos_min = 12106, pos_max = 13002, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  3 | task 23648 | erased invalidated context checkpoint (pos_min = 12451, pos_max = 13279, n_swa = 128, size = 19.439 MiB)
slot update_slots: id  3 | task 23648 | erased invalidated context checkpoint (pos_min = 13000, pos_max = 13871, n_swa = 128, size = 20.448 MiB)
slot update_slots: id  3 | task 23648 | erased invalidated context checkpoint (pos_min = 14506, pos_max = 15402, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  3 | task 23648 | erased invalidated context checkpoint (pos_min = 16557, pos_max = 17453, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  3 | task 23648 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  3 | task 23648 | prompt processing progress, n_tokens = 863, batch.n_tokens = 864, progress = 0.930960
slot update_slots: id  3 | task 23648 | n_tokens = 863, memory_seq_rm [863, end)
slot update_slots: id  3 | task 23648 | prompt processing progress, n_tokens = 927, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 23648 | prompt done, n_tokens = 927, batch.n_tokens = 65
slot init_sampler: id  3 | task 23648 | init sampler, took 0.20 ms, tokens: text = 927, total = 927
slot update_slots: id  3 | task 23648 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 862, size = 20.237 MiB)
slot print_timing: id  2 | task 23124 | 
prompt eval time =     903.49 ms /   301 tokens (    3.00 ms per token,   333.15 tokens per second)
       eval time =   22201.51 ms /   546 tokens (   40.66 ms per token,    24.59 tokens per second)
      total time =   23105.00 ms /   847 tokens
slot      release: id  2 | task 23124 | stop processing: n_tokens = 2578, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  3 | task 23648 | 
prompt eval time =    1630.08 ms /   927 tokens (    1.76 ms per token,   568.68 tokens per second)
       eval time =    1657.64 ms /    37 tokens (   44.80 ms per token,    22.32 tokens per second)
      total time =    3287.72 ms /   964 tokens
slot      release: id  3 | task 23648 | stop processing: n_tokens = 963, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.638 (> 0.100 thold), f_keep = 0.975
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 23687 | processing task, is_child = 0
slot update_slots: id  3 | task 23687 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1471
slot update_slots: id  3 | task 23687 | n_tokens = 939, memory_seq_rm [939, end)
slot update_slots: id  3 | task 23687 | prompt processing progress, n_tokens = 1407, batch.n_tokens = 468, progress = 0.956492
slot update_slots: id  3 | task 23687 | n_tokens = 1407, memory_seq_rm [1407, end)
slot update_slots: id  3 | task 23687 | prompt processing progress, n_tokens = 1471, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 23687 | prompt done, n_tokens = 1471, batch.n_tokens = 64
slot init_sampler: id  3 | task 23687 | init sampler, took 0.27 ms, tokens: text = 1471, total = 1471
slot update_slots: id  3 | task 23687 | created context checkpoint 2 of 8 (pos_min = 533, pos_max = 1406, size = 20.495 MiB)
slot print_timing: id  3 | task 23687 | 
prompt eval time =     940.05 ms /   532 tokens (    1.77 ms per token,   565.93 tokens per second)
       eval time =    6799.60 ms /   221 tokens (   30.77 ms per token,    32.50 tokens per second)
      total time =    7739.64 ms /   753 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 23687 | stop processing: n_tokens = 1691, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.847 (> 0.100 thold), f_keep = 0.885
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 23910 | processing task, is_child = 0
slot update_slots: id  3 | task 23910 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1767
slot update_slots: id  3 | task 23910 | n_tokens = 1496, memory_seq_rm [1496, end)
slot update_slots: id  3 | task 23910 | prompt processing progress, n_tokens = 1703, batch.n_tokens = 207, progress = 0.963780
slot update_slots: id  3 | task 23910 | n_tokens = 1703, memory_seq_rm [1703, end)
slot update_slots: id  3 | task 23910 | prompt processing progress, n_tokens = 1767, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 23910 | prompt done, n_tokens = 1767, batch.n_tokens = 64
slot init_sampler: id  3 | task 23910 | init sampler, took 0.31 ms, tokens: text = 1767, total = 1767
slot update_slots: id  3 | task 23910 | created context checkpoint 3 of 8 (pos_min = 879, pos_max = 1702, size = 19.322 MiB)
slot print_timing: id  3 | task 23910 | 
prompt eval time =     670.80 ms /   271 tokens (    2.48 ms per token,   403.99 tokens per second)
       eval time =    1398.01 ms /    42 tokens (   33.29 ms per token,    30.04 tokens per second)
      total time =    2068.82 ms /   313 tokens
slot      release: id  3 | task 23910 | stop processing: n_tokens = 1808, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.539 (> 0.100 thold), f_keep = 0.983
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 23954 | processing task, is_child = 0
slot update_slots: id  3 | task 23954 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 3297
slot update_slots: id  3 | task 23954 | n_tokens = 1777, memory_seq_rm [1777, end)
slot update_slots: id  3 | task 23954 | prompt processing progress, n_tokens = 3233, batch.n_tokens = 1456, progress = 0.980588
slot update_slots: id  3 | task 23954 | n_tokens = 3233, memory_seq_rm [3233, end)
slot update_slots: id  3 | task 23954 | prompt processing progress, n_tokens = 3297, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 23954 | prompt done, n_tokens = 3297, batch.n_tokens = 64
slot init_sampler: id  3 | task 23954 | init sampler, took 0.64 ms, tokens: text = 3297, total = 3297
slot update_slots: id  3 | task 23954 | created context checkpoint 4 of 8 (pos_min = 2336, pos_max = 3232, size = 21.034 MiB)
slot print_timing: id  3 | task 23954 | 
prompt eval time =    2326.55 ms /  1520 tokens (    1.53 ms per token,   653.33 tokens per second)
       eval time =    1877.12 ms /    62 tokens (   30.28 ms per token,    33.03 tokens per second)
      total time =    4203.67 ms /  1582 tokens
slot      release: id  3 | task 23954 | stop processing: n_tokens = 3358, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.617 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 24018 | processing task, is_child = 0
slot update_slots: id  3 | task 24018 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 5390
slot update_slots: id  3 | task 24018 | n_tokens = 3328, memory_seq_rm [3328, end)
slot update_slots: id  3 | task 24018 | prompt processing progress, n_tokens = 5326, batch.n_tokens = 1998, progress = 0.988126
slot update_slots: id  3 | task 24018 | n_tokens = 5326, memory_seq_rm [5326, end)
slot update_slots: id  3 | task 24018 | prompt processing progress, n_tokens = 5390, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 24018 | prompt done, n_tokens = 5390, batch.n_tokens = 64
slot init_sampler: id  3 | task 24018 | init sampler, took 1.09 ms, tokens: text = 5390, total = 5390
slot update_slots: id  3 | task 24018 | created context checkpoint 5 of 8 (pos_min = 4429, pos_max = 5325, size = 21.034 MiB)
slot print_timing: id  3 | task 24018 | 
prompt eval time =    3056.96 ms /  2062 tokens (    1.48 ms per token,   674.53 tokens per second)
       eval time =    1164.29 ms /    40 tokens (   29.11 ms per token,    34.36 tokens per second)
      total time =    4221.25 ms /  2102 tokens
slot      release: id  3 | task 24018 | stop processing: n_tokens = 5429, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.689 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 24060 | processing task, is_child = 0
slot update_slots: id  3 | task 24060 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 7832
slot update_slots: id  3 | task 24060 | n_tokens = 5399, memory_seq_rm [5399, end)
slot update_slots: id  3 | task 24060 | prompt processing progress, n_tokens = 7447, batch.n_tokens = 2048, progress = 0.950843
slot update_slots: id  3 | task 24060 | n_tokens = 7447, memory_seq_rm [7447, end)
slot update_slots: id  3 | task 24060 | prompt processing progress, n_tokens = 7768, batch.n_tokens = 321, progress = 0.991828
slot update_slots: id  3 | task 24060 | n_tokens = 7768, memory_seq_rm [7768, end)
slot update_slots: id  3 | task 24060 | prompt processing progress, n_tokens = 7832, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 24060 | prompt done, n_tokens = 7832, batch.n_tokens = 64
slot init_sampler: id  3 | task 24060 | init sampler, took 1.51 ms, tokens: text = 7832, total = 7832
slot update_slots: id  3 | task 24060 | created context checkpoint 6 of 8 (pos_min = 6871, pos_max = 7767, size = 21.034 MiB)
slot print_timing: id  3 | task 24060 | 
prompt eval time =    3641.48 ms /  2433 tokens (    1.50 ms per token,   668.14 tokens per second)
       eval time =    9048.53 ms /   313 tokens (   28.91 ms per token,    34.59 tokens per second)
      total time =   12690.01 ms /  2746 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 24060 | stop processing: n_tokens = 8144, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.954 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 24376 | processing task, is_child = 0
slot update_slots: id  3 | task 24376 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 8501
slot update_slots: id  3 | task 24376 | n_tokens = 8110, memory_seq_rm [8110, end)
slot update_slots: id  3 | task 24376 | prompt processing progress, n_tokens = 8437, batch.n_tokens = 327, progress = 0.992471
slot update_slots: id  3 | task 24376 | n_tokens = 8437, memory_seq_rm [8437, end)
slot update_slots: id  3 | task 24376 | prompt processing progress, n_tokens = 8501, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 24376 | prompt done, n_tokens = 8501, batch.n_tokens = 64
slot init_sampler: id  3 | task 24376 | init sampler, took 1.64 ms, tokens: text = 8501, total = 8501
slot update_slots: id  3 | task 24376 | created context checkpoint 7 of 8 (pos_min = 7540, pos_max = 8436, size = 21.034 MiB)
slot print_timing: id  3 | task 24376 | 
prompt eval time =     721.81 ms /   391 tokens (    1.85 ms per token,   541.69 tokens per second)
       eval time =    3518.32 ms /   121 tokens (   29.08 ms per token,    34.39 tokens per second)
      total time =    4240.13 ms /   512 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 24376 | stop processing: n_tokens = 8621, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.821 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 24499 | processing task, is_child = 0
slot update_slots: id  3 | task 24499 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 10469
slot update_slots: id  3 | task 24499 | n_tokens = 8590, memory_seq_rm [8590, end)
slot update_slots: id  3 | task 24499 | prompt processing progress, n_tokens = 10405, batch.n_tokens = 1815, progress = 0.993887
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.853 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 24501 | processing task, is_child = 0
slot update_slots: id  2 | task 24501 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2995
slot update_slots: id  2 | task 24501 | n_past = 2554, slot.prompt.tokens.size() = 2578, seq_id = 2, pos_min = 2451, n_swa = 128
slot update_slots: id  2 | task 24501 | restored context checkpoint (pos_min = 1072, pos_max = 1968, size = 21.034 MiB)
slot update_slots: id  2 | task 24501 | n_tokens = 1968, memory_seq_rm [1968, end)
slot update_slots: id  2 | task 24501 | prompt processing progress, n_tokens = 2931, batch.n_tokens = 963, progress = 0.978631
slot update_slots: id  3 | task 24499 | n_tokens = 10405, memory_seq_rm [10405, end)
slot update_slots: id  3 | task 24499 | prompt processing progress, n_tokens = 10469, batch.n_tokens = 1027, progress = 1.000000
slot update_slots: id  3 | task 24499 | prompt done, n_tokens = 10469, batch.n_tokens = 1027
slot init_sampler: id  3 | task 24499 | init sampler, took 1.44 ms, tokens: text = 10469, total = 10469
slot update_slots: id  3 | task 24499 | created context checkpoint 8 of 8 (pos_min = 10278, pos_max = 10404, size = 2.978 MiB)
slot update_slots: id  2 | task 24501 | n_tokens = 2931, memory_seq_rm [2931, end)
slot update_slots: id  2 | task 24501 | prompt processing progress, n_tokens = 2995, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  2 | task 24501 | prompt done, n_tokens = 2995, batch.n_tokens = 65
slot init_sampler: id  2 | task 24501 | init sampler, took 0.51 ms, tokens: text = 2995, total = 2995
slot update_slots: id  2 | task 24501 | created context checkpoint 4 of 8 (pos_min = 2098, pos_max = 2930, size = 19.533 MiB)
slot print_timing: id  3 | task 24499 | 
prompt eval time =    4024.39 ms /  1879 tokens (    2.14 ms per token,   466.90 tokens per second)
       eval time =    2296.05 ms /    43 tokens (   53.40 ms per token,    18.73 tokens per second)
      total time =    6320.43 ms /  1922 tokens
slot      release: id  3 | task 24499 | stop processing: n_tokens = 10511, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  2 | task 24501 | 
prompt eval time =    2169.73 ms /  1027 tokens (    2.11 ms per token,   473.33 tokens per second)
       eval time =    2191.70 ms /    47 tokens (   46.63 ms per token,    21.44 tokens per second)
      total time =    4361.43 ms /  1074 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 24501 | stop processing: n_tokens = 3041, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.836 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 24550 | processing task, is_child = 0
slot update_slots: id  3 | task 24550 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 12529
slot update_slots: id  3 | task 24550 | n_tokens = 10480, memory_seq_rm [10480, end)
slot update_slots: id  3 | task 24550 | prompt processing progress, n_tokens = 12465, batch.n_tokens = 1985, progress = 0.994892
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.884 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 24552 | processing task, is_child = 0
slot update_slots: id  2 | task 24552 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 3409
slot update_slots: id  2 | task 24552 | n_past = 3015, slot.prompt.tokens.size() = 3041, seq_id = 2, pos_min = 2914, n_swa = 128
slot update_slots: id  2 | task 24552 | restored context checkpoint (pos_min = 2098, pos_max = 2930, size = 19.533 MiB)
slot update_slots: id  2 | task 24552 | n_tokens = 2930, memory_seq_rm [2930, end)
slot update_slots: id  2 | task 24552 | prompt processing progress, n_tokens = 3345, batch.n_tokens = 415, progress = 0.981226
slot update_slots: id  3 | task 24550 | n_tokens = 12465, memory_seq_rm [12465, end)
slot update_slots: id  3 | task 24550 | prompt processing progress, n_tokens = 12529, batch.n_tokens = 479, progress = 1.000000
slot update_slots: id  3 | task 24550 | prompt done, n_tokens = 12529, batch.n_tokens = 479
slot init_sampler: id  3 | task 24550 | init sampler, took 1.71 ms, tokens: text = 12529, total = 12529
slot update_slots: id  3 | task 24550 | erasing old context checkpoint (pos_min = 0, pos_max = 862, size = 20.237 MiB)
slot update_slots: id  3 | task 24550 | created context checkpoint 8 of 8 (pos_min = 12338, pos_max = 12464, size = 2.978 MiB)
slot update_slots: id  2 | task 24552 | n_tokens = 3345, memory_seq_rm [3345, end)
slot update_slots: id  2 | task 24552 | prompt processing progress, n_tokens = 3409, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  2 | task 24552 | prompt done, n_tokens = 3409, batch.n_tokens = 65
slot init_sampler: id  2 | task 24552 | init sampler, took 0.56 ms, tokens: text = 3409, total = 3409
slot update_slots: id  2 | task 24552 | created context checkpoint 5 of 8 (pos_min = 2803, pos_max = 3344, size = 12.710 MiB)
slot print_timing: id  3 | task 24550 | 
prompt eval time =    3469.14 ms /  2049 tokens (    1.69 ms per token,   590.64 tokens per second)
       eval time =    2438.23 ms /    44 tokens (   55.41 ms per token,    18.05 tokens per second)
      total time =    5907.37 ms /  2093 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 24550 | stop processing: n_tokens = 12572, truncated = 0
slot print_timing: id  2 | task 24552 | 
prompt eval time =    1602.56 ms /   479 tokens (    3.35 ms per token,   298.90 tokens per second)
       eval time =    2322.45 ms /    48 tokens (   48.38 ms per token,    20.67 tokens per second)
      total time =    3925.01 ms /   527 tokens
slot      release: id  2 | task 24552 | stop processing: n_tokens = 3456, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.979 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 24602 | processing task, is_child = 0
slot update_slots: id  3 | task 24602 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 12805
slot update_slots: id  3 | task 24602 | n_tokens = 12537, memory_seq_rm [12537, end)
slot update_slots: id  3 | task 24602 | prompt processing progress, n_tokens = 12741, batch.n_tokens = 204, progress = 0.995002
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.958 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 24604 | processing task, is_child = 0
slot update_slots: id  2 | task 24604 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 3581
slot update_slots: id  2 | task 24604 | n_tokens = 3430, memory_seq_rm [3430, end)
slot update_slots: id  2 | task 24604 | prompt processing progress, n_tokens = 3517, batch.n_tokens = 87, progress = 0.982128
slot update_slots: id  3 | task 24602 | n_tokens = 12741, memory_seq_rm [12741, end)
slot update_slots: id  3 | task 24602 | prompt processing progress, n_tokens = 12805, batch.n_tokens = 151, progress = 1.000000
slot update_slots: id  3 | task 24602 | prompt done, n_tokens = 12805, batch.n_tokens = 151
slot init_sampler: id  3 | task 24602 | init sampler, took 2.42 ms, tokens: text = 12805, total = 12805
slot update_slots: id  3 | task 24602 | erasing old context checkpoint (pos_min = 533, pos_max = 1406, size = 20.495 MiB)
slot update_slots: id  3 | task 24602 | created context checkpoint 8 of 8 (pos_min = 12338, pos_max = 12740, size = 9.450 MiB)
slot update_slots: id  2 | task 24604 | n_tokens = 3517, memory_seq_rm [3517, end)
slot update_slots: id  2 | task 24604 | prompt processing progress, n_tokens = 3581, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  2 | task 24604 | prompt done, n_tokens = 3581, batch.n_tokens = 65
slot init_sampler: id  2 | task 24604 | init sampler, took 0.68 ms, tokens: text = 3581, total = 3581
slot update_slots: id  2 | task 24604 | created context checkpoint 6 of 8 (pos_min = 3024, pos_max = 3516, size = 11.561 MiB)
slot print_timing: id  2 | task 24604 | 
prompt eval time =     938.90 ms /   151 tokens (    6.22 ms per token,   160.83 tokens per second)
       eval time =    2348.93 ms /    47 tokens (   49.98 ms per token,    20.01 tokens per second)
      total time =    3287.82 ms /   198 tokens
slot      release: id  2 | task 24604 | stop processing: n_tokens = 3627, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.976 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 24661 | processing task, is_child = 0
slot update_slots: id  2 | task 24661 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 3699
slot update_slots: id  2 | task 24661 | n_tokens = 3611, memory_seq_rm [3611, end)
slot update_slots: id  2 | task 24661 | prompt processing progress, n_tokens = 3635, batch.n_tokens = 25, progress = 0.982698
slot update_slots: id  2 | task 24661 | n_tokens = 3635, memory_seq_rm [3635, end)
slot update_slots: id  2 | task 24661 | prompt processing progress, n_tokens = 3699, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  2 | task 24661 | prompt done, n_tokens = 3699, batch.n_tokens = 65
slot init_sampler: id  2 | task 24661 | init sampler, took 0.63 ms, tokens: text = 3699, total = 3699
slot update_slots: id  2 | task 24661 | created context checkpoint 7 of 8 (pos_min = 3198, pos_max = 3634, size = 10.247 MiB)
slot print_timing: id  3 | task 24602 | 
prompt eval time =     707.88 ms /   268 tokens (    2.64 ms per token,   378.60 tokens per second)
       eval time =    4021.22 ms /    73 tokens (   55.09 ms per token,    18.15 tokens per second)
      total time =    4729.09 ms /   341 tokens
slot      release: id  3 | task 24602 | stop processing: n_tokens = 12877, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 24691 | processing task, is_child = 0
slot update_slots: id  3 | task 24691 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 12928
slot update_slots: id  3 | task 24691 | n_tokens = 12843, memory_seq_rm [12843, end)
slot update_slots: id  3 | task 24691 | prompt processing progress, n_tokens = 12864, batch.n_tokens = 22, progress = 0.995049
slot update_slots: id  3 | task 24691 | n_tokens = 12864, memory_seq_rm [12864, end)
slot update_slots: id  3 | task 24691 | prompt processing progress, n_tokens = 12928, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 24691 | prompt done, n_tokens = 12928, batch.n_tokens = 65
slot init_sampler: id  3 | task 24691 | init sampler, took 1.78 ms, tokens: text = 12928, total = 12928
slot update_slots: id  3 | task 24691 | erasing old context checkpoint (pos_min = 879, pos_max = 1702, size = 19.322 MiB)
slot update_slots: id  3 | task 24691 | created context checkpoint 8 of 8 (pos_min = 12614, pos_max = 12863, size = 5.863 MiB)
slot print_timing: id  3 | task 24691 | 
prompt eval time =     380.93 ms /    85 tokens (    4.48 ms per token,   223.14 tokens per second)
       eval time =    1568.82 ms /    32 tokens (   49.03 ms per token,    20.40 tokens per second)
      total time =    1949.75 ms /   117 tokens
slot      release: id  3 | task 24691 | stop processing: n_tokens = 12959, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.979 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 24737 | processing task, is_child = 0
slot update_slots: id  3 | task 24737 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13210
slot update_slots: id  3 | task 24737 | n_tokens = 12928, memory_seq_rm [12928, end)
slot update_slots: id  3 | task 24737 | prompt processing progress, n_tokens = 13146, batch.n_tokens = 219, progress = 0.995155
slot update_slots: id  3 | task 24737 | n_tokens = 13146, memory_seq_rm [13146, end)
slot update_slots: id  3 | task 24737 | prompt processing progress, n_tokens = 13210, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 24737 | prompt done, n_tokens = 13210, batch.n_tokens = 65
slot init_sampler: id  3 | task 24737 | init sampler, took 2.39 ms, tokens: text = 13210, total = 13210
slot update_slots: id  3 | task 24737 | erasing old context checkpoint (pos_min = 2336, pos_max = 3232, size = 21.034 MiB)
slot update_slots: id  3 | task 24737 | created context checkpoint 8 of 8 (pos_min = 12614, pos_max = 13145, size = 12.475 MiB)
slot print_timing: id  2 | task 24661 | 
prompt eval time =     383.77 ms /    88 tokens (    4.36 ms per token,   229.30 tokens per second)
       eval time =   15986.22 ms /   301 tokens (   53.11 ms per token,    18.83 tokens per second)
      total time =   16369.99 ms /   389 tokens
slot      release: id  2 | task 24661 | stop processing: n_tokens = 3999, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.922 (> 0.100 thold), f_keep = 0.929
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 24976 | processing task, is_child = 0
slot update_slots: id  2 | task 24976 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 4030
slot update_slots: id  2 | task 24976 | n_past = 3716, slot.prompt.tokens.size() = 3999, seq_id = 2, pos_min = 3598, n_swa = 128
slot update_slots: id  2 | task 24976 | restored context checkpoint (pos_min = 3198, pos_max = 3634, size = 10.247 MiB)
slot update_slots: id  2 | task 24976 | n_tokens = 3634, memory_seq_rm [3634, end)
slot update_slots: id  2 | task 24976 | prompt processing progress, n_tokens = 3966, batch.n_tokens = 333, progress = 0.984119
slot update_slots: id  2 | task 24976 | n_tokens = 3966, memory_seq_rm [3966, end)
slot update_slots: id  2 | task 24976 | prompt processing progress, n_tokens = 4030, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  2 | task 24976 | prompt done, n_tokens = 4030, batch.n_tokens = 65
slot init_sampler: id  2 | task 24976 | init sampler, took 0.69 ms, tokens: text = 4030, total = 4030
slot update_slots: id  2 | task 24976 | created context checkpoint 8 of 8 (pos_min = 3345, pos_max = 3965, size = 14.562 MiB)
slot print_timing: id  2 | task 24976 | 
prompt eval time =     897.30 ms /   396 tokens (    2.27 ms per token,   441.32 tokens per second)
       eval time =    2436.46 ms /    47 tokens (   51.84 ms per token,    19.29 tokens per second)
      total time =    3333.76 ms /   443 tokens
slot      release: id  2 | task 24976 | stop processing: n_tokens = 4076, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.721 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 25036 | processing task, is_child = 0
slot update_slots: id  2 | task 25036 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 5619
slot update_slots: id  2 | task 25036 | n_tokens = 4050, memory_seq_rm [4050, end)
slot update_slots: id  2 | task 25036 | prompt processing progress, n_tokens = 5555, batch.n_tokens = 1506, progress = 0.988610
slot update_slots: id  2 | task 25036 | n_tokens = 5555, memory_seq_rm [5555, end)
slot update_slots: id  2 | task 25036 | prompt processing progress, n_tokens = 5619, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  2 | task 25036 | prompt done, n_tokens = 5619, batch.n_tokens = 65
slot init_sampler: id  2 | task 25036 | init sampler, took 3.41 ms, tokens: text = 5619, total = 5619
slot update_slots: id  2 | task 25036 | erasing old context checkpoint (pos_min = 0, pos_max = 830, size = 19.486 MiB)
slot update_slots: id  2 | task 25036 | created context checkpoint 8 of 8 (pos_min = 4658, pos_max = 5554, size = 21.034 MiB)
slot print_timing: id  2 | task 25036 | 
prompt eval time =    2489.07 ms /  1569 tokens (    1.59 ms per token,   630.36 tokens per second)
       eval time =   10864.99 ms /   209 tokens (   51.99 ms per token,    19.24 tokens per second)
      total time =   13354.06 ms /  1778 tokens
slot      release: id  2 | task 25036 | stop processing: n_tokens = 5827, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 25258 | processing task, is_child = 0
slot update_slots: id  2 | task 25258 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 5871
slot update_slots: id  2 | task 25258 | n_tokens = 5805, memory_seq_rm [5805, end)
slot update_slots: id  2 | task 25258 | prompt processing progress, n_tokens = 5807, batch.n_tokens = 3, progress = 0.989099
slot update_slots: id  2 | task 25258 | n_tokens = 5807, memory_seq_rm [5807, end)
slot update_slots: id  2 | task 25258 | prompt processing progress, n_tokens = 5871, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  2 | task 25258 | prompt done, n_tokens = 5871, batch.n_tokens = 65
slot init_sampler: id  2 | task 25258 | init sampler, took 1.04 ms, tokens: text = 5871, total = 5871
slot update_slots: id  2 | task 25258 | erasing old context checkpoint (pos_min = 346, pos_max = 980, size = 14.890 MiB)
slot update_slots: id  2 | task 25258 | created context checkpoint 8 of 8 (pos_min = 5093, pos_max = 5806, size = 16.743 MiB)
slot print_timing: id  2 | task 25258 | 
prompt eval time =     396.04 ms /    66 tokens (    6.00 ms per token,   166.65 tokens per second)
       eval time =    1513.09 ms /    29 tokens (   52.18 ms per token,    19.17 tokens per second)
      total time =    1909.13 ms /    95 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 25258 | stop processing: n_tokens = 5899, truncated = 0
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 25316 | processing task, is_child = 0
slot update_slots: id  2 | task 25316 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 5965
slot update_slots: id  2 | task 25316 | n_tokens = 5881, memory_seq_rm [5881, end)
slot update_slots: id  2 | task 25316 | prompt processing progress, n_tokens = 5901, batch.n_tokens = 21, progress = 0.989271
slot update_slots: id  2 | task 25316 | n_tokens = 5901, memory_seq_rm [5901, end)
slot update_slots: id  2 | task 25316 | prompt processing progress, n_tokens = 5965, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  2 | task 25316 | prompt done, n_tokens = 5965, batch.n_tokens = 65
slot init_sampler: id  2 | task 25316 | init sampler, took 1.13 ms, tokens: text = 5965, total = 5965
slot update_slots: id  2 | task 25316 | erasing old context checkpoint (pos_min = 1072, pos_max = 1968, size = 21.034 MiB)
slot update_slots: id  2 | task 25316 | created context checkpoint 8 of 8 (pos_min = 5225, pos_max = 5900, size = 15.852 MiB)
slot print_timing: id  3 | task 24737 | 
prompt eval time =     726.20 ms /   282 tokens (    2.58 ms per token,   388.32 tokens per second)
       eval time =   33978.00 ms /   601 tokens (   56.54 ms per token,    17.69 tokens per second)
      total time =   34704.21 ms /   883 tokens
slot      release: id  3 | task 24737 | stop processing: n_tokens = 13810, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  2 | task 25316 | 
prompt eval time =     456.45 ms /    84 tokens (    5.43 ms per token,   184.03 tokens per second)
       eval time =    1672.16 ms /    37 tokens (   45.19 ms per token,    22.13 tokens per second)
      total time =    2128.61 ms /   121 tokens
slot      release: id  2 | task 25316 | stop processing: n_tokens = 6001, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.744 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 25355 | processing task, is_child = 0
slot update_slots: id  2 | task 25355 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 8033
slot update_slots: id  2 | task 25355 | n_tokens = 5975, memory_seq_rm [5975, end)
slot update_slots: id  2 | task 25355 | prompt processing progress, n_tokens = 7969, batch.n_tokens = 1994, progress = 0.992033
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 25357 | processing task, is_child = 0
slot update_slots: id  2 | task 25355 | n_tokens = 7969, memory_seq_rm [7969, end)
slot update_slots: id  2 | task 25355 | prompt processing progress, n_tokens = 8033, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 25355 | prompt done, n_tokens = 8033, batch.n_tokens = 64
slot init_sampler: id  2 | task 25355 | init sampler, took 1.43 ms, tokens: text = 8033, total = 8033
slot update_slots: id  2 | task 25355 | erasing old context checkpoint (pos_min = 2098, pos_max = 2930, size = 19.533 MiB)
slot update_slots: id  2 | task 25355 | created context checkpoint 8 of 8 (pos_min = 7072, pos_max = 7968, size = 21.034 MiB)
slot update_slots: id  3 | task 25357 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13856
slot update_slots: id  3 | task 25357 | n_past = 13785, slot.prompt.tokens.size() = 13810, seq_id = 3, pos_min = 13683, n_swa = 128
slot update_slots: id  3 | task 25357 | restored context checkpoint (pos_min = 12614, pos_max = 13145, size = 12.475 MiB)
slot update_slots: id  3 | task 25357 | n_tokens = 13145, memory_seq_rm [13145, end)
slot update_slots: id  3 | task 25357 | prompt processing progress, n_tokens = 13792, batch.n_tokens = 711, progress = 0.995381
slot update_slots: id  3 | task 25357 | n_tokens = 13792, memory_seq_rm [13792, end)
slot update_slots: id  3 | task 25357 | prompt processing progress, n_tokens = 13856, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 25357 | prompt done, n_tokens = 13856, batch.n_tokens = 65
slot init_sampler: id  3 | task 25357 | init sampler, took 2.23 ms, tokens: text = 13856, total = 13856
slot update_slots: id  3 | task 25357 | erasing old context checkpoint (pos_min = 4429, pos_max = 5325, size = 21.034 MiB)
slot update_slots: id  3 | task 25357 | created context checkpoint 8 of 8 (pos_min = 12959, pos_max = 13791, size = 19.533 MiB)
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv          stop: cancel task, id_task = 25355
slot      release: id  2 | task 25355 | stop processing: n_tokens = 8148, truncated = 0
slot print_timing: id  3 | task 25357 | 
prompt eval time =    1556.02 ms /   711 tokens (    2.19 ms per token,   456.94 tokens per second)
       eval time =    7003.31 ms /   153 tokens (   45.77 ms per token,    21.85 tokens per second)
      total time =    8559.33 ms /   864 tokens
slot      release: id  3 | task 25357 | stop processing: n_tokens = 14008, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 25513 | processing task, is_child = 0
slot update_slots: id  3 | task 25513 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 14129
slot update_slots: id  3 | task 25513 | n_tokens = 13968, memory_seq_rm [13968, end)
slot update_slots: id  3 | task 25513 | prompt processing progress, n_tokens = 14065, batch.n_tokens = 97, progress = 0.995470
slot update_slots: id  3 | task 25513 | n_tokens = 14065, memory_seq_rm [14065, end)
slot update_slots: id  3 | task 25513 | prompt processing progress, n_tokens = 14129, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 25513 | prompt done, n_tokens = 14129, batch.n_tokens = 64
slot init_sampler: id  3 | task 25513 | init sampler, took 2.67 ms, tokens: text = 14129, total = 14129
slot update_slots: id  3 | task 25513 | erasing old context checkpoint (pos_min = 6871, pos_max = 7767, size = 21.034 MiB)
slot update_slots: id  3 | task 25513 | created context checkpoint 8 of 8 (pos_min = 13197, pos_max = 14064, size = 20.354 MiB)
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv          stop: cancel task, id_task = 25513
slot      release: id  3 | task 25513 | stop processing: n_tokens = 14386, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.936 (> 0.100 thold), f_keep = 0.108
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 8148, total state size = 194.041 MiB
srv          load:  - looking for better prompt, base f_keep = 0.108, sim = 0.936
srv        update:  - cache state: 9 prompts, 4248.856 MiB (limits: 8192.000 MiB, 56064 tokens, 216309 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv        update:    - prompt 0x58dc3fb8c770:    5127 tokens, checkpoints:  8,   320.808 MiB
srv        update:    - prompt 0x58dc3f318830:   24865 tokens, checkpoints:  8,   791.874 MiB
srv        update:    - prompt 0x58dc40d3cf50:   16080 tokens, checkpoints:  8,   571.219 MiB
srv        update:    - prompt 0x58dc4c8ce8a0:   23906 tokens, checkpoints:  8,   739.114 MiB
srv        update:    - prompt 0x58dc38d9f350:   18675 tokens, checkpoints:  8,   606.205 MiB
srv        update:    - prompt 0x58dc3f0d1370:    8148 tokens, checkpoints:  8,   317.783 MiB
srv  get_availabl: prompt cache update took 609.53 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 25774 | processing task, is_child = 0
slot update_slots: id  2 | task 25774 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 941
slot update_slots: id  2 | task 25774 | n_past = 881, slot.prompt.tokens.size() = 8148, seq_id = 2, pos_min = 8021, n_swa = 128
slot update_slots: id  2 | task 25774 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  2 | task 25774 | erased invalidated context checkpoint (pos_min = 2803, pos_max = 3344, n_swa = 128, size = 12.710 MiB)
slot update_slots: id  2 | task 25774 | erased invalidated context checkpoint (pos_min = 3024, pos_max = 3516, n_swa = 128, size = 11.561 MiB)
slot update_slots: id  2 | task 25774 | erased invalidated context checkpoint (pos_min = 3198, pos_max = 3634, n_swa = 128, size = 10.247 MiB)
slot update_slots: id  2 | task 25774 | erased invalidated context checkpoint (pos_min = 3345, pos_max = 3965, n_swa = 128, size = 14.562 MiB)
slot update_slots: id  2 | task 25774 | erased invalidated context checkpoint (pos_min = 4658, pos_max = 5554, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 25774 | erased invalidated context checkpoint (pos_min = 5093, pos_max = 5806, n_swa = 128, size = 16.743 MiB)
slot update_slots: id  2 | task 25774 | erased invalidated context checkpoint (pos_min = 5225, pos_max = 5900, n_swa = 128, size = 15.852 MiB)
slot update_slots: id  2 | task 25774 | erased invalidated context checkpoint (pos_min = 7072, pos_max = 7968, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 25774 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 25774 | prompt processing progress, n_tokens = 877, batch.n_tokens = 877, progress = 0.931987
slot update_slots: id  2 | task 25774 | n_tokens = 877, memory_seq_rm [877, end)
slot update_slots: id  2 | task 25774 | prompt processing progress, n_tokens = 941, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 25774 | prompt done, n_tokens = 941, batch.n_tokens = 64
slot init_sampler: id  2 | task 25774 | init sampler, took 0.14 ms, tokens: text = 941, total = 941
slot update_slots: id  2 | task 25774 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 876, size = 20.565 MiB)
slot print_timing: id  2 | task 25774 | 
prompt eval time =    1573.59 ms /   941 tokens (    1.67 ms per token,   598.00 tokens per second)
       eval time =   30957.73 ms /   965 tokens (   32.08 ms per token,    31.17 tokens per second)
      total time =   32531.32 ms /  1906 tokens
slot      release: id  2 | task 25774 | stop processing: n_tokens = 1905, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.629 (> 0.100 thold), f_keep = 0.494
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 1905, total state size = 65.705 MiB
srv          load:  - looking for better prompt, base f_keep = 0.494, sim = 0.629
srv        update:  - cache state: 10 prompts, 4335.126 MiB (limits: 8192.000 MiB, 56064 tokens, 215604 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv        update:    - prompt 0x58dc3fb8c770:    5127 tokens, checkpoints:  8,   320.808 MiB
srv        update:    - prompt 0x58dc3f318830:   24865 tokens, checkpoints:  8,   791.874 MiB
srv        update:    - prompt 0x58dc40d3cf50:   16080 tokens, checkpoints:  8,   571.219 MiB
srv        update:    - prompt 0x58dc4c8ce8a0:   23906 tokens, checkpoints:  8,   739.114 MiB
srv        update:    - prompt 0x58dc38d9f350:   18675 tokens, checkpoints:  8,   606.205 MiB
srv        update:    - prompt 0x58dc3f0d1370:    8148 tokens, checkpoints:  8,   317.783 MiB
srv        update:    - prompt 0x58dc4e559330:    1905 tokens, checkpoints:  1,    86.270 MiB
srv  get_availabl: prompt cache update took 193.97 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 26741 | processing task, is_child = 0
slot update_slots: id  2 | task 26741 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1498
slot update_slots: id  2 | task 26741 | n_past = 942, slot.prompt.tokens.size() = 1905, seq_id = 2, pos_min = 1008, n_swa = 128
slot update_slots: id  2 | task 26741 | restored context checkpoint (pos_min = 0, pos_max = 876, size = 20.565 MiB)
slot update_slots: id  2 | task 26741 | n_tokens = 876, memory_seq_rm [876, end)
slot update_slots: id  2 | task 26741 | prompt processing progress, n_tokens = 1434, batch.n_tokens = 558, progress = 0.957276
slot update_slots: id  2 | task 26741 | n_tokens = 1434, memory_seq_rm [1434, end)
slot update_slots: id  2 | task 26741 | prompt processing progress, n_tokens = 1498, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 26741 | prompt done, n_tokens = 1498, batch.n_tokens = 64
slot init_sampler: id  2 | task 26741 | init sampler, took 0.31 ms, tokens: text = 1498, total = 1498
slot update_slots: id  2 | task 26741 | created context checkpoint 2 of 8 (pos_min = 557, pos_max = 1433, size = 20.565 MiB)
slot print_timing: id  2 | task 26741 | 
prompt eval time =    1380.30 ms /   622 tokens (    2.22 ms per token,   450.63 tokens per second)
       eval time =    1457.56 ms /    48 tokens (   30.37 ms per token,    32.93 tokens per second)
      total time =    2837.86 ms /   670 tokens
slot      release: id  2 | task 26741 | stop processing: n_tokens = 1545, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.904 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 26791 | processing task, is_child = 0
slot update_slots: id  2 | task 26791 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1690
slot update_slots: id  2 | task 26791 | n_tokens = 1527, memory_seq_rm [1527, end)
slot update_slots: id  2 | task 26791 | prompt processing progress, n_tokens = 1626, batch.n_tokens = 99, progress = 0.962130
slot update_slots: id  2 | task 26791 | n_tokens = 1626, memory_seq_rm [1626, end)
slot update_slots: id  2 | task 26791 | prompt processing progress, n_tokens = 1690, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 26791 | prompt done, n_tokens = 1690, batch.n_tokens = 64
slot init_sampler: id  2 | task 26791 | init sampler, took 0.25 ms, tokens: text = 1690, total = 1690
slot update_slots: id  2 | task 26791 | created context checkpoint 3 of 8 (pos_min = 749, pos_max = 1625, size = 20.565 MiB)
slot print_timing: id  2 | task 26791 | 
prompt eval time =     525.79 ms /   163 tokens (    3.23 ms per token,   310.01 tokens per second)
       eval time =    1535.56 ms /    51 tokens (   30.11 ms per token,    33.21 tokens per second)
      total time =    2061.35 ms /   214 tokens
slot      release: id  2 | task 26791 | stop processing: n_tokens = 1740, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.821 (> 0.100 thold), f_keep = 0.980
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 26844 | processing task, is_child = 0
slot update_slots: id  2 | task 26844 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2076
slot update_slots: id  2 | task 26844 | n_tokens = 1705, memory_seq_rm [1705, end)
slot update_slots: id  2 | task 26844 | prompt processing progress, n_tokens = 2012, batch.n_tokens = 307, progress = 0.969171
slot update_slots: id  2 | task 26844 | n_tokens = 2012, memory_seq_rm [2012, end)
slot update_slots: id  2 | task 26844 | prompt processing progress, n_tokens = 2076, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 26844 | prompt done, n_tokens = 2076, batch.n_tokens = 64
slot init_sampler: id  2 | task 26844 | init sampler, took 0.29 ms, tokens: text = 2076, total = 2076
slot update_slots: id  2 | task 26844 | created context checkpoint 4 of 8 (pos_min = 1115, pos_max = 2011, size = 21.034 MiB)
slot print_timing: id  2 | task 26844 | 
prompt eval time =     752.40 ms /   371 tokens (    2.03 ms per token,   493.09 tokens per second)
       eval time =    1534.32 ms /    51 tokens (   30.08 ms per token,    33.24 tokens per second)
      total time =    2286.72 ms /   422 tokens
slot      release: id  2 | task 26844 | stop processing: n_tokens = 2126, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.967 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 26897 | processing task, is_child = 0
slot update_slots: id  2 | task 26897 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2172
slot update_slots: id  2 | task 26897 | n_tokens = 2101, memory_seq_rm [2101, end)
slot update_slots: id  2 | task 26897 | prompt processing progress, n_tokens = 2108, batch.n_tokens = 7, progress = 0.970534
slot update_slots: id  2 | task 26897 | n_tokens = 2108, memory_seq_rm [2108, end)
slot update_slots: id  2 | task 26897 | prompt processing progress, n_tokens = 2172, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 26897 | prompt done, n_tokens = 2172, batch.n_tokens = 64
slot init_sampler: id  2 | task 26897 | init sampler, took 0.30 ms, tokens: text = 2172, total = 2172
slot update_slots: id  2 | task 26897 | created context checkpoint 5 of 8 (pos_min = 1229, pos_max = 2107, size = 20.612 MiB)
slot print_timing: id  2 | task 26897 | 
prompt eval time =     301.41 ms /    71 tokens (    4.25 ms per token,   235.56 tokens per second)
       eval time =    1579.62 ms /    52 tokens (   30.38 ms per token,    32.92 tokens per second)
      total time =    1881.04 ms /   123 tokens
slot      release: id  2 | task 26897 | stop processing: n_tokens = 2223, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.823 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 26951 | processing task, is_child = 0
slot update_slots: id  2 | task 26951 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2666
slot update_slots: id  2 | task 26951 | n_tokens = 2194, memory_seq_rm [2194, end)
slot update_slots: id  2 | task 26951 | prompt processing progress, n_tokens = 2602, batch.n_tokens = 408, progress = 0.975994
slot update_slots: id  2 | task 26951 | n_tokens = 2602, memory_seq_rm [2602, end)
slot update_slots: id  2 | task 26951 | prompt processing progress, n_tokens = 2666, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 26951 | prompt done, n_tokens = 2666, batch.n_tokens = 64
slot init_sampler: id  2 | task 26951 | init sampler, took 0.39 ms, tokens: text = 2666, total = 2666
slot update_slots: id  2 | task 26951 | created context checkpoint 6 of 8 (pos_min = 1705, pos_max = 2601, size = 21.034 MiB)
slot print_timing: id  2 | task 26951 | 
prompt eval time =     897.42 ms /   472 tokens (    1.90 ms per token,   525.95 tokens per second)
       eval time =    1858.76 ms /    59 tokens (   31.50 ms per token,    31.74 tokens per second)
      total time =    2756.18 ms /   531 tokens
slot      release: id  2 | task 26951 | stop processing: n_tokens = 2724, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.967 (> 0.100 thold), f_keep = 0.983
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 27012 | processing task, is_child = 0
slot update_slots: id  2 | task 27012 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2768
slot update_slots: id  2 | task 27012 | n_tokens = 2677, memory_seq_rm [2677, end)
slot update_slots: id  2 | task 27012 | prompt processing progress, n_tokens = 2704, batch.n_tokens = 27, progress = 0.976879
slot update_slots: id  2 | task 27012 | n_tokens = 2704, memory_seq_rm [2704, end)
slot update_slots: id  2 | task 27012 | prompt processing progress, n_tokens = 2768, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 27012 | prompt done, n_tokens = 2768, batch.n_tokens = 64
slot init_sampler: id  2 | task 27012 | init sampler, took 0.54 ms, tokens: text = 2768, total = 2768
slot update_slots: id  2 | task 27012 | created context checkpoint 7 of 8 (pos_min = 1827, pos_max = 2703, size = 20.565 MiB)
slot print_timing: id  2 | task 27012 | 
prompt eval time =     373.59 ms /    91 tokens (    4.11 ms per token,   243.58 tokens per second)
       eval time =    1554.96 ms /    48 tokens (   32.39 ms per token,    30.87 tokens per second)
      total time =    1928.55 ms /   139 tokens
slot      release: id  2 | task 27012 | stop processing: n_tokens = 2815, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.575 (> 0.100 thold), f_keep = 0.989
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 27062 | processing task, is_child = 0
slot update_slots: id  2 | task 27062 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 4847
slot update_slots: id  2 | task 27062 | n_tokens = 2785, memory_seq_rm [2785, end)
slot update_slots: id  2 | task 27062 | prompt processing progress, n_tokens = 4783, batch.n_tokens = 1998, progress = 0.986796
slot update_slots: id  2 | task 27062 | n_tokens = 4783, memory_seq_rm [4783, end)
slot update_slots: id  2 | task 27062 | prompt processing progress, n_tokens = 4847, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 27062 | prompt done, n_tokens = 4847, batch.n_tokens = 64
slot init_sampler: id  2 | task 27062 | init sampler, took 0.69 ms, tokens: text = 4847, total = 4847
slot update_slots: id  2 | task 27062 | created context checkpoint 8 of 8 (pos_min = 3886, pos_max = 4782, size = 21.034 MiB)
slot print_timing: id  2 | task 27062 | 
prompt eval time =    3474.45 ms /  2062 tokens (    1.68 ms per token,   593.47 tokens per second)
       eval time =    1410.22 ms /    43 tokens (   32.80 ms per token,    30.49 tokens per second)
      total time =    4884.67 ms /  2105 tokens
slot      release: id  2 | task 27062 | stop processing: n_tokens = 4889, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.666 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 27107 | processing task, is_child = 0
slot update_slots: id  2 | task 27107 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 7292
slot update_slots: id  2 | task 27107 | n_tokens = 4859, memory_seq_rm [4859, end)
slot update_slots: id  2 | task 27107 | prompt processing progress, n_tokens = 6907, batch.n_tokens = 2048, progress = 0.947202
slot update_slots: id  2 | task 27107 | n_tokens = 6907, memory_seq_rm [6907, end)
slot update_slots: id  2 | task 27107 | prompt processing progress, n_tokens = 7228, batch.n_tokens = 321, progress = 0.991223
slot update_slots: id  2 | task 27107 | n_tokens = 7228, memory_seq_rm [7228, end)
slot update_slots: id  2 | task 27107 | prompt processing progress, n_tokens = 7292, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 27107 | prompt done, n_tokens = 7292, batch.n_tokens = 64
slot init_sampler: id  2 | task 27107 | init sampler, took 1.40 ms, tokens: text = 7292, total = 7292
slot update_slots: id  2 | task 27107 | erasing old context checkpoint (pos_min = 0, pos_max = 876, size = 20.565 MiB)
slot update_slots: id  2 | task 27107 | created context checkpoint 8 of 8 (pos_min = 6331, pos_max = 7227, size = 21.034 MiB)
slot print_timing: id  2 | task 27107 | 
prompt eval time =    4259.93 ms /  2433 tokens (    1.75 ms per token,   571.14 tokens per second)
       eval time =    3907.42 ms /   116 tokens (   33.68 ms per token,    29.69 tokens per second)
      total time =    8167.35 ms /  2549 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 27107 | stop processing: n_tokens = 7407, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.976 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 27226 | processing task, is_child = 0
slot update_slots: id  2 | task 27226 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 7549
slot update_slots: id  2 | task 27226 | n_tokens = 7370, memory_seq_rm [7370, end)
slot update_slots: id  2 | task 27226 | prompt processing progress, n_tokens = 7485, batch.n_tokens = 115, progress = 0.991522
slot update_slots: id  2 | task 27226 | n_tokens = 7485, memory_seq_rm [7485, end)
slot update_slots: id  2 | task 27226 | prompt processing progress, n_tokens = 7549, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 27226 | prompt done, n_tokens = 7549, batch.n_tokens = 64
slot init_sampler: id  2 | task 27226 | init sampler, took 1.40 ms, tokens: text = 7549, total = 7549
slot update_slots: id  2 | task 27226 | erasing old context checkpoint (pos_min = 557, pos_max = 1433, size = 20.565 MiB)
slot update_slots: id  2 | task 27226 | created context checkpoint 8 of 8 (pos_min = 6588, pos_max = 7484, size = 21.034 MiB)
slot print_timing: id  2 | task 27226 | 
prompt eval time =     618.11 ms /   179 tokens (    3.45 ms per token,   289.59 tokens per second)
       eval time =    1622.94 ms /    50 tokens (   32.46 ms per token,    30.81 tokens per second)
      total time =    2241.04 ms /   229 tokens
slot      release: id  2 | task 27226 | stop processing: n_tokens = 7598, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 27278 | processing task, is_child = 0
slot update_slots: id  2 | task 27278 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 7641
slot update_slots: id  2 | task 27278 | n_tokens = 7568, memory_seq_rm [7568, end)
slot update_slots: id  2 | task 27278 | prompt processing progress, n_tokens = 7577, batch.n_tokens = 9, progress = 0.991624
slot update_slots: id  2 | task 27278 | n_tokens = 7577, memory_seq_rm [7577, end)
slot update_slots: id  2 | task 27278 | prompt processing progress, n_tokens = 7641, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 27278 | prompt done, n_tokens = 7641, batch.n_tokens = 64
slot init_sampler: id  2 | task 27278 | init sampler, took 1.06 ms, tokens: text = 7641, total = 7641
slot update_slots: id  2 | task 27278 | erasing old context checkpoint (pos_min = 749, pos_max = 1625, size = 20.565 MiB)
slot update_slots: id  2 | task 27278 | created context checkpoint 8 of 8 (pos_min = 6701, pos_max = 7576, size = 20.542 MiB)
slot print_timing: id  2 | task 27278 | 
prompt eval time =     332.47 ms /    73 tokens (    4.55 ms per token,   219.57 tokens per second)
       eval time =    1822.46 ms /    58 tokens (   31.42 ms per token,    31.83 tokens per second)
      total time =    2154.93 ms /   131 tokens
slot      release: id  2 | task 27278 | stop processing: n_tokens = 7698, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 27338 | processing task, is_child = 0
slot update_slots: id  2 | task 27338 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 7730
slot update_slots: id  2 | task 27338 | n_tokens = 7668, memory_seq_rm [7668, end)
slot update_slots: id  2 | task 27338 | prompt processing progress, n_tokens = 7730, batch.n_tokens = 62, progress = 1.000000
slot update_slots: id  2 | task 27338 | prompt done, n_tokens = 7730, batch.n_tokens = 62
slot init_sampler: id  2 | task 27338 | init sampler, took 1.08 ms, tokens: text = 7730, total = 7730
slot update_slots: id  2 | task 27338 | erasing old context checkpoint (pos_min = 1115, pos_max = 2011, size = 21.034 MiB)
slot update_slots: id  2 | task 27338 | created context checkpoint 8 of 8 (pos_min = 6801, pos_max = 7667, size = 20.331 MiB)
slot print_timing: id  2 | task 27338 | 
prompt eval time =     251.35 ms /    62 tokens (    4.05 ms per token,   246.66 tokens per second)
       eval time =    1764.50 ms /    58 tokens (   30.42 ms per token,    32.87 tokens per second)
      total time =    2015.86 ms /   120 tokens
slot      release: id  2 | task 27338 | stop processing: n_tokens = 7787, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.836 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 27397 | processing task, is_child = 0
slot update_slots: id  2 | task 27397 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 9276
slot update_slots: id  2 | task 27397 | n_tokens = 7756, memory_seq_rm [7756, end)
slot update_slots: id  2 | task 27397 | prompt processing progress, n_tokens = 9212, batch.n_tokens = 1456, progress = 0.993100
slot update_slots: id  2 | task 27397 | n_tokens = 9212, memory_seq_rm [9212, end)
slot update_slots: id  2 | task 27397 | prompt processing progress, n_tokens = 9276, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 27397 | prompt done, n_tokens = 9276, batch.n_tokens = 64
slot init_sampler: id  2 | task 27397 | init sampler, took 1.34 ms, tokens: text = 9276, total = 9276
slot update_slots: id  2 | task 27397 | erasing old context checkpoint (pos_min = 1229, pos_max = 2107, size = 20.612 MiB)
slot update_slots: id  2 | task 27397 | created context checkpoint 8 of 8 (pos_min = 8315, pos_max = 9211, size = 21.034 MiB)
slot print_timing: id  2 | task 27397 | 
prompt eval time =    2485.38 ms /  1520 tokens (    1.64 ms per token,   611.58 tokens per second)
       eval time =    2200.91 ms /    72 tokens (   30.57 ms per token,    32.71 tokens per second)
      total time =    4686.29 ms /  1592 tokens
slot      release: id  2 | task 27397 | stop processing: n_tokens = 9347, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 27471 | processing task, is_child = 0
slot update_slots: id  2 | task 27471 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 9376
slot update_slots: id  2 | task 27471 | n_tokens = 9316, memory_seq_rm [9316, end)
slot update_slots: id  2 | task 27471 | prompt processing progress, n_tokens = 9376, batch.n_tokens = 60, progress = 1.000000
slot update_slots: id  2 | task 27471 | prompt done, n_tokens = 9376, batch.n_tokens = 60
slot init_sampler: id  2 | task 27471 | init sampler, took 1.83 ms, tokens: text = 9376, total = 9376
slot update_slots: id  2 | task 27471 | erasing old context checkpoint (pos_min = 1705, pos_max = 2601, size = 21.034 MiB)
slot update_slots: id  2 | task 27471 | created context checkpoint 8 of 8 (pos_min = 8450, pos_max = 9315, size = 20.307 MiB)
slot print_timing: id  2 | task 27471 | 
prompt eval time =     219.96 ms /    60 tokens (    3.67 ms per token,   272.78 tokens per second)
       eval time =    1032.83 ms /    35 tokens (   29.51 ms per token,    33.89 tokens per second)
      total time =    1252.79 ms /    95 tokens
slot      release: id  2 | task 27471 | stop processing: n_tokens = 9410, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 27507 | processing task, is_child = 0
slot update_slots: id  2 | task 27507 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 9442
slot update_slots: id  2 | task 27507 | n_tokens = 9387, memory_seq_rm [9387, end)
slot update_slots: id  2 | task 27507 | prompt processing progress, n_tokens = 9442, batch.n_tokens = 55, progress = 1.000000
slot update_slots: id  2 | task 27507 | prompt done, n_tokens = 9442, batch.n_tokens = 55
slot init_sampler: id  2 | task 27507 | init sampler, took 1.36 ms, tokens: text = 9442, total = 9442
slot update_slots: id  2 | task 27507 | erasing old context checkpoint (pos_min = 1827, pos_max = 2703, size = 20.565 MiB)
slot update_slots: id  2 | task 27507 | created context checkpoint 8 of 8 (pos_min = 8513, pos_max = 9386, size = 20.495 MiB)
slot print_timing: id  2 | task 27507 | 
prompt eval time =     213.21 ms /    55 tokens (    3.88 ms per token,   257.96 tokens per second)
       eval time =    3544.65 ms /   118 tokens (   30.04 ms per token,    33.29 tokens per second)
      total time =    3757.86 ms /   173 tokens
slot      release: id  2 | task 27507 | stop processing: n_tokens = 9559, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 27626 | processing task, is_child = 0
slot update_slots: id  2 | task 27626 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 9648
slot update_slots: id  2 | task 27626 | n_tokens = 9531, memory_seq_rm [9531, end)
slot update_slots: id  2 | task 27626 | prompt processing progress, n_tokens = 9584, batch.n_tokens = 53, progress = 0.993366
slot update_slots: id  2 | task 27626 | n_tokens = 9584, memory_seq_rm [9584, end)
slot update_slots: id  2 | task 27626 | prompt processing progress, n_tokens = 9648, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 27626 | prompt done, n_tokens = 9648, batch.n_tokens = 64
slot init_sampler: id  2 | task 27626 | init sampler, took 1.35 ms, tokens: text = 9648, total = 9648
slot update_slots: id  2 | task 27626 | erasing old context checkpoint (pos_min = 3886, pos_max = 4782, size = 21.034 MiB)
slot update_slots: id  2 | task 27626 | created context checkpoint 8 of 8 (pos_min = 8687, pos_max = 9583, size = 21.034 MiB)
slot print_timing: id  2 | task 27626 | 
prompt eval time =     431.28 ms /   117 tokens (    3.69 ms per token,   271.28 tokens per second)
       eval time =    3314.34 ms /   112 tokens (   29.59 ms per token,    33.79 tokens per second)
      total time =    3745.62 ms /   229 tokens
slot      release: id  2 | task 27626 | stop processing: n_tokens = 9759, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.975 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 27740 | processing task, is_child = 0
slot update_slots: id  2 | task 27740 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 9979
slot update_slots: id  2 | task 27740 | n_tokens = 9725, memory_seq_rm [9725, end)
slot update_slots: id  2 | task 27740 | prompt processing progress, n_tokens = 9915, batch.n_tokens = 190, progress = 0.993587
slot update_slots: id  2 | task 27740 | n_tokens = 9915, memory_seq_rm [9915, end)
slot update_slots: id  2 | task 27740 | prompt processing progress, n_tokens = 9979, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 27740 | prompt done, n_tokens = 9979, batch.n_tokens = 64
slot init_sampler: id  2 | task 27740 | init sampler, took 1.39 ms, tokens: text = 9979, total = 9979
slot update_slots: id  2 | task 27740 | erasing old context checkpoint (pos_min = 6331, pos_max = 7227, size = 21.034 MiB)
slot update_slots: id  2 | task 27740 | created context checkpoint 8 of 8 (pos_min = 9039, pos_max = 9914, size = 20.542 MiB)
slot print_timing: id  2 | task 27740 | 
prompt eval time =     594.25 ms /   254 tokens (    2.34 ms per token,   427.43 tokens per second)
       eval time =    2201.48 ms /    74 tokens (   29.75 ms per token,    33.61 tokens per second)
      total time =    2795.73 ms /   328 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 27740 | stop processing: n_tokens = 10052, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 27816 | processing task, is_child = 0
slot update_slots: id  2 | task 27816 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 10081
slot update_slots: id  2 | task 27816 | n_tokens = 10022, memory_seq_rm [10022, end)
slot update_slots: id  2 | task 27816 | prompt processing progress, n_tokens = 10081, batch.n_tokens = 59, progress = 1.000000
slot update_slots: id  2 | task 27816 | prompt done, n_tokens = 10081, batch.n_tokens = 59
slot init_sampler: id  2 | task 27816 | init sampler, took 2.01 ms, tokens: text = 10081, total = 10081
slot update_slots: id  2 | task 27816 | erasing old context checkpoint (pos_min = 6588, pos_max = 7484, size = 21.034 MiB)
slot update_slots: id  2 | task 27816 | created context checkpoint 8 of 8 (pos_min = 9176, pos_max = 10021, size = 19.838 MiB)
slot print_timing: id  2 | task 27816 | 
prompt eval time =     213.82 ms /    59 tokens (    3.62 ms per token,   275.93 tokens per second)
       eval time =    2923.42 ms /   101 tokens (   28.94 ms per token,    34.55 tokens per second)
      total time =    3137.24 ms /   160 tokens
slot      release: id  2 | task 27816 | stop processing: n_tokens = 10181, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.844 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 27918 | processing task, is_child = 0
slot update_slots: id  2 | task 27918 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 12029
slot update_slots: id  2 | task 27918 | n_tokens = 10150, memory_seq_rm [10150, end)
slot update_slots: id  2 | task 27918 | prompt processing progress, n_tokens = 11965, batch.n_tokens = 1815, progress = 0.994680
slot update_slots: id  2 | task 27918 | n_tokens = 11965, memory_seq_rm [11965, end)
slot update_slots: id  2 | task 27918 | prompt processing progress, n_tokens = 12029, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 27918 | prompt done, n_tokens = 12029, batch.n_tokens = 64
slot init_sampler: id  2 | task 27918 | init sampler, took 1.68 ms, tokens: text = 12029, total = 12029
slot update_slots: id  2 | task 27918 | erasing old context checkpoint (pos_min = 6701, pos_max = 7576, size = 20.542 MiB)
slot update_slots: id  2 | task 27918 | created context checkpoint 8 of 8 (pos_min = 11068, pos_max = 11964, size = 21.034 MiB)
slot print_timing: id  2 | task 27918 | 
prompt eval time =    2970.94 ms /  1879 tokens (    1.58 ms per token,   632.46 tokens per second)
       eval time =    1698.98 ms /    58 tokens (   29.29 ms per token,    34.14 tokens per second)
      total time =    4669.92 ms /  1937 tokens
slot      release: id  2 | task 27918 | stop processing: n_tokens = 12086, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.979 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 27978 | processing task, is_child = 0
slot update_slots: id  2 | task 27978 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 12306
slot update_slots: id  2 | task 27978 | n_tokens = 12047, memory_seq_rm [12047, end)
slot update_slots: id  2 | task 27978 | prompt processing progress, n_tokens = 12242, batch.n_tokens = 195, progress = 0.994799
slot update_slots: id  2 | task 27978 | n_tokens = 12242, memory_seq_rm [12242, end)
slot update_slots: id  2 | task 27978 | prompt processing progress, n_tokens = 12306, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 27978 | prompt done, n_tokens = 12306, batch.n_tokens = 64
slot init_sampler: id  2 | task 27978 | init sampler, took 1.68 ms, tokens: text = 12306, total = 12306
slot update_slots: id  2 | task 27978 | erasing old context checkpoint (pos_min = 6801, pos_max = 7667, size = 20.331 MiB)
slot update_slots: id  2 | task 27978 | created context checkpoint 8 of 8 (pos_min = 11345, pos_max = 12241, size = 21.034 MiB)
slot print_timing: id  2 | task 27978 | 
prompt eval time =     638.53 ms /   259 tokens (    2.47 ms per token,   405.62 tokens per second)
       eval time =   13512.55 ms /   449 tokens (   30.09 ms per token,    33.23 tokens per second)
      total time =   14151.08 ms /   708 tokens
slot      release: id  2 | task 27978 | stop processing: n_tokens = 12754, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.979 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 28429 | processing task, is_child = 0
slot update_slots: id  2 | task 28429 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 12996
slot update_slots: id  2 | task 28429 | n_tokens = 12725, memory_seq_rm [12725, end)
slot update_slots: id  2 | task 28429 | prompt processing progress, n_tokens = 12932, batch.n_tokens = 207, progress = 0.995075
slot update_slots: id  2 | task 28429 | n_tokens = 12932, memory_seq_rm [12932, end)
slot update_slots: id  2 | task 28429 | prompt processing progress, n_tokens = 12996, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 28429 | prompt done, n_tokens = 12996, batch.n_tokens = 64
slot init_sampler: id  2 | task 28429 | init sampler, took 1.81 ms, tokens: text = 12996, total = 12996
slot update_slots: id  2 | task 28429 | erasing old context checkpoint (pos_min = 8315, pos_max = 9211, size = 21.034 MiB)
slot update_slots: id  2 | task 28429 | created context checkpoint 8 of 8 (pos_min = 12035, pos_max = 12931, size = 21.034 MiB)
slot print_timing: id  2 | task 28429 | 
prompt eval time =     652.11 ms /   271 tokens (    2.41 ms per token,   415.57 tokens per second)
       eval time =    9119.26 ms /   301 tokens (   30.30 ms per token,    33.01 tokens per second)
      total time =    9771.37 ms /   572 tokens
slot      release: id  2 | task 28429 | stop processing: n_tokens = 13296, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.982 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 28732 | processing task, is_child = 0
slot update_slots: id  2 | task 28732 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13336
slot update_slots: id  2 | task 28732 | n_tokens = 13090, memory_seq_rm [13090, end)
slot update_slots: id  2 | task 28732 | prompt processing progress, n_tokens = 13272, batch.n_tokens = 182, progress = 0.995201
slot update_slots: id  2 | task 28732 | n_tokens = 13272, memory_seq_rm [13272, end)
slot update_slots: id  2 | task 28732 | prompt processing progress, n_tokens = 13336, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 28732 | prompt done, n_tokens = 13336, batch.n_tokens = 64
slot init_sampler: id  2 | task 28732 | init sampler, took 2.10 ms, tokens: text = 13336, total = 13336
slot update_slots: id  2 | task 28732 | erasing old context checkpoint (pos_min = 8450, pos_max = 9315, size = 20.307 MiB)
slot update_slots: id  2 | task 28732 | created context checkpoint 8 of 8 (pos_min = 12399, pos_max = 13271, size = 20.471 MiB)
slot print_timing: id  2 | task 28732 | 
prompt eval time =     634.77 ms /   246 tokens (    2.58 ms per token,   387.54 tokens per second)
       eval time =    4775.38 ms /   154 tokens (   31.01 ms per token,    32.25 tokens per second)
      total time =    5410.15 ms /   400 tokens
slot      release: id  2 | task 28732 | stop processing: n_tokens = 13489, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.990
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 28888 | processing task, is_child = 0
slot update_slots: id  2 | task 28888 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13535
slot update_slots: id  2 | task 28888 | n_tokens = 13348, memory_seq_rm [13348, end)
slot update_slots: id  2 | task 28888 | prompt processing progress, n_tokens = 13471, batch.n_tokens = 123, progress = 0.995272
slot update_slots: id  2 | task 28888 | n_tokens = 13471, memory_seq_rm [13471, end)
slot update_slots: id  2 | task 28888 | prompt processing progress, n_tokens = 13535, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 28888 | prompt done, n_tokens = 13535, batch.n_tokens = 64
slot init_sampler: id  2 | task 28888 | init sampler, took 2.55 ms, tokens: text = 13535, total = 13535
slot update_slots: id  2 | task 28888 | erasing old context checkpoint (pos_min = 8513, pos_max = 9386, size = 20.495 MiB)
slot update_slots: id  2 | task 28888 | created context checkpoint 8 of 8 (pos_min = 12592, pos_max = 13470, size = 20.612 MiB)
slot print_timing: id  2 | task 28888 | 
prompt eval time =     690.18 ms /   187 tokens (    3.69 ms per token,   270.94 tokens per second)
       eval time =    2846.59 ms /    90 tokens (   31.63 ms per token,    31.62 tokens per second)
      total time =    3536.77 ms /   277 tokens
slot      release: id  2 | task 28888 | stop processing: n_tokens = 13624, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 28980 | processing task, is_child = 0
slot update_slots: id  2 | task 28980 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13717
slot update_slots: id  2 | task 28980 | n_tokens = 13579, memory_seq_rm [13579, end)
slot update_slots: id  2 | task 28980 | prompt processing progress, n_tokens = 13653, batch.n_tokens = 74, progress = 0.995334
slot update_slots: id  2 | task 28980 | n_tokens = 13653, memory_seq_rm [13653, end)
slot update_slots: id  2 | task 28980 | prompt processing progress, n_tokens = 13717, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 28980 | prompt done, n_tokens = 13717, batch.n_tokens = 64
slot init_sampler: id  2 | task 28980 | init sampler, took 1.90 ms, tokens: text = 13717, total = 13717
slot update_slots: id  2 | task 28980 | erasing old context checkpoint (pos_min = 8687, pos_max = 9583, size = 21.034 MiB)
slot update_slots: id  2 | task 28980 | created context checkpoint 8 of 8 (pos_min = 12756, pos_max = 13652, size = 21.034 MiB)
slot print_timing: id  2 | task 28980 | 
prompt eval time =     545.83 ms /   138 tokens (    3.96 ms per token,   252.83 tokens per second)
       eval time =    3004.96 ms /    94 tokens (   31.97 ms per token,    31.28 tokens per second)
      total time =    3550.79 ms /   232 tokens
slot      release: id  2 | task 28980 | stop processing: n_tokens = 13810, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 29076 | processing task, is_child = 0
slot update_slots: id  2 | task 29076 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13861
slot update_slots: id  2 | task 29076 | n_tokens = 13801, memory_seq_rm [13801, end)
slot update_slots: id  2 | task 29076 | prompt processing progress, n_tokens = 13861, batch.n_tokens = 60, progress = 1.000000
slot update_slots: id  2 | task 29076 | prompt done, n_tokens = 13861, batch.n_tokens = 60
slot init_sampler: id  2 | task 29076 | init sampler, took 1.91 ms, tokens: text = 13861, total = 13861
slot update_slots: id  2 | task 29076 | erasing old context checkpoint (pos_min = 9039, pos_max = 9914, size = 20.542 MiB)
slot update_slots: id  2 | task 29076 | created context checkpoint 8 of 8 (pos_min = 12913, pos_max = 13800, size = 20.823 MiB)
slot print_timing: id  2 | task 29076 | 
prompt eval time =     229.28 ms /    60 tokens (    3.82 ms per token,   261.69 tokens per second)
       eval time =    2269.66 ms /    72 tokens (   31.52 ms per token,    31.72 tokens per second)
      total time =    2498.93 ms /   132 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 29076 | stop processing: n_tokens = 13932, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 29149 | processing task, is_child = 0
slot update_slots: id  2 | task 29149 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 14121
slot update_slots: id  2 | task 29149 | n_tokens = 13894, memory_seq_rm [13894, end)
slot update_slots: id  2 | task 29149 | prompt processing progress, n_tokens = 14057, batch.n_tokens = 163, progress = 0.995468
slot update_slots: id  2 | task 29149 | n_tokens = 14057, memory_seq_rm [14057, end)
slot update_slots: id  2 | task 29149 | prompt processing progress, n_tokens = 14121, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 29149 | prompt done, n_tokens = 14121, batch.n_tokens = 64
slot init_sampler: id  2 | task 29149 | init sampler, took 2.66 ms, tokens: text = 14121, total = 14121
slot update_slots: id  2 | task 29149 | erasing old context checkpoint (pos_min = 9176, pos_max = 10021, size = 19.838 MiB)
slot update_slots: id  2 | task 29149 | created context checkpoint 8 of 8 (pos_min = 13160, pos_max = 14056, size = 21.034 MiB)
slot print_timing: id  2 | task 29149 | 
prompt eval time =     622.14 ms /   227 tokens (    2.74 ms per token,   364.87 tokens per second)
       eval time =    1576.91 ms /    51 tokens (   30.92 ms per token,    32.34 tokens per second)
      total time =    2199.05 ms /   278 tokens
slot      release: id  2 | task 29149 | stop processing: n_tokens = 14171, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.955 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 29202 | processing task, is_child = 0
slot update_slots: id  2 | task 29202 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 14802
slot update_slots: id  2 | task 29202 | n_tokens = 14141, memory_seq_rm [14141, end)
slot update_slots: id  2 | task 29202 | prompt processing progress, n_tokens = 14738, batch.n_tokens = 597, progress = 0.995676
slot update_slots: id  2 | task 29202 | n_tokens = 14738, memory_seq_rm [14738, end)
slot update_slots: id  2 | task 29202 | prompt processing progress, n_tokens = 14802, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 29202 | prompt done, n_tokens = 14802, batch.n_tokens = 64
slot init_sampler: id  2 | task 29202 | init sampler, took 2.03 ms, tokens: text = 14802, total = 14802
slot update_slots: id  2 | task 29202 | erasing old context checkpoint (pos_min = 11068, pos_max = 11964, size = 21.034 MiB)
slot update_slots: id  2 | task 29202 | created context checkpoint 8 of 8 (pos_min = 13841, pos_max = 14737, size = 21.034 MiB)
slot print_timing: id  2 | task 29202 | 
prompt eval time =    1424.17 ms /   661 tokens (    2.15 ms per token,   464.13 tokens per second)
       eval time =   10544.65 ms /   339 tokens (   31.11 ms per token,    32.15 tokens per second)
      total time =   11968.82 ms /  1000 tokens
slot      release: id  2 | task 29202 | stop processing: n_tokens = 15140, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.983 (> 0.100 thold), f_keep = 0.986
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 29543 | processing task, is_child = 0
slot update_slots: id  2 | task 29543 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 15184
slot update_slots: id  2 | task 29543 | n_tokens = 14927, memory_seq_rm [14927, end)
slot update_slots: id  2 | task 29543 | prompt processing progress, n_tokens = 15120, batch.n_tokens = 193, progress = 0.995785
slot update_slots: id  2 | task 29543 | n_tokens = 15120, memory_seq_rm [15120, end)
slot update_slots: id  2 | task 29543 | prompt processing progress, n_tokens = 15184, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 29543 | prompt done, n_tokens = 15184, batch.n_tokens = 64
slot init_sampler: id  2 | task 29543 | init sampler, took 2.06 ms, tokens: text = 15184, total = 15184
slot update_slots: id  2 | task 29543 | erasing old context checkpoint (pos_min = 11345, pos_max = 12241, size = 21.034 MiB)
slot update_slots: id  2 | task 29543 | created context checkpoint 8 of 8 (pos_min = 14403, pos_max = 15119, size = 16.813 MiB)
slot print_timing: id  2 | task 29543 | 
prompt eval time =     663.89 ms /   257 tokens (    2.58 ms per token,   387.11 tokens per second)
       eval time =    1572.98 ms /    51 tokens (   30.84 ms per token,    32.42 tokens per second)
      total time =    2236.88 ms /   308 tokens
slot      release: id  2 | task 29543 | stop processing: n_tokens = 15234, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 29596 | processing task, is_child = 0
slot update_slots: id  2 | task 29596 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 15270
slot update_slots: id  2 | task 29596 | n_tokens = 15195, memory_seq_rm [15195, end)
slot update_slots: id  2 | task 29596 | prompt processing progress, n_tokens = 15206, batch.n_tokens = 11, progress = 0.995809
slot update_slots: id  2 | task 29596 | n_tokens = 15206, memory_seq_rm [15206, end)
slot update_slots: id  2 | task 29596 | prompt processing progress, n_tokens = 15270, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 29596 | prompt done, n_tokens = 15270, batch.n_tokens = 64
slot init_sampler: id  2 | task 29596 | init sampler, took 2.08 ms, tokens: text = 15270, total = 15270
slot update_slots: id  2 | task 29596 | erasing old context checkpoint (pos_min = 12035, pos_max = 12931, size = 21.034 MiB)
slot update_slots: id  2 | task 29596 | created context checkpoint 8 of 8 (pos_min = 14517, pos_max = 15205, size = 16.157 MiB)
slot print_timing: id  2 | task 29596 | 
prompt eval time =     324.96 ms /    75 tokens (    4.33 ms per token,   230.80 tokens per second)
       eval time =    3864.74 ms /   127 tokens (   30.43 ms per token,    32.86 tokens per second)
      total time =    4189.69 ms /   202 tokens
slot      release: id  2 | task 29596 | stop processing: n_tokens = 15396, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.057
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 15396, total state size = 377.833 MiB
srv          load:  - looking for better prompt, base f_keep = 0.057, sim = 0.989
srv        update:  - cache state: 11 prompts, 4870.937 MiB (limits: 8192.000 MiB, 56064 tokens, 217781 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv        update:    - prompt 0x58dc3fb8c770:    5127 tokens, checkpoints:  8,   320.808 MiB
srv        update:    - prompt 0x58dc3f318830:   24865 tokens, checkpoints:  8,   791.874 MiB
srv        update:    - prompt 0x58dc40d3cf50:   16080 tokens, checkpoints:  8,   571.219 MiB
srv        update:    - prompt 0x58dc4c8ce8a0:   23906 tokens, checkpoints:  8,   739.114 MiB
srv        update:    - prompt 0x58dc38d9f350:   18675 tokens, checkpoints:  8,   606.205 MiB
srv        update:    - prompt 0x58dc3f0d1370:    8148 tokens, checkpoints:  8,   317.783 MiB
srv        update:    - prompt 0x58dc4e559330:    1905 tokens, checkpoints:  1,    86.270 MiB
srv        update:    - prompt 0x58dc7370fb50:   15396 tokens, checkpoints:  8,   535.811 MiB
srv  get_availabl: prompt cache update took 740.45 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 29725 | processing task, is_child = 0
slot update_slots: id  2 | task 29725 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 891
slot update_slots: id  2 | task 29725 | n_past = 881, slot.prompt.tokens.size() = 15396, seq_id = 2, pos_min = 14679, n_swa = 128
slot update_slots: id  2 | task 29725 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  2 | task 29725 | erased invalidated context checkpoint (pos_min = 12399, pos_max = 13271, n_swa = 128, size = 20.471 MiB)
slot update_slots: id  2 | task 29725 | erased invalidated context checkpoint (pos_min = 12592, pos_max = 13470, n_swa = 128, size = 20.612 MiB)
slot update_slots: id  2 | task 29725 | erased invalidated context checkpoint (pos_min = 12756, pos_max = 13652, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 29725 | erased invalidated context checkpoint (pos_min = 12913, pos_max = 13800, n_swa = 128, size = 20.823 MiB)
slot update_slots: id  2 | task 29725 | erased invalidated context checkpoint (pos_min = 13160, pos_max = 14056, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 29725 | erased invalidated context checkpoint (pos_min = 13841, pos_max = 14737, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 29725 | erased invalidated context checkpoint (pos_min = 14403, pos_max = 15119, n_swa = 128, size = 16.813 MiB)
slot update_slots: id  2 | task 29725 | erased invalidated context checkpoint (pos_min = 14517, pos_max = 15205, n_swa = 128, size = 16.157 MiB)
slot update_slots: id  2 | task 29725 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 29725 | prompt processing progress, n_tokens = 827, batch.n_tokens = 827, progress = 0.928171
slot update_slots: id  2 | task 29725 | n_tokens = 827, memory_seq_rm [827, end)
slot update_slots: id  2 | task 29725 | prompt processing progress, n_tokens = 891, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 29725 | prompt done, n_tokens = 891, batch.n_tokens = 64
slot init_sampler: id  2 | task 29725 | init sampler, took 0.13 ms, tokens: text = 891, total = 891
slot update_slots: id  2 | task 29725 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 826, size = 19.393 MiB)
slot print_timing: id  2 | task 29725 | 
prompt eval time =    1491.76 ms /   891 tokens (    1.67 ms per token,   597.28 tokens per second)
       eval time =    2165.93 ms /    77 tokens (   28.13 ms per token,    35.55 tokens per second)
      total time =    3657.69 ms /   968 tokens
slot      release: id  2 | task 29725 | stop processing: n_tokens = 967, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.640 (> 0.100 thold), f_keep = 0.976
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 29804 | processing task, is_child = 0
slot update_slots: id  2 | task 29804 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1475
slot update_slots: id  2 | task 29804 | n_tokens = 944, memory_seq_rm [944, end)
slot update_slots: id  2 | task 29804 | prompt processing progress, n_tokens = 1411, batch.n_tokens = 467, progress = 0.956610
slot update_slots: id  2 | task 29804 | n_tokens = 1411, memory_seq_rm [1411, end)
slot update_slots: id  2 | task 29804 | prompt processing progress, n_tokens = 1475, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 29804 | prompt done, n_tokens = 1475, batch.n_tokens = 64
slot init_sampler: id  2 | task 29804 | init sampler, took 0.21 ms, tokens: text = 1475, total = 1475
slot update_slots: id  2 | task 29804 | created context checkpoint 2 of 8 (pos_min = 514, pos_max = 1410, size = 21.034 MiB)
slot print_timing: id  2 | task 29804 | 
prompt eval time =     901.37 ms /   531 tokens (    1.70 ms per token,   589.11 tokens per second)
       eval time =    6240.06 ms /   209 tokens (   29.86 ms per token,    33.49 tokens per second)
      total time =    7141.42 ms /   740 tokens
slot      release: id  2 | task 29804 | stop processing: n_tokens = 1683, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.528
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 30015 | processing task, is_child = 0
slot update_slots: id  2 | task 30015 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 893
slot update_slots: id  2 | task 30015 | n_past = 888, slot.prompt.tokens.size() = 1683, seq_id = 2, pos_min = 786, n_swa = 128
slot update_slots: id  2 | task 30015 | restored context checkpoint (pos_min = 514, pos_max = 1410, size = 21.034 MiB)
slot update_slots: id  2 | task 30015 | n_tokens = 888, memory_seq_rm [888, end)
slot update_slots: id  2 | task 30015 | prompt processing progress, n_tokens = 893, batch.n_tokens = 5, progress = 1.000000
slot update_slots: id  2 | task 30015 | prompt done, n_tokens = 893, batch.n_tokens = 5
slot init_sampler: id  2 | task 30015 | init sampler, took 0.14 ms, tokens: text = 893, total = 893
slot print_timing: id  2 | task 30015 | 
prompt eval time =     268.46 ms /     5 tokens (   53.69 ms per token,    18.63 tokens per second)
       eval time =    3853.61 ms /   126 tokens (   30.58 ms per token,    32.70 tokens per second)
      total time =    4122.06 ms /   131 tokens
slot      release: id  2 | task 30015 | stop processing: n_tokens = 1018, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.971 (> 0.100 thold), f_keep = 0.865
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 30142 | processing task, is_child = 0
slot update_slots: id  2 | task 30142 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 907
slot update_slots: id  2 | task 30142 | n_tokens = 881, memory_seq_rm [881, end)
slot update_slots: id  2 | task 30142 | prompt processing progress, n_tokens = 907, batch.n_tokens = 26, progress = 1.000000
slot update_slots: id  2 | task 30142 | prompt done, n_tokens = 907, batch.n_tokens = 26
slot init_sampler: id  2 | task 30142 | init sampler, took 0.14 ms, tokens: text = 907, total = 907
slot print_timing: id  2 | task 30142 | 
prompt eval time =     197.83 ms /    26 tokens (    7.61 ms per token,   131.43 tokens per second)
       eval time =    2499.53 ms /    83 tokens (   30.11 ms per token,    33.21 tokens per second)
      total time =    2697.36 ms /   109 tokens
slot      release: id  2 | task 30142 | stop processing: n_tokens = 989, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.647 (> 0.100 thold), f_keep = 0.980
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 30226 | processing task, is_child = 0
slot update_slots: id  2 | task 30226 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1497
slot update_slots: id  2 | task 30226 | n_tokens = 969, memory_seq_rm [969, end)
slot update_slots: id  2 | task 30226 | prompt processing progress, n_tokens = 1433, batch.n_tokens = 464, progress = 0.957248
slot update_slots: id  2 | task 30226 | n_tokens = 1433, memory_seq_rm [1433, end)
slot update_slots: id  2 | task 30226 | prompt processing progress, n_tokens = 1497, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 30226 | prompt done, n_tokens = 1497, batch.n_tokens = 64
slot init_sampler: id  2 | task 30226 | init sampler, took 0.23 ms, tokens: text = 1497, total = 1497
slot print_timing: id  2 | task 30226 | 
prompt eval time =     944.62 ms /   528 tokens (    1.79 ms per token,   558.96 tokens per second)
       eval time =   17607.13 ms /   529 tokens (   33.28 ms per token,    30.04 tokens per second)
      total time =   18551.75 ms /  1057 tokens
slot      release: id  2 | task 30226 | stop processing: n_tokens = 2025, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.723 (> 0.100 thold), f_keep = 0.744
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 30757 | processing task, is_child = 0
slot update_slots: id  2 | task 30757 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2084
slot update_slots: id  2 | task 30757 | n_tokens = 1507, memory_seq_rm [1507, end)
slot update_slots: id  2 | task 30757 | prompt processing progress, n_tokens = 2020, batch.n_tokens = 513, progress = 0.969290
slot update_slots: id  2 | task 30757 | n_tokens = 2020, memory_seq_rm [2020, end)
slot update_slots: id  2 | task 30757 | prompt processing progress, n_tokens = 2084, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 30757 | prompt done, n_tokens = 2084, batch.n_tokens = 64
slot init_sampler: id  2 | task 30757 | init sampler, took 0.30 ms, tokens: text = 2084, total = 2084
slot update_slots: id  2 | task 30757 | created context checkpoint 3 of 8 (pos_min = 1380, pos_max = 2019, size = 15.008 MiB)
slot print_timing: id  2 | task 30757 | 
prompt eval time =    1114.71 ms /   577 tokens (    1.93 ms per token,   517.62 tokens per second)
       eval time =    1386.53 ms /    42 tokens (   33.01 ms per token,    30.29 tokens per second)
      total time =    2501.24 ms /   619 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 30757 | stop processing: n_tokens = 2125, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.505 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 30801 | processing task, is_child = 0
slot update_slots: id  2 | task 30801 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 4157
slot update_slots: id  2 | task 30801 | n_tokens = 2099, memory_seq_rm [2099, end)
slot update_slots: id  2 | task 30801 | prompt processing progress, n_tokens = 4093, batch.n_tokens = 1994, progress = 0.984604
slot update_slots: id  2 | task 30801 | n_tokens = 4093, memory_seq_rm [4093, end)
slot update_slots: id  2 | task 30801 | prompt processing progress, n_tokens = 4157, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 30801 | prompt done, n_tokens = 4157, batch.n_tokens = 64
slot init_sampler: id  2 | task 30801 | init sampler, took 0.58 ms, tokens: text = 4157, total = 4157
slot update_slots: id  2 | task 30801 | created context checkpoint 4 of 8 (pos_min = 3196, pos_max = 4092, size = 21.034 MiB)
slot print_timing: id  2 | task 30801 | 
prompt eval time =    3466.56 ms /  2058 tokens (    1.68 ms per token,   593.67 tokens per second)
       eval time =    1098.47 ms /    35 tokens (   31.38 ms per token,    31.86 tokens per second)
      total time =    4565.03 ms /  2093 tokens
slot      release: id  2 | task 30801 | stop processing: n_tokens = 4191, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.629 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 30838 | processing task, is_child = 0
slot update_slots: id  2 | task 30838 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 6621
slot update_slots: id  2 | task 30838 | n_tokens = 4165, memory_seq_rm [4165, end)
slot update_slots: id  2 | task 30838 | prompt processing progress, n_tokens = 6213, batch.n_tokens = 2048, progress = 0.938378
slot update_slots: id  2 | task 30838 | n_tokens = 6213, memory_seq_rm [6213, end)
slot update_slots: id  2 | task 30838 | prompt processing progress, n_tokens = 6557, batch.n_tokens = 344, progress = 0.990334
slot update_slots: id  2 | task 30838 | n_tokens = 6557, memory_seq_rm [6557, end)
slot update_slots: id  2 | task 30838 | prompt processing progress, n_tokens = 6621, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 30838 | prompt done, n_tokens = 6621, batch.n_tokens = 64
slot init_sampler: id  2 | task 30838 | init sampler, took 0.95 ms, tokens: text = 6621, total = 6621
slot update_slots: id  2 | task 30838 | created context checkpoint 5 of 8 (pos_min = 5660, pos_max = 6556, size = 21.034 MiB)
slot print_timing: id  2 | task 30838 | 
prompt eval time =    4029.25 ms /  2456 tokens (    1.64 ms per token,   609.54 tokens per second)
       eval time =    5181.21 ms /   171 tokens (   30.30 ms per token,    33.00 tokens per second)
      total time =    9210.46 ms /  2627 tokens
slot      release: id  2 | task 30838 | stop processing: n_tokens = 6791, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.959 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 31012 | processing task, is_child = 0
slot update_slots: id  2 | task 31012 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 7049
slot update_slots: id  2 | task 31012 | n_tokens = 6762, memory_seq_rm [6762, end)
slot update_slots: id  2 | task 31012 | prompt processing progress, n_tokens = 6985, batch.n_tokens = 223, progress = 0.990921
slot update_slots: id  2 | task 31012 | n_tokens = 6985, memory_seq_rm [6985, end)
slot update_slots: id  2 | task 31012 | prompt processing progress, n_tokens = 7049, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 31012 | prompt done, n_tokens = 7049, batch.n_tokens = 64
slot init_sampler: id  2 | task 31012 | init sampler, took 1.38 ms, tokens: text = 7049, total = 7049
slot update_slots: id  2 | task 31012 | created context checkpoint 6 of 8 (pos_min = 6088, pos_max = 6984, size = 21.034 MiB)
slot print_timing: id  2 | task 31012 | 
prompt eval time =     660.13 ms /   287 tokens (    2.30 ms per token,   434.76 tokens per second)
       eval time =    2657.42 ms /    88 tokens (   30.20 ms per token,    33.11 tokens per second)
      total time =    3317.55 ms /   375 tokens
slot      release: id  2 | task 31012 | stop processing: n_tokens = 7136, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.790 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 31102 | processing task, is_child = 0
slot update_slots: id  2 | task 31102 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 8992
slot update_slots: id  2 | task 31102 | n_tokens = 7106, memory_seq_rm [7106, end)
slot update_slots: id  2 | task 31102 | prompt processing progress, n_tokens = 8928, batch.n_tokens = 1822, progress = 0.992883
slot update_slots: id  2 | task 31102 | n_tokens = 8928, memory_seq_rm [8928, end)
slot update_slots: id  2 | task 31102 | prompt processing progress, n_tokens = 8992, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 31102 | prompt done, n_tokens = 8992, batch.n_tokens = 64
slot init_sampler: id  2 | task 31102 | init sampler, took 1.26 ms, tokens: text = 8992, total = 8992
slot update_slots: id  2 | task 31102 | created context checkpoint 7 of 8 (pos_min = 8031, pos_max = 8927, size = 21.034 MiB)
slot print_timing: id  2 | task 31102 | 
prompt eval time =    2949.69 ms /  1886 tokens (    1.56 ms per token,   639.39 tokens per second)
       eval time =    6137.23 ms /   208 tokens (   29.51 ms per token,    33.89 tokens per second)
      total time =    9086.92 ms /  2094 tokens
slot      release: id  2 | task 31102 | stop processing: n_tokens = 9199, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.968 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 31312 | processing task, is_child = 0
slot update_slots: id  2 | task 31312 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 9476
slot update_slots: id  2 | task 31312 | n_tokens = 9171, memory_seq_rm [9171, end)
slot update_slots: id  2 | task 31312 | prompt processing progress, n_tokens = 9412, batch.n_tokens = 241, progress = 0.993246
slot update_slots: id  2 | task 31312 | n_tokens = 9412, memory_seq_rm [9412, end)
slot update_slots: id  2 | task 31312 | prompt processing progress, n_tokens = 9476, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 31312 | prompt done, n_tokens = 9476, batch.n_tokens = 64
slot init_sampler: id  2 | task 31312 | init sampler, took 2.08 ms, tokens: text = 9476, total = 9476
slot update_slots: id  2 | task 31312 | created context checkpoint 8 of 8 (pos_min = 8515, pos_max = 9411, size = 21.034 MiB)
slot print_timing: id  2 | task 31312 | 
prompt eval time =     681.42 ms /   305 tokens (    2.23 ms per token,   447.59 tokens per second)
       eval time =    6246.76 ms /   218 tokens (   28.65 ms per token,    34.90 tokens per second)
      total time =    6928.18 ms /   523 tokens
slot      release: id  2 | task 31312 | stop processing: n_tokens = 9693, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.980 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 31532 | processing task, is_child = 0
slot update_slots: id  2 | task 31532 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 9733
slot update_slots: id  2 | task 31532 | n_tokens = 9543, memory_seq_rm [9543, end)
slot update_slots: id  2 | task 31532 | prompt processing progress, n_tokens = 9669, batch.n_tokens = 126, progress = 0.993424
slot update_slots: id  2 | task 31532 | n_tokens = 9669, memory_seq_rm [9669, end)
slot update_slots: id  2 | task 31532 | prompt processing progress, n_tokens = 9733, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 31532 | prompt done, n_tokens = 9733, batch.n_tokens = 64
slot init_sampler: id  2 | task 31532 | init sampler, took 1.54 ms, tokens: text = 9733, total = 9733
slot update_slots: id  2 | task 31532 | erasing old context checkpoint (pos_min = 0, pos_max = 826, size = 19.393 MiB)
slot update_slots: id  2 | task 31532 | created context checkpoint 8 of 8 (pos_min = 8796, pos_max = 9668, size = 20.471 MiB)
slot print_timing: id  2 | task 31532 | 
prompt eval time =     685.84 ms /   190 tokens (    3.61 ms per token,   277.03 tokens per second)
       eval time =    7366.55 ms /   253 tokens (   29.12 ms per token,    34.34 tokens per second)
      total time =    8052.39 ms /   443 tokens
slot      release: id  2 | task 31532 | stop processing: n_tokens = 9985, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.971 (> 0.100 thold), f_keep = 0.976
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 31787 | processing task, is_child = 0
slot update_slots: id  2 | task 31787 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 10029
slot update_slots: id  2 | task 31787 | n_tokens = 9743, memory_seq_rm [9743, end)
slot update_slots: id  2 | task 31787 | prompt processing progress, n_tokens = 9965, batch.n_tokens = 222, progress = 0.993618
slot update_slots: id  2 | task 31787 | n_tokens = 9965, memory_seq_rm [9965, end)
slot update_slots: id  2 | task 31787 | prompt processing progress, n_tokens = 10029, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 31787 | prompt done, n_tokens = 10029, batch.n_tokens = 64
slot init_sampler: id  2 | task 31787 | init sampler, took 1.39 ms, tokens: text = 10029, total = 10029
slot update_slots: id  2 | task 31787 | erasing old context checkpoint (pos_min = 514, pos_max = 1410, size = 21.034 MiB)
slot update_slots: id  2 | task 31787 | created context checkpoint 8 of 8 (pos_min = 9088, pos_max = 9964, size = 20.565 MiB)
slot print_timing: id  2 | task 31787 | 
prompt eval time =     654.31 ms /   286 tokens (    2.29 ms per token,   437.10 tokens per second)
       eval time =    6555.64 ms /   217 tokens (   30.21 ms per token,    33.10 tokens per second)
      total time =    7209.95 ms /   503 tokens
slot      release: id  2 | task 31787 | stop processing: n_tokens = 10245, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.976 (> 0.100 thold), f_keep = 0.980
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 32006 | processing task, is_child = 0
slot update_slots: id  2 | task 32006 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 10287
slot update_slots: id  2 | task 32006 | n_tokens = 10039, memory_seq_rm [10039, end)
slot update_slots: id  2 | task 32006 | prompt processing progress, n_tokens = 10223, batch.n_tokens = 184, progress = 0.993779
slot update_slots: id  2 | task 32006 | n_tokens = 10223, memory_seq_rm [10223, end)
slot update_slots: id  2 | task 32006 | prompt processing progress, n_tokens = 10287, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 32006 | prompt done, n_tokens = 10287, batch.n_tokens = 64
slot init_sampler: id  2 | task 32006 | init sampler, took 1.41 ms, tokens: text = 10287, total = 10287
slot update_slots: id  2 | task 32006 | erasing old context checkpoint (pos_min = 1380, pos_max = 2019, size = 15.008 MiB)
slot update_slots: id  2 | task 32006 | created context checkpoint 8 of 8 (pos_min = 9348, pos_max = 10222, size = 20.518 MiB)
slot print_timing: id  2 | task 32006 | 
prompt eval time =     630.97 ms /   248 tokens (    2.54 ms per token,   393.05 tokens per second)
       eval time =    1879.08 ms /    62 tokens (   30.31 ms per token,    32.99 tokens per second)
      total time =    2510.05 ms /   310 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 32006 | stop processing: n_tokens = 10348, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.972 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 32070 | processing task, is_child = 0
slot update_slots: id  2 | task 32070 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 10615
slot update_slots: id  2 | task 32070 | n_tokens = 10323, memory_seq_rm [10323, end)
slot update_slots: id  2 | task 32070 | prompt processing progress, n_tokens = 10551, batch.n_tokens = 228, progress = 0.993971
slot update_slots: id  2 | task 32070 | n_tokens = 10551, memory_seq_rm [10551, end)
slot update_slots: id  2 | task 32070 | prompt processing progress, n_tokens = 10615, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 32070 | prompt done, n_tokens = 10615, batch.n_tokens = 64
slot init_sampler: id  2 | task 32070 | init sampler, took 2.00 ms, tokens: text = 10615, total = 10615
slot update_slots: id  2 | task 32070 | erasing old context checkpoint (pos_min = 3196, pos_max = 4092, size = 21.034 MiB)
slot update_slots: id  2 | task 32070 | created context checkpoint 8 of 8 (pos_min = 9654, pos_max = 10550, size = 21.034 MiB)
slot print_timing: id  2 | task 32070 | 
prompt eval time =     714.22 ms /   292 tokens (    2.45 ms per token,   408.84 tokens per second)
       eval time =   17348.78 ms /   547 tokens (   31.72 ms per token,    31.53 tokens per second)
      total time =   18063.00 ms /   839 tokens
slot      release: id  2 | task 32070 | stop processing: n_tokens = 11161, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.079
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 11161, total state size = 282.748 MiB
srv          load:  - looking for better prompt, base f_keep = 0.079, sim = 0.987
srv        update:  - cache state: 12 prompts, 5320.409 MiB (limits: 8192.000 MiB, 56064 tokens, 216567 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv        update:    - prompt 0x58dc3fb8c770:    5127 tokens, checkpoints:  8,   320.808 MiB
srv        update:    - prompt 0x58dc3f318830:   24865 tokens, checkpoints:  8,   791.874 MiB
srv        update:    - prompt 0x58dc40d3cf50:   16080 tokens, checkpoints:  8,   571.219 MiB
srv        update:    - prompt 0x58dc4c8ce8a0:   23906 tokens, checkpoints:  8,   739.114 MiB
srv        update:    - prompt 0x58dc38d9f350:   18675 tokens, checkpoints:  8,   606.205 MiB
srv        update:    - prompt 0x58dc3f0d1370:    8148 tokens, checkpoints:  8,   317.783 MiB
srv        update:    - prompt 0x58dc4e559330:    1905 tokens, checkpoints:  1,    86.270 MiB
srv        update:    - prompt 0x58dc7370fb50:   15396 tokens, checkpoints:  8,   535.811 MiB
srv        update:    - prompt 0x58dc3f803040:   11161 tokens, checkpoints:  8,   449.472 MiB
srv  get_availabl: prompt cache update took 853.59 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 32619 | processing task, is_child = 0
slot update_slots: id  2 | task 32619 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 893
slot update_slots: id  2 | task 32619 | n_past = 881, slot.prompt.tokens.size() = 11161, seq_id = 2, pos_min = 10264, n_swa = 128
slot update_slots: id  2 | task 32619 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  2 | task 32619 | erased invalidated context checkpoint (pos_min = 5660, pos_max = 6556, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 32619 | erased invalidated context checkpoint (pos_min = 6088, pos_max = 6984, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 32619 | erased invalidated context checkpoint (pos_min = 8031, pos_max = 8927, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 32619 | erased invalidated context checkpoint (pos_min = 8515, pos_max = 9411, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 32619 | erased invalidated context checkpoint (pos_min = 8796, pos_max = 9668, n_swa = 128, size = 20.471 MiB)
slot update_slots: id  2 | task 32619 | erased invalidated context checkpoint (pos_min = 9088, pos_max = 9964, n_swa = 128, size = 20.565 MiB)
slot update_slots: id  2 | task 32619 | erased invalidated context checkpoint (pos_min = 9348, pos_max = 10222, n_swa = 128, size = 20.518 MiB)
slot update_slots: id  2 | task 32619 | erased invalidated context checkpoint (pos_min = 9654, pos_max = 10550, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 32619 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 32619 | prompt processing progress, n_tokens = 829, batch.n_tokens = 829, progress = 0.928331
slot update_slots: id  2 | task 32619 | n_tokens = 829, memory_seq_rm [829, end)
slot update_slots: id  2 | task 32619 | prompt processing progress, n_tokens = 893, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 32619 | prompt done, n_tokens = 893, batch.n_tokens = 64
slot init_sampler: id  2 | task 32619 | init sampler, took 0.14 ms, tokens: text = 893, total = 893
slot update_slots: id  2 | task 32619 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 828, size = 19.439 MiB)
slot print_timing: id  2 | task 32619 | 
prompt eval time =    1492.96 ms /   893 tokens (    1.67 ms per token,   598.14 tokens per second)
       eval time =    2843.43 ms /   100 tokens (   28.43 ms per token,    35.17 tokens per second)
      total time =    4336.39 ms /   993 tokens
slot      release: id  2 | task 32619 | stop processing: n_tokens = 992, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 1.000 (> 0.100 thold), f_keep = 0.900
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 32721 | processing task, is_child = 0
slot update_slots: id  2 | task 32721 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 893
slot update_slots: id  2 | task 32721 | need to evaluate at least 1 token for each active slot (n_past = 893, task.n_tokens() = 893)
slot update_slots: id  2 | task 32721 | n_past was set to 892
slot update_slots: id  2 | task 32721 | n_tokens = 892, memory_seq_rm [892, end)
slot update_slots: id  2 | task 32721 | prompt processing progress, n_tokens = 893, batch.n_tokens = 1, progress = 1.000000
slot update_slots: id  2 | task 32721 | prompt done, n_tokens = 893, batch.n_tokens = 1
slot init_sampler: id  2 | task 32721 | init sampler, took 0.15 ms, tokens: text = 893, total = 893
slot print_timing: id  2 | task 32721 | 
prompt eval time =      36.58 ms /     1 tokens (   36.58 ms per token,    27.34 tokens per second)
       eval time =    2459.93 ms /    85 tokens (   28.94 ms per token,    34.55 tokens per second)
      total time =    2496.51 ms /    86 tokens
slot      release: id  2 | task 32721 | stop processing: n_tokens = 977, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 1.000 (> 0.100 thold), f_keep = 0.914
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 32807 | processing task, is_child = 0
slot update_slots: id  2 | task 32807 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 893
slot update_slots: id  2 | task 32807 | need to evaluate at least 1 token for each active slot (n_past = 893, task.n_tokens() = 893)
slot update_slots: id  2 | task 32807 | n_past was set to 892
slot update_slots: id  2 | task 32807 | n_tokens = 892, memory_seq_rm [892, end)
slot update_slots: id  2 | task 32807 | prompt processing progress, n_tokens = 893, batch.n_tokens = 1, progress = 1.000000
slot update_slots: id  2 | task 32807 | prompt done, n_tokens = 893, batch.n_tokens = 1
slot init_sampler: id  2 | task 32807 | init sampler, took 0.13 ms, tokens: text = 893, total = 893
slot print_timing: id  2 | task 32807 | 
prompt eval time =      36.53 ms /     1 tokens (   36.53 ms per token,    27.37 tokens per second)
       eval time =    3210.14 ms /   105 tokens (   30.57 ms per token,    32.71 tokens per second)
      total time =    3246.68 ms /   106 tokens
slot      release: id  2 | task 32807 | stop processing: n_tokens = 997, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.945 (> 0.100 thold), f_keep = 0.884
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 32913 | processing task, is_child = 0
slot update_slots: id  2 | task 32913 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 932
slot update_slots: id  2 | task 32913 | n_tokens = 881, memory_seq_rm [881, end)
slot update_slots: id  2 | task 32913 | prompt processing progress, n_tokens = 932, batch.n_tokens = 51, progress = 1.000000
slot update_slots: id  2 | task 32913 | prompt done, n_tokens = 932, batch.n_tokens = 51
slot init_sampler: id  2 | task 32913 | init sampler, took 0.14 ms, tokens: text = 932, total = 932
slot print_timing: id  2 | task 32913 | 
prompt eval time =     277.79 ms /    51 tokens (    5.45 ms per token,   183.59 tokens per second)
       eval time =    1727.91 ms /    57 tokens (   30.31 ms per token,    32.99 tokens per second)
      total time =    2005.69 ms /   108 tokens
slot      release: id  2 | task 32913 | stop processing: n_tokens = 988, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.648 (> 0.100 thold), f_keep = 0.981
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 32971 | processing task, is_child = 0
slot update_slots: id  2 | task 32971 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1496
slot update_slots: id  2 | task 32971 | n_tokens = 969, memory_seq_rm [969, end)
slot update_slots: id  2 | task 32971 | prompt processing progress, n_tokens = 1432, batch.n_tokens = 463, progress = 0.957219
slot update_slots: id  2 | task 32971 | n_tokens = 1432, memory_seq_rm [1432, end)
slot update_slots: id  2 | task 32971 | prompt processing progress, n_tokens = 1496, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 32971 | prompt done, n_tokens = 1496, batch.n_tokens = 64
slot init_sampler: id  2 | task 32971 | init sampler, took 0.21 ms, tokens: text = 1496, total = 1496
slot update_slots: id  2 | task 32971 | created context checkpoint 2 of 8 (pos_min = 551, pos_max = 1431, size = 20.659 MiB)
slot print_timing: id  2 | task 32971 | 
prompt eval time =     956.09 ms /   527 tokens (    1.81 ms per token,   551.20 tokens per second)
       eval time =    5447.81 ms /   167 tokens (   32.62 ms per token,    30.65 tokens per second)
      total time =    6403.90 ms /   694 tokens
slot      release: id  2 | task 32971 | stop processing: n_tokens = 1662, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.886 (> 0.100 thold), f_keep = 0.906
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 33140 | processing task, is_child = 0
slot update_slots: id  2 | task 33140 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1699
slot update_slots: id  2 | task 33140 | n_tokens = 1506, memory_seq_rm [1506, end)
slot update_slots: id  2 | task 33140 | prompt processing progress, n_tokens = 1635, batch.n_tokens = 129, progress = 0.962331
slot update_slots: id  2 | task 33140 | n_tokens = 1635, memory_seq_rm [1635, end)
slot update_slots: id  2 | task 33140 | prompt processing progress, n_tokens = 1699, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 33140 | prompt done, n_tokens = 1699, batch.n_tokens = 64
slot init_sampler: id  2 | task 33140 | init sampler, took 0.25 ms, tokens: text = 1699, total = 1699
slot update_slots: id  2 | task 33140 | created context checkpoint 3 of 8 (pos_min = 781, pos_max = 1634, size = 20.026 MiB)
slot print_timing: id  2 | task 33140 | 
prompt eval time =     637.52 ms /   193 tokens (    3.30 ms per token,   302.74 tokens per second)
       eval time =    1313.94 ms /    40 tokens (   32.85 ms per token,    30.44 tokens per second)
      total time =    1951.46 ms /   233 tokens
slot      release: id  2 | task 33140 | stop processing: n_tokens = 1738, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.452 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 33182 | processing task, is_child = 0
slot update_slots: id  2 | task 33182 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 3787
slot update_slots: id  2 | task 33182 | n_tokens = 1712, memory_seq_rm [1712, end)
slot update_slots: id  2 | task 33182 | prompt processing progress, n_tokens = 3723, batch.n_tokens = 2011, progress = 0.983100
slot update_slots: id  2 | task 33182 | n_tokens = 3723, memory_seq_rm [3723, end)
slot update_slots: id  2 | task 33182 | prompt processing progress, n_tokens = 3787, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 33182 | prompt done, n_tokens = 3787, batch.n_tokens = 64
slot init_sampler: id  2 | task 33182 | init sampler, took 0.52 ms, tokens: text = 3787, total = 3787
slot update_slots: id  2 | task 33182 | created context checkpoint 4 of 8 (pos_min = 2826, pos_max = 3722, size = 21.034 MiB)
slot print_timing: id  2 | task 33182 | 
prompt eval time =    3509.68 ms /  2075 tokens (    1.69 ms per token,   591.22 tokens per second)
       eval time =    1426.28 ms /    43 tokens (   33.17 ms per token,    30.15 tokens per second)
      total time =    4935.97 ms /  2118 tokens
slot      release: id  2 | task 33182 | stop processing: n_tokens = 3829, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.922 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 33227 | processing task, is_child = 0
slot update_slots: id  2 | task 33227 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 4123
slot update_slots: id  2 | task 33227 | n_tokens = 3802, memory_seq_rm [3802, end)
slot update_slots: id  2 | task 33227 | prompt processing progress, n_tokens = 4059, batch.n_tokens = 257, progress = 0.984477
slot update_slots: id  2 | task 33227 | n_tokens = 4059, memory_seq_rm [4059, end)
slot update_slots: id  2 | task 33227 | prompt processing progress, n_tokens = 4123, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 33227 | prompt done, n_tokens = 4123, batch.n_tokens = 64
slot init_sampler: id  2 | task 33227 | init sampler, took 0.57 ms, tokens: text = 4123, total = 4123
slot update_slots: id  2 | task 33227 | created context checkpoint 5 of 8 (pos_min = 3162, pos_max = 4058, size = 21.034 MiB)
slot print_timing: id  2 | task 33227 | 
prompt eval time =     748.15 ms /   321 tokens (    2.33 ms per token,   429.06 tokens per second)
       eval time =    5161.79 ms /   157 tokens (   32.88 ms per token,    30.42 tokens per second)
      total time =    5909.94 ms /   478 tokens
slot      release: id  2 | task 33227 | stop processing: n_tokens = 4279, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.959 (> 0.100 thold), f_keep = 0.968
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 33386 | processing task, is_child = 0
slot update_slots: id  2 | task 33386 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 4320
slot update_slots: id  2 | task 33386 | n_tokens = 4141, memory_seq_rm [4141, end)
slot update_slots: id  2 | task 33386 | prompt processing progress, n_tokens = 4256, batch.n_tokens = 115, progress = 0.985185
slot update_slots: id  2 | task 33386 | n_tokens = 4256, memory_seq_rm [4256, end)
slot update_slots: id  2 | task 33386 | prompt processing progress, n_tokens = 4320, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 33386 | prompt done, n_tokens = 4320, batch.n_tokens = 64
slot init_sampler: id  2 | task 33386 | init sampler, took 0.60 ms, tokens: text = 4320, total = 4320
slot update_slots: id  2 | task 33386 | created context checkpoint 6 of 8 (pos_min = 3382, pos_max = 4255, size = 20.495 MiB)
slot print_timing: id  2 | task 33386 | 
prompt eval time =     648.53 ms /   179 tokens (    3.62 ms per token,   276.01 tokens per second)
       eval time =    2695.23 ms /    86 tokens (   31.34 ms per token,    31.91 tokens per second)
      total time =    3343.76 ms /   265 tokens
slot      release: id  2 | task 33386 | stop processing: n_tokens = 4405, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.924 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 33474 | processing task, is_child = 0
slot update_slots: id  2 | task 33474 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 4737
slot update_slots: id  2 | task 33474 | n_tokens = 4379, memory_seq_rm [4379, end)
slot update_slots: id  2 | task 33474 | prompt processing progress, n_tokens = 4673, batch.n_tokens = 294, progress = 0.986489
slot update_slots: id  2 | task 33474 | n_tokens = 4673, memory_seq_rm [4673, end)
slot update_slots: id  2 | task 33474 | prompt processing progress, n_tokens = 4737, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 33474 | prompt done, n_tokens = 4737, batch.n_tokens = 64
slot init_sampler: id  2 | task 33474 | init sampler, took 0.65 ms, tokens: text = 4737, total = 4737
slot update_slots: id  2 | task 33474 | created context checkpoint 7 of 8 (pos_min = 3776, pos_max = 4672, size = 21.034 MiB)
slot print_timing: id  2 | task 33474 | 
prompt eval time =     775.20 ms /   358 tokens (    2.17 ms per token,   461.82 tokens per second)
       eval time =    2389.87 ms /    78 tokens (   30.64 ms per token,    32.64 tokens per second)
      total time =    3165.06 ms /   436 tokens
slot      release: id  2 | task 33474 | stop processing: n_tokens = 4814, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.715 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 33554 | processing task, is_child = 0
slot update_slots: id  2 | task 33554 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 6691
slot update_slots: id  2 | task 33554 | n_tokens = 4787, memory_seq_rm [4787, end)
slot update_slots: id  2 | task 33554 | prompt processing progress, n_tokens = 6627, batch.n_tokens = 1840, progress = 0.990435
slot update_slots: id  2 | task 33554 | n_tokens = 6627, memory_seq_rm [6627, end)
slot update_slots: id  2 | task 33554 | prompt processing progress, n_tokens = 6691, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 33554 | prompt done, n_tokens = 6691, batch.n_tokens = 64
slot init_sampler: id  2 | task 33554 | init sampler, took 1.27 ms, tokens: text = 6691, total = 6691
slot update_slots: id  2 | task 33554 | created context checkpoint 8 of 8 (pos_min = 5730, pos_max = 6626, size = 21.034 MiB)
slot print_timing: id  2 | task 33554 | 
prompt eval time =    3072.67 ms /  1904 tokens (    1.61 ms per token,   619.66 tokens per second)
       eval time =    1291.10 ms /    43 tokens (   30.03 ms per token,    33.30 tokens per second)
      total time =    4363.77 ms /  1947 tokens
slot      release: id  2 | task 33554 | stop processing: n_tokens = 6733, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.766 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 33599 | processing task, is_child = 0
slot update_slots: id  2 | task 33599 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 8754
slot update_slots: id  2 | task 33599 | n_tokens = 6706, memory_seq_rm [6706, end)
slot update_slots: id  2 | task 33599 | prompt processing progress, n_tokens = 8690, batch.n_tokens = 1984, progress = 0.992689
slot update_slots: id  2 | task 33599 | n_tokens = 8690, memory_seq_rm [8690, end)
slot update_slots: id  2 | task 33599 | prompt processing progress, n_tokens = 8754, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 33599 | prompt done, n_tokens = 8754, batch.n_tokens = 64
slot init_sampler: id  2 | task 33599 | init sampler, took 1.29 ms, tokens: text = 8754, total = 8754
slot update_slots: id  2 | task 33599 | erasing old context checkpoint (pos_min = 0, pos_max = 828, size = 19.439 MiB)
slot update_slots: id  2 | task 33599 | created context checkpoint 8 of 8 (pos_min = 7793, pos_max = 8689, size = 21.034 MiB)
slot print_timing: id  2 | task 33599 | 
prompt eval time =    3152.34 ms /  2048 tokens (    1.54 ms per token,   649.68 tokens per second)
       eval time =    1766.17 ms /    59 tokens (   29.94 ms per token,    33.41 tokens per second)
      total time =    4918.52 ms /  2107 tokens
slot      release: id  2 | task 33599 | stop processing: n_tokens = 8812, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.853 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 33660 | processing task, is_child = 0
slot update_slots: id  2 | task 33660 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 10301
slot update_slots: id  2 | task 33660 | n_tokens = 8785, memory_seq_rm [8785, end)
slot update_slots: id  2 | task 33660 | prompt processing progress, n_tokens = 10237, batch.n_tokens = 1452, progress = 0.993787
slot update_slots: id  2 | task 33660 | n_tokens = 10237, memory_seq_rm [10237, end)
slot update_slots: id  2 | task 33660 | prompt processing progress, n_tokens = 10301, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 33660 | prompt done, n_tokens = 10301, batch.n_tokens = 64
slot init_sampler: id  2 | task 33660 | init sampler, took 1.44 ms, tokens: text = 10301, total = 10301
slot update_slots: id  2 | task 33660 | erasing old context checkpoint (pos_min = 551, pos_max = 1431, size = 20.659 MiB)
slot update_slots: id  2 | task 33660 | created context checkpoint 8 of 8 (pos_min = 9340, pos_max = 10236, size = 21.034 MiB)
slot print_timing: id  2 | task 33660 | 
prompt eval time =    2427.23 ms /  1516 tokens (    1.60 ms per token,   624.58 tokens per second)
       eval time =    9433.67 ms /   315 tokens (   29.95 ms per token,    33.39 tokens per second)
      total time =   11860.91 ms /  1831 tokens
slot      release: id  2 | task 33660 | stop processing: n_tokens = 10615, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.807 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 33977 | processing task, is_child = 0
slot update_slots: id  2 | task 33977 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13114
slot update_slots: id  2 | task 33977 | n_tokens = 10586, memory_seq_rm [10586, end)
slot update_slots: id  2 | task 33977 | prompt processing progress, n_tokens = 12634, batch.n_tokens = 2048, progress = 0.963398
slot update_slots: id  2 | task 33977 | n_tokens = 12634, memory_seq_rm [12634, end)
slot update_slots: id  2 | task 33977 | prompt processing progress, n_tokens = 13050, batch.n_tokens = 416, progress = 0.995120
slot update_slots: id  2 | task 33977 | n_tokens = 13050, memory_seq_rm [13050, end)
slot update_slots: id  2 | task 33977 | prompt processing progress, n_tokens = 13114, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 33977 | prompt done, n_tokens = 13114, batch.n_tokens = 64
slot init_sampler: id  2 | task 33977 | init sampler, took 1.90 ms, tokens: text = 13114, total = 13114
slot update_slots: id  2 | task 33977 | erasing old context checkpoint (pos_min = 781, pos_max = 1634, size = 20.026 MiB)
slot update_slots: id  2 | task 33977 | created context checkpoint 8 of 8 (pos_min = 12153, pos_max = 13049, size = 21.034 MiB)
slot print_timing: id  2 | task 33977 | 
prompt eval time =    4026.43 ms /  2528 tokens (    1.59 ms per token,   627.85 tokens per second)
       eval time =    1037.18 ms /    35 tokens (   29.63 ms per token,    33.75 tokens per second)
      total time =    5063.62 ms /  2563 tokens
slot      release: id  2 | task 33977 | stop processing: n_tokens = 13148, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 34015 | processing task, is_child = 0
slot update_slots: id  2 | task 34015 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13238
slot update_slots: id  2 | task 34015 | n_tokens = 13122, memory_seq_rm [13122, end)
slot update_slots: id  2 | task 34015 | prompt processing progress, n_tokens = 13174, batch.n_tokens = 52, progress = 0.995165
slot update_slots: id  2 | task 34015 | n_tokens = 13174, memory_seq_rm [13174, end)
slot update_slots: id  2 | task 34015 | prompt processing progress, n_tokens = 13238, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 34015 | prompt done, n_tokens = 13238, batch.n_tokens = 64
slot init_sampler: id  2 | task 34015 | init sampler, took 1.84 ms, tokens: text = 13238, total = 13238
slot update_slots: id  2 | task 34015 | erasing old context checkpoint (pos_min = 2826, pos_max = 3722, size = 21.034 MiB)
slot update_slots: id  2 | task 34015 | created context checkpoint 8 of 8 (pos_min = 12277, pos_max = 13173, size = 21.034 MiB)
slot print_timing: id  2 | task 34015 | 
prompt eval time =     433.84 ms /   116 tokens (    3.74 ms per token,   267.38 tokens per second)
       eval time =   16172.87 ms /   533 tokens (   30.34 ms per token,    32.96 tokens per second)
      total time =   16606.72 ms /   649 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 34015 | stop processing: n_tokens = 13770, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.973 (> 0.100 thold), f_keep = 0.976
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 34550 | processing task, is_child = 0
slot update_slots: id  2 | task 34550 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13811
slot update_slots: id  2 | task 34550 | n_tokens = 13444, memory_seq_rm [13444, end)
slot update_slots: id  2 | task 34550 | prompt processing progress, n_tokens = 13747, batch.n_tokens = 303, progress = 0.995366
slot update_slots: id  2 | task 34550 | n_tokens = 13747, memory_seq_rm [13747, end)
slot update_slots: id  2 | task 34550 | prompt processing progress, n_tokens = 13811, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 34550 | prompt done, n_tokens = 13811, batch.n_tokens = 64
slot init_sampler: id  2 | task 34550 | init sampler, took 2.72 ms, tokens: text = 13811, total = 13811
slot update_slots: id  2 | task 34550 | erasing old context checkpoint (pos_min = 3162, pos_max = 4058, size = 21.034 MiB)
slot update_slots: id  2 | task 34550 | created context checkpoint 8 of 8 (pos_min = 12873, pos_max = 13746, size = 20.495 MiB)
slot print_timing: id  2 | task 34550 | 
prompt eval time =     812.67 ms /   367 tokens (    2.21 ms per token,   451.60 tokens per second)
       eval time =   15524.24 ms /   505 tokens (   30.74 ms per token,    32.53 tokens per second)
      total time =   16336.91 ms /   872 tokens
slot      release: id  2 | task 34550 | stop processing: n_tokens = 14315, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.969 (> 0.100 thold), f_keep = 0.972
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 35057 | processing task, is_child = 0
slot update_slots: id  2 | task 35057 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 14359
slot update_slots: id  2 | task 35057 | n_tokens = 13908, memory_seq_rm [13908, end)
slot update_slots: id  2 | task 35057 | prompt processing progress, n_tokens = 14295, batch.n_tokens = 387, progress = 0.995543
slot update_slots: id  2 | task 35057 | n_tokens = 14295, memory_seq_rm [14295, end)
slot update_slots: id  2 | task 35057 | prompt processing progress, n_tokens = 14359, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 35057 | prompt done, n_tokens = 14359, batch.n_tokens = 64
slot init_sampler: id  2 | task 35057 | init sampler, took 1.97 ms, tokens: text = 14359, total = 14359
slot update_slots: id  2 | task 35057 | erasing old context checkpoint (pos_min = 3382, pos_max = 4255, size = 20.495 MiB)
slot update_slots: id  2 | task 35057 | created context checkpoint 8 of 8 (pos_min = 13418, pos_max = 14294, size = 20.565 MiB)
slot print_timing: id  2 | task 35057 | 
prompt eval time =     947.70 ms /   451 tokens (    2.10 ms per token,   475.89 tokens per second)
       eval time =    2414.50 ms /    76 tokens (   31.77 ms per token,    31.48 tokens per second)
      total time =    3362.19 ms /   527 tokens
slot      release: id  2 | task 35057 | stop processing: n_tokens = 14434, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 35135 | processing task, is_child = 0
slot update_slots: id  2 | task 35135 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 14493
slot update_slots: id  2 | task 35135 | n_tokens = 14406, memory_seq_rm [14406, end)
slot update_slots: id  2 | task 35135 | prompt processing progress, n_tokens = 14429, batch.n_tokens = 23, progress = 0.995584
slot update_slots: id  2 | task 35135 | n_tokens = 14429, memory_seq_rm [14429, end)
slot update_slots: id  2 | task 35135 | prompt processing progress, n_tokens = 14493, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 35135 | prompt done, n_tokens = 14493, batch.n_tokens = 64
slot init_sampler: id  2 | task 35135 | init sampler, took 2.12 ms, tokens: text = 14493, total = 14493
slot update_slots: id  2 | task 35135 | erasing old context checkpoint (pos_min = 3776, pos_max = 4672, size = 21.034 MiB)
slot update_slots: id  2 | task 35135 | created context checkpoint 8 of 8 (pos_min = 13537, pos_max = 14428, size = 20.917 MiB)
slot print_timing: id  2 | task 35135 | 
prompt eval time =     381.67 ms /    87 tokens (    4.39 ms per token,   227.95 tokens per second)
       eval time =    1268.80 ms /    40 tokens (   31.72 ms per token,    31.53 tokens per second)
      total time =    1650.47 ms /   127 tokens
slot      release: id  2 | task 35135 | stop processing: n_tokens = 14532, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.960 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 35177 | processing task, is_child = 0
slot update_slots: id  2 | task 35177 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 15115
slot update_slots: id  2 | task 35177 | n_tokens = 14506, memory_seq_rm [14506, end)
slot update_slots: id  2 | task 35177 | prompt processing progress, n_tokens = 15051, batch.n_tokens = 545, progress = 0.995766
slot update_slots: id  2 | task 35177 | n_tokens = 15051, memory_seq_rm [15051, end)
slot update_slots: id  2 | task 35177 | prompt processing progress, n_tokens = 15115, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 35177 | prompt done, n_tokens = 15115, batch.n_tokens = 64
slot init_sampler: id  2 | task 35177 | init sampler, took 2.72 ms, tokens: text = 15115, total = 15115
slot update_slots: id  2 | task 35177 | erasing old context checkpoint (pos_min = 5730, pos_max = 6626, size = 21.034 MiB)
slot update_slots: id  2 | task 35177 | created context checkpoint 8 of 8 (pos_min = 14154, pos_max = 15050, size = 21.034 MiB)
slot print_timing: id  2 | task 35177 | 
prompt eval time =    1323.12 ms /   609 tokens (    2.17 ms per token,   460.28 tokens per second)
       eval time =    7032.62 ms /   219 tokens (   32.11 ms per token,    31.14 tokens per second)
      total time =    8355.74 ms /   828 tokens
slot      release: id  2 | task 35177 | stop processing: n_tokens = 15333, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 35398 | processing task, is_child = 0
slot update_slots: id  2 | task 35398 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 15377
slot update_slots: id  2 | task 35398 | n_tokens = 15140, memory_seq_rm [15140, end)
slot update_slots: id  2 | task 35398 | prompt processing progress, n_tokens = 15313, batch.n_tokens = 173, progress = 0.995838
slot update_slots: id  2 | task 35398 | n_tokens = 15313, memory_seq_rm [15313, end)
slot update_slots: id  2 | task 35398 | prompt processing progress, n_tokens = 15377, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 35398 | prompt done, n_tokens = 15377, batch.n_tokens = 64
slot init_sampler: id  2 | task 35398 | init sampler, took 2.11 ms, tokens: text = 15377, total = 15377
slot update_slots: id  2 | task 35398 | erasing old context checkpoint (pos_min = 7793, pos_max = 8689, size = 21.034 MiB)
slot update_slots: id  2 | task 35398 | created context checkpoint 8 of 8 (pos_min = 14509, pos_max = 15312, size = 18.853 MiB)
slot print_timing: id  2 | task 35398 | 
prompt eval time =     635.99 ms /   237 tokens (    2.68 ms per token,   372.65 tokens per second)
       eval time =    1875.18 ms /    59 tokens (   31.78 ms per token,    31.46 tokens per second)
      total time =    2511.16 ms /   296 tokens
slot      release: id  2 | task 35398 | stop processing: n_tokens = 15435, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 35459 | processing task, is_child = 0
slot update_slots: id  2 | task 35459 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 15520
slot update_slots: id  2 | task 35459 | n_tokens = 15408, memory_seq_rm [15408, end)
slot update_slots: id  2 | task 35459 | prompt processing progress, n_tokens = 15456, batch.n_tokens = 48, progress = 0.995876
slot update_slots: id  2 | task 35459 | n_tokens = 15456, memory_seq_rm [15456, end)
slot update_slots: id  2 | task 35459 | prompt processing progress, n_tokens = 15520, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 35459 | prompt done, n_tokens = 15520, batch.n_tokens = 64
slot init_sampler: id  2 | task 35459 | init sampler, took 4.03 ms, tokens: text = 15520, total = 15520
slot update_slots: id  2 | task 35459 | erasing old context checkpoint (pos_min = 9340, pos_max = 10236, size = 21.034 MiB)
slot update_slots: id  2 | task 35459 | created context checkpoint 8 of 8 (pos_min = 14652, pos_max = 15455, size = 18.853 MiB)
slot print_timing: id  2 | task 35459 | 
prompt eval time =     438.45 ms /   112 tokens (    3.91 ms per token,   255.45 tokens per second)
       eval time =    1477.23 ms /    46 tokens (   32.11 ms per token,    31.14 tokens per second)
      total time =    1915.68 ms /   158 tokens
slot      release: id  2 | task 35459 | stop processing: n_tokens = 15565, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.057
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 15565, total state size = 383.836 MiB
srv          load:  - looking for better prompt, base f_keep = 0.057, sim = 0.987
srv        update:  - cache state: 13 prompts, 5867.031 MiB (limits: 8192.000 MiB, 56064 tokens, 218123 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv        update:    - prompt 0x58dc3fb8c770:    5127 tokens, checkpoints:  8,   320.808 MiB
srv        update:    - prompt 0x58dc3f318830:   24865 tokens, checkpoints:  8,   791.874 MiB
srv        update:    - prompt 0x58dc40d3cf50:   16080 tokens, checkpoints:  8,   571.219 MiB
srv        update:    - prompt 0x58dc4c8ce8a0:   23906 tokens, checkpoints:  8,   739.114 MiB
srv        update:    - prompt 0x58dc38d9f350:   18675 tokens, checkpoints:  8,   606.205 MiB
srv        update:    - prompt 0x58dc3f0d1370:    8148 tokens, checkpoints:  8,   317.783 MiB
srv        update:    - prompt 0x58dc4e559330:    1905 tokens, checkpoints:  1,    86.270 MiB
srv        update:    - prompt 0x58dc7370fb50:   15396 tokens, checkpoints:  8,   535.811 MiB
srv        update:    - prompt 0x58dc3f803040:   11161 tokens, checkpoints:  8,   449.472 MiB
srv        update:    - prompt 0x58dc4b0f2100:   15565 tokens, checkpoints:  8,   546.621 MiB
srv  get_availabl: prompt cache update took 762.93 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 35507 | processing task, is_child = 0
slot update_slots: id  2 | task 35507 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 893
slot update_slots: id  2 | task 35507 | n_past = 881, slot.prompt.tokens.size() = 15565, seq_id = 2, pos_min = 14761, n_swa = 128
slot update_slots: id  2 | task 35507 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  2 | task 35507 | erased invalidated context checkpoint (pos_min = 12153, pos_max = 13049, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 35507 | erased invalidated context checkpoint (pos_min = 12277, pos_max = 13173, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 35507 | erased invalidated context checkpoint (pos_min = 12873, pos_max = 13746, n_swa = 128, size = 20.495 MiB)
slot update_slots: id  2 | task 35507 | erased invalidated context checkpoint (pos_min = 13418, pos_max = 14294, n_swa = 128, size = 20.565 MiB)
slot update_slots: id  2 | task 35507 | erased invalidated context checkpoint (pos_min = 13537, pos_max = 14428, n_swa = 128, size = 20.917 MiB)
slot update_slots: id  2 | task 35507 | erased invalidated context checkpoint (pos_min = 14154, pos_max = 15050, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 35507 | erased invalidated context checkpoint (pos_min = 14509, pos_max = 15312, n_swa = 128, size = 18.853 MiB)
slot update_slots: id  2 | task 35507 | erased invalidated context checkpoint (pos_min = 14652, pos_max = 15455, n_swa = 128, size = 18.853 MiB)
slot update_slots: id  2 | task 35507 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 35507 | prompt processing progress, n_tokens = 829, batch.n_tokens = 829, progress = 0.928331
slot update_slots: id  2 | task 35507 | n_tokens = 829, memory_seq_rm [829, end)
slot update_slots: id  2 | task 35507 | prompt processing progress, n_tokens = 893, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 35507 | prompt done, n_tokens = 893, batch.n_tokens = 64
slot init_sampler: id  2 | task 35507 | init sampler, took 0.13 ms, tokens: text = 893, total = 893
slot update_slots: id  2 | task 35507 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 828, size = 19.439 MiB)
slot print_timing: id  2 | task 35507 | 
prompt eval time =    1552.72 ms /   893 tokens (    1.74 ms per token,   575.12 tokens per second)
       eval time =    3389.95 ms /   111 tokens (   30.54 ms per token,    32.74 tokens per second)
      total time =    4942.67 ms /  1004 tokens
slot      release: id  2 | task 35507 | stop processing: n_tokens = 1003, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.909 (> 0.100 thold), f_keep = 0.891
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 35620 | processing task, is_child = 0
slot update_slots: id  2 | task 35620 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 984
slot update_slots: id  2 | task 35620 | n_tokens = 894, memory_seq_rm [894, end)
slot update_slots: id  2 | task 35620 | prompt processing progress, n_tokens = 920, batch.n_tokens = 26, progress = 0.934959
slot update_slots: id  2 | task 35620 | n_tokens = 920, memory_seq_rm [920, end)
slot update_slots: id  2 | task 35620 | prompt processing progress, n_tokens = 984, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 35620 | prompt done, n_tokens = 984, batch.n_tokens = 64
slot init_sampler: id  2 | task 35620 | init sampler, took 0.19 ms, tokens: text = 984, total = 984
slot update_slots: id  2 | task 35620 | created context checkpoint 2 of 8 (pos_min = 106, pos_max = 919, size = 19.088 MiB)
slot print_timing: id  2 | task 35620 | 
prompt eval time =     462.05 ms /    90 tokens (    5.13 ms per token,   194.78 tokens per second)
       eval time =    9413.92 ms /   303 tokens (   31.07 ms per token,    32.19 tokens per second)
      total time =    9875.97 ms /   393 tokens
slot      release: id  2 | task 35620 | stop processing: n_tokens = 1286, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.973 (> 0.100 thold), f_keep = 0.685
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 35925 | processing task, is_child = 0
slot update_slots: id  2 | task 35925 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 905
slot update_slots: id  2 | task 35925 | n_tokens = 881, memory_seq_rm [881, end)
slot update_slots: id  2 | task 35925 | prompt processing progress, n_tokens = 905, batch.n_tokens = 24, progress = 1.000000
slot update_slots: id  2 | task 35925 | prompt done, n_tokens = 905, batch.n_tokens = 24
slot init_sampler: id  2 | task 35925 | init sampler, took 0.14 ms, tokens: text = 905, total = 905
slot print_timing: id  2 | task 35925 | 
prompt eval time =     168.59 ms /    24 tokens (    7.02 ms per token,   142.36 tokens per second)
       eval time =    2761.72 ms /    95 tokens (   29.07 ms per token,    34.40 tokens per second)
      total time =    2930.30 ms /   119 tokens
slot      release: id  2 | task 35925 | stop processing: n_tokens = 999, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.855 (> 0.100 thold), f_keep = 0.977
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36021 | processing task, is_child = 0
slot update_slots: id  2 | task 36021 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1141
slot update_slots: id  2 | task 36021 | n_tokens = 976, memory_seq_rm [976, end)
slot update_slots: id  2 | task 36021 | prompt processing progress, n_tokens = 1077, batch.n_tokens = 101, progress = 0.943909
slot update_slots: id  2 | task 36021 | n_tokens = 1077, memory_seq_rm [1077, end)
slot update_slots: id  2 | task 36021 | prompt processing progress, n_tokens = 1141, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 36021 | prompt done, n_tokens = 1141, batch.n_tokens = 64
slot init_sampler: id  2 | task 36021 | init sampler, took 0.17 ms, tokens: text = 1141, total = 1141
slot update_slots: id  2 | task 36021 | created context checkpoint 3 of 8 (pos_min = 392, pos_max = 1076, size = 16.063 MiB)
slot print_timing: id  2 | task 36021 | 
prompt eval time =     490.11 ms /   165 tokens (    2.97 ms per token,   336.66 tokens per second)
       eval time =     965.32 ms /    34 tokens (   28.39 ms per token,    35.22 tokens per second)
      total time =    1455.43 ms /   199 tokens
slot      release: id  2 | task 36021 | stop processing: n_tokens = 1174, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.875 (> 0.100 thold), f_keep = 0.986
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36057 | processing task, is_child = 0
slot update_slots: id  2 | task 36057 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1323
slot update_slots: id  2 | task 36057 | n_tokens = 1158, memory_seq_rm [1158, end)
slot update_slots: id  2 | task 36057 | prompt processing progress, n_tokens = 1259, batch.n_tokens = 101, progress = 0.951625
slot update_slots: id  2 | task 36057 | n_tokens = 1259, memory_seq_rm [1259, end)
slot update_slots: id  2 | task 36057 | prompt processing progress, n_tokens = 1323, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 36057 | prompt done, n_tokens = 1323, batch.n_tokens = 64
slot init_sampler: id  2 | task 36057 | init sampler, took 0.20 ms, tokens: text = 1323, total = 1323
slot update_slots: id  2 | task 36057 | created context checkpoint 4 of 8 (pos_min = 392, pos_max = 1258, size = 20.331 MiB)
slot print_timing: id  2 | task 36057 | 
prompt eval time =     503.03 ms /   165 tokens (    3.05 ms per token,   328.01 tokens per second)
       eval time =     925.09 ms /    33 tokens (   28.03 ms per token,    35.67 tokens per second)
      total time =    1428.12 ms /   198 tokens
slot      release: id  2 | task 36057 | stop processing: n_tokens = 1355, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.890 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36092 | processing task, is_child = 0
slot update_slots: id  2 | task 36092 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1500
slot update_slots: id  2 | task 36092 | n_tokens = 1335, memory_seq_rm [1335, end)
slot update_slots: id  2 | task 36092 | prompt processing progress, n_tokens = 1436, batch.n_tokens = 101, progress = 0.957333
slot update_slots: id  2 | task 36092 | n_tokens = 1436, memory_seq_rm [1436, end)
slot update_slots: id  2 | task 36092 | prompt processing progress, n_tokens = 1500, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 36092 | prompt done, n_tokens = 1500, batch.n_tokens = 64
slot init_sampler: id  2 | task 36092 | init sampler, took 0.22 ms, tokens: text = 1500, total = 1500
slot update_slots: id  2 | task 36092 | created context checkpoint 5 of 8 (pos_min = 555, pos_max = 1435, size = 20.659 MiB)
slot print_timing: id  2 | task 36092 | 
prompt eval time =     497.57 ms /   165 tokens (    3.02 ms per token,   331.61 tokens per second)
       eval time =     948.38 ms /    34 tokens (   27.89 ms per token,    35.85 tokens per second)
      total time =    1445.95 ms /   199 tokens
slot      release: id  2 | task 36092 | stop processing: n_tokens = 1533, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.902 (> 0.100 thold), f_keep = 0.990
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36128 | processing task, is_child = 0
slot update_slots: id  2 | task 36128 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1682
slot update_slots: id  2 | task 36128 | n_tokens = 1517, memory_seq_rm [1517, end)
slot update_slots: id  2 | task 36128 | prompt processing progress, n_tokens = 1618, batch.n_tokens = 101, progress = 0.961950
slot update_slots: id  2 | task 36128 | n_tokens = 1618, memory_seq_rm [1618, end)
slot update_slots: id  2 | task 36128 | prompt processing progress, n_tokens = 1682, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 36128 | prompt done, n_tokens = 1682, batch.n_tokens = 64
slot init_sampler: id  2 | task 36128 | init sampler, took 0.26 ms, tokens: text = 1682, total = 1682
slot update_slots: id  2 | task 36128 | created context checkpoint 6 of 8 (pos_min = 737, pos_max = 1617, size = 20.659 MiB)
slot print_timing: id  2 | task 36128 | 
prompt eval time =     496.08 ms /   165 tokens (    3.01 ms per token,   332.60 tokens per second)
       eval time =     937.34 ms /    33 tokens (   28.40 ms per token,    35.21 tokens per second)
      total time =    1433.42 ms /   198 tokens
slot      release: id  2 | task 36128 | stop processing: n_tokens = 1714, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.911 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36163 | processing task, is_child = 0
slot update_slots: id  2 | task 36163 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1859
slot update_slots: id  2 | task 36163 | n_tokens = 1694, memory_seq_rm [1694, end)
slot update_slots: id  2 | task 36163 | prompt processing progress, n_tokens = 1795, batch.n_tokens = 101, progress = 0.965573
slot update_slots: id  2 | task 36163 | n_tokens = 1795, memory_seq_rm [1795, end)
slot update_slots: id  2 | task 36163 | prompt processing progress, n_tokens = 1859, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 36163 | prompt done, n_tokens = 1859, batch.n_tokens = 64
slot init_sampler: id  2 | task 36163 | init sampler, took 0.36 ms, tokens: text = 1859, total = 1859
slot update_slots: id  2 | task 36163 | created context checkpoint 7 of 8 (pos_min = 898, pos_max = 1794, size = 21.034 MiB)
slot print_timing: id  2 | task 36163 | 
prompt eval time =     493.77 ms /   165 tokens (    2.99 ms per token,   334.16 tokens per second)
       eval time =    1059.47 ms /    39 tokens (   27.17 ms per token,    36.81 tokens per second)
      total time =    1553.25 ms /   204 tokens
slot      release: id  2 | task 36163 | stop processing: n_tokens = 1897, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.808 (> 0.100 thold), f_keep = 0.986
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36204 | processing task, is_child = 0
slot update_slots: id  2 | task 36204 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 2315
slot update_slots: id  2 | task 36204 | n_tokens = 1870, memory_seq_rm [1870, end)
slot update_slots: id  2 | task 36204 | prompt processing progress, n_tokens = 2251, batch.n_tokens = 381, progress = 0.972354
slot update_slots: id  2 | task 36204 | n_tokens = 2251, memory_seq_rm [2251, end)
slot update_slots: id  2 | task 36204 | prompt processing progress, n_tokens = 2315, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 36204 | prompt done, n_tokens = 2315, batch.n_tokens = 64
slot init_sampler: id  2 | task 36204 | init sampler, took 0.33 ms, tokens: text = 2315, total = 2315
slot update_slots: id  2 | task 36204 | created context checkpoint 8 of 8 (pos_min = 1354, pos_max = 2250, size = 21.034 MiB)
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv          stop: cancel task, id_task = 36204
slot      release: id  2 | task 36204 | stop processing: n_tokens = 2343, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 1.000 (> 0.100 thold), f_keep = 0.386
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 2343, total state size = 75.975 MiB
srv          load:  - looking for better prompt, base f_keep = 0.386, sim = 1.000
srv        update:  - cache state: 14 prompts, 6101.312 MiB (limits: 8192.000 MiB, 56064 tokens, 212893 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv        update:    - prompt 0x58dc3fb8c770:    5127 tokens, checkpoints:  8,   320.808 MiB
srv        update:    - prompt 0x58dc3f318830:   24865 tokens, checkpoints:  8,   791.874 MiB
srv        update:    - prompt 0x58dc40d3cf50:   16080 tokens, checkpoints:  8,   571.219 MiB
srv        update:    - prompt 0x58dc4c8ce8a0:   23906 tokens, checkpoints:  8,   739.114 MiB
srv        update:    - prompt 0x58dc38d9f350:   18675 tokens, checkpoints:  8,   606.205 MiB
srv        update:    - prompt 0x58dc3f0d1370:    8148 tokens, checkpoints:  8,   317.783 MiB
srv        update:    - prompt 0x58dc4e559330:    1905 tokens, checkpoints:  1,    86.270 MiB
srv        update:    - prompt 0x58dc7370fb50:   15396 tokens, checkpoints:  8,   535.811 MiB
srv        update:    - prompt 0x58dc3f803040:   11161 tokens, checkpoints:  8,   449.472 MiB
srv        update:    - prompt 0x58dc4b0f2100:   15565 tokens, checkpoints:  8,   546.621 MiB
srv        update:    - prompt 0x58dc4b0ed760:    2343 tokens, checkpoints:  8,   234.281 MiB
srv  get_availabl: prompt cache update took 333.55 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36236 | processing task, is_child = 0
slot update_slots: id  2 | task 36236 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 905
slot update_slots: id  2 | task 36236 | n_past = 905, slot.prompt.tokens.size() = 2343, seq_id = 2, pos_min = 1446, n_swa = 128
slot update_slots: id  2 | task 36236 | restored context checkpoint (pos_min = 737, pos_max = 1617, size = 20.659 MiB)
slot update_slots: id  2 | task 36236 | erased invalidated context checkpoint (pos_min = 898, pos_max = 1794, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 36236 | erased invalidated context checkpoint (pos_min = 1354, pos_max = 2250, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 36236 | need to evaluate at least 1 token for each active slot (n_past = 905, task.n_tokens() = 905)
slot update_slots: id  2 | task 36236 | n_past was set to 904
slot update_slots: id  2 | task 36236 | n_tokens = 904, memory_seq_rm [904, end)
slot update_slots: id  2 | task 36236 | prompt processing progress, n_tokens = 905, batch.n_tokens = 1, progress = 1.000000
slot update_slots: id  2 | task 36236 | prompt done, n_tokens = 905, batch.n_tokens = 1
slot init_sampler: id  2 | task 36236 | init sampler, took 0.14 ms, tokens: text = 905, total = 905
slot print_timing: id  2 | task 36236 | 
prompt eval time =     206.72 ms /     1 tokens (  206.72 ms per token,     4.84 tokens per second)
       eval time =    1687.79 ms /    63 tokens (   26.79 ms per token,    37.33 tokens per second)
      total time =    1894.51 ms /    64 tokens
slot      release: id  2 | task 36236 | stop processing: n_tokens = 967, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.643 (> 0.100 thold), f_keep = 0.980
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36300 | processing task, is_child = 0
slot update_slots: id  2 | task 36300 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1475
slot update_slots: id  2 | task 36300 | n_tokens = 948, memory_seq_rm [948, end)
slot update_slots: id  2 | task 36300 | prompt processing progress, n_tokens = 1411, batch.n_tokens = 463, progress = 0.956610
slot update_slots: id  2 | task 36300 | n_tokens = 1411, memory_seq_rm [1411, end)
slot update_slots: id  2 | task 36300 | prompt processing progress, n_tokens = 1475, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 36300 | prompt done, n_tokens = 1475, batch.n_tokens = 64
slot init_sampler: id  2 | task 36300 | init sampler, took 0.22 ms, tokens: text = 1475, total = 1475
slot print_timing: id  2 | task 36300 | 
prompt eval time =     830.83 ms /   527 tokens (    1.58 ms per token,   634.31 tokens per second)
       eval time =   69234.23 ms /  2294 tokens (   30.18 ms per token,    33.13 tokens per second)
      total time =   70065.06 ms /  2821 tokens
slot      release: id  2 | task 36300 | stop processing: n_tokens = 3768, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.316 (> 0.100 thold), f_keep = 0.394
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 3768, total state size = 109.390 MiB
srv          load:  - looking for better prompt, base f_keep = 0.394, sim = 0.316
srv        update:  - cache state: 15 prompts, 6326.940 MiB (limits: 8192.000 MiB, 56064 tokens, 210180 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv        update:    - prompt 0x58dc3fb8c770:    5127 tokens, checkpoints:  8,   320.808 MiB
srv        update:    - prompt 0x58dc3f318830:   24865 tokens, checkpoints:  8,   791.874 MiB
srv        update:    - prompt 0x58dc40d3cf50:   16080 tokens, checkpoints:  8,   571.219 MiB
srv        update:    - prompt 0x58dc4c8ce8a0:   23906 tokens, checkpoints:  8,   739.114 MiB
srv        update:    - prompt 0x58dc38d9f350:   18675 tokens, checkpoints:  8,   606.205 MiB
srv        update:    - prompt 0x58dc3f0d1370:    8148 tokens, checkpoints:  8,   317.783 MiB
srv        update:    - prompt 0x58dc4e559330:    1905 tokens, checkpoints:  1,    86.270 MiB
srv        update:    - prompt 0x58dc7370fb50:   15396 tokens, checkpoints:  8,   535.811 MiB
srv        update:    - prompt 0x58dc3f803040:   11161 tokens, checkpoints:  8,   449.472 MiB
srv        update:    - prompt 0x58dc4b0f2100:   15565 tokens, checkpoints:  8,   546.621 MiB
srv        update:    - prompt 0x58dc4b0ed760:    2343 tokens, checkpoints:  8,   234.281 MiB
srv        update:    - prompt 0x58dc3e3ce6c0:    3768 tokens, checkpoints:  6,   225.628 MiB
srv  get_availabl: prompt cache update took 342.16 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 38596 | processing task, is_child = 0
slot update_slots: id  2 | task 38596 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 4690
slot update_slots: id  2 | task 38596 | n_past = 1484, slot.prompt.tokens.size() = 3768, seq_id = 2, pos_min = 2871, n_swa = 128
slot update_slots: id  2 | task 38596 | restored context checkpoint (pos_min = 737, pos_max = 1617, size = 20.659 MiB)
slot update_slots: id  2 | task 38596 | n_tokens = 1484, memory_seq_rm [1484, end)
slot update_slots: id  2 | task 38596 | prompt processing progress, n_tokens = 3532, batch.n_tokens = 2048, progress = 0.753092
slot update_slots: id  2 | task 38596 | n_tokens = 3532, memory_seq_rm [3532, end)
slot update_slots: id  2 | task 38596 | prompt processing progress, n_tokens = 4626, batch.n_tokens = 1094, progress = 0.986354
slot update_slots: id  2 | task 38596 | n_tokens = 4626, memory_seq_rm [4626, end)
slot update_slots: id  2 | task 38596 | prompt processing progress, n_tokens = 4690, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 38596 | prompt done, n_tokens = 4690, batch.n_tokens = 64
slot init_sampler: id  2 | task 38596 | init sampler, took 0.72 ms, tokens: text = 4690, total = 4690
slot update_slots: id  2 | task 38596 | created context checkpoint 7 of 8 (pos_min = 3729, pos_max = 4625, size = 21.034 MiB)
slot print_timing: id  2 | task 38596 | 
prompt eval time =    5027.56 ms /  3206 tokens (    1.57 ms per token,   637.69 tokens per second)
       eval time =    1706.56 ms /    57 tokens (   29.94 ms per token,    33.40 tokens per second)
      total time =    6734.12 ms /  3263 tokens
slot      release: id  2 | task 38596 | stop processing: n_tokens = 4746, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.702 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 38656 | processing task, is_child = 0
slot update_slots: id  2 | task 38656 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 6719
slot update_slots: id  2 | task 38656 | n_tokens = 4717, memory_seq_rm [4717, end)
slot update_slots: id  2 | task 38656 | prompt processing progress, n_tokens = 6655, batch.n_tokens = 1938, progress = 0.990475
slot update_slots: id  2 | task 38656 | n_tokens = 6655, memory_seq_rm [6655, end)
slot update_slots: id  2 | task 38656 | prompt processing progress, n_tokens = 6719, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 38656 | prompt done, n_tokens = 6719, batch.n_tokens = 64
slot init_sampler: id  2 | task 38656 | init sampler, took 1.26 ms, tokens: text = 6719, total = 6719
slot update_slots: id  2 | task 38656 | created context checkpoint 8 of 8 (pos_min = 5758, pos_max = 6654, size = 21.034 MiB)
slot print_timing: id  2 | task 38656 | 
prompt eval time =    3076.17 ms /  2002 tokens (    1.54 ms per token,   650.81 tokens per second)
       eval time =    6028.12 ms /   205 tokens (   29.41 ms per token,    34.01 tokens per second)
      total time =    9104.29 ms /  2207 tokens
slot      release: id  2 | task 38656 | stop processing: n_tokens = 6923, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.820 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 38863 | processing task, is_child = 0
slot update_slots: id  2 | task 38863 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 8409
slot update_slots: id  2 | task 38863 | n_tokens = 6893, memory_seq_rm [6893, end)
slot update_slots: id  2 | task 38863 | prompt processing progress, n_tokens = 8345, batch.n_tokens = 1452, progress = 0.992389
slot update_slots: id  2 | task 38863 | n_tokens = 8345, memory_seq_rm [8345, end)
slot update_slots: id  2 | task 38863 | prompt processing progress, n_tokens = 8409, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 38863 | prompt done, n_tokens = 8409, batch.n_tokens = 64
slot init_sampler: id  2 | task 38863 | init sampler, took 1.27 ms, tokens: text = 8409, total = 8409
slot update_slots: id  2 | task 38863 | erasing old context checkpoint (pos_min = 0, pos_max = 828, size = 19.439 MiB)
slot update_slots: id  2 | task 38863 | created context checkpoint 8 of 8 (pos_min = 7448, pos_max = 8344, size = 21.034 MiB)
slot print_timing: id  2 | task 38863 | 
prompt eval time =    2352.51 ms /  1516 tokens (    1.55 ms per token,   644.42 tokens per second)
       eval time =    1264.28 ms /    43 tokens (   29.40 ms per token,    34.01 tokens per second)
      total time =    3616.80 ms /  1559 tokens
slot      release: id  2 | task 38863 | stop processing: n_tokens = 8451, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 38908 | processing task, is_child = 0
slot update_slots: id  2 | task 38908 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 8545
slot update_slots: id  2 | task 38908 | n_tokens = 8423, memory_seq_rm [8423, end)
slot update_slots: id  2 | task 38908 | prompt processing progress, n_tokens = 8481, batch.n_tokens = 58, progress = 0.992510
slot update_slots: id  2 | task 38908 | n_tokens = 8481, memory_seq_rm [8481, end)
slot update_slots: id  2 | task 38908 | prompt processing progress, n_tokens = 8545, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 38908 | prompt done, n_tokens = 8545, batch.n_tokens = 64
slot init_sampler: id  2 | task 38908 | init sampler, took 1.17 ms, tokens: text = 8545, total = 8545
slot update_slots: id  2 | task 38908 | erasing old context checkpoint (pos_min = 106, pos_max = 919, size = 19.088 MiB)
slot update_slots: id  2 | task 38908 | created context checkpoint 8 of 8 (pos_min = 7584, pos_max = 8480, size = 21.034 MiB)
slot print_timing: id  2 | task 38908 | 
prompt eval time =     433.88 ms /   122 tokens (    3.56 ms per token,   281.18 tokens per second)
       eval time =    1199.10 ms /    41 tokens (   29.25 ms per token,    34.19 tokens per second)
      total time =    1632.99 ms /   163 tokens
slot      release: id  2 | task 38908 | stop processing: n_tokens = 8585, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.874 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 38951 | processing task, is_child = 0
slot update_slots: id  2 | task 38951 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 9789
slot update_slots: id  2 | task 38951 | n_tokens = 8555, memory_seq_rm [8555, end)
slot update_slots: id  2 | task 38951 | prompt processing progress, n_tokens = 9725, batch.n_tokens = 1170, progress = 0.993462
slot update_slots: id  2 | task 38951 | n_tokens = 9725, memory_seq_rm [9725, end)
slot update_slots: id  2 | task 38951 | prompt processing progress, n_tokens = 9789, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 38951 | prompt done, n_tokens = 9789, batch.n_tokens = 64
slot init_sampler: id  2 | task 38951 | init sampler, took 1.38 ms, tokens: text = 9789, total = 9789
slot update_slots: id  2 | task 38951 | erasing old context checkpoint (pos_min = 392, pos_max = 1076, size = 16.063 MiB)
slot update_slots: id  2 | task 38951 | created context checkpoint 8 of 8 (pos_min = 8828, pos_max = 9724, size = 21.034 MiB)
slot print_timing: id  2 | task 38951 | 
prompt eval time =    2103.52 ms /  1234 tokens (    1.70 ms per token,   586.63 tokens per second)
       eval time =    3093.82 ms /   104 tokens (   29.75 ms per token,    33.62 tokens per second)
      total time =    5197.35 ms /  1338 tokens
slot      release: id  2 | task 38951 | stop processing: n_tokens = 9892, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.965 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 39057 | processing task, is_child = 0
slot update_slots: id  2 | task 39057 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 10221
slot update_slots: id  2 | task 39057 | n_tokens = 9863, memory_seq_rm [9863, end)
slot update_slots: id  2 | task 39057 | prompt processing progress, n_tokens = 10157, batch.n_tokens = 294, progress = 0.993738
slot update_slots: id  2 | task 39057 | n_tokens = 10157, memory_seq_rm [10157, end)
slot update_slots: id  2 | task 39057 | prompt processing progress, n_tokens = 10221, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 39057 | prompt done, n_tokens = 10221, batch.n_tokens = 64
slot init_sampler: id  2 | task 39057 | init sampler, took 2.43 ms, tokens: text = 10221, total = 10221
slot update_slots: id  2 | task 39057 | erasing old context checkpoint (pos_min = 392, pos_max = 1258, size = 20.331 MiB)
slot update_slots: id  2 | task 39057 | created context checkpoint 8 of 8 (pos_min = 9260, pos_max = 10156, size = 21.034 MiB)
slot print_timing: id  2 | task 39057 | 
prompt eval time =     751.30 ms /   358 tokens (    2.10 ms per token,   476.51 tokens per second)
       eval time =   12924.74 ms /   426 tokens (   30.34 ms per token,    32.96 tokens per second)
      total time =   13676.05 ms /   784 tokens
slot      release: id  2 | task 39057 | stop processing: n_tokens = 10646, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 39485 | processing task, is_child = 0
slot update_slots: id  2 | task 39485 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 10738
slot update_slots: id  2 | task 39485 | n_tokens = 10582, memory_seq_rm [10582, end)
slot update_slots: id  2 | task 39485 | prompt processing progress, n_tokens = 10674, batch.n_tokens = 92, progress = 0.994040
slot update_slots: id  2 | task 39485 | n_tokens = 10674, memory_seq_rm [10674, end)
slot update_slots: id  2 | task 39485 | prompt processing progress, n_tokens = 10738, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 39485 | prompt done, n_tokens = 10738, batch.n_tokens = 64
slot init_sampler: id  2 | task 39485 | init sampler, took 2.22 ms, tokens: text = 10738, total = 10738
slot update_slots: id  2 | task 39485 | erasing old context checkpoint (pos_min = 555, pos_max = 1435, size = 20.659 MiB)
slot update_slots: id  2 | task 39485 | created context checkpoint 8 of 8 (pos_min = 9777, pos_max = 10673, size = 21.034 MiB)
slot print_timing: id  2 | task 39485 | 
prompt eval time =     492.38 ms /   156 tokens (    3.16 ms per token,   316.83 tokens per second)
       eval time =   23776.64 ms /   771 tokens (   30.84 ms per token,    32.43 tokens per second)
      total time =   24269.02 ms /   927 tokens
slot      release: id  2 | task 39485 | stop processing: n_tokens = 11508, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.965 (> 0.100 thold), f_keep = 0.973
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 40258 | processing task, is_child = 0
slot update_slots: id  2 | task 40258 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 11610
slot update_slots: id  2 | task 40258 | n_tokens = 11201, memory_seq_rm [11201, end)
slot update_slots: id  2 | task 40258 | prompt processing progress, n_tokens = 11546, batch.n_tokens = 345, progress = 0.994488
slot update_slots: id  2 | task 40258 | n_tokens = 11546, memory_seq_rm [11546, end)
slot update_slots: id  2 | task 40258 | prompt processing progress, n_tokens = 11610, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 40258 | prompt done, n_tokens = 11610, batch.n_tokens = 64
slot init_sampler: id  2 | task 40258 | init sampler, took 1.67 ms, tokens: text = 11610, total = 11610
slot update_slots: id  2 | task 40258 | erasing old context checkpoint (pos_min = 737, pos_max = 1617, size = 20.659 MiB)
slot update_slots: id  2 | task 40258 | created context checkpoint 8 of 8 (pos_min = 10649, pos_max = 11545, size = 21.034 MiB)
slot print_timing: id  2 | task 40258 | 
prompt eval time =     879.88 ms /   409 tokens (    2.15 ms per token,   464.84 tokens per second)
       eval time =    1511.44 ms /    48 tokens (   31.49 ms per token,    31.76 tokens per second)
      total time =    2391.32 ms /   457 tokens
slot      release: id  2 | task 40258 | stop processing: n_tokens = 11657, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 40308 | processing task, is_child = 0
slot update_slots: id  2 | task 40308 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 11734
slot update_slots: id  2 | task 40308 | n_tokens = 11629, memory_seq_rm [11629, end)
slot update_slots: id  2 | task 40308 | prompt processing progress, n_tokens = 11670, batch.n_tokens = 41, progress = 0.994546
slot update_slots: id  2 | task 40308 | n_tokens = 11670, memory_seq_rm [11670, end)
slot update_slots: id  2 | task 40308 | prompt processing progress, n_tokens = 11734, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 40308 | prompt done, n_tokens = 11734, batch.n_tokens = 64
slot init_sampler: id  2 | task 40308 | init sampler, took 2.29 ms, tokens: text = 11734, total = 11734
slot update_slots: id  2 | task 40308 | erasing old context checkpoint (pos_min = 3729, pos_max = 4625, size = 21.034 MiB)
slot update_slots: id  2 | task 40308 | created context checkpoint 8 of 8 (pos_min = 10789, pos_max = 11669, size = 20.659 MiB)
slot print_timing: id  2 | task 40308 | 
prompt eval time =     439.38 ms /   105 tokens (    4.18 ms per token,   238.98 tokens per second)
       eval time =    1281.66 ms /    41 tokens (   31.26 ms per token,    31.99 tokens per second)
      total time =    1721.04 ms /   146 tokens
slot      release: id  2 | task 40308 | stop processing: n_tokens = 11774, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.964 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 40351 | processing task, is_child = 0
slot update_slots: id  2 | task 40351 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 12181
slot update_slots: id  2 | task 40351 | n_tokens = 11748, memory_seq_rm [11748, end)
slot update_slots: id  2 | task 40351 | prompt processing progress, n_tokens = 12117, batch.n_tokens = 369, progress = 0.994746
slot update_slots: id  2 | task 40351 | n_tokens = 12117, memory_seq_rm [12117, end)
slot update_slots: id  2 | task 40351 | prompt processing progress, n_tokens = 12181, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 40351 | prompt done, n_tokens = 12181, batch.n_tokens = 64
slot init_sampler: id  2 | task 40351 | init sampler, took 1.73 ms, tokens: text = 12181, total = 12181
slot update_slots: id  2 | task 40351 | erasing old context checkpoint (pos_min = 5758, pos_max = 6654, size = 21.034 MiB)
slot update_slots: id  2 | task 40351 | created context checkpoint 8 of 8 (pos_min = 11236, pos_max = 12116, size = 20.659 MiB)
slot print_timing: id  2 | task 40351 | 
prompt eval time =     911.76 ms /   433 tokens (    2.11 ms per token,   474.90 tokens per second)
       eval time =    9663.24 ms /   317 tokens (   30.48 ms per token,    32.80 tokens per second)
      total time =   10575.00 ms /   750 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 40351 | stop processing: n_tokens = 12497, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.973 (> 0.100 thold), f_keep = 0.976
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 40670 | processing task, is_child = 0
slot update_slots: id  2 | task 40670 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 12541
slot update_slots: id  2 | task 40670 | n_tokens = 12197, memory_seq_rm [12197, end)
slot update_slots: id  2 | task 40670 | prompt processing progress, n_tokens = 12477, batch.n_tokens = 280, progress = 0.994897
slot update_slots: id  2 | task 40670 | n_tokens = 12477, memory_seq_rm [12477, end)
slot update_slots: id  2 | task 40670 | prompt processing progress, n_tokens = 12541, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 40670 | prompt done, n_tokens = 12541, batch.n_tokens = 64
slot init_sampler: id  2 | task 40670 | init sampler, took 2.35 ms, tokens: text = 12541, total = 12541
slot update_slots: id  2 | task 40670 | erasing old context checkpoint (pos_min = 7448, pos_max = 8344, size = 21.034 MiB)
slot update_slots: id  2 | task 40670 | created context checkpoint 8 of 8 (pos_min = 11616, pos_max = 12476, size = 20.190 MiB)
slot print_timing: id  2 | task 40670 | 
prompt eval time =     765.27 ms /   344 tokens (    2.22 ms per token,   449.51 tokens per second)
       eval time =   23804.99 ms /   785 tokens (   30.32 ms per token,    32.98 tokens per second)
      total time =   24570.27 ms /  1129 tokens
slot      release: id  2 | task 40670 | stop processing: n_tokens = 13325, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.972 (> 0.100 thold), f_keep = 0.975
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 41457 | processing task, is_child = 0
slot update_slots: id  2 | task 41457 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13369
slot update_slots: id  2 | task 41457 | n_tokens = 12993, memory_seq_rm [12993, end)
slot update_slots: id  2 | task 41457 | prompt processing progress, n_tokens = 13305, batch.n_tokens = 312, progress = 0.995213
slot update_slots: id  2 | task 41457 | n_tokens = 13305, memory_seq_rm [13305, end)
slot update_slots: id  2 | task 41457 | prompt processing progress, n_tokens = 13369, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 41457 | prompt done, n_tokens = 13369, batch.n_tokens = 64
slot init_sampler: id  2 | task 41457 | init sampler, took 1.97 ms, tokens: text = 13369, total = 13369
slot update_slots: id  2 | task 41457 | erasing old context checkpoint (pos_min = 7584, pos_max = 8480, size = 21.034 MiB)
slot update_slots: id  2 | task 41457 | created context checkpoint 8 of 8 (pos_min = 12428, pos_max = 13304, size = 20.565 MiB)
slot print_timing: id  2 | task 41457 | 
prompt eval time =     808.04 ms /   376 tokens (    2.15 ms per token,   465.32 tokens per second)
       eval time =    1971.89 ms /    63 tokens (   31.30 ms per token,    31.95 tokens per second)
      total time =    2779.93 ms /   439 tokens
slot      release: id  2 | task 41457 | stop processing: n_tokens = 13431, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 41522 | processing task, is_child = 0
slot update_slots: id  2 | task 41522 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13482
slot update_slots: id  2 | task 41522 | n_tokens = 13422, memory_seq_rm [13422, end)
slot update_slots: id  2 | task 41522 | prompt processing progress, n_tokens = 13482, batch.n_tokens = 60, progress = 1.000000
slot update_slots: id  2 | task 41522 | prompt done, n_tokens = 13482, batch.n_tokens = 60
slot init_sampler: id  2 | task 41522 | init sampler, took 1.93 ms, tokens: text = 13482, total = 13482
slot update_slots: id  2 | task 41522 | erasing old context checkpoint (pos_min = 8828, pos_max = 9724, size = 21.034 MiB)
slot update_slots: id  2 | task 41522 | created context checkpoint 8 of 8 (pos_min = 12534, pos_max = 13421, size = 20.823 MiB)
slot print_timing: id  2 | task 41522 | 
prompt eval time =     280.39 ms /    60 tokens (    4.67 ms per token,   213.99 tokens per second)
       eval time =    2757.49 ms /    92 tokens (   29.97 ms per token,    33.36 tokens per second)
      total time =    3037.89 ms /   152 tokens
slot      release: id  2 | task 41522 | stop processing: n_tokens = 13573, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 41615 | processing task, is_child = 0
slot update_slots: id  2 | task 41615 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13719
slot update_slots: id  2 | task 41615 | n_tokens = 13514, memory_seq_rm [13514, end)
slot update_slots: id  2 | task 41615 | prompt processing progress, n_tokens = 13655, batch.n_tokens = 141, progress = 0.995335
slot update_slots: id  2 | task 41615 | n_tokens = 13655, memory_seq_rm [13655, end)
slot update_slots: id  2 | task 41615 | prompt processing progress, n_tokens = 13719, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 41615 | prompt done, n_tokens = 13719, batch.n_tokens = 64
slot init_sampler: id  2 | task 41615 | init sampler, took 2.03 ms, tokens: text = 13719, total = 13719
slot update_slots: id  2 | task 41615 | erasing old context checkpoint (pos_min = 9260, pos_max = 10156, size = 21.034 MiB)
slot update_slots: id  2 | task 41615 | created context checkpoint 8 of 8 (pos_min = 12759, pos_max = 13654, size = 21.011 MiB)
slot print_timing: id  2 | task 41615 | 
prompt eval time =     549.77 ms /   205 tokens (    2.68 ms per token,   372.89 tokens per second)
       eval time =    5424.53 ms /   179 tokens (   30.30 ms per token,    33.00 tokens per second)
      total time =    5974.29 ms /   384 tokens
slot      release: id  2 | task 41615 | stop processing: n_tokens = 13897, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.981 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 41796 | processing task, is_child = 0
slot update_slots: id  2 | task 41796 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 14115
slot update_slots: id  2 | task 41796 | n_tokens = 13842, memory_seq_rm [13842, end)
slot update_slots: id  2 | task 41796 | prompt processing progress, n_tokens = 14051, batch.n_tokens = 209, progress = 0.995466
slot update_slots: id  2 | task 41796 | n_tokens = 14051, memory_seq_rm [14051, end)
slot update_slots: id  2 | task 41796 | prompt processing progress, n_tokens = 14115, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 41796 | prompt done, n_tokens = 14115, batch.n_tokens = 64
slot init_sampler: id  2 | task 41796 | init sampler, took 2.65 ms, tokens: text = 14115, total = 14115
slot update_slots: id  2 | task 41796 | erasing old context checkpoint (pos_min = 9777, pos_max = 10673, size = 21.034 MiB)
slot update_slots: id  2 | task 41796 | created context checkpoint 8 of 8 (pos_min = 13155, pos_max = 14050, size = 21.011 MiB)
slot print_timing: id  2 | task 41796 | 
prompt eval time =     657.10 ms /   273 tokens (    2.41 ms per token,   415.46 tokens per second)
       eval time =   41650.21 ms /  1332 tokens (   31.27 ms per token,    31.98 tokens per second)
      total time =   42307.30 ms /  1605 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 41796 | stop processing: n_tokens = 15446, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.970 (> 0.100 thold), f_keep = 0.973
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 43130 | processing task, is_child = 0
slot update_slots: id  2 | task 43130 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 15490
slot update_slots: id  2 | task 43130 | n_tokens = 15027, memory_seq_rm [15027, end)
slot update_slots: id  2 | task 43130 | prompt processing progress, n_tokens = 15426, batch.n_tokens = 399, progress = 0.995868
slot update_slots: id  2 | task 43130 | n_tokens = 15426, memory_seq_rm [15426, end)
slot update_slots: id  2 | task 43130 | prompt processing progress, n_tokens = 15490, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 43130 | prompt done, n_tokens = 15490, batch.n_tokens = 64
slot init_sampler: id  2 | task 43130 | init sampler, took 2.12 ms, tokens: text = 15490, total = 15490
slot update_slots: id  2 | task 43130 | erasing old context checkpoint (pos_min = 10649, pos_max = 11545, size = 21.034 MiB)
slot update_slots: id  2 | task 43130 | created context checkpoint 8 of 8 (pos_min = 14718, pos_max = 15425, size = 16.602 MiB)
slot print_timing: id  2 | task 43130 | 
prompt eval time =     954.67 ms /   463 tokens (    2.06 ms per token,   484.99 tokens per second)
       eval time =    2015.47 ms /    66 tokens (   30.54 ms per token,    32.75 tokens per second)
      total time =    2970.14 ms /   529 tokens
slot      release: id  2 | task 43130 | stop processing: n_tokens = 15555, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.982 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 43198 | processing task, is_child = 0
slot update_slots: id  2 | task 43198 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 15792
slot update_slots: id  2 | task 43198 | n_tokens = 15500, memory_seq_rm [15500, end)
slot update_slots: id  2 | task 43198 | prompt processing progress, n_tokens = 15728, batch.n_tokens = 228, progress = 0.995947
slot update_slots: id  2 | task 43198 | n_tokens = 15728, memory_seq_rm [15728, end)
slot update_slots: id  2 | task 43198 | prompt processing progress, n_tokens = 15792, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 43198 | prompt done, n_tokens = 15792, batch.n_tokens = 64
slot init_sampler: id  2 | task 43198 | init sampler, took 2.16 ms, tokens: text = 15792, total = 15792
slot update_slots: id  2 | task 43198 | erasing old context checkpoint (pos_min = 10789, pos_max = 11669, size = 20.659 MiB)
slot update_slots: id  2 | task 43198 | created context checkpoint 8 of 8 (pos_min = 15020, pos_max = 15727, size = 16.602 MiB)
slot print_timing: id  2 | task 43198 | 
prompt eval time =     725.58 ms /   292 tokens (    2.48 ms per token,   402.44 tokens per second)
       eval time =    8898.28 ms /   294 tokens (   30.27 ms per token,    33.04 tokens per second)
      total time =    9623.86 ms /   586 tokens
slot      release: id  2 | task 43198 | stop processing: n_tokens = 16085, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.986
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 43494 | processing task, is_child = 0
slot update_slots: id  2 | task 43494 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 16123
slot update_slots: id  2 | task 43494 | n_tokens = 15864, memory_seq_rm [15864, end)
slot update_slots: id  2 | task 43494 | prompt processing progress, n_tokens = 16059, batch.n_tokens = 195, progress = 0.996031
slot update_slots: id  2 | task 43494 | n_tokens = 16059, memory_seq_rm [16059, end)
slot update_slots: id  2 | task 43494 | prompt processing progress, n_tokens = 16123, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 43494 | prompt done, n_tokens = 16123, batch.n_tokens = 64
slot init_sampler: id  2 | task 43494 | init sampler, took 2.23 ms, tokens: text = 16123, total = 16123
slot update_slots: id  2 | task 43494 | erasing old context checkpoint (pos_min = 11236, pos_max = 12116, size = 20.659 MiB)
slot update_slots: id  2 | task 43494 | created context checkpoint 8 of 8 (pos_min = 15222, pos_max = 16058, size = 19.627 MiB)
slot print_timing: id  2 | task 43494 | 
prompt eval time =     699.05 ms /   259 tokens (    2.70 ms per token,   370.50 tokens per second)
       eval time =    1925.08 ms /    64 tokens (   30.08 ms per token,    33.25 tokens per second)
      total time =    2624.14 ms /   323 tokens
slot      release: id  2 | task 43494 | stop processing: n_tokens = 16186, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.983 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 43560 | processing task, is_child = 0
slot update_slots: id  2 | task 43560 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 16419
slot update_slots: id  2 | task 43560 | n_tokens = 16132, memory_seq_rm [16132, end)
slot update_slots: id  2 | task 43560 | prompt processing progress, n_tokens = 16355, batch.n_tokens = 223, progress = 0.996102
slot update_slots: id  2 | task 43560 | n_tokens = 16355, memory_seq_rm [16355, end)
slot update_slots: id  2 | task 43560 | prompt processing progress, n_tokens = 16419, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 43560 | prompt done, n_tokens = 16419, batch.n_tokens = 64
slot init_sampler: id  2 | task 43560 | init sampler, took 2.27 ms, tokens: text = 16419, total = 16419
slot update_slots: id  2 | task 43560 | erasing old context checkpoint (pos_min = 11616, pos_max = 12476, size = 20.190 MiB)
slot update_slots: id  2 | task 43560 | created context checkpoint 8 of 8 (pos_min = 15518, pos_max = 16354, size = 19.627 MiB)
slot print_timing: id  2 | task 43560 | 
prompt eval time =     687.45 ms /   287 tokens (    2.40 ms per token,   417.48 tokens per second)
       eval time =    8502.45 ms /   280 tokens (   30.37 ms per token,    32.93 tokens per second)
      total time =    9189.90 ms /   567 tokens
slot      release: id  2 | task 43560 | stop processing: n_tokens = 16698, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.053
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 16698, total state size = 411.178 MiB
srv          load:  - looking for better prompt, base f_keep = 0.053, sim = 0.987
srv        update:  - cache state: 16 prompts, 6893.985 MiB (limits: 8192.000 MiB, 56064 tokens, 212734 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv        update:    - prompt 0x58dc3fb8c770:    5127 tokens, checkpoints:  8,   320.808 MiB
srv        update:    - prompt 0x58dc3f318830:   24865 tokens, checkpoints:  8,   791.874 MiB
srv        update:    - prompt 0x58dc40d3cf50:   16080 tokens, checkpoints:  8,   571.219 MiB
srv        update:    - prompt 0x58dc4c8ce8a0:   23906 tokens, checkpoints:  8,   739.114 MiB
srv        update:    - prompt 0x58dc38d9f350:   18675 tokens, checkpoints:  8,   606.205 MiB
srv        update:    - prompt 0x58dc3f0d1370:    8148 tokens, checkpoints:  8,   317.783 MiB
srv        update:    - prompt 0x58dc4e559330:    1905 tokens, checkpoints:  1,    86.270 MiB
srv        update:    - prompt 0x58dc7370fb50:   15396 tokens, checkpoints:  8,   535.811 MiB
srv        update:    - prompt 0x58dc3f803040:   11161 tokens, checkpoints:  8,   449.472 MiB
srv        update:    - prompt 0x58dc4b0f2100:   15565 tokens, checkpoints:  8,   546.621 MiB
srv        update:    - prompt 0x58dc4b0ed760:    2343 tokens, checkpoints:  8,   234.281 MiB
srv        update:    - prompt 0x58dc3e3ce6c0:    3768 tokens, checkpoints:  6,   225.628 MiB
srv        update:    - prompt 0x58dc40b2ad30:   16698 tokens, checkpoints:  8,   567.045 MiB
srv  get_availabl: prompt cache update took 841.45 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 43842 | processing task, is_child = 0
slot update_slots: id  2 | task 43842 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 893
slot update_slots: id  2 | task 43842 | n_past = 881, slot.prompt.tokens.size() = 16698, seq_id = 2, pos_min = 15861, n_swa = 128
slot update_slots: id  2 | task 43842 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  2 | task 43842 | erased invalidated context checkpoint (pos_min = 12428, pos_max = 13304, n_swa = 128, size = 20.565 MiB)
slot update_slots: id  2 | task 43842 | erased invalidated context checkpoint (pos_min = 12534, pos_max = 13421, n_swa = 128, size = 20.823 MiB)
slot update_slots: id  2 | task 43842 | erased invalidated context checkpoint (pos_min = 12759, pos_max = 13654, n_swa = 128, size = 21.011 MiB)
slot update_slots: id  2 | task 43842 | erased invalidated context checkpoint (pos_min = 13155, pos_max = 14050, n_swa = 128, size = 21.011 MiB)
slot update_slots: id  2 | task 43842 | erased invalidated context checkpoint (pos_min = 14718, pos_max = 15425, n_swa = 128, size = 16.602 MiB)
slot update_slots: id  2 | task 43842 | erased invalidated context checkpoint (pos_min = 15020, pos_max = 15727, n_swa = 128, size = 16.602 MiB)
slot update_slots: id  2 | task 43842 | erased invalidated context checkpoint (pos_min = 15222, pos_max = 16058, n_swa = 128, size = 19.627 MiB)
slot update_slots: id  2 | task 43842 | erased invalidated context checkpoint (pos_min = 15518, pos_max = 16354, n_swa = 128, size = 19.627 MiB)
slot update_slots: id  2 | task 43842 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 43842 | prompt processing progress, n_tokens = 829, batch.n_tokens = 829, progress = 0.928331
slot update_slots: id  2 | task 43842 | n_tokens = 829, memory_seq_rm [829, end)
slot update_slots: id  2 | task 43842 | prompt processing progress, n_tokens = 893, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 43842 | prompt done, n_tokens = 893, batch.n_tokens = 64
slot init_sampler: id  2 | task 43842 | init sampler, took 0.14 ms, tokens: text = 893, total = 893
slot update_slots: id  2 | task 43842 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 828, size = 19.439 MiB)
slot print_timing: id  2 | task 43842 | 
prompt eval time =    1464.47 ms /   893 tokens (    1.64 ms per token,   609.78 tokens per second)
       eval time =    1361.36 ms /    49 tokens (   27.78 ms per token,    35.99 tokens per second)
      total time =    2825.83 ms /   942 tokens
slot      release: id  2 | task 43842 | stop processing: n_tokens = 941, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.973 (> 0.100 thold), f_keep = 0.936
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 43893 | processing task, is_child = 0
slot update_slots: id  2 | task 43893 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 905
slot update_slots: id  2 | task 43893 | n_tokens = 881, memory_seq_rm [881, end)
slot update_slots: id  2 | task 43893 | prompt processing progress, n_tokens = 905, batch.n_tokens = 24, progress = 1.000000
slot update_slots: id  2 | task 43893 | prompt done, n_tokens = 905, batch.n_tokens = 24
slot init_sampler: id  2 | task 43893 | init sampler, took 0.14 ms, tokens: text = 905, total = 905
slot print_timing: id  2 | task 43893 | 
prompt eval time =     167.70 ms /    24 tokens (    6.99 ms per token,   143.12 tokens per second)
       eval time =     937.20 ms /    32 tokens (   29.29 ms per token,    34.14 tokens per second)
      total time =    1104.89 ms /    56 tokens
slot      release: id  2 | task 43893 | stop processing: n_tokens = 936, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.635 (> 0.100 thold), f_keep = 0.980
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 43926 | processing task, is_child = 0
slot update_slots: id  2 | task 43926 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1444
slot update_slots: id  2 | task 43926 | n_tokens = 917, memory_seq_rm [917, end)
slot update_slots: id  2 | task 43926 | prompt processing progress, n_tokens = 1380, batch.n_tokens = 463, progress = 0.955679
slot update_slots: id  2 | task 43926 | n_tokens = 1380, memory_seq_rm [1380, end)
slot update_slots: id  2 | task 43926 | prompt processing progress, n_tokens = 1444, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 43926 | prompt done, n_tokens = 1444, batch.n_tokens = 64
slot init_sampler: id  2 | task 43926 | init sampler, took 0.21 ms, tokens: text = 1444, total = 1444
slot update_slots: id  2 | task 43926 | created context checkpoint 2 of 8 (pos_min = 499, pos_max = 1379, size = 20.659 MiB)
slot print_timing: id  2 | task 43926 | 
prompt eval time =     931.33 ms /   527 tokens (    1.77 ms per token,   565.86 tokens per second)
       eval time =    7734.39 ms /   245 tokens (   31.57 ms per token,    31.68 tokens per second)
      total time =    8665.72 ms /   772 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 43926 | stop processing: n_tokens = 1688, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.846 (> 0.100 thold), f_keep = 0.861
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 44173 | processing task, is_child = 0
slot update_slots: id  2 | task 44173 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1718
slot update_slots: id  2 | task 44173 | n_tokens = 1454, memory_seq_rm [1454, end)
slot update_slots: id  2 | task 44173 | prompt processing progress, n_tokens = 1654, batch.n_tokens = 200, progress = 0.962747
slot update_slots: id  2 | task 44173 | n_tokens = 1654, memory_seq_rm [1654, end)
slot update_slots: id  2 | task 44173 | prompt processing progress, n_tokens = 1718, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 44173 | prompt done, n_tokens = 1718, batch.n_tokens = 64
slot init_sampler: id  2 | task 44173 | init sampler, took 0.45 ms, tokens: text = 1718, total = 1718
slot update_slots: id  2 | task 44173 | created context checkpoint 3 of 8 (pos_min = 807, pos_max = 1653, size = 19.862 MiB)
slot print_timing: id  2 | task 44173 | 
prompt eval time =     720.48 ms /   264 tokens (    2.73 ms per token,   366.42 tokens per second)
       eval time =    1229.74 ms /    37 tokens (   33.24 ms per token,    30.09 tokens per second)
      total time =    1950.21 ms /   301 tokens
slot      release: id  2 | task 44173 | stop processing: n_tokens = 1754, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.454 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 44212 | processing task, is_child = 0
slot update_slots: id  2 | task 44212 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 3807
slot update_slots: id  2 | task 44212 | n_tokens = 1728, memory_seq_rm [1728, end)
slot update_slots: id  2 | task 44212 | prompt processing progress, n_tokens = 3743, batch.n_tokens = 2015, progress = 0.983189
slot update_slots: id  2 | task 44212 | n_tokens = 3743, memory_seq_rm [3743, end)
slot update_slots: id  2 | task 44212 | prompt processing progress, n_tokens = 3807, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 44212 | prompt done, n_tokens = 3807, batch.n_tokens = 64
slot init_sampler: id  2 | task 44212 | init sampler, took 0.58 ms, tokens: text = 3807, total = 3807
slot update_slots: id  2 | task 44212 | created context checkpoint 4 of 8 (pos_min = 2846, pos_max = 3742, size = 21.034 MiB)
slot print_timing: id  2 | task 44212 | 
prompt eval time =    3514.16 ms /  2079 tokens (    1.69 ms per token,   591.61 tokens per second)
       eval time =    1177.41 ms /    36 tokens (   32.71 ms per token,    30.58 tokens per second)
      total time =    4691.57 ms /  2115 tokens
slot      release: id  2 | task 44212 | stop processing: n_tokens = 3842, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.592 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 44250 | processing task, is_child = 0
slot update_slots: id  2 | task 44250 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 6450
slot update_slots: id  2 | task 44250 | n_tokens = 3816, memory_seq_rm [3816, end)
slot update_slots: id  2 | task 44250 | prompt processing progress, n_tokens = 5864, batch.n_tokens = 2048, progress = 0.909147
slot update_slots: id  2 | task 44250 | n_tokens = 5864, memory_seq_rm [5864, end)
slot update_slots: id  2 | task 44250 | prompt processing progress, n_tokens = 6386, batch.n_tokens = 522, progress = 0.990077
slot update_slots: id  2 | task 44250 | n_tokens = 6386, memory_seq_rm [6386, end)
slot update_slots: id  2 | task 44250 | prompt processing progress, n_tokens = 6450, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 44250 | prompt done, n_tokens = 6450, batch.n_tokens = 64
slot init_sampler: id  2 | task 44250 | init sampler, took 0.90 ms, tokens: text = 6450, total = 6450
slot update_slots: id  2 | task 44250 | created context checkpoint 5 of 8 (pos_min = 5489, pos_max = 6385, size = 21.034 MiB)
slot print_timing: id  2 | task 44250 | 
prompt eval time =    4549.32 ms /  2634 tokens (    1.73 ms per token,   578.99 tokens per second)
       eval time =    1307.55 ms /    39 tokens (   33.53 ms per token,    29.83 tokens per second)
      total time =    5856.87 ms /  2673 tokens
slot      release: id  2 | task 44250 | stop processing: n_tokens = 6488, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.941 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 44292 | processing task, is_child = 0
slot update_slots: id  2 | task 44292 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 6862
slot update_slots: id  2 | task 44292 | n_tokens = 6458, memory_seq_rm [6458, end)
slot update_slots: id  2 | task 44292 | prompt processing progress, n_tokens = 6798, batch.n_tokens = 340, progress = 0.990673
slot update_slots: id  2 | task 44292 | n_tokens = 6798, memory_seq_rm [6798, end)
slot update_slots: id  2 | task 44292 | prompt processing progress, n_tokens = 6862, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 44292 | prompt done, n_tokens = 6862, batch.n_tokens = 64
slot init_sampler: id  2 | task 44292 | init sampler, took 1.32 ms, tokens: text = 6862, total = 6862
slot update_slots: id  2 | task 44292 | created context checkpoint 6 of 8 (pos_min = 5901, pos_max = 6797, size = 21.034 MiB)
slot print_timing: id  2 | task 44292 | 
prompt eval time =     895.20 ms /   404 tokens (    2.22 ms per token,   451.30 tokens per second)
       eval time =    4127.87 ms /   128 tokens (   32.25 ms per token,    31.01 tokens per second)
      total time =    5023.07 ms /   532 tokens
slot      release: id  2 | task 44292 | stop processing: n_tokens = 6989, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 44422 | processing task, is_child = 0
slot update_slots: id  2 | task 44422 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 7021
slot update_slots: id  2 | task 44422 | n_tokens = 6964, memory_seq_rm [6964, end)
slot update_slots: id  2 | task 44422 | prompt processing progress, n_tokens = 7021, batch.n_tokens = 57, progress = 1.000000
slot update_slots: id  2 | task 44422 | prompt done, n_tokens = 7021, batch.n_tokens = 57
slot init_sampler: id  2 | task 44422 | init sampler, took 1.10 ms, tokens: text = 7021, total = 7021
slot update_slots: id  2 | task 44422 | created context checkpoint 7 of 8 (pos_min = 6092, pos_max = 6963, size = 20.448 MiB)
slot print_timing: id  2 | task 44422 | 
prompt eval time =     297.08 ms /    57 tokens (    5.21 ms per token,   191.87 tokens per second)
       eval time =    1402.02 ms /    50 tokens (   28.04 ms per token,    35.66 tokens per second)
      total time =    1699.10 ms /   107 tokens
slot      release: id  2 | task 44422 | stop processing: n_tokens = 7070, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.936 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 44473 | processing task, is_child = 0
slot update_slots: id  2 | task 44473 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 7521
slot update_slots: id  2 | task 44473 | n_tokens = 7042, memory_seq_rm [7042, end)
slot update_slots: id  2 | task 44473 | prompt processing progress, n_tokens = 7457, batch.n_tokens = 415, progress = 0.991490
slot update_slots: id  2 | task 44473 | n_tokens = 7457, memory_seq_rm [7457, end)
slot update_slots: id  2 | task 44473 | prompt processing progress, n_tokens = 7521, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 44473 | prompt done, n_tokens = 7521, batch.n_tokens = 64
slot init_sampler: id  2 | task 44473 | init sampler, took 2.95 ms, tokens: text = 7521, total = 7521
slot update_slots: id  2 | task 44473 | created context checkpoint 8 of 8 (pos_min = 6560, pos_max = 7456, size = 21.034 MiB)
slot print_timing: id  2 | task 44473 | 
prompt eval time =     832.47 ms /   479 tokens (    1.74 ms per token,   575.40 tokens per second)
       eval time =    1147.63 ms /    40 tokens (   28.69 ms per token,    34.85 tokens per second)
      total time =    1980.10 ms /   519 tokens
slot      release: id  2 | task 44473 | stop processing: n_tokens = 7560, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.919 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 44515 | processing task, is_child = 0
slot update_slots: id  2 | task 44515 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 8194
slot update_slots: id  2 | task 44515 | n_tokens = 7533, memory_seq_rm [7533, end)
slot update_slots: id  2 | task 44515 | prompt processing progress, n_tokens = 8130, batch.n_tokens = 597, progress = 0.992189
slot update_slots: id  2 | task 44515 | n_tokens = 8130, memory_seq_rm [8130, end)
slot update_slots: id  2 | task 44515 | prompt processing progress, n_tokens = 8194, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 44515 | prompt done, n_tokens = 8194, batch.n_tokens = 64
slot init_sampler: id  2 | task 44515 | init sampler, took 1.15 ms, tokens: text = 8194, total = 8194
slot update_slots: id  2 | task 44515 | erasing old context checkpoint (pos_min = 0, pos_max = 828, size = 19.439 MiB)
slot update_slots: id  2 | task 44515 | created context checkpoint 8 of 8 (pos_min = 7233, pos_max = 8129, size = 21.034 MiB)
slot print_timing: id  2 | task 44515 | 
prompt eval time =    1219.03 ms /   661 tokens (    1.84 ms per token,   542.23 tokens per second)
       eval time =    4687.46 ms /   163 tokens (   28.76 ms per token,    34.77 tokens per second)
      total time =    5906.49 ms /   824 tokens
slot      release: id  2 | task 44515 | stop processing: n_tokens = 8356, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.949 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 44680 | processing task, is_child = 0
slot update_slots: id  2 | task 44680 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 8776
slot update_slots: id  2 | task 44680 | n_tokens = 8331, memory_seq_rm [8331, end)
slot update_slots: id  2 | task 44680 | prompt processing progress, n_tokens = 8712, batch.n_tokens = 381, progress = 0.992707
slot update_slots: id  2 | task 44680 | n_tokens = 8712, memory_seq_rm [8712, end)
slot update_slots: id  2 | task 44680 | prompt processing progress, n_tokens = 8776, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 44680 | prompt done, n_tokens = 8776, batch.n_tokens = 64
slot init_sampler: id  2 | task 44680 | init sampler, took 1.22 ms, tokens: text = 8776, total = 8776
slot update_slots: id  2 | task 44680 | erasing old context checkpoint (pos_min = 499, pos_max = 1379, size = 20.659 MiB)
slot update_slots: id  2 | task 44680 | created context checkpoint 8 of 8 (pos_min = 7815, pos_max = 8711, size = 21.034 MiB)
slot print_timing: id  2 | task 44680 | 
prompt eval time =     839.49 ms /   445 tokens (    1.89 ms per token,   530.08 tokens per second)
       eval time =    1314.90 ms /    44 tokens (   29.88 ms per token,    33.46 tokens per second)
      total time =    2154.39 ms /   489 tokens
slot      release: id  2 | task 44680 | stop processing: n_tokens = 8819, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.954 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 44726 | processing task, is_child = 0
slot update_slots: id  2 | task 44726 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 9213
slot update_slots: id  2 | task 44726 | n_tokens = 8791, memory_seq_rm [8791, end)
slot update_slots: id  2 | task 44726 | prompt processing progress, n_tokens = 9149, batch.n_tokens = 358, progress = 0.993053
slot update_slots: id  2 | task 44726 | n_tokens = 9149, memory_seq_rm [9149, end)
slot update_slots: id  2 | task 44726 | prompt processing progress, n_tokens = 9213, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 44726 | prompt done, n_tokens = 9213, batch.n_tokens = 64
slot init_sampler: id  2 | task 44726 | init sampler, took 1.70 ms, tokens: text = 9213, total = 9213
slot update_slots: id  2 | task 44726 | erasing old context checkpoint (pos_min = 807, pos_max = 1653, size = 19.862 MiB)
slot update_slots: id  2 | task 44726 | created context checkpoint 8 of 8 (pos_min = 8252, pos_max = 9148, size = 21.034 MiB)
slot print_timing: id  2 | task 44726 | 
prompt eval time =     823.91 ms /   422 tokens (    1.95 ms per token,   512.19 tokens per second)
       eval time =    5161.86 ms /   170 tokens (   30.36 ms per token,    32.93 tokens per second)
      total time =    5985.77 ms /   592 tokens
slot      release: id  2 | task 44726 | stop processing: n_tokens = 9382, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.963 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 44898 | processing task, is_child = 0
slot update_slots: id  2 | task 44898 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 9714
slot update_slots: id  2 | task 44898 | n_tokens = 9356, memory_seq_rm [9356, end)
slot update_slots: id  2 | task 44898 | prompt processing progress, n_tokens = 9650, batch.n_tokens = 294, progress = 0.993412
slot update_slots: id  2 | task 44898 | n_tokens = 9650, memory_seq_rm [9650, end)
slot update_slots: id  2 | task 44898 | prompt processing progress, n_tokens = 9714, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 44898 | prompt done, n_tokens = 9714, batch.n_tokens = 64
slot init_sampler: id  2 | task 44898 | init sampler, took 1.40 ms, tokens: text = 9714, total = 9714
slot update_slots: id  2 | task 44898 | erasing old context checkpoint (pos_min = 2846, pos_max = 3742, size = 21.034 MiB)
slot update_slots: id  2 | task 44898 | created context checkpoint 8 of 8 (pos_min = 8753, pos_max = 9649, size = 21.034 MiB)
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv          stop: cancel task, id_task = 44898
slot      release: id  2 | task 44898 | stop processing: n_tokens = 10072, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.087
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 10072, total state size = 257.212 MiB
srv          load:  - looking for better prompt, base f_keep = 0.087, sim = 0.989
srv        update:  - cache state: 17 prompts, 7318.883 MiB (limits: 8192.000 MiB, 56064 tokens, 211657 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv        update:    - prompt 0x58dc3fb8c770:    5127 tokens, checkpoints:  8,   320.808 MiB
srv        update:    - prompt 0x58dc3f318830:   24865 tokens, checkpoints:  8,   791.874 MiB
srv        update:    - prompt 0x58dc40d3cf50:   16080 tokens, checkpoints:  8,   571.219 MiB
srv        update:    - prompt 0x58dc4c8ce8a0:   23906 tokens, checkpoints:  8,   739.114 MiB
srv        update:    - prompt 0x58dc38d9f350:   18675 tokens, checkpoints:  8,   606.205 MiB
srv        update:    - prompt 0x58dc3f0d1370:    8148 tokens, checkpoints:  8,   317.783 MiB
srv        update:    - prompt 0x58dc4e559330:    1905 tokens, checkpoints:  1,    86.270 MiB
srv        update:    - prompt 0x58dc7370fb50:   15396 tokens, checkpoints:  8,   535.811 MiB
srv        update:    - prompt 0x58dc3f803040:   11161 tokens, checkpoints:  8,   449.472 MiB
srv        update:    - prompt 0x58dc4b0f2100:   15565 tokens, checkpoints:  8,   546.621 MiB
srv        update:    - prompt 0x58dc4b0ed760:    2343 tokens, checkpoints:  8,   234.281 MiB
srv        update:    - prompt 0x58dc3e3ce6c0:    3768 tokens, checkpoints:  6,   225.628 MiB
srv        update:    - prompt 0x58dc40b2ad30:   16698 tokens, checkpoints:  8,   567.045 MiB
srv        update:    - prompt 0x58dc91e19670:   10072 tokens, checkpoints:  8,   424.898 MiB
srv  get_availabl: prompt cache update took 680.74 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 45260 | processing task, is_child = 0
slot update_slots: id  2 | task 45260 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 891
slot update_slots: id  2 | task 45260 | n_past = 881, slot.prompt.tokens.size() = 10072, seq_id = 2, pos_min = 9175, n_swa = 128
slot update_slots: id  2 | task 45260 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  2 | task 45260 | erased invalidated context checkpoint (pos_min = 5489, pos_max = 6385, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 45260 | erased invalidated context checkpoint (pos_min = 5901, pos_max = 6797, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 45260 | erased invalidated context checkpoint (pos_min = 6092, pos_max = 6963, n_swa = 128, size = 20.448 MiB)
slot update_slots: id  2 | task 45260 | erased invalidated context checkpoint (pos_min = 6560, pos_max = 7456, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 45260 | erased invalidated context checkpoint (pos_min = 7233, pos_max = 8129, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 45260 | erased invalidated context checkpoint (pos_min = 7815, pos_max = 8711, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 45260 | erased invalidated context checkpoint (pos_min = 8252, pos_max = 9148, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 45260 | erased invalidated context checkpoint (pos_min = 8753, pos_max = 9649, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 45260 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 45260 | prompt processing progress, n_tokens = 827, batch.n_tokens = 827, progress = 0.928171
slot update_slots: id  2 | task 45260 | n_tokens = 827, memory_seq_rm [827, end)
slot update_slots: id  2 | task 45260 | prompt processing progress, n_tokens = 891, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 45260 | prompt done, n_tokens = 891, batch.n_tokens = 64
slot init_sampler: id  2 | task 45260 | init sampler, took 0.13 ms, tokens: text = 891, total = 891
slot update_slots: id  2 | task 45260 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 826, size = 19.393 MiB)
slot print_timing: id  2 | task 45260 | 
prompt eval time =    1349.91 ms /   891 tokens (    1.52 ms per token,   660.04 tokens per second)
       eval time =    2298.41 ms /    90 tokens (   25.54 ms per token,    39.16 tokens per second)
      total time =    3648.33 ms /   981 tokens
slot      release: id  2 | task 45260 | stop processing: n_tokens = 980, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 1.000 (> 0.100 thold), f_keep = 0.909
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 45352 | processing task, is_child = 0
slot update_slots: id  2 | task 45352 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 891
slot update_slots: id  2 | task 45352 | need to evaluate at least 1 token for each active slot (n_past = 891, task.n_tokens() = 891)
slot update_slots: id  2 | task 45352 | n_past was set to 890
slot update_slots: id  2 | task 45352 | n_tokens = 890, memory_seq_rm [890, end)
slot update_slots: id  2 | task 45352 | prompt processing progress, n_tokens = 891, batch.n_tokens = 1, progress = 1.000000
slot update_slots: id  2 | task 45352 | prompt done, n_tokens = 891, batch.n_tokens = 1
slot init_sampler: id  2 | task 45352 | init sampler, took 0.13 ms, tokens: text = 891, total = 891
slot print_timing: id  2 | task 45352 | 
prompt eval time =      36.69 ms /     1 tokens (   36.69 ms per token,    27.26 tokens per second)
       eval time =    2164.35 ms /    82 tokens (   26.39 ms per token,    37.89 tokens per second)
      total time =    2201.04 ms /    83 tokens
slot      release: id  2 | task 45352 | stop processing: n_tokens = 972, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 1.000 (> 0.100 thold), f_keep = 0.917
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 45435 | processing task, is_child = 0
slot update_slots: id  2 | task 45435 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 891
slot update_slots: id  2 | task 45435 | need to evaluate at least 1 token for each active slot (n_past = 891, task.n_tokens() = 891)
slot update_slots: id  2 | task 45435 | n_past was set to 890
slot update_slots: id  2 | task 45435 | n_tokens = 890, memory_seq_rm [890, end)
slot update_slots: id  2 | task 45435 | prompt processing progress, n_tokens = 891, batch.n_tokens = 1, progress = 1.000000
slot update_slots: id  2 | task 45435 | prompt done, n_tokens = 891, batch.n_tokens = 1
slot init_sampler: id  2 | task 45435 | init sampler, took 0.14 ms, tokens: text = 891, total = 891
slot print_timing: id  2 | task 45435 | 
prompt eval time =      36.42 ms /     1 tokens (   36.42 ms per token,    27.45 tokens per second)
       eval time =    3152.78 ms /   119 tokens (   26.49 ms per token,    37.74 tokens per second)
      total time =    3189.21 ms /   120 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 45435 | stop processing: n_tokens = 1009, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.873
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 45555 | processing task, is_child = 0
slot update_slots: id  2 | task 45555 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 892
slot update_slots: id  2 | task 45555 | n_tokens = 881, memory_seq_rm [881, end)
slot update_slots: id  2 | task 45555 | prompt processing progress, n_tokens = 892, batch.n_tokens = 11, progress = 1.000000
slot update_slots: id  2 | task 45555 | prompt done, n_tokens = 892, batch.n_tokens = 11
slot init_sampler: id  2 | task 45555 | init sampler, took 0.13 ms, tokens: text = 892, total = 892
slot print_timing: id  2 | task 45555 | 
prompt eval time =     122.77 ms /    11 tokens (   11.16 ms per token,    89.60 tokens per second)
       eval time =    4121.48 ms /   157 tokens (   26.25 ms per token,    38.09 tokens per second)
      total time =    4244.24 ms /   168 tokens
slot      release: id  2 | task 45555 | stop processing: n_tokens = 1048, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.841
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 45713 | processing task, is_child = 0
slot update_slots: id  2 | task 45713 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 891
slot update_slots: id  2 | task 45713 | n_tokens = 881, memory_seq_rm [881, end)
slot update_slots: id  2 | task 45713 | prompt processing progress, n_tokens = 891, batch.n_tokens = 10, progress = 1.000000
slot update_slots: id  2 | task 45713 | prompt done, n_tokens = 891, batch.n_tokens = 10
slot init_sampler: id  2 | task 45713 | init sampler, took 0.14 ms, tokens: text = 891, total = 891
slot print_timing: id  2 | task 45713 | 
prompt eval time =     121.85 ms /    10 tokens (   12.19 ms per token,    82.07 tokens per second)
       eval time =    1083.48 ms /    42 tokens (   25.80 ms per token,    38.76 tokens per second)
      total time =    1205.33 ms /    52 tokens
slot      release: id  2 | task 45713 | stop processing: n_tokens = 932, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.847 (> 0.100 thold), f_keep = 0.981
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 45756 | processing task, is_child = 0
slot update_slots: id  2 | task 45756 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1079
slot update_slots: id  2 | task 45756 | n_tokens = 914, memory_seq_rm [914, end)
slot update_slots: id  2 | task 45756 | prompt processing progress, n_tokens = 1015, batch.n_tokens = 101, progress = 0.940686
slot update_slots: id  2 | task 45756 | n_tokens = 1015, memory_seq_rm [1015, end)
slot update_slots: id  2 | task 45756 | prompt processing progress, n_tokens = 1079, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 45756 | prompt done, n_tokens = 1079, batch.n_tokens = 64
slot init_sampler: id  2 | task 45756 | init sampler, took 0.21 ms, tokens: text = 1079, total = 1079
slot update_slots: id  2 | task 45756 | created context checkpoint 2 of 8 (pos_min = 167, pos_max = 1014, size = 19.885 MiB)
slot print_timing: id  2 | task 45756 | 
prompt eval time =     474.98 ms /   165 tokens (    2.88 ms per token,   347.39 tokens per second)
       eval time =    2331.26 ms /    89 tokens (   26.19 ms per token,    38.18 tokens per second)
      total time =    2806.24 ms /   254 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 45756 | stop processing: n_tokens = 1167, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.771 (> 0.100 thold), f_keep = 0.763
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 45847 | processing task, is_child = 0
slot update_slots: id  2 | task 45847 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1155
slot update_slots: id  2 | task 45847 | n_tokens = 891, memory_seq_rm [891, end)
slot update_slots: id  2 | task 45847 | prompt processing progress, n_tokens = 1091, batch.n_tokens = 200, progress = 0.944589
slot update_slots: id  2 | task 45847 | n_tokens = 1091, memory_seq_rm [1091, end)
slot update_slots: id  2 | task 45847 | prompt processing progress, n_tokens = 1155, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 45847 | prompt done, n_tokens = 1155, batch.n_tokens = 64
slot init_sampler: id  2 | task 45847 | init sampler, took 0.21 ms, tokens: text = 1155, total = 1155
slot update_slots: id  2 | task 45847 | created context checkpoint 3 of 8 (pos_min = 286, pos_max = 1090, size = 18.877 MiB)
slot print_timing: id  2 | task 45847 | 
prompt eval time =     686.22 ms /   264 tokens (    2.60 ms per token,   384.72 tokens per second)
       eval time =    1697.23 ms /    65 tokens (   26.11 ms per token,    38.30 tokens per second)
      total time =    2383.45 ms /   329 tokens
slot      release: id  2 | task 45847 | stop processing: n_tokens = 1219, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.873 (> 0.100 thold), f_keep = 0.978
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 45914 | processing task, is_child = 0
slot update_slots: id  2 | task 45914 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1366
slot update_slots: id  2 | task 45914 | n_tokens = 1192, memory_seq_rm [1192, end)
slot update_slots: id  2 | task 45914 | prompt processing progress, n_tokens = 1302, batch.n_tokens = 110, progress = 0.953148
slot update_slots: id  2 | task 45914 | n_tokens = 1302, memory_seq_rm [1302, end)
slot update_slots: id  2 | task 45914 | prompt processing progress, n_tokens = 1366, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 45914 | prompt done, n_tokens = 1366, batch.n_tokens = 64
slot init_sampler: id  2 | task 45914 | init sampler, took 0.27 ms, tokens: text = 1366, total = 1366
slot update_slots: id  2 | task 45914 | created context checkpoint 4 of 8 (pos_min = 421, pos_max = 1301, size = 20.659 MiB)
slot print_timing: id  2 | task 45914 | 
prompt eval time =     495.10 ms /   174 tokens (    2.85 ms per token,   351.44 tokens per second)
       eval time =    2000.40 ms /    76 tokens (   26.32 ms per token,    37.99 tokens per second)
      total time =    2495.50 ms /   250 tokens
slot      release: id  2 | task 45914 | stop processing: n_tokens = 1441, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.813 (> 0.100 thold), f_keep = 0.802
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 45992 | processing task, is_child = 0
slot update_slots: id  2 | task 45992 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1420
slot update_slots: id  2 | task 45992 | n_tokens = 1155, memory_seq_rm [1155, end)
slot update_slots: id  2 | task 45992 | prompt processing progress, n_tokens = 1356, batch.n_tokens = 201, progress = 0.954930
slot update_slots: id  2 | task 45992 | n_tokens = 1356, memory_seq_rm [1356, end)
slot update_slots: id  2 | task 45992 | prompt processing progress, n_tokens = 1420, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 45992 | prompt done, n_tokens = 1420, batch.n_tokens = 64
slot init_sampler: id  2 | task 45992 | init sampler, took 0.21 ms, tokens: text = 1420, total = 1420
slot print_timing: id  2 | task 45992 | 
prompt eval time =     686.17 ms /   265 tokens (    2.59 ms per token,   386.20 tokens per second)
       eval time =    1043.17 ms /    40 tokens (   26.08 ms per token,    38.34 tokens per second)
      total time =    1729.34 ms /   305 tokens
slot      release: id  2 | task 45992 | stop processing: n_tokens = 1459, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.977 (> 0.100 thold), f_keep = 0.974
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 46034 | processing task, is_child = 0
slot update_slots: id  2 | task 46034 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1455
slot update_slots: id  2 | task 46034 | n_tokens = 1421, memory_seq_rm [1421, end)
slot update_slots: id  2 | task 46034 | prompt processing progress, n_tokens = 1455, batch.n_tokens = 34, progress = 1.000000
slot update_slots: id  2 | task 46034 | prompt done, n_tokens = 1455, batch.n_tokens = 34
slot init_sampler: id  2 | task 46034 | init sampler, took 0.22 ms, tokens: text = 1455, total = 1455
slot update_slots: id  2 | task 46034 | created context checkpoint 5 of 8 (pos_min = 578, pos_max = 1420, size = 19.768 MiB)
slot print_timing: id  2 | task 46034 | 
prompt eval time =     223.04 ms /    34 tokens (    6.56 ms per token,   152.44 tokens per second)
       eval time =   11688.84 ms /   432 tokens (   27.06 ms per token,    36.96 tokens per second)
      total time =   11911.89 ms /   466 tokens
slot      release: id  2 | task 46034 | stop processing: n_tokens = 1886, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.814 (> 0.100 thold), f_keep = 0.772
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 46467 | processing task, is_child = 0
slot update_slots: id  2 | task 46467 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1788
slot update_slots: id  2 | task 46467 | n_tokens = 1456, memory_seq_rm [1456, end)
slot update_slots: id  2 | task 46467 | prompt processing progress, n_tokens = 1724, batch.n_tokens = 268, progress = 0.964206
slot update_slots: id  2 | task 46467 | n_tokens = 1724, memory_seq_rm [1724, end)
slot update_slots: id  2 | task 46467 | prompt processing progress, n_tokens = 1788, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 46467 | prompt done, n_tokens = 1788, batch.n_tokens = 64
slot init_sampler: id  2 | task 46467 | init sampler, took 0.26 ms, tokens: text = 1788, total = 1788
slot update_slots: id  2 | task 46467 | created context checkpoint 6 of 8 (pos_min = 1149, pos_max = 1723, size = 13.483 MiB)
slot print_timing: id  2 | task 46467 | 
prompt eval time =     755.02 ms /   332 tokens (    2.27 ms per token,   439.72 tokens per second)
       eval time =    1832.80 ms /    69 tokens (   26.56 ms per token,    37.65 tokens per second)
      total time =    2587.82 ms /   401 tokens
slot      release: id  2 | task 46467 | stop processing: n_tokens = 1856, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.964
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 46538 | processing task, is_child = 0
slot update_slots: id  2 | task 46538 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1812
slot update_slots: id  2 | task 46538 | n_tokens = 1789, memory_seq_rm [1789, end)
slot update_slots: id  2 | task 46538 | prompt processing progress, n_tokens = 1812, batch.n_tokens = 23, progress = 1.000000
slot update_slots: id  2 | task 46538 | prompt done, n_tokens = 1812, batch.n_tokens = 23
slot init_sampler: id  2 | task 46538 | init sampler, took 0.32 ms, tokens: text = 1812, total = 1812
slot update_slots: id  2 | task 46538 | created context checkpoint 7 of 8 (pos_min = 1281, pos_max = 1788, size = 11.912 MiB)
slot print_timing: id  2 | task 46538 | 
prompt eval time =     182.98 ms /    23 tokens (    7.96 ms per token,   125.70 tokens per second)
       eval time =    3293.54 ms /   123 tokens (   26.78 ms per token,    37.35 tokens per second)
      total time =    3476.52 ms /   146 tokens
slot      release: id  2 | task 46538 | stop processing: n_tokens = 1934, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.456
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 1934, total state size = 58.834 MiB
srv          load:  - looking for better prompt, base f_keep = 0.456, sim = 0.990
srv        update:  - cache state: 18 prompts, 7501.694 MiB (limits: 8192.000 MiB, 56064 tokens, 208611 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv        update:    - prompt 0x58dc3fb8c770:    5127 tokens, checkpoints:  8,   320.808 MiB
srv        update:    - prompt 0x58dc3f318830:   24865 tokens, checkpoints:  8,   791.874 MiB
srv        update:    - prompt 0x58dc40d3cf50:   16080 tokens, checkpoints:  8,   571.219 MiB
srv        update:    - prompt 0x58dc4c8ce8a0:   23906 tokens, checkpoints:  8,   739.114 MiB
srv        update:    - prompt 0x58dc38d9f350:   18675 tokens, checkpoints:  8,   606.205 MiB
srv        update:    - prompt 0x58dc3f0d1370:    8148 tokens, checkpoints:  8,   317.783 MiB
srv        update:    - prompt 0x58dc4e559330:    1905 tokens, checkpoints:  1,    86.270 MiB
srv        update:    - prompt 0x58dc7370fb50:   15396 tokens, checkpoints:  8,   535.811 MiB
srv        update:    - prompt 0x58dc3f803040:   11161 tokens, checkpoints:  8,   449.472 MiB
srv        update:    - prompt 0x58dc4b0f2100:   15565 tokens, checkpoints:  8,   546.621 MiB
srv        update:    - prompt 0x58dc4b0ed760:    2343 tokens, checkpoints:  8,   234.281 MiB
srv        update:    - prompt 0x58dc3e3ce6c0:    3768 tokens, checkpoints:  6,   225.628 MiB
srv        update:    - prompt 0x58dc40b2ad30:   16698 tokens, checkpoints:  8,   567.045 MiB
srv        update:    - prompt 0x58dc91e19670:   10072 tokens, checkpoints:  8,   424.898 MiB
srv        update:    - prompt 0x58dc3fbbf660:    1934 tokens, checkpoints:  7,   182.811 MiB
srv  get_availabl: prompt cache update took 219.37 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 46662 | processing task, is_child = 0
slot update_slots: id  2 | task 46662 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 890
slot update_slots: id  2 | task 46662 | n_past = 881, slot.prompt.tokens.size() = 1934, seq_id = 2, pos_min = 1359, n_swa = 128
slot update_slots: id  2 | task 46662 | restored context checkpoint (pos_min = 578, pos_max = 1420, size = 19.768 MiB)
slot update_slots: id  2 | task 46662 | erased invalidated context checkpoint (pos_min = 1149, pos_max = 1723, n_swa = 128, size = 13.483 MiB)
slot update_slots: id  2 | task 46662 | erased invalidated context checkpoint (pos_min = 1281, pos_max = 1788, n_swa = 128, size = 11.912 MiB)
slot update_slots: id  2 | task 46662 | n_tokens = 881, memory_seq_rm [881, end)
slot update_slots: id  2 | task 46662 | prompt processing progress, n_tokens = 890, batch.n_tokens = 9, progress = 1.000000
slot update_slots: id  2 | task 46662 | prompt done, n_tokens = 890, batch.n_tokens = 9
slot init_sampler: id  2 | task 46662 | init sampler, took 0.15 ms, tokens: text = 890, total = 890
slot print_timing: id  2 | task 46662 | 
prompt eval time =     286.25 ms /     9 tokens (   31.81 ms per token,    31.44 tokens per second)
       eval time =    1601.55 ms /    60 tokens (   26.69 ms per token,    37.46 tokens per second)
      total time =    1887.80 ms /    69 tokens
slot      release: id  2 | task 46662 | stop processing: n_tokens = 949, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.981 (> 0.100 thold), f_keep = 0.928
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 46723 | processing task, is_child = 0
slot update_slots: id  2 | task 46723 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 898
slot update_slots: id  2 | task 46723 | n_tokens = 881, memory_seq_rm [881, end)
slot update_slots: id  2 | task 46723 | prompt processing progress, n_tokens = 898, batch.n_tokens = 17, progress = 1.000000
slot update_slots: id  2 | task 46723 | prompt done, n_tokens = 898, batch.n_tokens = 17
slot init_sampler: id  2 | task 46723 | init sampler, took 0.13 ms, tokens: text = 898, total = 898
slot print_timing: id  2 | task 46723 | 
prompt eval time =     160.57 ms /    17 tokens (    9.45 ms per token,   105.87 tokens per second)
       eval time =    1319.13 ms /    50 tokens (   26.38 ms per token,    37.90 tokens per second)
      total time =    1479.70 ms /    67 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 46723 | stop processing: n_tokens = 947, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.613 (> 0.100 thold), f_keep = 0.980
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 46774 | processing task, is_child = 0
slot update_slots: id  2 | task 46774 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1513
slot update_slots: id  2 | task 46774 | n_tokens = 928, memory_seq_rm [928, end)
slot update_slots: id  2 | task 46774 | prompt processing progress, n_tokens = 1449, batch.n_tokens = 521, progress = 0.957700
slot update_slots: id  2 | task 46774 | n_tokens = 1449, memory_seq_rm [1449, end)
slot update_slots: id  2 | task 46774 | prompt processing progress, n_tokens = 1513, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 46774 | prompt done, n_tokens = 1513, batch.n_tokens = 64
slot init_sampler: id  2 | task 46774 | init sampler, took 0.29 ms, tokens: text = 1513, total = 1513
slot print_timing: id  2 | task 46774 | 
prompt eval time =     960.30 ms /   585 tokens (    1.64 ms per token,   609.19 tokens per second)
       eval time =    3987.58 ms /   145 tokens (   27.50 ms per token,    36.36 tokens per second)
      total time =    4947.88 ms /   730 tokens
slot      release: id  2 | task 46774 | stop processing: n_tokens = 1657, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.888 (> 0.100 thold), f_keep = 0.919
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 46921 | processing task, is_child = 0
slot update_slots: id  2 | task 46921 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1716
slot update_slots: id  2 | task 46921 | n_tokens = 1523, memory_seq_rm [1523, end)
slot update_slots: id  2 | task 46921 | prompt processing progress, n_tokens = 1652, batch.n_tokens = 129, progress = 0.962704
slot update_slots: id  2 | task 46921 | n_tokens = 1652, memory_seq_rm [1652, end)
slot update_slots: id  2 | task 46921 | prompt processing progress, n_tokens = 1716, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 46921 | prompt done, n_tokens = 1716, batch.n_tokens = 64
slot init_sampler: id  2 | task 46921 | init sampler, took 0.25 ms, tokens: text = 1716, total = 1716
slot update_slots: id  2 | task 46921 | created context checkpoint 6 of 8 (pos_min = 814, pos_max = 1651, size = 19.651 MiB)
slot print_timing: id  2 | task 46921 | 
prompt eval time =     527.87 ms /   193 tokens (    2.74 ms per token,   365.62 tokens per second)
       eval time =    1251.92 ms /    46 tokens (   27.22 ms per token,    36.74 tokens per second)
      total time =    1779.79 ms /   239 tokens
slot      release: id  2 | task 46921 | stop processing: n_tokens = 1761, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.496 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 46969 | processing task, is_child = 0
slot update_slots: id  2 | task 46969 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 3496
slot update_slots: id  2 | task 46969 | n_tokens = 1735, memory_seq_rm [1735, end)
slot update_slots: id  2 | task 46969 | prompt processing progress, n_tokens = 3432, batch.n_tokens = 1697, progress = 0.981693
slot update_slots: id  2 | task 46969 | n_tokens = 3432, memory_seq_rm [3432, end)
slot update_slots: id  2 | task 46969 | prompt processing progress, n_tokens = 3496, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 46969 | prompt done, n_tokens = 3496, batch.n_tokens = 64
slot init_sampler: id  2 | task 46969 | init sampler, took 0.48 ms, tokens: text = 3496, total = 3496
slot update_slots: id  2 | task 46969 | created context checkpoint 7 of 8 (pos_min = 2535, pos_max = 3431, size = 21.034 MiB)
slot print_timing: id  2 | task 46969 | 
prompt eval time =    2585.43 ms /  1761 tokens (    1.47 ms per token,   681.12 tokens per second)
       eval time =    1897.07 ms /    69 tokens (   27.49 ms per token,    36.37 tokens per second)
      total time =    4482.51 ms /  1830 tokens
slot      release: id  2 | task 46969 | stop processing: n_tokens = 3564, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.977 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 47040 | processing task, is_child = 0
slot update_slots: id  2 | task 47040 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 3620
slot update_slots: id  2 | task 47040 | n_tokens = 3535, memory_seq_rm [3535, end)
slot update_slots: id  2 | task 47040 | prompt processing progress, n_tokens = 3556, batch.n_tokens = 21, progress = 0.982320
slot update_slots: id  2 | task 47040 | n_tokens = 3556, memory_seq_rm [3556, end)
slot update_slots: id  2 | task 47040 | prompt processing progress, n_tokens = 3620, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 47040 | prompt done, n_tokens = 3620, batch.n_tokens = 64
slot init_sampler: id  2 | task 47040 | init sampler, took 0.51 ms, tokens: text = 3620, total = 3620
slot update_slots: id  2 | task 47040 | created context checkpoint 8 of 8 (pos_min = 2667, pos_max = 3555, size = 20.846 MiB)
slot print_timing: id  2 | task 47040 | 
prompt eval time =     321.30 ms /    85 tokens (    3.78 ms per token,   264.55 tokens per second)
       eval time =    1186.82 ms /    43 tokens (   27.60 ms per token,    36.23 tokens per second)
      total time =    1508.12 ms /   128 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 47040 | stop processing: n_tokens = 3662, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.750 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 47085 | processing task, is_child = 0
slot update_slots: id  2 | task 47085 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 4844
slot update_slots: id  2 | task 47085 | n_tokens = 3632, memory_seq_rm [3632, end)
slot update_slots: id  2 | task 47085 | prompt processing progress, n_tokens = 4780, batch.n_tokens = 1148, progress = 0.986788
slot update_slots: id  2 | task 47085 | n_tokens = 4780, memory_seq_rm [4780, end)
slot update_slots: id  2 | task 47085 | prompt processing progress, n_tokens = 4844, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 47085 | prompt done, n_tokens = 4844, batch.n_tokens = 64
slot init_sampler: id  2 | task 47085 | init sampler, took 1.00 ms, tokens: text = 4844, total = 4844
slot update_slots: id  2 | task 47085 | erasing old context checkpoint (pos_min = 0, pos_max = 826, size = 19.393 MiB)
slot update_slots: id  2 | task 47085 | created context checkpoint 8 of 8 (pos_min = 3883, pos_max = 4779, size = 21.034 MiB)
slot print_timing: id  2 | task 47085 | 
prompt eval time =    1989.25 ms /  1212 tokens (    1.64 ms per token,   609.27 tokens per second)
       eval time =    3110.33 ms /   111 tokens (   28.02 ms per token,    35.69 tokens per second)
      total time =    5099.58 ms /  1323 tokens
slot      release: id  2 | task 47085 | stop processing: n_tokens = 4954, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.932 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 47198 | processing task, is_child = 0
slot update_slots: id  2 | task 47198 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 5288
slot update_slots: id  2 | task 47198 | n_tokens = 4929, memory_seq_rm [4929, end)
slot update_slots: id  2 | task 47198 | prompt processing progress, n_tokens = 5224, batch.n_tokens = 295, progress = 0.987897
slot update_slots: id  2 | task 47198 | n_tokens = 5224, memory_seq_rm [5224, end)
slot update_slots: id  2 | task 47198 | prompt processing progress, n_tokens = 5288, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 47198 | prompt done, n_tokens = 5288, batch.n_tokens = 64
slot init_sampler: id  2 | task 47198 | init sampler, took 0.75 ms, tokens: text = 5288, total = 5288
slot update_slots: id  2 | task 47198 | erasing old context checkpoint (pos_min = 167, pos_max = 1014, size = 19.885 MiB)
slot update_slots: id  2 | task 47198 | created context checkpoint 8 of 8 (pos_min = 4327, pos_max = 5223, size = 21.034 MiB)
slot print_timing: id  2 | task 47198 | 
prompt eval time =     707.38 ms /   359 tokens (    1.97 ms per token,   507.51 tokens per second)
       eval time =    1379.87 ms /    49 tokens (   28.16 ms per token,    35.51 tokens per second)
      total time =    2087.25 ms /   408 tokens
slot      release: id  2 | task 47198 | stop processing: n_tokens = 5336, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.903 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 47249 | processing task, is_child = 0
slot update_slots: id  2 | task 47249 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 5877
slot update_slots: id  2 | task 47249 | n_tokens = 5309, memory_seq_rm [5309, end)
slot update_slots: id  2 | task 47249 | prompt processing progress, n_tokens = 5813, batch.n_tokens = 504, progress = 0.989110
slot update_slots: id  2 | task 47249 | n_tokens = 5813, memory_seq_rm [5813, end)
slot update_slots: id  2 | task 47249 | prompt processing progress, n_tokens = 5877, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 47249 | prompt done, n_tokens = 5877, batch.n_tokens = 64
slot init_sampler: id  2 | task 47249 | init sampler, took 0.81 ms, tokens: text = 5877, total = 5877
slot update_slots: id  2 | task 47249 | erasing old context checkpoint (pos_min = 286, pos_max = 1090, size = 18.877 MiB)
slot update_slots: id  2 | task 47249 | created context checkpoint 8 of 8 (pos_min = 4916, pos_max = 5812, size = 21.034 MiB)
slot print_timing: id  2 | task 47249 | 
prompt eval time =     944.37 ms /   568 tokens (    1.66 ms per token,   601.46 tokens per second)
       eval time =    1329.19 ms /    47 tokens (   28.28 ms per token,    35.36 tokens per second)
      total time =    2273.55 ms /   615 tokens
slot      release: id  2 | task 47249 | stop processing: n_tokens = 5923, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.756 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 47298 | processing task, is_child = 0
slot update_slots: id  2 | task 47298 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 7800
slot update_slots: id  2 | task 47298 | n_tokens = 5896, memory_seq_rm [5896, end)
slot update_slots: id  2 | task 47298 | prompt processing progress, n_tokens = 7736, batch.n_tokens = 1840, progress = 0.991795
slot update_slots: id  2 | task 47298 | n_tokens = 7736, memory_seq_rm [7736, end)
slot update_slots: id  2 | task 47298 | prompt processing progress, n_tokens = 7800, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 47298 | prompt done, n_tokens = 7800, batch.n_tokens = 64
slot init_sampler: id  2 | task 47298 | init sampler, took 1.53 ms, tokens: text = 7800, total = 7800
slot update_slots: id  2 | task 47298 | erasing old context checkpoint (pos_min = 421, pos_max = 1301, size = 20.659 MiB)
slot update_slots: id  2 | task 47298 | created context checkpoint 8 of 8 (pos_min = 6839, pos_max = 7735, size = 21.034 MiB)
slot print_timing: id  2 | task 47298 | 
prompt eval time =    2913.70 ms /  1904 tokens (    1.53 ms per token,   653.46 tokens per second)
       eval time =    1236.06 ms /    42 tokens (   29.43 ms per token,    33.98 tokens per second)
      total time =    4149.76 ms /  1946 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 47298 | stop processing: n_tokens = 7841, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.792 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 47342 | processing task, is_child = 0
slot update_slots: id  2 | task 47342 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 9862
slot update_slots: id  2 | task 47342 | n_tokens = 7814, memory_seq_rm [7814, end)
slot update_slots: id  2 | task 47342 | prompt processing progress, n_tokens = 9798, batch.n_tokens = 1984, progress = 0.993510
slot update_slots: id  2 | task 47342 | n_tokens = 9798, memory_seq_rm [9798, end)
slot update_slots: id  2 | task 47342 | prompt processing progress, n_tokens = 9862, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 47342 | prompt done, n_tokens = 9862, batch.n_tokens = 64
slot init_sampler: id  2 | task 47342 | init sampler, took 1.37 ms, tokens: text = 9862, total = 9862
slot update_slots: id  2 | task 47342 | erasing old context checkpoint (pos_min = 578, pos_max = 1420, size = 19.768 MiB)
slot update_slots: id  2 | task 47342 | created context checkpoint 8 of 8 (pos_min = 8901, pos_max = 9797, size = 21.034 MiB)
slot print_timing: id  2 | task 47342 | 
prompt eval time =    3140.66 ms /  2048 tokens (    1.53 ms per token,   652.09 tokens per second)
       eval time =    3605.32 ms /   119 tokens (   30.30 ms per token,    33.01 tokens per second)
      total time =    6745.98 ms /  2167 tokens
slot      release: id  2 | task 47342 | stop processing: n_tokens = 9980, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.943 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 47463 | processing task, is_child = 0
slot update_slots: id  2 | task 47463 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 10546
slot update_slots: id  2 | task 47463 | n_tokens = 9950, memory_seq_rm [9950, end)
slot update_slots: id  2 | task 47463 | prompt processing progress, n_tokens = 10482, batch.n_tokens = 532, progress = 0.993931
slot update_slots: id  2 | task 47463 | n_tokens = 10482, memory_seq_rm [10482, end)
slot update_slots: id  2 | task 47463 | prompt processing progress, n_tokens = 10546, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 47463 | prompt done, n_tokens = 10546, batch.n_tokens = 64
slot init_sampler: id  2 | task 47463 | init sampler, took 1.46 ms, tokens: text = 10546, total = 10546
slot update_slots: id  2 | task 47463 | erasing old context checkpoint (pos_min = 814, pos_max = 1651, size = 19.651 MiB)
slot update_slots: id  2 | task 47463 | created context checkpoint 8 of 8 (pos_min = 9585, pos_max = 10481, size = 21.034 MiB)
slot print_timing: id  2 | task 47463 | 
prompt eval time =    1154.32 ms /   596 tokens (    1.94 ms per token,   516.32 tokens per second)
       eval time =    4034.95 ms /   133 tokens (   30.34 ms per token,    32.96 tokens per second)
      total time =    5189.27 ms /   729 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 47463 | stop processing: n_tokens = 10678, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.932 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 47598 | processing task, is_child = 0
slot update_slots: id  2 | task 47598 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 11428
slot update_slots: id  2 | task 47598 | n_tokens = 10652, memory_seq_rm [10652, end)
slot update_slots: id  2 | task 47598 | prompt processing progress, n_tokens = 11364, batch.n_tokens = 712, progress = 0.994400
slot update_slots: id  2 | task 47598 | n_tokens = 11364, memory_seq_rm [11364, end)
slot update_slots: id  2 | task 47598 | prompt processing progress, n_tokens = 11428, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 47598 | prompt done, n_tokens = 11428, batch.n_tokens = 64
slot init_sampler: id  2 | task 47598 | init sampler, took 2.14 ms, tokens: text = 11428, total = 11428
slot update_slots: id  2 | task 47598 | erasing old context checkpoint (pos_min = 2535, pos_max = 3431, size = 21.034 MiB)
slot update_slots: id  2 | task 47598 | created context checkpoint 8 of 8 (pos_min = 10467, pos_max = 11363, size = 21.034 MiB)
slot print_timing: id  2 | task 47598 | 
prompt eval time =    1425.26 ms /   776 tokens (    1.84 ms per token,   544.46 tokens per second)
       eval time =    1768.55 ms /    58 tokens (   30.49 ms per token,    32.80 tokens per second)
      total time =    3193.82 ms /   834 tokens
slot      release: id  2 | task 47598 | stop processing: n_tokens = 11485, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 47658 | processing task, is_child = 0
slot update_slots: id  2 | task 47658 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 11532
slot update_slots: id  2 | task 47658 | n_tokens = 11461, memory_seq_rm [11461, end)
slot update_slots: id  2 | task 47658 | prompt processing progress, n_tokens = 11468, batch.n_tokens = 7, progress = 0.994450
slot update_slots: id  2 | task 47658 | n_tokens = 11468, memory_seq_rm [11468, end)
slot update_slots: id  2 | task 47658 | prompt processing progress, n_tokens = 11532, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 47658 | prompt done, n_tokens = 11532, batch.n_tokens = 64
slot init_sampler: id  2 | task 47658 | init sampler, took 1.94 ms, tokens: text = 11532, total = 11532
slot update_slots: id  2 | task 47658 | erasing old context checkpoint (pos_min = 2667, pos_max = 3555, size = 20.846 MiB)
slot update_slots: id  2 | task 47658 | created context checkpoint 8 of 8 (pos_min = 10588, pos_max = 11467, size = 20.635 MiB)
slot print_timing: id  2 | task 47658 | 
prompt eval time =     310.59 ms /    71 tokens (    4.37 ms per token,   228.59 tokens per second)
       eval time =     963.35 ms /    31 tokens (   31.08 ms per token,    32.18 tokens per second)
      total time =    1273.94 ms /   102 tokens
slot      release: id  2 | task 47658 | stop processing: n_tokens = 11562, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 47691 | processing task, is_child = 0
slot update_slots: id  2 | task 47691 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 11591
slot update_slots: id  2 | task 47691 | n_tokens = 11543, memory_seq_rm [11543, end)
slot update_slots: id  2 | task 47691 | prompt processing progress, n_tokens = 11591, batch.n_tokens = 48, progress = 1.000000
slot update_slots: id  2 | task 47691 | prompt done, n_tokens = 11591, batch.n_tokens = 48
slot init_sampler: id  2 | task 47691 | init sampler, took 1.61 ms, tokens: text = 11591, total = 11591
slot update_slots: id  2 | task 47691 | erasing old context checkpoint (pos_min = 3883, pos_max = 4779, size = 21.034 MiB)
slot update_slots: id  2 | task 47691 | created context checkpoint 8 of 8 (pos_min = 10665, pos_max = 11542, size = 20.588 MiB)
slot print_timing: id  2 | task 47691 | 
prompt eval time =     186.77 ms /    48 tokens (    3.89 ms per token,   257.00 tokens per second)
       eval time =    1209.61 ms /    39 tokens (   31.02 ms per token,    32.24 tokens per second)
      total time =    1396.38 ms /    87 tokens
slot      release: id  2 | task 47691 | stop processing: n_tokens = 11629, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.969 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 47731 | processing task, is_child = 0
slot update_slots: id  2 | task 47731 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 11980
slot update_slots: id  2 | task 47731 | n_tokens = 11606, memory_seq_rm [11606, end)
slot update_slots: id  2 | task 47731 | prompt processing progress, n_tokens = 11916, batch.n_tokens = 310, progress = 0.994658
slot update_slots: id  2 | task 47731 | n_tokens = 11916, memory_seq_rm [11916, end)
slot update_slots: id  2 | task 47731 | prompt processing progress, n_tokens = 11980, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 47731 | prompt done, n_tokens = 11980, batch.n_tokens = 64
slot init_sampler: id  2 | task 47731 | init sampler, took 1.64 ms, tokens: text = 11980, total = 11980
slot update_slots: id  2 | task 47731 | erasing old context checkpoint (pos_min = 4327, pos_max = 5223, size = 21.034 MiB)
slot update_slots: id  2 | task 47731 | created context checkpoint 8 of 8 (pos_min = 11019, pos_max = 11915, size = 21.034 MiB)
slot print_timing: id  2 | task 47731 | 
prompt eval time =     804.43 ms /   374 tokens (    2.15 ms per token,   464.93 tokens per second)
       eval time =    6459.08 ms /   198 tokens (   32.62 ms per token,    30.65 tokens per second)
      total time =    7263.51 ms /   572 tokens
slot      release: id  2 | task 47731 | stop processing: n_tokens = 12177, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 47931 | processing task, is_child = 0
slot update_slots: id  2 | task 47931 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 12261
slot update_slots: id  2 | task 47931 | n_tokens = 12149, memory_seq_rm [12149, end)
slot update_slots: id  2 | task 47931 | prompt processing progress, n_tokens = 12197, batch.n_tokens = 48, progress = 0.994780
slot update_slots: id  2 | task 47931 | n_tokens = 12197, memory_seq_rm [12197, end)
slot update_slots: id  2 | task 47931 | prompt processing progress, n_tokens = 12261, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 47931 | prompt done, n_tokens = 12261, batch.n_tokens = 64
slot init_sampler: id  2 | task 47931 | init sampler, took 2.69 ms, tokens: text = 12261, total = 12261
slot update_slots: id  2 | task 47931 | erasing old context checkpoint (pos_min = 4916, pos_max = 5812, size = 21.034 MiB)
slot update_slots: id  2 | task 47931 | created context checkpoint 8 of 8 (pos_min = 11300, pos_max = 12196, size = 21.034 MiB)
slot print_timing: id  2 | task 47931 | 
prompt eval time =     445.14 ms /   112 tokens (    3.97 ms per token,   251.61 tokens per second)
       eval time =    5550.98 ms /   165 tokens (   33.64 ms per token,    29.72 tokens per second)
      total time =    5996.12 ms /   277 tokens
slot      release: id  2 | task 47931 | stop processing: n_tokens = 12425, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 48098 | processing task, is_child = 0
slot update_slots: id  2 | task 48098 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 12473
slot update_slots: id  2 | task 48098 | n_tokens = 12413, memory_seq_rm [12413, end)
slot update_slots: id  2 | task 48098 | prompt processing progress, n_tokens = 12473, batch.n_tokens = 60, progress = 1.000000
slot update_slots: id  2 | task 48098 | prompt done, n_tokens = 12473, batch.n_tokens = 60
slot init_sampler: id  2 | task 48098 | init sampler, took 4.26 ms, tokens: text = 12473, total = 12473
slot update_slots: id  2 | task 48098 | erasing old context checkpoint (pos_min = 6839, pos_max = 7735, size = 21.034 MiB)
slot update_slots: id  2 | task 48098 | created context checkpoint 8 of 8 (pos_min = 11528, pos_max = 12412, size = 20.753 MiB)
slot print_timing: id  2 | task 48098 | 
prompt eval time =     232.56 ms /    60 tokens (    3.88 ms per token,   257.99 tokens per second)
       eval time =    6277.83 ms /   191 tokens (   32.87 ms per token,    30.42 tokens per second)
      total time =    6510.39 ms /   251 tokens
slot      release: id  2 | task 48098 | stop processing: n_tokens = 12663, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.913 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 48290 | processing task, is_child = 0
slot update_slots: id  2 | task 48290 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 13849
slot update_slots: id  2 | task 48290 | n_tokens = 12638, memory_seq_rm [12638, end)
slot update_slots: id  2 | task 48290 | prompt processing progress, n_tokens = 13785, batch.n_tokens = 1147, progress = 0.995379
slot update_slots: id  2 | task 48290 | n_tokens = 13785, memory_seq_rm [13785, end)
slot update_slots: id  2 | task 48290 | prompt processing progress, n_tokens = 13849, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 48290 | prompt done, n_tokens = 13849, batch.n_tokens = 64
slot init_sampler: id  2 | task 48290 | init sampler, took 1.94 ms, tokens: text = 13849, total = 13849
slot update_slots: id  2 | task 48290 | erasing old context checkpoint (pos_min = 8901, pos_max = 9797, size = 21.034 MiB)
slot update_slots: id  2 | task 48290 | created context checkpoint 8 of 8 (pos_min = 12888, pos_max = 13784, size = 21.034 MiB)
slot print_timing: id  2 | task 48290 | 
prompt eval time =    2338.28 ms /  1211 tokens (    1.93 ms per token,   517.90 tokens per second)
       eval time =   13138.64 ms /   428 tokens (   30.70 ms per token,    32.58 tokens per second)
      total time =   15476.91 ms /  1639 tokens
slot      release: id  2 | task 48290 | stop processing: n_tokens = 14276, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 48720 | processing task, is_child = 0
slot update_slots: id  2 | task 48720 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 14390
slot update_slots: id  2 | task 48720 | n_tokens = 14248, memory_seq_rm [14248, end)
slot update_slots: id  2 | task 48720 | prompt processing progress, n_tokens = 14326, batch.n_tokens = 78, progress = 0.995552
slot update_slots: id  2 | task 48720 | n_tokens = 14326, memory_seq_rm [14326, end)
slot update_slots: id  2 | task 48720 | prompt processing progress, n_tokens = 14390, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 48720 | prompt done, n_tokens = 14390, batch.n_tokens = 64
slot init_sampler: id  2 | task 48720 | init sampler, took 2.04 ms, tokens: text = 14390, total = 14390
slot update_slots: id  2 | task 48720 | erasing old context checkpoint (pos_min = 9585, pos_max = 10481, size = 21.034 MiB)
slot update_slots: id  2 | task 48720 | created context checkpoint 8 of 8 (pos_min = 13429, pos_max = 14325, size = 21.034 MiB)
slot print_timing: id  2 | task 48720 | 
prompt eval time =     507.34 ms /   142 tokens (    3.57 ms per token,   279.89 tokens per second)
       eval time =    7935.39 ms /   262 tokens (   30.29 ms per token,    33.02 tokens per second)
      total time =    8442.73 ms /   404 tokens
slot      release: id  2 | task 48720 | stop processing: n_tokens = 14651, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 48984 | processing task, is_child = 0
slot update_slots: id  2 | task 48984 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 14800
slot update_slots: id  2 | task 48984 | n_tokens = 14627, memory_seq_rm [14627, end)
slot update_slots: id  2 | task 48984 | prompt processing progress, n_tokens = 14736, batch.n_tokens = 109, progress = 0.995676
slot update_slots: id  2 | task 48984 | n_tokens = 14736, memory_seq_rm [14736, end)
slot update_slots: id  2 | task 48984 | prompt processing progress, n_tokens = 14800, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 48984 | prompt done, n_tokens = 14800, batch.n_tokens = 64
slot init_sampler: id  2 | task 48984 | init sampler, took 2.87 ms, tokens: text = 14800, total = 14800
slot update_slots: id  2 | task 48984 | erasing old context checkpoint (pos_min = 10467, pos_max = 11363, size = 21.034 MiB)
slot update_slots: id  2 | task 48984 | created context checkpoint 8 of 8 (pos_min = 13839, pos_max = 14735, size = 21.034 MiB)
slot print_timing: id  2 | task 48984 | 
prompt eval time =     569.39 ms /   173 tokens (    3.29 ms per token,   303.83 tokens per second)
       eval time =   10380.39 ms /   342 tokens (   30.35 ms per token,    32.95 tokens per second)
      total time =   10949.78 ms /   515 tokens
slot      release: id  2 | task 48984 | stop processing: n_tokens = 15141, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 49328 | processing task, is_child = 0
slot update_slots: id  2 | task 49328 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 15187
slot update_slots: id  2 | task 49328 | n_tokens = 15118, memory_seq_rm [15118, end)
slot update_slots: id  2 | task 49328 | prompt processing progress, n_tokens = 15123, batch.n_tokens = 5, progress = 0.995786
slot update_slots: id  2 | task 49328 | n_tokens = 15123, memory_seq_rm [15123, end)
slot update_slots: id  2 | task 49328 | prompt processing progress, n_tokens = 15187, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 49328 | prompt done, n_tokens = 15187, batch.n_tokens = 64
slot init_sampler: id  2 | task 49328 | init sampler, took 2.80 ms, tokens: text = 15187, total = 15187
slot update_slots: id  2 | task 49328 | erasing old context checkpoint (pos_min = 10588, pos_max = 11467, size = 20.635 MiB)
slot update_slots: id  2 | task 49328 | created context checkpoint 8 of 8 (pos_min = 14244, pos_max = 15122, size = 20.612 MiB)
slot print_timing: id  2 | task 49328 | 
prompt eval time =     314.56 ms /    69 tokens (    4.56 ms per token,   219.35 tokens per second)
       eval time =   17755.76 ms /   582 tokens (   30.51 ms per token,    32.78 tokens per second)
      total time =   18070.33 ms /   651 tokens
slot      release: id  2 | task 49328 | stop processing: n_tokens = 15768, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.056
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 15768, total state size = 390.777 MiB
srv          load:  - looking for better prompt, base f_keep = 0.056, sim = 0.988
srv        update:  - cache state: 19 prompts, 8059.594 MiB (limits: 8192.000 MiB, 56064 tokens, 210198 est)
srv        update:    - prompt 0x58dc3f707740:    2882 tokens, checkpoints:  4,   182.270 MiB
srv        update:    - prompt 0x58dc3f7067c0:    9745 tokens, checkpoints:  8,   443.282 MiB
srv        update:    - prompt 0x58dc3873f620:    2763 tokens, checkpoints:  8,   276.302 MiB
srv        update:    - prompt 0x58dc3fb8c770:    5127 tokens, checkpoints:  8,   320.808 MiB
srv        update:    - prompt 0x58dc3f318830:   24865 tokens, checkpoints:  8,   791.874 MiB
srv        update:    - prompt 0x58dc40d3cf50:   16080 tokens, checkpoints:  8,   571.219 MiB
srv        update:    - prompt 0x58dc4c8ce8a0:   23906 tokens, checkpoints:  8,   739.114 MiB
srv        update:    - prompt 0x58dc38d9f350:   18675 tokens, checkpoints:  8,   606.205 MiB
srv        update:    - prompt 0x58dc3f0d1370:    8148 tokens, checkpoints:  8,   317.783 MiB
srv        update:    - prompt 0x58dc4e559330:    1905 tokens, checkpoints:  1,    86.270 MiB
srv        update:    - prompt 0x58dc7370fb50:   15396 tokens, checkpoints:  8,   535.811 MiB
srv        update:    - prompt 0x58dc3f803040:   11161 tokens, checkpoints:  8,   449.472 MiB
srv        update:    - prompt 0x58dc4b0f2100:   15565 tokens, checkpoints:  8,   546.621 MiB
srv        update:    - prompt 0x58dc4b0ed760:    2343 tokens, checkpoints:  8,   234.281 MiB
srv        update:    - prompt 0x58dc3e3ce6c0:    3768 tokens, checkpoints:  6,   225.628 MiB
srv        update:    - prompt 0x58dc40b2ad30:   16698 tokens, checkpoints:  8,   567.045 MiB
srv        update:    - prompt 0x58dc91e19670:   10072 tokens, checkpoints:  8,   424.898 MiB
srv        update:    - prompt 0x58dc3fbbf660:    1934 tokens, checkpoints:  7,   182.811 MiB
srv        update:    - prompt 0x58dc3f93e680:   15768 tokens, checkpoints:  8,   557.900 MiB
srv  get_availabl: prompt cache update took 908.35 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 49912 | processing task, is_child = 0
slot update_slots: id  2 | task 49912 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 892
slot update_slots: id  2 | task 49912 | n_past = 881, slot.prompt.tokens.size() = 15768, seq_id = 2, pos_min = 14871, n_swa = 128
slot update_slots: id  2 | task 49912 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  2 | task 49912 | erased invalidated context checkpoint (pos_min = 10665, pos_max = 11542, n_swa = 128, size = 20.588 MiB)
slot update_slots: id  2 | task 49912 | erased invalidated context checkpoint (pos_min = 11019, pos_max = 11915, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 49912 | erased invalidated context checkpoint (pos_min = 11300, pos_max = 12196, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 49912 | erased invalidated context checkpoint (pos_min = 11528, pos_max = 12412, n_swa = 128, size = 20.753 MiB)
slot update_slots: id  2 | task 49912 | erased invalidated context checkpoint (pos_min = 12888, pos_max = 13784, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 49912 | erased invalidated context checkpoint (pos_min = 13429, pos_max = 14325, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 49912 | erased invalidated context checkpoint (pos_min = 13839, pos_max = 14735, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 49912 | erased invalidated context checkpoint (pos_min = 14244, pos_max = 15122, n_swa = 128, size = 20.612 MiB)
slot update_slots: id  2 | task 49912 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 49912 | prompt processing progress, n_tokens = 828, batch.n_tokens = 828, progress = 0.928251
slot update_slots: id  2 | task 49912 | n_tokens = 828, memory_seq_rm [828, end)
slot update_slots: id  2 | task 49912 | prompt processing progress, n_tokens = 892, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 49912 | prompt done, n_tokens = 892, batch.n_tokens = 64
slot init_sampler: id  2 | task 49912 | init sampler, took 0.13 ms, tokens: text = 892, total = 892
slot update_slots: id  2 | task 49912 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 827, size = 19.416 MiB)
slot print_timing: id  2 | task 49912 | 
prompt eval time =    1595.06 ms /   892 tokens (    1.79 ms per token,   559.23 tokens per second)
       eval time =    1767.12 ms /    57 tokens (   31.00 ms per token,    32.26 tokens per second)
      total time =    3362.18 ms /   949 tokens
slot      release: id  2 | task 49912 | stop processing: n_tokens = 948, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.849 (> 0.100 thold), f_keep = 0.981
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 49971 | processing task, is_child = 0
slot update_slots: id  2 | task 49971 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1095
slot update_slots: id  2 | task 49971 | n_tokens = 930, memory_seq_rm [930, end)
slot update_slots: id  2 | task 49971 | prompt processing progress, n_tokens = 1031, batch.n_tokens = 101, progress = 0.941553
slot update_slots: id  2 | task 49971 | n_tokens = 1031, memory_seq_rm [1031, end)
slot update_slots: id  2 | task 49971 | prompt processing progress, n_tokens = 1095, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 49971 | prompt done, n_tokens = 1095, batch.n_tokens = 64
slot init_sampler: id  2 | task 49971 | init sampler, took 0.20 ms, tokens: text = 1095, total = 1095
slot update_slots: id  2 | task 49971 | created context checkpoint 2 of 8 (pos_min = 134, pos_max = 1030, size = 21.034 MiB)
slot print_timing: id  2 | task 49971 | 
prompt eval time =     542.70 ms /   165 tokens (    3.29 ms per token,   304.04 tokens per second)
       eval time =    3820.57 ms /   118 tokens (   32.38 ms per token,    30.89 tokens per second)
      total time =    4363.27 ms /   283 tokens
slot      release: id  2 | task 49971 | stop processing: n_tokens = 1212, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 1.000 (> 0.100 thold), f_keep = 0.736
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 50091 | processing task, is_child = 0
slot update_slots: id  2 | task 50091 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 892
slot update_slots: id  2 | task 50091 | need to evaluate at least 1 token for each active slot (n_past = 892, task.n_tokens() = 892)
slot update_slots: id  2 | task 50091 | n_past was set to 891
slot update_slots: id  2 | task 50091 | n_tokens = 891, memory_seq_rm [891, end)
slot update_slots: id  2 | task 50091 | prompt processing progress, n_tokens = 892, batch.n_tokens = 1, progress = 1.000000
slot update_slots: id  2 | task 50091 | prompt done, n_tokens = 892, batch.n_tokens = 1
slot init_sampler: id  2 | task 50091 | init sampler, took 0.17 ms, tokens: text = 892, total = 892
slot print_timing: id  2 | task 50091 | 
prompt eval time =      37.30 ms /     1 tokens (   37.30 ms per token,    26.81 tokens per second)
       eval time =    1325.72 ms /    45 tokens (   29.46 ms per token,    33.94 tokens per second)
      total time =    1363.02 ms /    46 tokens
slot      release: id  2 | task 50091 | stop processing: n_tokens = 936, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.848 (> 0.100 thold), f_keep = 0.981
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 50137 | processing task, is_child = 0
slot update_slots: id  2 | task 50137 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1083
slot update_slots: id  2 | task 50137 | n_tokens = 918, memory_seq_rm [918, end)
slot update_slots: id  2 | task 50137 | prompt processing progress, n_tokens = 1019, batch.n_tokens = 101, progress = 0.940905
slot update_slots: id  2 | task 50137 | n_tokens = 1019, memory_seq_rm [1019, end)
slot update_slots: id  2 | task 50137 | prompt processing progress, n_tokens = 1083, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 50137 | prompt done, n_tokens = 1083, batch.n_tokens = 64
slot init_sampler: id  2 | task 50137 | init sampler, took 0.21 ms, tokens: text = 1083, total = 1083
slot print_timing: id  2 | task 50137 | 
prompt eval time =     524.31 ms /   165 tokens (    3.18 ms per token,   314.70 tokens per second)
       eval time =    4184.61 ms /   138 tokens (   30.32 ms per token,    32.98 tokens per second)
      total time =    4708.92 ms /   303 tokens
slot      release: id  2 | task 50137 | stop processing: n_tokens = 1220, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 1.000 (> 0.100 thold), f_keep = 0.731
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 50277 | processing task, is_child = 0
slot update_slots: id  2 | task 50277 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 892
slot update_slots: id  2 | task 50277 | need to evaluate at least 1 token for each active slot (n_past = 892, task.n_tokens() = 892)
slot update_slots: id  2 | task 50277 | n_past was set to 891
slot update_slots: id  2 | task 50277 | n_tokens = 891, memory_seq_rm [891, end)
slot update_slots: id  2 | task 50277 | prompt processing progress, n_tokens = 892, batch.n_tokens = 1, progress = 1.000000
slot update_slots: id  2 | task 50277 | prompt done, n_tokens = 892, batch.n_tokens = 1
slot init_sampler: id  2 | task 50277 | init sampler, took 0.14 ms, tokens: text = 892, total = 892
slot print_timing: id  2 | task 50277 | 
prompt eval time =      36.82 ms /     1 tokens (   36.82 ms per token,    27.16 tokens per second)
       eval time =    1151.81 ms /    41 tokens (   28.09 ms per token,    35.60 tokens per second)
      total time =    1188.62 ms /    42 tokens
slot      release: id  2 | task 50277 | stop processing: n_tokens = 932, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.847 (> 0.100 thold), f_keep = 0.981
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 50319 | processing task, is_child = 0
slot update_slots: id  2 | task 50319 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1079
slot update_slots: id  2 | task 50319 | n_tokens = 914, memory_seq_rm [914, end)
slot update_slots: id  2 | task 50319 | prompt processing progress, n_tokens = 1015, batch.n_tokens = 101, progress = 0.940686
slot update_slots: id  2 | task 50319 | n_tokens = 1015, memory_seq_rm [1015, end)
slot update_slots: id  2 | task 50319 | prompt processing progress, n_tokens = 1079, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 50319 | prompt done, n_tokens = 1079, batch.n_tokens = 64
slot init_sampler: id  2 | task 50319 | init sampler, took 0.16 ms, tokens: text = 1079, total = 1079
slot print_timing: id  2 | task 50319 | 
prompt eval time =     495.73 ms /   165 tokens (    3.00 ms per token,   332.84 tokens per second)
       eval time =    3730.32 ms /   133 tokens (   28.05 ms per token,    35.65 tokens per second)
      total time =    4226.05 ms /   298 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 50319 | stop processing: n_tokens = 1211, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 1.000 (> 0.100 thold), f_keep = 0.737
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 50454 | processing task, is_child = 0
slot update_slots: id  2 | task 50454 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 892
slot update_slots: id  2 | task 50454 | need to evaluate at least 1 token for each active slot (n_past = 892, task.n_tokens() = 892)
slot update_slots: id  2 | task 50454 | n_past was set to 891
slot update_slots: id  2 | task 50454 | n_tokens = 891, memory_seq_rm [891, end)
slot update_slots: id  2 | task 50454 | prompt processing progress, n_tokens = 892, batch.n_tokens = 1, progress = 1.000000
slot update_slots: id  2 | task 50454 | prompt done, n_tokens = 892, batch.n_tokens = 1
slot init_sampler: id  2 | task 50454 | init sampler, took 0.13 ms, tokens: text = 892, total = 892
slot print_timing: id  2 | task 50454 | 
prompt eval time =      36.71 ms /     1 tokens (   36.71 ms per token,    27.24 tokens per second)
       eval time =    1980.13 ms /    72 tokens (   27.50 ms per token,    36.36 tokens per second)
      total time =    2016.84 ms /    73 tokens
slot      release: id  2 | task 50454 | stop processing: n_tokens = 963, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.851 (> 0.100 thold), f_keep = 0.981
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 50527 | processing task, is_child = 0
slot update_slots: id  2 | task 50527 | new prompt, n_ctx_slot = 56064, n_keep = 0, task.n_tokens = 1110
slot update_slots: id  2 | task 50527 | n_tokens = 945, memory_seq_rm [945, end)
slot update_slots: id  2 | task 50527 | prompt processing progress, n_tokens = 1046, batch.n_tokens = 101, progress = 0.942342
slot update_slots: id  2 | task 50527 | n_tokens = 1046, memory_seq_rm [1046, end)
slot update_slots: id  2 | task 50527 | prompt processing progress, n_tokens = 1110, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 50527 | prompt done, n_tokens = 1110, batch.n_tokens = 64
slot init_sampler: id  2 | task 50527 | init sampler, took 0.18 ms, tokens: text = 1110, total = 1110
slot print_timing: id  2 | task 50527 | 
prompt eval time =     485.64 ms /   165 tokens (    2.94 ms per token,   339.76 tokens per second)
       eval time =    3171.14 ms /   118 tokens (   26.87 ms per token,    37.21 tokens per second)
      total time =    3656.78 ms /   283 tokens
slot      release: id  2 | task 50527 | stop processing: n_tokens = 1227, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
