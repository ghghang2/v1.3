ggml_cuda_init: found 1 CUDA devices:
  Device 0: Tesla T4, compute capability 7.5, VMM: yes
common_download_file_single_online: no previous model file found /root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_preset.ini
common_download_file_single_online: HEAD invalid http status code received: 404
no remote preset found, skipping
common_download_file_single_online: no previous model file found /root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-F16.gguf
common_download_file_single_online: trying to download model from https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-F16.gguf to /root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-F16.gguf.downloadInProgress (etag:"78f73a4ef91c8f92d4df971f570ff3719007201f6d955b8695384a1b21b04a80")...
main: n_parallel is set to auto, using n_parallel = 4 and kv_unified = true
build: 7772 (287a33017) with GNU 11.4.0 for Linux x86_64
system info: n_threads = 1, n_threads_batch = 1, total_threads = 2

system_info: n_threads = 1 (n_threads_batch = 1) / 2 | CUDA : ARCHS = 750 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | 

Running without SSL
init: using 6 threads for HTTP server
start: binding port with default address family
main: loading model
srv    load_model: loading model '/root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-F16.gguf'
common_init_result: fitting params to device memory, for bugs during this step try to reproduce them with -fit off, or provide --verbose logs if the bug only occurs with -fit on
srv  log_server_r: request: GET /health 127.0.0.1 503
llama_params_fit_impl: projected to use 15546 MiB of device memory vs. 14992 MiB of free device memory
llama_params_fit_impl: cannot meet free memory target of 1024 MiB, need to reduce device memory by 1578 MiB
srv  log_server_r: request: GET /health 127.0.0.1 503
llama_params_fit_impl: context size reduced from 131072 to 64000 -> need 1580 MiB less memory in total
llama_params_fit_impl: entire model can be fit by reducing context
llama_params_fit: successfully fit params to free device memory
llama_params_fit: fitting params to free memory took 1.67 seconds
llama_model_load_from_file_impl: using device CUDA0 (Tesla T4) (0000:00:04.0) - 14992 MiB free
llama_model_loader: direct I/O is enabled, disabling mmap
llama_model_loader: loaded meta data with 37 key-value pairs and 459 tensors from /root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-F16.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = gpt-oss
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Gpt-Oss-20B
llama_model_loader: - kv   3:                           general.basename str              = Gpt-Oss-20B
llama_model_loader: - kv   4:                       general.quantized_by str              = Unsloth
llama_model_loader: - kv   5:                         general.size_label str              = 20B
llama_model_loader: - kv   6:                            general.license str              = apache-2.0
llama_model_loader: - kv   7:                           general.repo_url str              = https://huggingface.co/unsloth
llama_model_loader: - kv   8:                               general.tags arr[str,2]       = ["vllm", "text-generation"]
llama_model_loader: - kv   9:                        gpt-oss.block_count u32              = 24
llama_model_loader: - kv  10:                     gpt-oss.context_length u32              = 131072
llama_model_loader: - kv  11:                   gpt-oss.embedding_length u32              = 2880
llama_model_loader: - kv  12:                gpt-oss.feed_forward_length u32              = 2880
llama_model_loader: - kv  13:               gpt-oss.attention.head_count u32              = 64
llama_model_loader: - kv  14:            gpt-oss.attention.head_count_kv u32              = 8
llama_model_loader: - kv  15:                     gpt-oss.rope.freq_base f32              = 150000.000000
llama_model_loader: - kv  16:   gpt-oss.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  17:                       gpt-oss.expert_count u32              = 32
llama_model_loader: - kv  18:                  gpt-oss.expert_used_count u32              = 4
llama_model_loader: - kv  19:               gpt-oss.attention.key_length u32              = 64
llama_model_loader: - kv  20:             gpt-oss.attention.value_length u32              = 64
llama_model_loader: - kv  21:                          general.file_type u32              = 1
llama_model_loader: - kv  22:           gpt-oss.attention.sliding_window u32              = 128
llama_model_loader: - kv  23:         gpt-oss.expert_feed_forward_length u32              = 2880
llama_model_loader: - kv  24:                  gpt-oss.rope.scaling.type str              = yarn
llama_model_loader: - kv  25:                gpt-oss.rope.scaling.factor f32              = 32.000000
llama_model_loader: - kv  26: gpt-oss.rope.scaling.original_context_length u32              = 4096
llama_model_loader: - kv  27:               general.quantization_version u32              = 2
llama_model_loader: - kv  28:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  29:                         tokenizer.ggml.pre str              = gpt-4o
llama_model_loader: - kv  30:                      tokenizer.ggml.tokens arr[str,201088]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  31:                  tokenizer.ggml.token_type arr[i32,201088]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  32:                      tokenizer.ggml.merges arr[str,446189]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  33:                tokenizer.ggml.bos_token_id u32              = 199998
llama_model_loader: - kv  34:                tokenizer.ggml.eos_token_id u32              = 200002
llama_model_loader: - kv  35:            tokenizer.ggml.padding_token_id u32              = 200017
llama_model_loader: - kv  36:                    tokenizer.chat_template str              = {# Chat template fixes by Unsloth #}\n...
llama_model_loader: - type  f32:  289 tensors
llama_model_loader: - type  f16:   98 tensors
llama_model_loader: - type mxfp4:   72 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = F16
print_info: file size   = 12.83 GiB (5.27 BPW) 
load: 0 unused tokens
load: setting token '<|message|>' (200008) attribute to USER_DEFINED (16), old attributes: 8
load: setting token '<|start|>' (200006) attribute to USER_DEFINED (16), old attributes: 8
load: setting token '<|constrain|>' (200003) attribute to USER_DEFINED (16), old attributes: 8
load: setting token '<|channel|>' (200005) attribute to USER_DEFINED (16), old attributes: 8
load: printing all EOG tokens:
load:   - 199999 ('<|endoftext|>')
load:   - 200002 ('<|return|>')
load:   - 200007 ('<|end|>')
load:   - 200012 ('<|call|>')
load: special_eog_ids contains both '<|return|>' and '<|call|>', or '<|calls|>' and '<|flush|>' tokens, removing '<|end|>' token from EOG list
load: special tokens cache size = 21
load: token to piece cache size = 1.3332 MB
print_info: arch                  = gpt-oss
print_info: vocab_only            = 0
print_info: no_alloc              = 0
print_info: n_ctx_train           = 131072
print_info: n_embd                = 2880
print_info: n_embd_inp            = 2880
print_info: n_layer               = 24
print_info: n_head                = 64
print_info: n_head_kv             = 8
print_info: n_rot                 = 64
print_info: n_swa                 = 128
print_info: is_swa_any            = 1
print_info: n_embd_head_k         = 64
print_info: n_embd_head_v         = 64
print_info: n_gqa                 = 8
print_info: n_embd_k_gqa          = 512
print_info: n_embd_v_gqa          = 512
print_info: f_norm_eps            = 0.0e+00
print_info: f_norm_rms_eps        = 1.0e-05
print_info: f_clamp_kqv           = 0.0e+00
print_info: f_max_alibi_bias      = 0.0e+00
print_info: f_logit_scale         = 0.0e+00
print_info: f_attn_scale          = 0.0e+00
print_info: n_ff                  = 2880
print_info: n_expert              = 32
print_info: n_expert_used         = 4
print_info: n_expert_groups       = 0
print_info: n_group_used          = 0
print_info: causal attn           = 1
print_info: pooling type          = 0
print_info: rope type             = 2
print_info: rope scaling          = yarn
print_info: freq_base_train       = 150000.0
print_info: freq_scale_train      = 0.03125
print_info: freq_base_swa         = 150000.0
print_info: freq_scale_swa        = 0.03125
print_info: n_ctx_orig_yarn       = 4096
print_info: rope_yarn_log_mul     = 0.0000
print_info: rope_finetuned        = unknown
print_info: model type            = 20B
print_info: model params          = 20.91 B
print_info: general.name          = Gpt-Oss-20B
print_info: n_ff_exp              = 2880
print_info: vocab type            = BPE
print_info: n_vocab               = 201088
print_info: n_merges              = 446189
print_info: BOS token             = 199998 '<|startoftext|>'
print_info: EOS token             = 200002 '<|return|>'
print_info: EOT token             = 199999 '<|endoftext|>'
print_info: PAD token             = 200017 '<|reserved_200017|>'
print_info: LF token              = 198 'Ċ'
print_info: EOG token             = 199999 '<|endoftext|>'
print_info: EOG token             = 200002 '<|return|>'
print_info: EOG token             = 200012 '<|call|>'
print_info: max token length      = 256
load_tensors: loading model tensors, this can take a while... (mmap = false, direct_io = true)
srv  log_server_r: request: GET /health 127.0.0.1 503
load_tensors: offloading output layer to GPU
load_tensors: offloading 23 repeating layers to GPU
load_tensors: offloaded 25/25 layers to GPU
load_tensors:        CUDA0 model buffer size = 12036.68 MiB
load_tensors:    CUDA_Host model buffer size =  1104.61 MiB
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
srv  log_server_r: request: GET /health 127.0.0.1 503
srv  log_server_r: request: GET /health 127.0.0.1 503
srv  log_server_r: request: GET /health 127.0.0.1 503
.
common_init_result: added <|endoftext|> logit bias = -inf
common_init_result: added <|return|> logit bias = -inf
common_init_result: added <|call|> logit bias = -inf
llama_context: constructing llama_context
llama_context: n_seq_max     = 4
llama_context: n_ctx         = 64000
llama_context: n_ctx_seq     = 64000
llama_context: n_batch       = 2048
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = auto
llama_context: kv_unified    = true
llama_context: freq_base     = 150000.0
llama_context: freq_scale    = 0.03125
llama_context: n_ctx_seq (64000) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_context:  CUDA_Host  output buffer size =     3.07 MiB
llama_kv_cache_iswa: creating non-SWA KV cache, size = 64000 cells
llama_kv_cache:      CUDA0 KV buffer size =  1500.00 MiB
llama_kv_cache: size = 1500.00 MiB ( 64000 cells,  12 layers,  4/1 seqs), K (f16):  750.00 MiB, V (f16):  750.00 MiB
llama_kv_cache_iswa: creating     SWA KV cache, size = 1024 cells
llama_kv_cache:      CUDA0 KV buffer size =    24.00 MiB
llama_kv_cache: size =   24.00 MiB (  1024 cells,  12 layers,  4/1 seqs), K (f16):   12.00 MiB, V (f16):   12.00 MiB
sched_reserve: reserving ...
sched_reserve: Flash Attention was auto, set to enabled
sched_reserve:      CUDA0 compute buffer size =   398.38 MiB
sched_reserve:  CUDA_Host compute buffer size =   132.65 MiB
sched_reserve: graph nodes  = 1352
sched_reserve: graph splits = 2
sched_reserve: reserve took 61.66 ms, sched copies = 1
common_init_from_params: warming up the model with an empty run - please wait ... (--no-warmup to disable)
srv  log_server_r: request: GET /health 127.0.0.1 503
srv    load_model: initializing slots, n_slots = 4
slot   load_model: id  0 | task -1 | new slot, n_ctx = 64000
slot   load_model: id  1 | task -1 | new slot, n_ctx = 64000
slot   load_model: id  2 | task -1 | new slot, n_ctx = 64000
slot   load_model: id  3 | task -1 | new slot, n_ctx = 64000
srv    load_model: prompt cache is enabled, size limit: 8192 MiB
srv    load_model: use `--cache-ram 0` to disable the prompt cache
srv    load_model: for more info see https://github.com/ggml-org/llama.cpp/pull/16391
srv    load_model: thinking = 0
load_model: chat template, example_format: '<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2026-02-10

Reasoning: medium

# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions

You are a helpful assistant<|end|><|start|>user<|message|>Hello<|end|><|start|>assistant<|channel|>final<|message|>Hi there<|end|><|start|>user<|message|>How are you?<|end|><|start|>assistant'
main: model loaded
main: server is listening on http://127.0.0.1:8000
main: starting the main loop...
srv  update_slots: all slots are idle
srv  log_server_r: request: GET /health 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LRU, t_last = -1
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 0 | processing task, is_child = 0
slot update_slots: id  3 | task 0 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 575
slot update_slots: id  3 | task 0 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  3 | task 0 | prompt processing progress, n_tokens = 511, batch.n_tokens = 511, progress = 0.888696
slot update_slots: id  3 | task 0 | n_tokens = 511, memory_seq_rm [511, end)
slot update_slots: id  3 | task 0 | prompt processing progress, n_tokens = 575, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 0 | prompt done, n_tokens = 575, batch.n_tokens = 64
slot init_sampler: id  3 | task 0 | init sampler, took 0.15 ms, tokens: text = 575, total = 575
slot update_slots: id  3 | task 0 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 510, size = 11.983 MiB)
slot print_timing: id  3 | task 0 | 
prompt eval time =     871.95 ms /   575 tokens (    1.52 ms per token,   659.44 tokens per second)
       eval time =     667.97 ms /    30 tokens (   22.27 ms per token,    44.91 tokens per second)
      total time =    1539.92 ms /   605 tokens
slot      release: id  3 | task 0 | stop processing: n_tokens = 604, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.890 (> 0.100 thold), f_keep = 0.952
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 32 | processing task, is_child = 0
slot update_slots: id  3 | task 32 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 646
slot update_slots: id  3 | task 32 | n_tokens = 575, memory_seq_rm [575, end)
slot update_slots: id  3 | task 32 | prompt processing progress, n_tokens = 582, batch.n_tokens = 7, progress = 0.900929
slot update_slots: id  3 | task 32 | n_tokens = 582, memory_seq_rm [582, end)
slot update_slots: id  3 | task 32 | prompt processing progress, n_tokens = 646, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 32 | prompt done, n_tokens = 646, batch.n_tokens = 64
slot init_sampler: id  3 | task 32 | init sampler, took 0.12 ms, tokens: text = 646, total = 646
slot update_slots: id  3 | task 32 | created context checkpoint 2 of 8 (pos_min = 0, pos_max = 581, size = 13.648 MiB)
slot print_timing: id  3 | task 32 | 
prompt eval time =     287.56 ms /    71 tokens (    4.05 ms per token,   246.90 tokens per second)
       eval time =    1613.65 ms /    74 tokens (   21.81 ms per token,    45.86 tokens per second)
      total time =    1901.21 ms /   145 tokens
slot      release: id  3 | task 32 | stop processing: n_tokens = 719, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.891 (> 0.100 thold), f_keep = 0.787
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 108 | processing task, is_child = 0
slot update_slots: id  3 | task 108 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 635
slot update_slots: id  3 | task 108 | n_tokens = 566, memory_seq_rm [566, end)
slot update_slots: id  3 | task 108 | prompt processing progress, n_tokens = 571, batch.n_tokens = 5, progress = 0.899213
slot update_slots: id  3 | task 108 | n_tokens = 571, memory_seq_rm [571, end)
slot update_slots: id  3 | task 108 | prompt processing progress, n_tokens = 635, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 108 | prompt done, n_tokens = 635, batch.n_tokens = 64
slot init_sampler: id  3 | task 108 | init sampler, took 0.11 ms, tokens: text = 635, total = 635
slot print_timing: id  3 | task 108 | 
prompt eval time =     267.58 ms /    69 tokens (    3.88 ms per token,   257.86 tokens per second)
       eval time =     733.22 ms /    35 tokens (   20.95 ms per token,    47.73 tokens per second)
      total time =    1000.80 ms /   104 tokens
slot      release: id  3 | task 108 | stop processing: n_tokens = 669, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.906 (> 0.100 thold), f_keep = 0.949
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 145 | processing task, is_child = 0
slot update_slots: id  3 | task 145 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 701
slot update_slots: id  3 | task 145 | n_tokens = 635, memory_seq_rm [635, end)
slot update_slots: id  3 | task 145 | prompt processing progress, n_tokens = 637, batch.n_tokens = 2, progress = 0.908702
slot update_slots: id  3 | task 145 | n_tokens = 637, memory_seq_rm [637, end)
slot update_slots: id  3 | task 145 | prompt processing progress, n_tokens = 701, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 145 | prompt done, n_tokens = 701, batch.n_tokens = 64
slot init_sampler: id  3 | task 145 | init sampler, took 0.13 ms, tokens: text = 701, total = 701
slot print_timing: id  3 | task 145 | 
prompt eval time =     250.96 ms /    66 tokens (    3.80 ms per token,   262.99 tokens per second)
       eval time =     266.90 ms /    13 tokens (   20.53 ms per token,    48.71 tokens per second)
      total time =     517.86 ms /    79 tokens
slot      release: id  3 | task 145 | stop processing: n_tokens = 713, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.887 (> 0.100 thold), f_keep = 0.879
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 160 | processing task, is_child = 0
slot update_slots: id  3 | task 160 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 707
slot update_slots: id  3 | task 160 | n_tokens = 627, memory_seq_rm [627, end)
slot update_slots: id  3 | task 160 | prompt processing progress, n_tokens = 643, batch.n_tokens = 16, progress = 0.909477
slot update_slots: id  3 | task 160 | n_tokens = 643, memory_seq_rm [643, end)
slot update_slots: id  3 | task 160 | prompt processing progress, n_tokens = 707, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 160 | prompt done, n_tokens = 707, batch.n_tokens = 64
slot init_sampler: id  3 | task 160 | init sampler, took 0.13 ms, tokens: text = 707, total = 707
slot print_timing: id  3 | task 160 | 
prompt eval time =     320.34 ms /    80 tokens (    4.00 ms per token,   249.73 tokens per second)
       eval time =     672.25 ms /    32 tokens (   21.01 ms per token,    47.60 tokens per second)
      total time =     992.59 ms /   112 tokens
slot      release: id  3 | task 160 | stop processing: n_tokens = 738, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.530 (> 0.100 thold), f_keep = 0.958
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 194 | processing task, is_child = 0
slot update_slots: id  3 | task 194 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1333
slot update_slots: id  3 | task 194 | n_tokens = 707, memory_seq_rm [707, end)
slot update_slots: id  3 | task 194 | prompt processing progress, n_tokens = 1269, batch.n_tokens = 562, progress = 0.951988
slot update_slots: id  3 | task 194 | n_tokens = 1269, memory_seq_rm [1269, end)
slot update_slots: id  3 | task 194 | prompt processing progress, n_tokens = 1333, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 194 | prompt done, n_tokens = 1333, batch.n_tokens = 64
slot init_sampler: id  3 | task 194 | init sampler, took 0.25 ms, tokens: text = 1333, total = 1333
slot update_slots: id  3 | task 194 | created context checkpoint 3 of 8 (pos_min = 245, pos_max = 1268, size = 24.012 MiB)
slot print_timing: id  3 | task 194 | 
prompt eval time =     711.03 ms /   626 tokens (    1.14 ms per token,   880.42 tokens per second)
       eval time =     943.75 ms /    42 tokens (   22.47 ms per token,    44.50 tokens per second)
      total time =    1654.78 ms /   668 tokens
slot      release: id  3 | task 194 | stop processing: n_tokens = 1374, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.410 (> 0.100 thold), f_keep = 0.970
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 238 | processing task, is_child = 0
slot update_slots: id  3 | task 238 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3255
slot update_slots: id  3 | task 238 | n_tokens = 1333, memory_seq_rm [1333, end)
slot update_slots: id  3 | task 238 | prompt processing progress, n_tokens = 3191, batch.n_tokens = 1858, progress = 0.980338
slot update_slots: id  3 | task 238 | n_tokens = 3191, memory_seq_rm [3191, end)
slot update_slots: id  3 | task 238 | prompt processing progress, n_tokens = 3255, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 238 | prompt done, n_tokens = 3255, batch.n_tokens = 64
slot init_sampler: id  3 | task 238 | init sampler, took 0.64 ms, tokens: text = 3255, total = 3255
slot update_slots: id  3 | task 238 | created context checkpoint 4 of 8 (pos_min = 2167, pos_max = 3190, size = 24.012 MiB)
slot print_timing: id  3 | task 238 | 
prompt eval time =    1860.62 ms /  1922 tokens (    0.97 ms per token,  1032.99 tokens per second)
       eval time =     705.56 ms /    30 tokens (   23.52 ms per token,    42.52 tokens per second)
      total time =    2566.18 ms /  1952 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 238 | stop processing: n_tokens = 3284, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.747 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 270 | processing task, is_child = 0
slot update_slots: id  3 | task 270 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4360
slot update_slots: id  3 | task 270 | n_tokens = 3255, memory_seq_rm [3255, end)
slot update_slots: id  3 | task 270 | prompt processing progress, n_tokens = 4296, batch.n_tokens = 1041, progress = 0.985321
slot update_slots: id  3 | task 270 | n_tokens = 4296, memory_seq_rm [4296, end)
slot update_slots: id  3 | task 270 | prompt processing progress, n_tokens = 4360, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 270 | prompt done, n_tokens = 4360, batch.n_tokens = 64
slot init_sampler: id  3 | task 270 | init sampler, took 0.69 ms, tokens: text = 4360, total = 4360
slot update_slots: id  3 | task 270 | created context checkpoint 5 of 8 (pos_min = 3272, pos_max = 4295, size = 24.012 MiB)
slot print_timing: id  3 | task 270 | 
prompt eval time =    1171.36 ms /  1105 tokens (    1.06 ms per token,   943.35 tokens per second)
       eval time =   11721.16 ms /   514 tokens (   22.80 ms per token,    43.85 tokens per second)
      total time =   12892.52 ms /  1619 tokens
slot      release: id  3 | task 270 | stop processing: n_tokens = 4873, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.602 (> 0.100 thold), f_keep = 0.137
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 4873, total state size = 138.279 MiB
srv          load:  - looking for better prompt, base f_keep = 0.137, sim = 0.602
srv        update:  - cache state: 1 prompts, 235.945 MiB (limits: 8192.000 MiB, 64000 tokens, 169190 est)
srv        update:    - prompt 0x5a234b577500:    4873 tokens, checkpoints:  5,   235.945 MiB
srv  get_availabl: prompt cache update took 182.77 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 786 | processing task, is_child = 0
slot update_slots: id  3 | task 786 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1109
slot update_slots: id  3 | task 786 | n_past = 668, slot.prompt.tokens.size() = 4873, seq_id = 3, pos_min = 3849, n_swa = 128
slot update_slots: id  3 | task 786 | restored context checkpoint (pos_min = 245, pos_max = 1268, size = 24.012 MiB)
slot update_slots: id  3 | task 786 | erased invalidated context checkpoint (pos_min = 2167, pos_max = 3190, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 786 | erased invalidated context checkpoint (pos_min = 3272, pos_max = 4295, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 786 | n_tokens = 668, memory_seq_rm [668, end)
slot update_slots: id  3 | task 786 | prompt processing progress, n_tokens = 1045, batch.n_tokens = 377, progress = 0.942290
slot update_slots: id  3 | task 786 | n_tokens = 1045, memory_seq_rm [1045, end)
slot update_slots: id  3 | task 786 | prompt processing progress, n_tokens = 1109, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 786 | prompt done, n_tokens = 1109, batch.n_tokens = 64
slot init_sampler: id  3 | task 786 | init sampler, took 0.24 ms, tokens: text = 1109, total = 1109
slot print_timing: id  3 | task 786 | 
prompt eval time =     638.54 ms /   441 tokens (    1.45 ms per token,   690.64 tokens per second)
       eval time =    1345.47 ms /    60 tokens (   22.42 ms per token,    44.59 tokens per second)
      total time =    1984.01 ms /   501 tokens
slot      release: id  3 | task 786 | stop processing: n_tokens = 1168, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.774 (> 0.100 thold), f_keep = 0.949
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 848 | processing task, is_child = 0
slot update_slots: id  3 | task 848 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1433
slot update_slots: id  3 | task 848 | n_tokens = 1109, memory_seq_rm [1109, end)
slot update_slots: id  3 | task 848 | prompt processing progress, n_tokens = 1369, batch.n_tokens = 260, progress = 0.955338
slot update_slots: id  3 | task 848 | n_tokens = 1369, memory_seq_rm [1369, end)
slot update_slots: id  3 | task 848 | prompt processing progress, n_tokens = 1433, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 848 | prompt done, n_tokens = 1433, batch.n_tokens = 64
slot init_sampler: id  3 | task 848 | init sampler, took 0.28 ms, tokens: text = 1433, total = 1433
slot update_slots: id  3 | task 848 | created context checkpoint 4 of 8 (pos_min = 668, pos_max = 1368, size = 16.438 MiB)
slot print_timing: id  3 | task 848 | 
prompt eval time =     430.48 ms /   324 tokens (    1.33 ms per token,   752.64 tokens per second)
       eval time =    1530.81 ms /    69 tokens (   22.19 ms per token,    45.07 tokens per second)
      total time =    1961.29 ms /   393 tokens
slot      release: id  3 | task 848 | stop processing: n_tokens = 1501, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.427 (> 0.100 thold), f_keep = 0.955
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 919 | processing task, is_child = 0
slot update_slots: id  3 | task 919 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3355
slot update_slots: id  3 | task 919 | n_tokens = 1433, memory_seq_rm [1433, end)
slot update_slots: id  3 | task 919 | prompt processing progress, n_tokens = 3291, batch.n_tokens = 1858, progress = 0.980924
slot update_slots: id  3 | task 919 | n_tokens = 3291, memory_seq_rm [3291, end)
slot update_slots: id  3 | task 919 | prompt processing progress, n_tokens = 3355, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 919 | prompt done, n_tokens = 3355, batch.n_tokens = 64
slot init_sampler: id  3 | task 919 | init sampler, took 0.65 ms, tokens: text = 3355, total = 3355
slot update_slots: id  3 | task 919 | created context checkpoint 5 of 8 (pos_min = 2267, pos_max = 3290, size = 24.012 MiB)
slot print_timing: id  3 | task 919 | 
prompt eval time =    1896.07 ms /  1922 tokens (    0.99 ms per token,  1013.67 tokens per second)
       eval time =    1192.71 ms /    52 tokens (   22.94 ms per token,    43.60 tokens per second)
      total time =    3088.79 ms /  1974 tokens
slot      release: id  3 | task 919 | stop processing: n_tokens = 3406, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.752 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 973 | processing task, is_child = 0
slot update_slots: id  3 | task 973 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4460
slot update_slots: id  3 | task 973 | n_tokens = 3355, memory_seq_rm [3355, end)
slot update_slots: id  3 | task 973 | prompt processing progress, n_tokens = 4396, batch.n_tokens = 1041, progress = 0.985650
slot update_slots: id  3 | task 973 | n_tokens = 4396, memory_seq_rm [4396, end)
slot update_slots: id  3 | task 973 | prompt processing progress, n_tokens = 4460, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 973 | prompt done, n_tokens = 4460, batch.n_tokens = 64
slot init_sampler: id  3 | task 973 | init sampler, took 0.69 ms, tokens: text = 4460, total = 4460
slot update_slots: id  3 | task 973 | created context checkpoint 6 of 8 (pos_min = 3372, pos_max = 4395, size = 24.012 MiB)
slot print_timing: id  3 | task 973 | 
prompt eval time =    1188.24 ms /  1105 tokens (    1.08 ms per token,   929.95 tokens per second)
       eval time =   12717.61 ms /   545 tokens (   23.34 ms per token,    42.85 tokens per second)
      total time =   13905.85 ms /  1650 tokens
slot      release: id  3 | task 973 | stop processing: n_tokens = 5004, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.953 (> 0.100 thold), f_keep = 0.891
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1520 | processing task, is_child = 0
slot update_slots: id  3 | task 1520 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4680
slot update_slots: id  3 | task 1520 | n_tokens = 4460, memory_seq_rm [4460, end)
slot update_slots: id  3 | task 1520 | prompt processing progress, n_tokens = 4616, batch.n_tokens = 156, progress = 0.986325
slot update_slots: id  3 | task 1520 | n_tokens = 4616, memory_seq_rm [4616, end)
slot update_slots: id  3 | task 1520 | prompt processing progress, n_tokens = 4680, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 1520 | prompt done, n_tokens = 4680, batch.n_tokens = 64
slot init_sampler: id  3 | task 1520 | init sampler, took 0.89 ms, tokens: text = 4680, total = 4680
slot update_slots: id  3 | task 1520 | created context checkpoint 7 of 8 (pos_min = 3980, pos_max = 4615, size = 14.914 MiB)
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv          stop: cancel task, id_task = 1520
slot      release: id  3 | task 1520 | stop processing: n_tokens = 4947, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.748 (> 0.100 thold), f_keep = 0.212
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 4947, total state size = 132.886 MiB
srv          load:  - looking for better prompt, base f_keep = 0.212, sim = 0.748
srv        update:  - cache state: 2 prompts, 497.849 MiB (limits: 8192.000 MiB, 64000 tokens, 161585 est)
srv        update:    - prompt 0x5a234b577500:    4873 tokens, checkpoints:  5,   235.945 MiB
srv        update:    - prompt 0x5a234d243b70:    4947 tokens, checkpoints:  7,   261.904 MiB
srv  get_availabl: prompt cache update took 178.21 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1791 | processing task, is_child = 0
slot update_slots: id  3 | task 1791 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1404
slot update_slots: id  3 | task 1791 | n_past = 1050, slot.prompt.tokens.size() = 4947, seq_id = 3, pos_min = 4227, n_swa = 128
slot update_slots: id  3 | task 1791 | restored context checkpoint (pos_min = 668, pos_max = 1368, size = 16.438 MiB)
slot update_slots: id  3 | task 1791 | erased invalidated context checkpoint (pos_min = 2267, pos_max = 3290, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 1791 | erased invalidated context checkpoint (pos_min = 3372, pos_max = 4395, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 1791 | erased invalidated context checkpoint (pos_min = 3980, pos_max = 4615, n_swa = 128, size = 14.914 MiB)
slot update_slots: id  3 | task 1791 | n_tokens = 1050, memory_seq_rm [1050, end)
slot update_slots: id  3 | task 1791 | prompt processing progress, n_tokens = 1340, batch.n_tokens = 290, progress = 0.954416
slot update_slots: id  3 | task 1791 | n_tokens = 1340, memory_seq_rm [1340, end)
slot update_slots: id  3 | task 1791 | prompt processing progress, n_tokens = 1404, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 1791 | prompt done, n_tokens = 1404, batch.n_tokens = 64
slot init_sampler: id  3 | task 1791 | init sampler, took 0.24 ms, tokens: text = 1404, total = 1404
slot print_timing: id  3 | task 1791 | 
prompt eval time =     587.43 ms /   354 tokens (    1.66 ms per token,   602.62 tokens per second)
       eval time =    1067.12 ms /    46 tokens (   23.20 ms per token,    43.11 tokens per second)
      total time =    1654.55 ms /   400 tokens
slot      release: id  3 | task 1791 | stop processing: n_tokens = 1449, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.692 (> 0.100 thold), f_keep = 0.969
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1839 | processing task, is_child = 0
slot update_slots: id  3 | task 1839 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2030
slot update_slots: id  3 | task 1839 | n_tokens = 1404, memory_seq_rm [1404, end)
slot update_slots: id  3 | task 1839 | prompt processing progress, n_tokens = 1966, batch.n_tokens = 562, progress = 0.968473
slot update_slots: id  3 | task 1839 | n_tokens = 1966, memory_seq_rm [1966, end)
slot update_slots: id  3 | task 1839 | prompt processing progress, n_tokens = 2030, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 1839 | prompt done, n_tokens = 2030, batch.n_tokens = 64
slot init_sampler: id  3 | task 1839 | init sampler, took 0.34 ms, tokens: text = 2030, total = 2030
slot update_slots: id  3 | task 1839 | created context checkpoint 5 of 8 (pos_min = 942, pos_max = 1965, size = 24.012 MiB)
slot print_timing: id  3 | task 1839 | 
prompt eval time =     754.08 ms /   626 tokens (    1.20 ms per token,   830.15 tokens per second)
       eval time =     777.46 ms /    33 tokens (   23.56 ms per token,    42.45 tokens per second)
      total time =    1531.53 ms /   659 tokens
slot      release: id  3 | task 1839 | stop processing: n_tokens = 2062, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.969 (> 0.100 thold), f_keep = 0.984
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1874 | processing task, is_child = 0
slot update_slots: id  3 | task 1874 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2096
slot update_slots: id  3 | task 1874 | n_tokens = 2030, memory_seq_rm [2030, end)
slot update_slots: id  3 | task 1874 | prompt processing progress, n_tokens = 2032, batch.n_tokens = 2, progress = 0.969466
slot update_slots: id  3 | task 1874 | n_tokens = 2032, memory_seq_rm [2032, end)
slot update_slots: id  3 | task 1874 | prompt processing progress, n_tokens = 2096, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 1874 | prompt done, n_tokens = 2096, batch.n_tokens = 64
slot init_sampler: id  3 | task 1874 | init sampler, took 0.33 ms, tokens: text = 2096, total = 2096
slot update_slots: id  3 | task 1874 | created context checkpoint 6 of 8 (pos_min = 1038, pos_max = 2031, size = 23.309 MiB)
slot print_timing: id  3 | task 1874 | 
prompt eval time =     277.91 ms /    66 tokens (    4.21 ms per token,   237.49 tokens per second)
       eval time =    2642.16 ms /   113 tokens (   23.38 ms per token,    42.77 tokens per second)
      total time =    2920.07 ms /   179 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 1874 | stop processing: n_tokens = 2208, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.866 (> 0.100 thold), f_keep = 0.949
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1989 | processing task, is_child = 0
slot update_slots: id  3 | task 1989 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2420
slot update_slots: id  3 | task 1989 | n_tokens = 2096, memory_seq_rm [2096, end)
slot update_slots: id  3 | task 1989 | prompt processing progress, n_tokens = 2356, batch.n_tokens = 260, progress = 0.973554
slot update_slots: id  3 | task 1989 | n_tokens = 2356, memory_seq_rm [2356, end)
slot update_slots: id  3 | task 1989 | prompt processing progress, n_tokens = 2420, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 1989 | prompt done, n_tokens = 2420, batch.n_tokens = 64
slot init_sampler: id  3 | task 1989 | init sampler, took 0.38 ms, tokens: text = 2420, total = 2420
slot update_slots: id  3 | task 1989 | created context checkpoint 7 of 8 (pos_min = 1332, pos_max = 2355, size = 24.012 MiB)
slot print_timing: id  3 | task 1989 | 
prompt eval time =     473.69 ms /   324 tokens (    1.46 ms per token,   683.99 tokens per second)
       eval time =    3014.94 ms /   129 tokens (   23.37 ms per token,    42.79 tokens per second)
      total time =    3488.63 ms /   453 tokens
slot      release: id  3 | task 1989 | stop processing: n_tokens = 2548, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.870 (> 0.100 thold), f_keep = 0.547
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 2120 | processing task, is_child = 0
slot update_slots: id  3 | task 2120 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1602
slot update_slots: id  3 | task 2120 | n_past = 1394, slot.prompt.tokens.size() = 2548, seq_id = 3, pos_min = 1524, n_swa = 128
slot update_slots: id  3 | task 2120 | restored context checkpoint (pos_min = 1038, pos_max = 2031, size = 23.309 MiB)
slot update_slots: id  3 | task 2120 | erased invalidated context checkpoint (pos_min = 1332, pos_max = 2355, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 2120 | n_tokens = 1394, memory_seq_rm [1394, end)
slot update_slots: id  3 | task 2120 | prompt processing progress, n_tokens = 1538, batch.n_tokens = 144, progress = 0.960050
slot update_slots: id  3 | task 2120 | n_tokens = 1538, memory_seq_rm [1538, end)
slot update_slots: id  3 | task 2120 | prompt processing progress, n_tokens = 1602, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 2120 | prompt done, n_tokens = 1602, batch.n_tokens = 64
slot init_sampler: id  3 | task 2120 | init sampler, took 0.31 ms, tokens: text = 1602, total = 1602
slot print_timing: id  3 | task 2120 | 
prompt eval time =     510.77 ms /   208 tokens (    2.46 ms per token,   407.23 tokens per second)
       eval time =    7147.67 ms /   306 tokens (   23.36 ms per token,    42.81 tokens per second)
      total time =    7658.44 ms /   514 tokens
slot      release: id  3 | task 2120 | stop processing: n_tokens = 1907, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.860 (> 0.100 thold), f_keep = 0.840
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 2428 | processing task, is_child = 0
slot update_slots: id  3 | task 2428 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1863
slot update_slots: id  3 | task 2428 | n_tokens = 1602, memory_seq_rm [1602, end)
slot update_slots: id  3 | task 2428 | prompt processing progress, n_tokens = 1799, batch.n_tokens = 197, progress = 0.965647
slot update_slots: id  3 | task 2428 | n_tokens = 1799, memory_seq_rm [1799, end)
slot update_slots: id  3 | task 2428 | prompt processing progress, n_tokens = 1863, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 2428 | prompt done, n_tokens = 1863, batch.n_tokens = 64
slot init_sampler: id  3 | task 2428 | init sampler, took 0.34 ms, tokens: text = 1863, total = 1863
slot print_timing: id  3 | task 2428 | 
prompt eval time =     510.06 ms /   261 tokens (    1.95 ms per token,   511.71 tokens per second)
       eval time =    5038.74 ms /   217 tokens (   23.22 ms per token,    43.07 tokens per second)
      total time =    5548.80 ms /   478 tokens
slot      release: id  3 | task 2428 | stop processing: n_tokens = 2079, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.826 (> 0.100 thold), f_keep = 0.764
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 2647 | processing task, is_child = 0
slot update_slots: id  3 | task 2647 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1922
slot update_slots: id  3 | task 2647 | n_tokens = 1588, memory_seq_rm [1588, end)
slot update_slots: id  3 | task 2647 | prompt processing progress, n_tokens = 1858, batch.n_tokens = 270, progress = 0.966701
slot update_slots: id  3 | task 2647 | n_tokens = 1858, memory_seq_rm [1858, end)
slot update_slots: id  3 | task 2647 | prompt processing progress, n_tokens = 1922, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 2647 | prompt done, n_tokens = 1922, batch.n_tokens = 64
slot init_sampler: id  3 | task 2647 | init sampler, took 0.33 ms, tokens: text = 1922, total = 1922
slot print_timing: id  3 | task 2647 | 
prompt eval time =     580.40 ms /   334 tokens (    1.74 ms per token,   575.47 tokens per second)
       eval time =    6722.91 ms /   288 tokens (   23.34 ms per token,    42.84 tokens per second)
      total time =    7303.31 ms /   622 tokens
slot      release: id  3 | task 2647 | stop processing: n_tokens = 2209, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.587 (> 0.100 thold), f_keep = 0.870
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 2937 | processing task, is_child = 0
slot update_slots: id  3 | task 2937 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3275
slot update_slots: id  3 | task 2937 | n_tokens = 1922, memory_seq_rm [1922, end)
slot update_slots: id  3 | task 2937 | prompt processing progress, n_tokens = 3211, batch.n_tokens = 1289, progress = 0.980458
slot update_slots: id  3 | task 2937 | n_tokens = 3211, memory_seq_rm [3211, end)
slot update_slots: id  3 | task 2937 | prompt processing progress, n_tokens = 3275, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 2937 | prompt done, n_tokens = 3275, batch.n_tokens = 64
slot init_sampler: id  3 | task 2937 | init sampler, took 0.51 ms, tokens: text = 3275, total = 3275
slot update_slots: id  3 | task 2937 | created context checkpoint 7 of 8 (pos_min = 2187, pos_max = 3210, size = 24.012 MiB)
slot print_timing: id  3 | task 2937 | 
prompt eval time =    1439.71 ms /  1353 tokens (    1.06 ms per token,   939.77 tokens per second)
       eval time =    8152.65 ms /   344 tokens (   23.70 ms per token,    42.19 tokens per second)
      total time =    9592.37 ms /  1697 tokens
slot      release: id  3 | task 2937 | stop processing: n_tokens = 3618, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.795 (> 0.100 thold), f_keep = 0.525
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3283 | processing task, is_child = 0
slot update_slots: id  3 | task 3283 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2390
slot update_slots: id  3 | task 3283 | n_past = 1900, slot.prompt.tokens.size() = 3618, seq_id = 3, pos_min = 2594, n_swa = 128
slot update_slots: id  3 | task 3283 | restored context checkpoint (pos_min = 1038, pos_max = 2031, size = 23.309 MiB)
slot update_slots: id  3 | task 3283 | erased invalidated context checkpoint (pos_min = 2187, pos_max = 3210, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 3283 | n_tokens = 1900, memory_seq_rm [1900, end)
slot update_slots: id  3 | task 3283 | prompt processing progress, n_tokens = 2326, batch.n_tokens = 426, progress = 0.973222
slot update_slots: id  3 | task 3283 | n_tokens = 2326, memory_seq_rm [2326, end)
slot update_slots: id  3 | task 3283 | prompt processing progress, n_tokens = 2390, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3283 | prompt done, n_tokens = 2390, batch.n_tokens = 64
slot init_sampler: id  3 | task 3283 | init sampler, took 0.47 ms, tokens: text = 2390, total = 2390
slot update_slots: id  3 | task 3283 | created context checkpoint 7 of 8 (pos_min = 1332, pos_max = 2325, size = 23.309 MiB)
slot print_timing: id  3 | task 3283 | 
prompt eval time =     681.33 ms /   490 tokens (    1.39 ms per token,   719.18 tokens per second)
       eval time =   18279.78 ms /   762 tokens (   23.99 ms per token,    41.69 tokens per second)
      total time =   18961.11 ms /  1252 tokens
slot      release: id  3 | task 3283 | stop processing: n_tokens = 3151, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.888 (> 0.100 thold), f_keep = 0.758
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4047 | processing task, is_child = 0
slot update_slots: id  3 | task 4047 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2692
slot update_slots: id  3 | task 4047 | n_tokens = 2390, memory_seq_rm [2390, end)
slot update_slots: id  3 | task 4047 | prompt processing progress, n_tokens = 2628, batch.n_tokens = 238, progress = 0.976226
slot update_slots: id  3 | task 4047 | n_tokens = 2628, memory_seq_rm [2628, end)
slot update_slots: id  3 | task 4047 | prompt processing progress, n_tokens = 2692, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4047 | prompt done, n_tokens = 2692, batch.n_tokens = 64
slot init_sampler: id  3 | task 4047 | init sampler, took 0.41 ms, tokens: text = 2692, total = 2692
slot update_slots: id  3 | task 4047 | created context checkpoint 8 of 8 (pos_min = 2127, pos_max = 2627, size = 11.748 MiB)
slot print_timing: id  3 | task 4047 | 
prompt eval time =     526.25 ms /   302 tokens (    1.74 ms per token,   573.87 tokens per second)
       eval time =   10438.84 ms /   429 tokens (   24.33 ms per token,    41.10 tokens per second)
      total time =   10965.10 ms /   731 tokens
slot      release: id  3 | task 4047 | stop processing: n_tokens = 3120, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.881 (> 0.100 thold), f_keep = 0.863
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4478 | processing task, is_child = 0
slot update_slots: id  3 | task 4478 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3054
slot update_slots: id  3 | task 4478 | n_tokens = 2692, memory_seq_rm [2692, end)
slot update_slots: id  3 | task 4478 | prompt processing progress, n_tokens = 2990, batch.n_tokens = 298, progress = 0.979044
slot update_slots: id  3 | task 4478 | n_tokens = 2990, memory_seq_rm [2990, end)
slot update_slots: id  3 | task 4478 | prompt processing progress, n_tokens = 3054, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4478 | prompt done, n_tokens = 3054, batch.n_tokens = 64
slot init_sampler: id  3 | task 4478 | init sampler, took 0.48 ms, tokens: text = 3054, total = 3054
slot update_slots: id  3 | task 4478 | erasing old context checkpoint (pos_min = 0, pos_max = 510, size = 11.983 MiB)
slot update_slots: id  3 | task 4478 | created context checkpoint 8 of 8 (pos_min = 2390, pos_max = 2989, size = 14.070 MiB)
slot print_timing: id  3 | task 4478 | 
prompt eval time =     521.11 ms /   362 tokens (    1.44 ms per token,   694.67 tokens per second)
       eval time =    1403.49 ms /    57 tokens (   24.62 ms per token,    40.61 tokens per second)
      total time =    1924.60 ms /   419 tokens
slot      release: id  3 | task 4478 | stop processing: n_tokens = 3110, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.979 (> 0.100 thold), f_keep = 0.982
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4537 | processing task, is_child = 0
slot update_slots: id  3 | task 4537 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3120
slot update_slots: id  3 | task 4537 | n_tokens = 3054, memory_seq_rm [3054, end)
slot update_slots: id  3 | task 4537 | prompt processing progress, n_tokens = 3056, batch.n_tokens = 2, progress = 0.979487
slot update_slots: id  3 | task 4537 | n_tokens = 3056, memory_seq_rm [3056, end)
slot update_slots: id  3 | task 4537 | prompt processing progress, n_tokens = 3120, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4537 | prompt done, n_tokens = 3120, batch.n_tokens = 64
slot init_sampler: id  3 | task 4537 | init sampler, took 0.50 ms, tokens: text = 3120, total = 3120
slot update_slots: id  3 | task 4537 | erasing old context checkpoint (pos_min = 0, pos_max = 581, size = 13.648 MiB)
slot update_slots: id  3 | task 4537 | created context checkpoint 8 of 8 (pos_min = 2390, pos_max = 3055, size = 15.617 MiB)
slot print_timing: id  3 | task 4537 | 
prompt eval time =     260.30 ms /    66 tokens (    3.94 ms per token,   253.56 tokens per second)
       eval time =    3497.56 ms /   148 tokens (   23.63 ms per token,    42.32 tokens per second)
      total time =    3757.86 ms /   214 tokens
slot      release: id  3 | task 4537 | stop processing: n_tokens = 3267, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.741 (> 0.100 thold), f_keep = 0.721
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4687 | processing task, is_child = 0
slot update_slots: id  3 | task 4687 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3175
slot update_slots: id  3 | task 4687 | n_past = 2354, slot.prompt.tokens.size() = 3267, seq_id = 3, pos_min = 2390, n_swa = 128
slot update_slots: id  3 | task 4687 | restored context checkpoint (pos_min = 2127, pos_max = 2627, size = 11.748 MiB)
slot update_slots: id  3 | task 4687 | erased invalidated context checkpoint (pos_min = 2390, pos_max = 2989, n_swa = 128, size = 14.070 MiB)
slot update_slots: id  3 | task 4687 | erased invalidated context checkpoint (pos_min = 2390, pos_max = 3055, n_swa = 128, size = 15.617 MiB)
slot update_slots: id  3 | task 4687 | n_tokens = 2354, memory_seq_rm [2354, end)
slot update_slots: id  3 | task 4687 | prompt processing progress, n_tokens = 3111, batch.n_tokens = 757, progress = 0.979843
slot update_slots: id  3 | task 4687 | n_tokens = 3111, memory_seq_rm [3111, end)
slot update_slots: id  3 | task 4687 | prompt processing progress, n_tokens = 3175, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4687 | prompt done, n_tokens = 3175, batch.n_tokens = 64
slot init_sampler: id  3 | task 4687 | init sampler, took 0.49 ms, tokens: text = 3175, total = 3175
slot update_slots: id  3 | task 4687 | created context checkpoint 7 of 8 (pos_min = 2227, pos_max = 3110, size = 20.729 MiB)
slot print_timing: id  3 | task 4687 | 
prompt eval time =    1076.77 ms /   821 tokens (    1.31 ms per token,   762.47 tokens per second)
       eval time =    2032.92 ms /    86 tokens (   23.64 ms per token,    42.30 tokens per second)
      total time =    3109.69 ms /   907 tokens
slot      release: id  3 | task 4687 | stop processing: n_tokens = 3260, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.940 (> 0.100 thold), f_keep = 0.974
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4775 | processing task, is_child = 0
slot update_slots: id  3 | task 4775 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3378
slot update_slots: id  3 | task 4775 | n_tokens = 3175, memory_seq_rm [3175, end)
slot update_slots: id  3 | task 4775 | prompt processing progress, n_tokens = 3314, batch.n_tokens = 139, progress = 0.981054
slot update_slots: id  3 | task 4775 | n_tokens = 3314, memory_seq_rm [3314, end)
slot update_slots: id  3 | task 4775 | prompt processing progress, n_tokens = 3378, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4775 | prompt done, n_tokens = 3378, batch.n_tokens = 64
slot init_sampler: id  3 | task 4775 | init sampler, took 0.51 ms, tokens: text = 3378, total = 3378
slot update_slots: id  3 | task 4775 | created context checkpoint 8 of 8 (pos_min = 2493, pos_max = 3313, size = 19.252 MiB)
slot print_timing: id  3 | task 4775 | 
prompt eval time =     447.53 ms /   203 tokens (    2.20 ms per token,   453.60 tokens per second)
       eval time =    1374.88 ms /    59 tokens (   23.30 ms per token,    42.91 tokens per second)
      total time =    1822.40 ms /   262 tokens
slot      release: id  3 | task 4775 | stop processing: n_tokens = 3436, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.637 (> 0.100 thold), f_keep = 0.983
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4836 | processing task, is_child = 0
slot update_slots: id  3 | task 4836 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5300
slot update_slots: id  3 | task 4836 | n_tokens = 3378, memory_seq_rm [3378, end)
slot update_slots: id  3 | task 4836 | prompt processing progress, n_tokens = 5236, batch.n_tokens = 1858, progress = 0.987925
slot update_slots: id  3 | task 4836 | n_tokens = 5236, memory_seq_rm [5236, end)
slot update_slots: id  3 | task 4836 | prompt processing progress, n_tokens = 5300, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4836 | prompt done, n_tokens = 5300, batch.n_tokens = 64
slot init_sampler: id  3 | task 4836 | init sampler, took 0.80 ms, tokens: text = 5300, total = 5300
slot update_slots: id  3 | task 4836 | erasing old context checkpoint (pos_min = 245, pos_max = 1268, size = 24.012 MiB)
slot update_slots: id  3 | task 4836 | created context checkpoint 8 of 8 (pos_min = 4212, pos_max = 5235, size = 24.012 MiB)
slot print_timing: id  3 | task 4836 | 
prompt eval time =    2049.80 ms /  1922 tokens (    1.07 ms per token,   937.65 tokens per second)
       eval time =    1165.34 ms /    49 tokens (   23.78 ms per token,    42.05 tokens per second)
      total time =    3215.15 ms /  1971 tokens
slot      release: id  3 | task 4836 | stop processing: n_tokens = 5348, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.881 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4887 | processing task, is_child = 0
slot update_slots: id  3 | task 4887 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6019
slot update_slots: id  3 | task 4887 | n_tokens = 5300, memory_seq_rm [5300, end)
slot update_slots: id  3 | task 4887 | prompt processing progress, n_tokens = 5955, batch.n_tokens = 655, progress = 0.989367
slot update_slots: id  3 | task 4887 | n_tokens = 5955, memory_seq_rm [5955, end)
slot update_slots: id  3 | task 4887 | prompt processing progress, n_tokens = 6019, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4887 | prompt done, n_tokens = 6019, batch.n_tokens = 64
slot init_sampler: id  3 | task 4887 | init sampler, took 0.94 ms, tokens: text = 6019, total = 6019
slot update_slots: id  3 | task 4887 | erasing old context checkpoint (pos_min = 668, pos_max = 1368, size = 16.438 MiB)
slot update_slots: id  3 | task 4887 | created context checkpoint 8 of 8 (pos_min = 4931, pos_max = 5954, size = 24.012 MiB)
slot print_timing: id  3 | task 4887 | 
prompt eval time =     930.12 ms /   719 tokens (    1.29 ms per token,   773.02 tokens per second)
       eval time =    1287.90 ms /    54 tokens (   23.85 ms per token,    41.93 tokens per second)
      total time =    2218.02 ms /   773 tokens
slot      release: id  3 | task 4887 | stop processing: n_tokens = 6072, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4943 | processing task, is_child = 0
slot update_slots: id  3 | task 4943 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6076
slot update_slots: id  3 | task 4943 | n_tokens = 6019, memory_seq_rm [6019, end)
slot update_slots: id  3 | task 4943 | prompt processing progress, n_tokens = 6076, batch.n_tokens = 57, progress = 1.000000
slot update_slots: id  3 | task 4943 | prompt done, n_tokens = 6076, batch.n_tokens = 57
slot init_sampler: id  3 | task 4943 | init sampler, took 0.96 ms, tokens: text = 6076, total = 6076
slot print_timing: id  3 | task 4943 | 
prompt eval time =     153.20 ms /    57 tokens (    2.69 ms per token,   372.07 tokens per second)
       eval time =    7066.09 ms /   291 tokens (   24.28 ms per token,    41.18 tokens per second)
      total time =    7219.29 ms /   348 tokens
slot      release: id  3 | task 4943 | stop processing: n_tokens = 6366, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.952 (> 0.100 thold), f_keep = 0.954
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5235 | processing task, is_child = 0
slot update_slots: id  3 | task 5235 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6380
slot update_slots: id  3 | task 5235 | n_tokens = 6076, memory_seq_rm [6076, end)
slot update_slots: id  3 | task 5235 | prompt processing progress, n_tokens = 6316, batch.n_tokens = 240, progress = 0.989969
slot update_slots: id  3 | task 5235 | n_tokens = 6316, memory_seq_rm [6316, end)
slot update_slots: id  3 | task 5235 | prompt processing progress, n_tokens = 6380, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5235 | prompt done, n_tokens = 6380, batch.n_tokens = 64
slot init_sampler: id  3 | task 5235 | init sampler, took 0.92 ms, tokens: text = 6380, total = 6380
slot update_slots: id  3 | task 5235 | erasing old context checkpoint (pos_min = 942, pos_max = 1965, size = 24.012 MiB)
slot update_slots: id  3 | task 5235 | created context checkpoint 8 of 8 (pos_min = 5463, pos_max = 6315, size = 20.002 MiB)
slot print_timing: id  3 | task 5235 | 
prompt eval time =     548.43 ms /   304 tokens (    1.80 ms per token,   554.31 tokens per second)
       eval time =    1004.88 ms /    41 tokens (   24.51 ms per token,    40.80 tokens per second)
      total time =    1553.31 ms /   345 tokens
slot      release: id  3 | task 5235 | stop processing: n_tokens = 6420, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.970 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5278 | processing task, is_child = 0
slot update_slots: id  3 | task 5278 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6579
slot update_slots: id  3 | task 5278 | n_tokens = 6380, memory_seq_rm [6380, end)
slot update_slots: id  3 | task 5278 | prompt processing progress, n_tokens = 6515, batch.n_tokens = 135, progress = 0.990272
slot update_slots: id  3 | task 5278 | n_tokens = 6515, memory_seq_rm [6515, end)
slot update_slots: id  3 | task 5278 | prompt processing progress, n_tokens = 6579, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5278 | prompt done, n_tokens = 6579, batch.n_tokens = 64
slot init_sampler: id  3 | task 5278 | init sampler, took 1.26 ms, tokens: text = 6579, total = 6579
slot update_slots: id  3 | task 5278 | erasing old context checkpoint (pos_min = 1038, pos_max = 2031, size = 23.309 MiB)
slot update_slots: id  3 | task 5278 | created context checkpoint 8 of 8 (pos_min = 5662, pos_max = 6514, size = 20.002 MiB)
slot print_timing: id  3 | task 5278 | 
prompt eval time =     461.24 ms /   199 tokens (    2.32 ms per token,   431.44 tokens per second)
       eval time =    1822.76 ms /    74 tokens (   24.63 ms per token,    40.60 tokens per second)
      total time =    2284.00 ms /   273 tokens
slot      release: id  3 | task 5278 | stop processing: n_tokens = 6652, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.907 (> 0.100 thold), f_keep = 0.989
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5354 | processing task, is_child = 0
slot update_slots: id  3 | task 5354 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7255
slot update_slots: id  3 | task 5354 | n_tokens = 6579, memory_seq_rm [6579, end)
slot update_slots: id  3 | task 5354 | prompt processing progress, n_tokens = 7191, batch.n_tokens = 612, progress = 0.991179
slot update_slots: id  3 | task 5354 | n_tokens = 7191, memory_seq_rm [7191, end)
slot update_slots: id  3 | task 5354 | prompt processing progress, n_tokens = 7255, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5354 | prompt done, n_tokens = 7255, batch.n_tokens = 64
slot init_sampler: id  3 | task 5354 | init sampler, took 1.08 ms, tokens: text = 7255, total = 7255
slot update_slots: id  3 | task 5354 | erasing old context checkpoint (pos_min = 1332, pos_max = 2325, size = 23.309 MiB)
slot update_slots: id  3 | task 5354 | created context checkpoint 8 of 8 (pos_min = 6167, pos_max = 7190, size = 24.012 MiB)
slot print_timing: id  3 | task 5354 | 
prompt eval time =     951.75 ms /   676 tokens (    1.41 ms per token,   710.27 tokens per second)
       eval time =    3041.47 ms /   124 tokens (   24.53 ms per token,    40.77 tokens per second)
      total time =    3993.22 ms /   800 tokens
slot      release: id  3 | task 5354 | stop processing: n_tokens = 7378, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.983
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5480 | processing task, is_child = 0
slot update_slots: id  3 | task 5480 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7313
slot update_slots: id  3 | task 5480 | n_tokens = 7255, memory_seq_rm [7255, end)
slot update_slots: id  3 | task 5480 | prompt processing progress, n_tokens = 7313, batch.n_tokens = 58, progress = 1.000000
slot update_slots: id  3 | task 5480 | prompt done, n_tokens = 7313, batch.n_tokens = 58
slot init_sampler: id  3 | task 5480 | init sampler, took 1.12 ms, tokens: text = 7313, total = 7313
slot print_timing: id  3 | task 5480 | 
prompt eval time =     161.87 ms /    58 tokens (    2.79 ms per token,   358.31 tokens per second)
       eval time =    2171.00 ms /    88 tokens (   24.67 ms per token,    40.53 tokens per second)
      total time =    2332.87 ms /   146 tokens
slot      release: id  3 | task 5480 | stop processing: n_tokens = 7400, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5569 | processing task, is_child = 0
slot update_slots: id  3 | task 5569 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7370
slot update_slots: id  3 | task 5569 | n_tokens = 7313, memory_seq_rm [7313, end)
slot update_slots: id  3 | task 5569 | prompt processing progress, n_tokens = 7370, batch.n_tokens = 57, progress = 1.000000
slot update_slots: id  3 | task 5569 | prompt done, n_tokens = 7370, batch.n_tokens = 57
slot init_sampler: id  3 | task 5569 | init sampler, took 1.14 ms, tokens: text = 7370, total = 7370
slot update_slots: id  3 | task 5569 | erasing old context checkpoint (pos_min = 2127, pos_max = 2627, size = 11.748 MiB)
slot update_slots: id  3 | task 5569 | created context checkpoint 8 of 8 (pos_min = 6376, pos_max = 7312, size = 21.972 MiB)
slot print_timing: id  3 | task 5569 | 
prompt eval time =     172.27 ms /    57 tokens (    3.02 ms per token,   330.88 tokens per second)
       eval time =    1898.65 ms /    77 tokens (   24.66 ms per token,    40.56 tokens per second)
      total time =    2070.91 ms /   134 tokens
slot      release: id  3 | task 5569 | stop processing: n_tokens = 7446, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.943 (> 0.100 thold), f_keep = 0.990
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5647 | processing task, is_child = 0
slot update_slots: id  3 | task 5647 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7813
slot update_slots: id  3 | task 5647 | n_tokens = 7370, memory_seq_rm [7370, end)
slot update_slots: id  3 | task 5647 | prompt processing progress, n_tokens = 7749, batch.n_tokens = 379, progress = 0.991809
slot update_slots: id  3 | task 5647 | n_tokens = 7749, memory_seq_rm [7749, end)
slot update_slots: id  3 | task 5647 | prompt processing progress, n_tokens = 7813, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5647 | prompt done, n_tokens = 7813, batch.n_tokens = 64
slot init_sampler: id  3 | task 5647 | init sampler, took 1.55 ms, tokens: text = 7813, total = 7813
slot update_slots: id  3 | task 5647 | erasing old context checkpoint (pos_min = 2227, pos_max = 3110, size = 20.729 MiB)
slot update_slots: id  3 | task 5647 | created context checkpoint 8 of 8 (pos_min = 6725, pos_max = 7748, size = 24.012 MiB)
slot print_timing: id  3 | task 5647 | 
prompt eval time =     620.22 ms /   443 tokens (    1.40 ms per token,   714.26 tokens per second)
       eval time =    2598.44 ms /   101 tokens (   25.73 ms per token,    38.87 tokens per second)
      total time =    3218.66 ms /   544 tokens
slot      release: id  3 | task 5647 | stop processing: n_tokens = 7913, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5750 | processing task, is_child = 0
slot update_slots: id  3 | task 5750 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7871
slot update_slots: id  3 | task 5750 | n_tokens = 7813, memory_seq_rm [7813, end)
slot update_slots: id  3 | task 5750 | prompt processing progress, n_tokens = 7871, batch.n_tokens = 58, progress = 1.000000
slot update_slots: id  3 | task 5750 | prompt done, n_tokens = 7871, batch.n_tokens = 58
slot init_sampler: id  3 | task 5750 | init sampler, took 1.15 ms, tokens: text = 7871, total = 7871
slot print_timing: id  3 | task 5750 | 
prompt eval time =     162.36 ms /    58 tokens (    2.80 ms per token,   357.24 tokens per second)
       eval time =    1575.98 ms /    64 tokens (   24.62 ms per token,    40.61 tokens per second)
      total time =    1738.33 ms /   122 tokens
slot      release: id  3 | task 5750 | stop processing: n_tokens = 7934, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.804 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5815 | processing task, is_child = 0
slot update_slots: id  3 | task 5815 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 9793
slot update_slots: id  3 | task 5815 | n_tokens = 7871, memory_seq_rm [7871, end)
slot update_slots: id  3 | task 5815 | prompt processing progress, n_tokens = 9729, batch.n_tokens = 1858, progress = 0.993465
slot update_slots: id  3 | task 5815 | n_tokens = 9729, memory_seq_rm [9729, end)
slot update_slots: id  3 | task 5815 | prompt processing progress, n_tokens = 9793, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5815 | prompt done, n_tokens = 9793, batch.n_tokens = 64
slot init_sampler: id  3 | task 5815 | init sampler, took 1.95 ms, tokens: text = 9793, total = 9793
slot update_slots: id  3 | task 5815 | erasing old context checkpoint (pos_min = 2493, pos_max = 3313, size = 19.252 MiB)
slot update_slots: id  3 | task 5815 | created context checkpoint 8 of 8 (pos_min = 8705, pos_max = 9728, size = 24.012 MiB)
slot print_timing: id  3 | task 5815 | 
prompt eval time =    2193.19 ms /  1922 tokens (    1.14 ms per token,   876.35 tokens per second)
       eval time =    2982.79 ms /   120 tokens (   24.86 ms per token,    40.23 tokens per second)
      total time =    5175.98 ms /  2042 tokens
slot      release: id  3 | task 5815 | stop processing: n_tokens = 9912, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5937 | processing task, is_child = 0
slot update_slots: id  3 | task 5937 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 9851
slot update_slots: id  3 | task 5937 | n_tokens = 9793, memory_seq_rm [9793, end)
slot update_slots: id  3 | task 5937 | prompt processing progress, n_tokens = 9851, batch.n_tokens = 58, progress = 1.000000
slot update_slots: id  3 | task 5937 | prompt done, n_tokens = 9851, batch.n_tokens = 58
slot init_sampler: id  3 | task 5937 | init sampler, took 1.64 ms, tokens: text = 9851, total = 9851
slot print_timing: id  3 | task 5937 | 
prompt eval time =     165.32 ms /    58 tokens (    2.85 ms per token,   350.84 tokens per second)
       eval time =    7112.85 ms /   285 tokens (   24.96 ms per token,    40.07 tokens per second)
      total time =    7278.17 ms /   343 tokens
slot      release: id  3 | task 5937 | stop processing: n_tokens = 10135, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.970 (> 0.100 thold), f_keep = 0.972
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 6223 | processing task, is_child = 0
slot update_slots: id  3 | task 6223 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 10155
slot update_slots: id  3 | task 6223 | n_tokens = 9851, memory_seq_rm [9851, end)
slot update_slots: id  3 | task 6223 | prompt processing progress, n_tokens = 10091, batch.n_tokens = 240, progress = 0.993698
slot update_slots: id  3 | task 6223 | n_tokens = 10091, memory_seq_rm [10091, end)
slot update_slots: id  3 | task 6223 | prompt processing progress, n_tokens = 10155, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 6223 | prompt done, n_tokens = 10155, batch.n_tokens = 64
slot init_sampler: id  3 | task 6223 | init sampler, took 1.48 ms, tokens: text = 10155, total = 10155
slot update_slots: id  3 | task 6223 | erasing old context checkpoint (pos_min = 4212, pos_max = 5235, size = 24.012 MiB)
slot update_slots: id  3 | task 6223 | created context checkpoint 8 of 8 (pos_min = 9111, pos_max = 10090, size = 22.980 MiB)
slot print_timing: id  3 | task 6223 | 
prompt eval time =     566.94 ms /   304 tokens (    1.86 ms per token,   536.21 tokens per second)
       eval time =    3240.65 ms /   131 tokens (   24.74 ms per token,    40.42 tokens per second)
      total time =    3807.59 ms /   435 tokens
slot      release: id  3 | task 6223 | stop processing: n_tokens = 10285, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 6356 | processing task, is_child = 0
slot update_slots: id  3 | task 6356 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 10221
slot update_slots: id  3 | task 6356 | n_tokens = 10155, memory_seq_rm [10155, end)
slot update_slots: id  3 | task 6356 | prompt processing progress, n_tokens = 10157, batch.n_tokens = 2, progress = 0.993738
slot update_slots: id  3 | task 6356 | n_tokens = 10157, memory_seq_rm [10157, end)
slot update_slots: id  3 | task 6356 | prompt processing progress, n_tokens = 10221, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 6356 | prompt done, n_tokens = 10221, batch.n_tokens = 64
slot init_sampler: id  3 | task 6356 | init sampler, took 1.44 ms, tokens: text = 10221, total = 10221
slot update_slots: id  3 | task 6356 | erasing old context checkpoint (pos_min = 4931, pos_max = 5954, size = 24.012 MiB)
slot update_slots: id  3 | task 6356 | created context checkpoint 8 of 8 (pos_min = 9261, pos_max = 10156, size = 21.011 MiB)
slot print_timing: id  3 | task 6356 | 
prompt eval time =     211.57 ms /    66 tokens (    3.21 ms per token,   311.96 tokens per second)
       eval time =    1553.97 ms /    62 tokens (   25.06 ms per token,    39.90 tokens per second)
      total time =    1765.54 ms /   128 tokens
slot      release: id  3 | task 6356 | stop processing: n_tokens = 10282, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.964 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 6420 | processing task, is_child = 0
slot update_slots: id  3 | task 6420 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 10607
slot update_slots: id  3 | task 6420 | n_tokens = 10221, memory_seq_rm [10221, end)
slot update_slots: id  3 | task 6420 | prompt processing progress, n_tokens = 10543, batch.n_tokens = 322, progress = 0.993966
slot update_slots: id  3 | task 6420 | n_tokens = 10543, memory_seq_rm [10543, end)
slot update_slots: id  3 | task 6420 | prompt processing progress, n_tokens = 10607, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 6420 | prompt done, n_tokens = 10607, batch.n_tokens = 64
slot init_sampler: id  3 | task 6420 | init sampler, took 1.52 ms, tokens: text = 10607, total = 10607
slot update_slots: id  3 | task 6420 | erasing old context checkpoint (pos_min = 5463, pos_max = 6315, size = 20.002 MiB)
slot update_slots: id  3 | task 6420 | created context checkpoint 8 of 8 (pos_min = 9536, pos_max = 10542, size = 23.613 MiB)
slot print_timing: id  3 | task 6420 | 
prompt eval time =     563.41 ms /   386 tokens (    1.46 ms per token,   685.12 tokens per second)
       eval time =    2683.01 ms /   108 tokens (   24.84 ms per token,    40.25 tokens per second)
      total time =    3246.42 ms /   494 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 6420 | stop processing: n_tokens = 10714, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.990
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 6530 | processing task, is_child = 0
slot update_slots: id  3 | task 6530 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 10665
slot update_slots: id  3 | task 6530 | n_tokens = 10607, memory_seq_rm [10607, end)
slot update_slots: id  3 | task 6530 | prompt processing progress, n_tokens = 10665, batch.n_tokens = 58, progress = 1.000000
slot update_slots: id  3 | task 6530 | prompt done, n_tokens = 10665, batch.n_tokens = 58
slot init_sampler: id  3 | task 6530 | init sampler, took 2.18 ms, tokens: text = 10665, total = 10665
slot print_timing: id  3 | task 6530 | 
prompt eval time =     165.52 ms /    58 tokens (    2.85 ms per token,   350.40 tokens per second)
       eval time =    1627.41 ms /    65 tokens (   25.04 ms per token,    39.94 tokens per second)
      total time =    1792.94 ms /   123 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 6530 | stop processing: n_tokens = 10729, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.949 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 6596 | processing task, is_child = 0
slot update_slots: id  3 | task 6596 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 11233
slot update_slots: id  3 | task 6596 | n_tokens = 10665, memory_seq_rm [10665, end)
slot update_slots: id  3 | task 6596 | prompt processing progress, n_tokens = 11169, batch.n_tokens = 504, progress = 0.994303
slot update_slots: id  3 | task 6596 | n_tokens = 11169, memory_seq_rm [11169, end)
slot update_slots: id  3 | task 6596 | prompt processing progress, n_tokens = 11233, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 6596 | prompt done, n_tokens = 11233, batch.n_tokens = 64
slot init_sampler: id  3 | task 6596 | init sampler, took 1.60 ms, tokens: text = 11233, total = 11233
slot update_slots: id  3 | task 6596 | erasing old context checkpoint (pos_min = 5662, pos_max = 6514, size = 20.002 MiB)
slot update_slots: id  3 | task 6596 | created context checkpoint 8 of 8 (pos_min = 10155, pos_max = 11168, size = 23.778 MiB)
slot print_timing: id  3 | task 6596 | 
prompt eval time =     714.45 ms /   568 tokens (    1.26 ms per token,   795.01 tokens per second)
       eval time =    5764.23 ms /   235 tokens (   24.53 ms per token,    40.77 tokens per second)
      total time =    6478.69 ms /   803 tokens
slot      release: id  3 | task 6596 | stop processing: n_tokens = 11467, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.980
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 6833 | processing task, is_child = 0
slot update_slots: id  3 | task 6833 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 11315
slot update_slots: id  3 | task 6833 | n_tokens = 11233, memory_seq_rm [11233, end)
slot update_slots: id  3 | task 6833 | prompt processing progress, n_tokens = 11251, batch.n_tokens = 18, progress = 0.994344
slot update_slots: id  3 | task 6833 | n_tokens = 11251, memory_seq_rm [11251, end)
slot update_slots: id  3 | task 6833 | prompt processing progress, n_tokens = 11315, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 6833 | prompt done, n_tokens = 11315, batch.n_tokens = 64
slot init_sampler: id  3 | task 6833 | init sampler, took 1.79 ms, tokens: text = 11315, total = 11315
slot update_slots: id  3 | task 6833 | erasing old context checkpoint (pos_min = 6167, pos_max = 7190, size = 24.012 MiB)
slot update_slots: id  3 | task 6833 | created context checkpoint 8 of 8 (pos_min = 10443, pos_max = 11250, size = 18.947 MiB)
slot print_timing: id  3 | task 6833 | 
prompt eval time =     269.28 ms /    82 tokens (    3.28 ms per token,   304.52 tokens per second)
       eval time =    8862.89 ms /   360 tokens (   24.62 ms per token,    40.62 tokens per second)
      total time =    9132.17 ms /   442 tokens
slot      release: id  3 | task 6833 | stop processing: n_tokens = 11674, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.974 (> 0.100 thold), f_keep = 0.969
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 7195 | processing task, is_child = 0
slot update_slots: id  3 | task 7195 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 11620
slot update_slots: id  3 | task 7195 | n_tokens = 11315, memory_seq_rm [11315, end)
slot update_slots: id  3 | task 7195 | prompt processing progress, n_tokens = 11556, batch.n_tokens = 241, progress = 0.994492
slot update_slots: id  3 | task 7195 | n_tokens = 11556, memory_seq_rm [11556, end)
slot update_slots: id  3 | task 7195 | prompt processing progress, n_tokens = 11620, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 7195 | prompt done, n_tokens = 11620, batch.n_tokens = 64
slot init_sampler: id  3 | task 7195 | init sampler, took 1.71 ms, tokens: text = 11620, total = 11620
slot update_slots: id  3 | task 7195 | erasing old context checkpoint (pos_min = 6376, pos_max = 7312, size = 21.972 MiB)
slot update_slots: id  3 | task 7195 | created context checkpoint 8 of 8 (pos_min = 10650, pos_max = 11555, size = 21.245 MiB)
slot print_timing: id  3 | task 7195 | 
prompt eval time =     565.79 ms /   305 tokens (    1.86 ms per token,   539.07 tokens per second)
       eval time =    1872.24 ms /    76 tokens (   24.63 ms per token,    40.59 tokens per second)
      total time =    2438.03 ms /   381 tokens
slot      release: id  3 | task 7195 | stop processing: n_tokens = 11695, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 7273 | processing task, is_child = 0
slot update_slots: id  3 | task 7273 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 11678
slot update_slots: id  3 | task 7273 | n_tokens = 11620, memory_seq_rm [11620, end)
slot update_slots: id  3 | task 7273 | prompt processing progress, n_tokens = 11678, batch.n_tokens = 58, progress = 1.000000
slot update_slots: id  3 | task 7273 | prompt done, n_tokens = 11678, batch.n_tokens = 58
slot init_sampler: id  3 | task 7273 | init sampler, took 1.64 ms, tokens: text = 11678, total = 11678
slot print_timing: id  3 | task 7273 | 
prompt eval time =     161.71 ms /    58 tokens (    2.79 ms per token,   358.66 tokens per second)
       eval time =    1279.29 ms /    52 tokens (   24.60 ms per token,    40.65 tokens per second)
      total time =    1441.00 ms /   110 tokens
slot      release: id  3 | task 7273 | stop processing: n_tokens = 11729, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.971 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 7326 | processing task, is_child = 0
slot update_slots: id  3 | task 7326 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 12026
slot update_slots: id  3 | task 7326 | n_tokens = 11678, memory_seq_rm [11678, end)
slot update_slots: id  3 | task 7326 | prompt processing progress, n_tokens = 11962, batch.n_tokens = 284, progress = 0.994678
slot update_slots: id  3 | task 7326 | n_tokens = 11962, memory_seq_rm [11962, end)
slot update_slots: id  3 | task 7326 | prompt processing progress, n_tokens = 12026, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 7326 | prompt done, n_tokens = 12026, batch.n_tokens = 64
slot init_sampler: id  3 | task 7326 | init sampler, took 1.76 ms, tokens: text = 12026, total = 12026
slot update_slots: id  3 | task 7326 | erasing old context checkpoint (pos_min = 6725, pos_max = 7748, size = 24.012 MiB)
slot update_slots: id  3 | task 7326 | created context checkpoint 8 of 8 (pos_min = 10938, pos_max = 11961, size = 24.012 MiB)
slot print_timing: id  3 | task 7326 | 
prompt eval time =     531.32 ms /   348 tokens (    1.53 ms per token,   654.98 tokens per second)
       eval time =    1580.24 ms /    64 tokens (   24.69 ms per token,    40.50 tokens per second)
      total time =    2111.56 ms /   412 tokens
slot      release: id  3 | task 7326 | stop processing: n_tokens = 12089, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.962 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 7392 | processing task, is_child = 0
slot update_slots: id  3 | task 7392 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 12499
slot update_slots: id  3 | task 7392 | n_tokens = 12026, memory_seq_rm [12026, end)
slot update_slots: id  3 | task 7392 | prompt processing progress, n_tokens = 12435, batch.n_tokens = 409, progress = 0.994880
slot update_slots: id  3 | task 7392 | n_tokens = 12435, memory_seq_rm [12435, end)
slot update_slots: id  3 | task 7392 | prompt processing progress, n_tokens = 12499, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 7392 | prompt done, n_tokens = 12499, batch.n_tokens = 64
slot init_sampler: id  3 | task 7392 | init sampler, took 2.40 ms, tokens: text = 12499, total = 12499
slot update_slots: id  3 | task 7392 | erasing old context checkpoint (pos_min = 8705, pos_max = 9728, size = 24.012 MiB)
slot update_slots: id  3 | task 7392 | created context checkpoint 8 of 8 (pos_min = 11411, pos_max = 12434, size = 24.012 MiB)
slot print_timing: id  3 | task 7392 | 
prompt eval time =     636.62 ms /   473 tokens (    1.35 ms per token,   742.98 tokens per second)
       eval time =    9677.65 ms /   389 tokens (   24.88 ms per token,    40.20 tokens per second)
      total time =   10314.27 ms /   862 tokens
slot      release: id  3 | task 7392 | stop processing: n_tokens = 12887, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.963 (> 0.100 thold), f_keep = 0.970
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 7783 | processing task, is_child = 0
slot update_slots: id  3 | task 7783 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 12974
slot update_slots: id  3 | task 7783 | n_tokens = 12499, memory_seq_rm [12499, end)
slot update_slots: id  3 | task 7783 | prompt processing progress, n_tokens = 12910, batch.n_tokens = 411, progress = 0.995067
slot update_slots: id  3 | task 7783 | n_tokens = 12910, memory_seq_rm [12910, end)
slot update_slots: id  3 | task 7783 | prompt processing progress, n_tokens = 12974, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 7783 | prompt done, n_tokens = 12974, batch.n_tokens = 64
slot init_sampler: id  3 | task 7783 | init sampler, took 1.87 ms, tokens: text = 12974, total = 12974
slot update_slots: id  3 | task 7783 | erasing old context checkpoint (pos_min = 9111, pos_max = 10090, size = 22.980 MiB)
slot update_slots: id  3 | task 7783 | created context checkpoint 8 of 8 (pos_min = 11886, pos_max = 12909, size = 24.012 MiB)
slot print_timing: id  3 | task 7783 | 
prompt eval time =     649.59 ms /   475 tokens (    1.37 ms per token,   731.23 tokens per second)
       eval time =    5853.29 ms /   234 tokens (   25.01 ms per token,    39.98 tokens per second)
      total time =    6502.88 ms /   709 tokens
slot      release: id  3 | task 7783 | stop processing: n_tokens = 13207, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.967 (> 0.100 thold), f_keep = 0.982
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8019 | processing task, is_child = 0
slot update_slots: id  3 | task 8019 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13423
slot update_slots: id  3 | task 8019 | n_tokens = 12974, memory_seq_rm [12974, end)
slot update_slots: id  3 | task 8019 | prompt processing progress, n_tokens = 13359, batch.n_tokens = 385, progress = 0.995232
slot update_slots: id  3 | task 8019 | n_tokens = 13359, memory_seq_rm [13359, end)
slot update_slots: id  3 | task 8019 | prompt processing progress, n_tokens = 13423, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 8019 | prompt done, n_tokens = 13423, batch.n_tokens = 64
slot init_sampler: id  3 | task 8019 | init sampler, took 1.97 ms, tokens: text = 13423, total = 13423
slot update_slots: id  3 | task 8019 | erasing old context checkpoint (pos_min = 9261, pos_max = 10156, size = 21.011 MiB)
slot update_slots: id  3 | task 8019 | created context checkpoint 8 of 8 (pos_min = 12335, pos_max = 13358, size = 24.012 MiB)
slot print_timing: id  3 | task 8019 | 
prompt eval time =     630.00 ms /   449 tokens (    1.40 ms per token,   712.70 tokens per second)
       eval time =    2696.09 ms /   107 tokens (   25.20 ms per token,    39.69 tokens per second)
      total time =    3326.09 ms /   556 tokens
slot      release: id  3 | task 8019 | stop processing: n_tokens = 13529, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8128 | processing task, is_child = 0
slot update_slots: id  3 | task 8128 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13480
slot update_slots: id  3 | task 8128 | n_tokens = 13423, memory_seq_rm [13423, end)
slot update_slots: id  3 | task 8128 | prompt processing progress, n_tokens = 13480, batch.n_tokens = 57, progress = 1.000000
slot update_slots: id  3 | task 8128 | prompt done, n_tokens = 13480, batch.n_tokens = 57
slot init_sampler: id  3 | task 8128 | init sampler, took 2.00 ms, tokens: text = 13480, total = 13480
slot print_timing: id  3 | task 8128 | 
prompt eval time =     163.23 ms /    57 tokens (    2.86 ms per token,   349.20 tokens per second)
       eval time =    1643.84 ms /    65 tokens (   25.29 ms per token,    39.54 tokens per second)
      total time =    1807.07 ms /   122 tokens
slot      release: id  3 | task 8128 | stop processing: n_tokens = 13544, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.960 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8194 | processing task, is_child = 0
slot update_slots: id  3 | task 8194 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 14042
slot update_slots: id  3 | task 8194 | n_tokens = 13480, memory_seq_rm [13480, end)
slot update_slots: id  3 | task 8194 | prompt processing progress, n_tokens = 13978, batch.n_tokens = 498, progress = 0.995442
slot update_slots: id  3 | task 8194 | n_tokens = 13978, memory_seq_rm [13978, end)
slot update_slots: id  3 | task 8194 | prompt processing progress, n_tokens = 14042, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 8194 | prompt done, n_tokens = 14042, batch.n_tokens = 64
slot init_sampler: id  3 | task 8194 | init sampler, took 2.09 ms, tokens: text = 14042, total = 14042
slot update_slots: id  3 | task 8194 | erasing old context checkpoint (pos_min = 9536, pos_max = 10542, size = 23.613 MiB)
slot update_slots: id  3 | task 8194 | created context checkpoint 8 of 8 (pos_min = 12954, pos_max = 13977, size = 24.012 MiB)
slot print_timing: id  3 | task 8194 | 
prompt eval time =     748.74 ms /   562 tokens (    1.33 ms per token,   750.60 tokens per second)
       eval time =    3716.07 ms /   145 tokens (   25.63 ms per token,    39.02 tokens per second)
      total time =    4464.81 ms /   707 tokens
slot      release: id  3 | task 8194 | stop processing: n_tokens = 14186, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.880 (> 0.100 thold), f_keep = 0.990
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8341 | processing task, is_child = 0
slot update_slots: id  3 | task 8341 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15964
slot update_slots: id  3 | task 8341 | n_tokens = 14042, memory_seq_rm [14042, end)
slot update_slots: id  3 | task 8341 | prompt processing progress, n_tokens = 15900, batch.n_tokens = 1858, progress = 0.995991
slot update_slots: id  3 | task 8341 | n_tokens = 15900, memory_seq_rm [15900, end)
slot update_slots: id  3 | task 8341 | prompt processing progress, n_tokens = 15964, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 8341 | prompt done, n_tokens = 15964, batch.n_tokens = 64
slot init_sampler: id  3 | task 8341 | init sampler, took 2.69 ms, tokens: text = 15964, total = 15964
slot update_slots: id  3 | task 8341 | erasing old context checkpoint (pos_min = 10155, pos_max = 11168, size = 23.778 MiB)
slot update_slots: id  3 | task 8341 | created context checkpoint 8 of 8 (pos_min = 14876, pos_max = 15899, size = 24.012 MiB)
slot print_timing: id  3 | task 8341 | 
prompt eval time =    2349.41 ms /  1922 tokens (    1.22 ms per token,   818.08 tokens per second)
       eval time =   10359.81 ms /   410 tokens (   25.27 ms per token,    39.58 tokens per second)
      total time =   12709.22 ms /  2332 tokens
slot      release: id  3 | task 8341 | stop processing: n_tokens = 16373, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.981 (> 0.100 thold), f_keep = 0.975
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8753 | processing task, is_child = 0
slot update_slots: id  3 | task 8753 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16269
slot update_slots: id  3 | task 8753 | n_tokens = 15964, memory_seq_rm [15964, end)
slot update_slots: id  3 | task 8753 | prompt processing progress, n_tokens = 16205, batch.n_tokens = 241, progress = 0.996066
slot update_slots: id  3 | task 8753 | n_tokens = 16205, memory_seq_rm [16205, end)
slot update_slots: id  3 | task 8753 | prompt processing progress, n_tokens = 16269, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 8753 | prompt done, n_tokens = 16269, batch.n_tokens = 64
slot init_sampler: id  3 | task 8753 | init sampler, took 3.40 ms, tokens: text = 16269, total = 16269
slot update_slots: id  3 | task 8753 | erasing old context checkpoint (pos_min = 10443, pos_max = 11250, size = 18.947 MiB)
slot update_slots: id  3 | task 8753 | created context checkpoint 8 of 8 (pos_min = 15516, pos_max = 16204, size = 16.157 MiB)
slot print_timing: id  3 | task 8753 | 
prompt eval time =     600.30 ms /   305 tokens (    1.97 ms per token,   508.08 tokens per second)
       eval time =    1831.29 ms /    73 tokens (   25.09 ms per token,    39.86 tokens per second)
      total time =    2431.59 ms /   378 tokens
slot      release: id  3 | task 8753 | stop processing: n_tokens = 16341, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8828 | processing task, is_child = 0
slot update_slots: id  3 | task 8828 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16327
slot update_slots: id  3 | task 8828 | n_tokens = 16269, memory_seq_rm [16269, end)
slot update_slots: id  3 | task 8828 | prompt processing progress, n_tokens = 16327, batch.n_tokens = 58, progress = 1.000000
slot update_slots: id  3 | task 8828 | prompt done, n_tokens = 16327, batch.n_tokens = 58
slot init_sampler: id  3 | task 8828 | init sampler, took 2.58 ms, tokens: text = 16327, total = 16327
slot print_timing: id  3 | task 8828 | 
prompt eval time =     167.51 ms /    58 tokens (    2.89 ms per token,   346.25 tokens per second)
       eval time =    2520.53 ms /   100 tokens (   25.21 ms per token,    39.67 tokens per second)
      total time =    2688.04 ms /   158 tokens
slot      release: id  3 | task 8828 | stop processing: n_tokens = 16426, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8929 | processing task, is_child = 0
slot update_slots: id  3 | task 8929 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16384
slot update_slots: id  3 | task 8929 | n_tokens = 16327, memory_seq_rm [16327, end)
slot update_slots: id  3 | task 8929 | prompt processing progress, n_tokens = 16384, batch.n_tokens = 57, progress = 1.000000
slot update_slots: id  3 | task 8929 | prompt done, n_tokens = 16384, batch.n_tokens = 57
slot init_sampler: id  3 | task 8929 | init sampler, took 2.29 ms, tokens: text = 16384, total = 16384
slot update_slots: id  3 | task 8929 | erasing old context checkpoint (pos_min = 10650, pos_max = 11555, size = 21.245 MiB)
slot update_slots: id  3 | task 8929 | created context checkpoint 8 of 8 (pos_min = 15737, pos_max = 16326, size = 13.835 MiB)
slot print_timing: id  3 | task 8929 | 
prompt eval time =     175.05 ms /    57 tokens (    3.07 ms per token,   325.62 tokens per second)
       eval time =    3652.08 ms /   145 tokens (   25.19 ms per token,    39.70 tokens per second)
      total time =    3827.14 ms /   202 tokens
slot      release: id  3 | task 8929 | stop processing: n_tokens = 16528, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.967 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9075 | processing task, is_child = 0
slot update_slots: id  3 | task 9075 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16946
slot update_slots: id  3 | task 9075 | n_tokens = 16384, memory_seq_rm [16384, end)
slot update_slots: id  3 | task 9075 | prompt processing progress, n_tokens = 16882, batch.n_tokens = 498, progress = 0.996223
slot update_slots: id  3 | task 9075 | n_tokens = 16882, memory_seq_rm [16882, end)
slot update_slots: id  3 | task 9075 | prompt processing progress, n_tokens = 16946, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9075 | prompt done, n_tokens = 16946, batch.n_tokens = 64
slot init_sampler: id  3 | task 9075 | init sampler, took 2.42 ms, tokens: text = 16946, total = 16946
slot update_slots: id  3 | task 9075 | erasing old context checkpoint (pos_min = 10938, pos_max = 11961, size = 24.012 MiB)
slot update_slots: id  3 | task 9075 | created context checkpoint 8 of 8 (pos_min = 15964, pos_max = 16881, size = 21.526 MiB)
slot print_timing: id  3 | task 9075 | 
prompt eval time =     774.77 ms /   562 tokens (    1.38 ms per token,   725.38 tokens per second)
       eval time =    2130.06 ms /    82 tokens (   25.98 ms per token,    38.50 tokens per second)
      total time =    2904.83 ms /   644 tokens
slot      release: id  3 | task 9075 | stop processing: n_tokens = 17027, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.969 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9159 | processing task, is_child = 0
slot update_slots: id  3 | task 9159 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 17495
slot update_slots: id  3 | task 9159 | n_tokens = 16946, memory_seq_rm [16946, end)
slot update_slots: id  3 | task 9159 | prompt processing progress, n_tokens = 17431, batch.n_tokens = 485, progress = 0.996342
slot update_slots: id  3 | task 9159 | n_tokens = 17431, memory_seq_rm [17431, end)
slot update_slots: id  3 | task 9159 | prompt processing progress, n_tokens = 17495, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9159 | prompt done, n_tokens = 17495, batch.n_tokens = 64
slot init_sampler: id  3 | task 9159 | init sampler, took 2.45 ms, tokens: text = 17495, total = 17495
slot update_slots: id  3 | task 9159 | erasing old context checkpoint (pos_min = 11411, pos_max = 12434, size = 24.012 MiB)
slot update_slots: id  3 | task 9159 | created context checkpoint 8 of 8 (pos_min = 16449, pos_max = 17430, size = 23.027 MiB)
slot print_timing: id  3 | task 9159 | 
prompt eval time =     766.19 ms /   549 tokens (    1.40 ms per token,   716.53 tokens per second)
       eval time =    3746.30 ms /   148 tokens (   25.31 ms per token,    39.51 tokens per second)
      total time =    4512.49 ms /   697 tokens
slot      release: id  3 | task 9159 | stop processing: n_tokens = 17642, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.901 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9309 | processing task, is_child = 0
slot update_slots: id  3 | task 9309 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 19417
slot update_slots: id  3 | task 9309 | n_tokens = 17495, memory_seq_rm [17495, end)
slot update_slots: id  3 | task 9309 | prompt processing progress, n_tokens = 19353, batch.n_tokens = 1858, progress = 0.996704
slot update_slots: id  3 | task 9309 | n_tokens = 19353, memory_seq_rm [19353, end)
slot update_slots: id  3 | task 9309 | prompt processing progress, n_tokens = 19417, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9309 | prompt done, n_tokens = 19417, batch.n_tokens = 64
slot init_sampler: id  3 | task 9309 | init sampler, took 2.88 ms, tokens: text = 19417, total = 19417
slot update_slots: id  3 | task 9309 | erasing old context checkpoint (pos_min = 11886, pos_max = 12909, size = 24.012 MiB)
slot update_slots: id  3 | task 9309 | created context checkpoint 8 of 8 (pos_min = 18329, pos_max = 19352, size = 24.012 MiB)
slot print_timing: id  3 | task 9309 | 
prompt eval time =    2440.70 ms /  1922 tokens (    1.27 ms per token,   787.48 tokens per second)
       eval time =    3495.88 ms /   136 tokens (   25.71 ms per token,    38.90 tokens per second)
      total time =    5936.58 ms /  2058 tokens
slot      release: id  3 | task 9309 | stop processing: n_tokens = 19552, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.981 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9447 | processing task, is_child = 0
slot update_slots: id  3 | task 9447 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 19803
slot update_slots: id  3 | task 9447 | n_tokens = 19417, memory_seq_rm [19417, end)
slot update_slots: id  3 | task 9447 | prompt processing progress, n_tokens = 19739, batch.n_tokens = 322, progress = 0.996768
slot update_slots: id  3 | task 9447 | n_tokens = 19739, memory_seq_rm [19739, end)
slot update_slots: id  3 | task 9447 | prompt processing progress, n_tokens = 19803, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9447 | prompt done, n_tokens = 19803, batch.n_tokens = 64
slot init_sampler: id  3 | task 9447 | init sampler, took 4.47 ms, tokens: text = 19803, total = 19803
slot update_slots: id  3 | task 9447 | erasing old context checkpoint (pos_min = 12335, pos_max = 13358, size = 24.012 MiB)
slot update_slots: id  3 | task 9447 | created context checkpoint 8 of 8 (pos_min = 18715, pos_max = 19738, size = 24.012 MiB)
slot print_timing: id  3 | task 9447 | 
prompt eval time =     628.33 ms /   386 tokens (    1.63 ms per token,   614.33 tokens per second)
       eval time =    2031.78 ms /    79 tokens (   25.72 ms per token,    38.88 tokens per second)
      total time =    2660.11 ms /   465 tokens
slot      release: id  3 | task 9447 | stop processing: n_tokens = 19881, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.972 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9528 | processing task, is_child = 0
slot update_slots: id  3 | task 9528 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20365
slot update_slots: id  3 | task 9528 | n_tokens = 19803, memory_seq_rm [19803, end)
slot update_slots: id  3 | task 9528 | prompt processing progress, n_tokens = 20301, batch.n_tokens = 498, progress = 0.996857
slot update_slots: id  3 | task 9528 | n_tokens = 20301, memory_seq_rm [20301, end)
slot update_slots: id  3 | task 9528 | prompt processing progress, n_tokens = 20365, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9528 | prompt done, n_tokens = 20365, batch.n_tokens = 64
slot init_sampler: id  3 | task 9528 | init sampler, took 2.87 ms, tokens: text = 20365, total = 20365
slot update_slots: id  3 | task 9528 | erasing old context checkpoint (pos_min = 12954, pos_max = 13977, size = 24.012 MiB)
slot update_slots: id  3 | task 9528 | created context checkpoint 8 of 8 (pos_min = 19277, pos_max = 20300, size = 24.012 MiB)
slot print_timing: id  3 | task 9528 | 
prompt eval time =     808.77 ms /   562 tokens (    1.44 ms per token,   694.88 tokens per second)
       eval time =    9201.82 ms /   359 tokens (   25.63 ms per token,    39.01 tokens per second)
      total time =   10010.60 ms /   921 tokens
slot      release: id  3 | task 9528 | stop processing: n_tokens = 20723, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.983
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9889 | processing task, is_child = 0
slot update_slots: id  3 | task 9889 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20670
slot update_slots: id  3 | task 9889 | n_tokens = 20365, memory_seq_rm [20365, end)
slot update_slots: id  3 | task 9889 | prompt processing progress, n_tokens = 20606, batch.n_tokens = 241, progress = 0.996904
slot update_slots: id  3 | task 9889 | n_tokens = 20606, memory_seq_rm [20606, end)
slot update_slots: id  3 | task 9889 | prompt processing progress, n_tokens = 20670, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9889 | prompt done, n_tokens = 20670, batch.n_tokens = 64
slot init_sampler: id  3 | task 9889 | init sampler, took 4.00 ms, tokens: text = 20670, total = 20670
slot update_slots: id  3 | task 9889 | erasing old context checkpoint (pos_min = 14876, pos_max = 15899, size = 24.012 MiB)
slot update_slots: id  3 | task 9889 | created context checkpoint 8 of 8 (pos_min = 19699, pos_max = 20605, size = 21.268 MiB)
slot print_timing: id  3 | task 9889 | 
prompt eval time =     633.50 ms /   305 tokens (    2.08 ms per token,   481.45 tokens per second)
       eval time =    1230.90 ms /    48 tokens (   25.64 ms per token,    39.00 tokens per second)
      total time =    1864.40 ms /   353 tokens
slot      release: id  3 | task 9889 | stop processing: n_tokens = 20717, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9939 | processing task, is_child = 0
slot update_slots: id  3 | task 9939 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20727
slot update_slots: id  3 | task 9939 | n_tokens = 20670, memory_seq_rm [20670, end)
slot update_slots: id  3 | task 9939 | prompt processing progress, n_tokens = 20727, batch.n_tokens = 57, progress = 1.000000
slot update_slots: id  3 | task 9939 | prompt done, n_tokens = 20727, batch.n_tokens = 57
slot init_sampler: id  3 | task 9939 | init sampler, took 3.22 ms, tokens: text = 20727, total = 20727
slot print_timing: id  3 | task 9939 | 
prompt eval time =     173.97 ms /    57 tokens (    3.05 ms per token,   327.63 tokens per second)
       eval time =    1814.34 ms /    71 tokens (   25.55 ms per token,    39.13 tokens per second)
      total time =    1988.31 ms /   128 tokens
slot      release: id  3 | task 9939 | stop processing: n_tokens = 20797, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10011 | processing task, is_child = 0
slot update_slots: id  3 | task 10011 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20784
slot update_slots: id  3 | task 10011 | n_tokens = 20727, memory_seq_rm [20727, end)
slot update_slots: id  3 | task 10011 | prompt processing progress, n_tokens = 20784, batch.n_tokens = 57, progress = 1.000000
slot update_slots: id  3 | task 10011 | prompt done, n_tokens = 20784, batch.n_tokens = 57
slot init_sampler: id  3 | task 10011 | init sampler, took 2.97 ms, tokens: text = 20784, total = 20784
slot update_slots: id  3 | task 10011 | erasing old context checkpoint (pos_min = 15516, pos_max = 16204, size = 16.157 MiB)
slot update_slots: id  3 | task 10011 | created context checkpoint 8 of 8 (pos_min = 19773, pos_max = 20726, size = 22.371 MiB)
slot print_timing: id  3 | task 10011 | 
prompt eval time =     191.29 ms /    57 tokens (    3.36 ms per token,   297.97 tokens per second)
       eval time =    2043.24 ms /    80 tokens (   25.54 ms per token,    39.15 tokens per second)
      total time =    2234.54 ms /   137 tokens
slot      release: id  3 | task 10011 | stop processing: n_tokens = 20863, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.973 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10092 | processing task, is_child = 0
slot update_slots: id  3 | task 10092 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 21352
slot update_slots: id  3 | task 10092 | n_tokens = 20784, memory_seq_rm [20784, end)
slot update_slots: id  3 | task 10092 | prompt processing progress, n_tokens = 21288, batch.n_tokens = 504, progress = 0.997003
slot update_slots: id  3 | task 10092 | n_tokens = 21288, memory_seq_rm [21288, end)
slot update_slots: id  3 | task 10092 | prompt processing progress, n_tokens = 21352, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 10092 | prompt done, n_tokens = 21352, batch.n_tokens = 64
slot init_sampler: id  3 | task 10092 | init sampler, took 3.53 ms, tokens: text = 21352, total = 21352
slot update_slots: id  3 | task 10092 | erasing old context checkpoint (pos_min = 15737, pos_max = 16326, size = 13.835 MiB)
slot update_slots: id  3 | task 10092 | created context checkpoint 8 of 8 (pos_min = 20264, pos_max = 21287, size = 24.012 MiB)
slot print_timing: id  3 | task 10092 | 
prompt eval time =     829.81 ms /   568 tokens (    1.46 ms per token,   684.50 tokens per second)
       eval time =    2194.86 ms /    85 tokens (   25.82 ms per token,    38.73 tokens per second)
      total time =    3024.67 ms /   653 tokens
slot      release: id  3 | task 10092 | stop processing: n_tokens = 21436, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.975 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10179 | processing task, is_child = 0
slot update_slots: id  3 | task 10179 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 21901
slot update_slots: id  3 | task 10179 | n_tokens = 21352, memory_seq_rm [21352, end)
slot update_slots: id  3 | task 10179 | prompt processing progress, n_tokens = 21837, batch.n_tokens = 485, progress = 0.997078
slot update_slots: id  3 | task 10179 | n_tokens = 21837, memory_seq_rm [21837, end)
slot update_slots: id  3 | task 10179 | prompt processing progress, n_tokens = 21901, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 10179 | prompt done, n_tokens = 21901, batch.n_tokens = 64
slot init_sampler: id  3 | task 10179 | init sampler, took 4.33 ms, tokens: text = 21901, total = 21901
slot update_slots: id  3 | task 10179 | erasing old context checkpoint (pos_min = 15964, pos_max = 16881, size = 21.526 MiB)
slot update_slots: id  3 | task 10179 | created context checkpoint 8 of 8 (pos_min = 20813, pos_max = 21836, size = 24.012 MiB)
slot print_timing: id  3 | task 10179 | 
prompt eval time =     809.81 ms /   549 tokens (    1.48 ms per token,   677.94 tokens per second)
       eval time =    2106.73 ms /    81 tokens (   26.01 ms per token,    38.45 tokens per second)
      total time =    2916.55 ms /   630 tokens
slot      release: id  3 | task 10179 | stop processing: n_tokens = 21981, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10262 | processing task, is_child = 0
slot update_slots: id  3 | task 10262 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 21958
slot update_slots: id  3 | task 10262 | n_tokens = 21901, memory_seq_rm [21901, end)
slot update_slots: id  3 | task 10262 | prompt processing progress, n_tokens = 21958, batch.n_tokens = 57, progress = 1.000000
slot update_slots: id  3 | task 10262 | prompt done, n_tokens = 21958, batch.n_tokens = 57
slot init_sampler: id  3 | task 10262 | init sampler, took 3.25 ms, tokens: text = 21958, total = 21958
slot print_timing: id  3 | task 10262 | 
prompt eval time =     174.58 ms /    57 tokens (    3.06 ms per token,   326.50 tokens per second)
       eval time =    1753.53 ms /    68 tokens (   25.79 ms per token,    38.78 tokens per second)
      total time =    1928.11 ms /   125 tokens
slot      release: id  3 | task 10262 | stop processing: n_tokens = 22025, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.920 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10331 | processing task, is_child = 0
slot update_slots: id  3 | task 10331 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23880
slot update_slots: id  3 | task 10331 | n_tokens = 21958, memory_seq_rm [21958, end)
slot update_slots: id  3 | task 10331 | prompt processing progress, n_tokens = 23816, batch.n_tokens = 1858, progress = 0.997320
slot update_slots: id  3 | task 10331 | n_tokens = 23816, memory_seq_rm [23816, end)
slot update_slots: id  3 | task 10331 | prompt processing progress, n_tokens = 23880, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 10331 | prompt done, n_tokens = 23880, batch.n_tokens = 64
slot init_sampler: id  3 | task 10331 | init sampler, took 3.43 ms, tokens: text = 23880, total = 23880
slot update_slots: id  3 | task 10331 | erasing old context checkpoint (pos_min = 16449, pos_max = 17430, size = 23.027 MiB)
slot update_slots: id  3 | task 10331 | created context checkpoint 8 of 8 (pos_min = 22792, pos_max = 23815, size = 24.012 MiB)
slot print_timing: id  3 | task 10331 | 
prompt eval time =    2577.40 ms /  1922 tokens (    1.34 ms per token,   745.71 tokens per second)
       eval time =    1559.48 ms /    60 tokens (   25.99 ms per token,    38.47 tokens per second)
      total time =    4136.88 ms /  1982 tokens
slot      release: id  3 | task 10331 | stop processing: n_tokens = 23939, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10393 | processing task, is_child = 0
slot update_slots: id  3 | task 10393 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23937
slot update_slots: id  3 | task 10393 | n_tokens = 23880, memory_seq_rm [23880, end)
slot update_slots: id  3 | task 10393 | prompt processing progress, n_tokens = 23937, batch.n_tokens = 57, progress = 1.000000
slot update_slots: id  3 | task 10393 | prompt done, n_tokens = 23937, batch.n_tokens = 57
slot init_sampler: id  3 | task 10393 | init sampler, took 3.34 ms, tokens: text = 23937, total = 23937
slot print_timing: id  3 | task 10393 | 
prompt eval time =     174.07 ms /    57 tokens (    3.05 ms per token,   327.46 tokens per second)
       eval time =   11114.09 ms /   426 tokens (   26.09 ms per token,    38.33 tokens per second)
      total time =   11288.16 ms /   483 tokens
slot      release: id  3 | task 10393 | stop processing: n_tokens = 24362, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.983
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10820 | processing task, is_child = 0
slot update_slots: id  3 | task 10820 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 24242
slot update_slots: id  3 | task 10820 | n_tokens = 23937, memory_seq_rm [23937, end)
slot update_slots: id  3 | task 10820 | prompt processing progress, n_tokens = 24178, batch.n_tokens = 241, progress = 0.997360
slot update_slots: id  3 | task 10820 | n_tokens = 24178, memory_seq_rm [24178, end)
slot update_slots: id  3 | task 10820 | prompt processing progress, n_tokens = 24242, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 10820 | prompt done, n_tokens = 24242, batch.n_tokens = 64
slot init_sampler: id  3 | task 10820 | init sampler, took 3.44 ms, tokens: text = 24242, total = 24242
slot update_slots: id  3 | task 10820 | erasing old context checkpoint (pos_min = 18329, pos_max = 19352, size = 24.012 MiB)
slot update_slots: id  3 | task 10820 | created context checkpoint 8 of 8 (pos_min = 23338, pos_max = 24177, size = 19.697 MiB)
slot print_timing: id  3 | task 10820 | 
prompt eval time =     646.99 ms /   305 tokens (    2.12 ms per token,   471.42 tokens per second)
       eval time =    3298.76 ms /   125 tokens (   26.39 ms per token,    37.89 tokens per second)
      total time =    3945.75 ms /   430 tokens
slot      release: id  3 | task 10820 | stop processing: n_tokens = 24366, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.975 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10947 | processing task, is_child = 0
slot update_slots: id  3 | task 10947 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 24867
slot update_slots: id  3 | task 10947 | n_tokens = 24242, memory_seq_rm [24242, end)
slot update_slots: id  3 | task 10947 | prompt processing progress, n_tokens = 24803, batch.n_tokens = 561, progress = 0.997426
slot update_slots: id  3 | task 10947 | n_tokens = 24803, memory_seq_rm [24803, end)
slot update_slots: id  3 | task 10947 | prompt processing progress, n_tokens = 24867, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 10947 | prompt done, n_tokens = 24867, batch.n_tokens = 64
slot init_sampler: id  3 | task 10947 | init sampler, took 4.91 ms, tokens: text = 24867, total = 24867
slot update_slots: id  3 | task 10947 | erasing old context checkpoint (pos_min = 18715, pos_max = 19738, size = 24.012 MiB)
slot update_slots: id  3 | task 10947 | created context checkpoint 8 of 8 (pos_min = 23937, pos_max = 24802, size = 20.307 MiB)
slot print_timing: id  3 | task 10947 | 
prompt eval time =    1052.88 ms /   625 tokens (    1.68 ms per token,   593.61 tokens per second)
       eval time =    3272.82 ms /   125 tokens (   26.18 ms per token,    38.19 tokens per second)
      total time =    4325.70 ms /   750 tokens
slot      release: id  3 | task 10947 | stop processing: n_tokens = 24991, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11074 | processing task, is_child = 0
slot update_slots: id  3 | task 11074 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 24925
slot update_slots: id  3 | task 11074 | n_tokens = 24867, memory_seq_rm [24867, end)
slot update_slots: id  3 | task 11074 | prompt processing progress, n_tokens = 24925, batch.n_tokens = 58, progress = 1.000000
slot update_slots: id  3 | task 11074 | prompt done, n_tokens = 24925, batch.n_tokens = 58
slot init_sampler: id  3 | task 11074 | init sampler, took 3.54 ms, tokens: text = 24925, total = 24925
slot print_timing: id  3 | task 11074 | 
prompt eval time =     178.32 ms /    58 tokens (    3.07 ms per token,   325.26 tokens per second)
       eval time =    9964.63 ms /   377 tokens (   26.43 ms per token,    37.83 tokens per second)
      total time =   10142.95 ms /   435 tokens
slot      release: id  3 | task 11074 | stop processing: n_tokens = 25301, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11452 | processing task, is_child = 0
slot update_slots: id  3 | task 11452 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 25230
slot update_slots: id  3 | task 11452 | n_tokens = 24925, memory_seq_rm [24925, end)
slot update_slots: id  3 | task 11452 | prompt processing progress, n_tokens = 25166, batch.n_tokens = 241, progress = 0.997463
slot update_slots: id  3 | task 11452 | n_tokens = 25166, memory_seq_rm [25166, end)
slot update_slots: id  3 | task 11452 | prompt processing progress, n_tokens = 25230, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11452 | prompt done, n_tokens = 25230, batch.n_tokens = 64
slot init_sampler: id  3 | task 11452 | init sampler, took 3.52 ms, tokens: text = 25230, total = 25230
slot update_slots: id  3 | task 11452 | erasing old context checkpoint (pos_min = 19277, pos_max = 20300, size = 24.012 MiB)
slot update_slots: id  3 | task 11452 | created context checkpoint 8 of 8 (pos_min = 24371, pos_max = 25165, size = 18.642 MiB)
slot print_timing: id  3 | task 11452 | 
prompt eval time =     651.77 ms /   305 tokens (    2.14 ms per token,   467.96 tokens per second)
       eval time =    2151.46 ms /    82 tokens (   26.24 ms per token,    38.11 tokens per second)
      total time =    2803.23 ms /   387 tokens
slot      release: id  3 | task 11452 | stop processing: n_tokens = 25311, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11536 | processing task, is_child = 0
slot update_slots: id  3 | task 11536 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 25287
slot update_slots: id  3 | task 11536 | n_tokens = 25230, memory_seq_rm [25230, end)
slot update_slots: id  3 | task 11536 | prompt processing progress, n_tokens = 25287, batch.n_tokens = 57, progress = 1.000000
slot update_slots: id  3 | task 11536 | prompt done, n_tokens = 25287, batch.n_tokens = 57
slot init_sampler: id  3 | task 11536 | init sampler, took 3.52 ms, tokens: text = 25287, total = 25287
slot print_timing: id  3 | task 11536 | 
prompt eval time =     177.43 ms /    57 tokens (    3.11 ms per token,   321.26 tokens per second)
       eval time =    1264.48 ms /    48 tokens (   26.34 ms per token,    37.96 tokens per second)
      total time =    1441.91 ms /   105 tokens
slot      release: id  3 | task 11536 | stop processing: n_tokens = 25334, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.979 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11585 | processing task, is_child = 0
slot update_slots: id  3 | task 11585 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 25836
slot update_slots: id  3 | task 11585 | n_tokens = 25287, memory_seq_rm [25287, end)
slot update_slots: id  3 | task 11585 | prompt processing progress, n_tokens = 25772, batch.n_tokens = 485, progress = 0.997523
slot update_slots: id  3 | task 11585 | n_tokens = 25772, memory_seq_rm [25772, end)
slot update_slots: id  3 | task 11585 | prompt processing progress, n_tokens = 25836, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11585 | prompt done, n_tokens = 25836, batch.n_tokens = 64
slot init_sampler: id  3 | task 11585 | init sampler, took 3.68 ms, tokens: text = 25836, total = 25836
slot update_slots: id  3 | task 11585 | erasing old context checkpoint (pos_min = 19699, pos_max = 20605, size = 21.268 MiB)
slot update_slots: id  3 | task 11585 | created context checkpoint 8 of 8 (pos_min = 24842, pos_max = 25771, size = 21.808 MiB)
slot print_timing: id  3 | task 11585 | 
prompt eval time =     859.17 ms /   549 tokens (    1.56 ms per token,   638.99 tokens per second)
       eval time =    2258.16 ms /    86 tokens (   26.26 ms per token,    38.08 tokens per second)
      total time =    3117.33 ms /   635 tokens
slot      release: id  3 | task 11585 | stop processing: n_tokens = 25921, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.975 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11673 | processing task, is_child = 0
slot update_slots: id  3 | task 11673 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 26512
slot update_slots: id  3 | task 11673 | n_tokens = 25836, memory_seq_rm [25836, end)
slot update_slots: id  3 | task 11673 | prompt processing progress, n_tokens = 26448, batch.n_tokens = 612, progress = 0.997586
slot update_slots: id  3 | task 11673 | n_tokens = 26448, memory_seq_rm [26448, end)
slot update_slots: id  3 | task 11673 | prompt processing progress, n_tokens = 26512, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11673 | prompt done, n_tokens = 26512, batch.n_tokens = 64
slot init_sampler: id  3 | task 11673 | init sampler, took 4.21 ms, tokens: text = 26512, total = 26512
slot update_slots: id  3 | task 11673 | erasing old context checkpoint (pos_min = 19773, pos_max = 20726, size = 22.371 MiB)
slot update_slots: id  3 | task 11673 | created context checkpoint 8 of 8 (pos_min = 25479, pos_max = 26447, size = 22.722 MiB)
slot print_timing: id  3 | task 11673 | 
prompt eval time =    1122.23 ms /   676 tokens (    1.66 ms per token,   602.37 tokens per second)
       eval time =    2946.43 ms /   111 tokens (   26.54 ms per token,    37.67 tokens per second)
      total time =    4068.66 ms /   787 tokens
slot      release: id  3 | task 11673 | stop processing: n_tokens = 26622, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.982 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11786 | processing task, is_child = 0
slot update_slots: id  3 | task 11786 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 26985
slot update_slots: id  3 | task 11786 | n_tokens = 26512, memory_seq_rm [26512, end)
slot update_slots: id  3 | task 11786 | prompt processing progress, n_tokens = 26921, batch.n_tokens = 409, progress = 0.997628
slot update_slots: id  3 | task 11786 | n_tokens = 26921, memory_seq_rm [26921, end)
slot update_slots: id  3 | task 11786 | prompt processing progress, n_tokens = 26985, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11786 | prompt done, n_tokens = 26985, batch.n_tokens = 64
slot init_sampler: id  3 | task 11786 | init sampler, took 3.75 ms, tokens: text = 26985, total = 26985
slot update_slots: id  3 | task 11786 | erasing old context checkpoint (pos_min = 20264, pos_max = 21287, size = 24.012 MiB)
slot update_slots: id  3 | task 11786 | created context checkpoint 8 of 8 (pos_min = 25897, pos_max = 26920, size = 24.012 MiB)
slot print_timing: id  3 | task 11786 | 
prompt eval time =     758.94 ms /   473 tokens (    1.60 ms per token,   623.24 tokens per second)
       eval time =    3320.05 ms /   126 tokens (   26.35 ms per token,    37.95 tokens per second)
      total time =    4078.99 ms /   599 tokens
slot      release: id  3 | task 11786 | stop processing: n_tokens = 27110, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11914 | processing task, is_child = 0
slot update_slots: id  3 | task 11914 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 27042
slot update_slots: id  3 | task 11914 | n_tokens = 26985, memory_seq_rm [26985, end)
slot update_slots: id  3 | task 11914 | prompt processing progress, n_tokens = 27042, batch.n_tokens = 57, progress = 1.000000
slot update_slots: id  3 | task 11914 | prompt done, n_tokens = 27042, batch.n_tokens = 57
slot init_sampler: id  3 | task 11914 | init sampler, took 3.81 ms, tokens: text = 27042, total = 27042
slot print_timing: id  3 | task 11914 | 
prompt eval time =     180.62 ms /    57 tokens (    3.17 ms per token,   315.57 tokens per second)
       eval time =    3324.66 ms /   126 tokens (   26.39 ms per token,    37.90 tokens per second)
      total time =    3505.28 ms /   183 tokens
slot      release: id  3 | task 11914 | stop processing: n_tokens = 27167, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.983 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12041 | processing task, is_child = 0
slot update_slots: id  3 | task 12041 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 27497
slot update_slots: id  3 | task 12041 | n_tokens = 27042, memory_seq_rm [27042, end)
slot update_slots: id  3 | task 12041 | prompt processing progress, n_tokens = 27433, batch.n_tokens = 391, progress = 0.997672
slot update_slots: id  3 | task 12041 | n_tokens = 27433, memory_seq_rm [27433, end)
slot update_slots: id  3 | task 12041 | prompt processing progress, n_tokens = 27497, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12041 | prompt done, n_tokens = 27497, batch.n_tokens = 64
slot init_sampler: id  3 | task 12041 | init sampler, took 5.56 ms, tokens: text = 27497, total = 27497
slot update_slots: id  3 | task 12041 | erasing old context checkpoint (pos_min = 20813, pos_max = 21836, size = 24.012 MiB)
slot update_slots: id  3 | task 12041 | created context checkpoint 8 of 8 (pos_min = 26409, pos_max = 27432, size = 24.012 MiB)
slot print_timing: id  3 | task 12041 | 
prompt eval time =     748.94 ms /   455 tokens (    1.65 ms per token,   607.53 tokens per second)
       eval time =   10128.38 ms /   383 tokens (   26.44 ms per token,    37.81 tokens per second)
      total time =   10877.32 ms /   838 tokens
slot      release: id  3 | task 12041 | stop processing: n_tokens = 27879, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.986
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12426 | processing task, is_child = 0
slot update_slots: id  3 | task 12426 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 27817
slot update_slots: id  3 | task 12426 | n_tokens = 27497, memory_seq_rm [27497, end)
slot update_slots: id  3 | task 12426 | prompt processing progress, n_tokens = 27753, batch.n_tokens = 256, progress = 0.997699
slot update_slots: id  3 | task 12426 | n_tokens = 27753, memory_seq_rm [27753, end)
slot update_slots: id  3 | task 12426 | prompt processing progress, n_tokens = 27817, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12426 | prompt done, n_tokens = 27817, batch.n_tokens = 64
slot init_sampler: id  3 | task 12426 | init sampler, took 4.00 ms, tokens: text = 27817, total = 27817
slot update_slots: id  3 | task 12426 | erasing old context checkpoint (pos_min = 22792, pos_max = 23815, size = 24.012 MiB)
slot update_slots: id  3 | task 12426 | created context checkpoint 8 of 8 (pos_min = 26855, pos_max = 27752, size = 21.057 MiB)
slot print_timing: id  3 | task 12426 | 
prompt eval time =     677.41 ms /   320 tokens (    2.12 ms per token,   472.38 tokens per second)
       eval time =    2968.94 ms /   110 tokens (   26.99 ms per token,    37.05 tokens per second)
      total time =    3646.36 ms /   430 tokens
slot      release: id  3 | task 12426 | stop processing: n_tokens = 27926, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12538 | processing task, is_child = 0
slot update_slots: id  3 | task 12538 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 27875
slot update_slots: id  3 | task 12538 | n_tokens = 27817, memory_seq_rm [27817, end)
slot update_slots: id  3 | task 12538 | prompt processing progress, n_tokens = 27875, batch.n_tokens = 58, progress = 1.000000
slot update_slots: id  3 | task 12538 | prompt done, n_tokens = 27875, batch.n_tokens = 58
slot init_sampler: id  3 | task 12538 | init sampler, took 3.88 ms, tokens: text = 27875, total = 27875
slot print_timing: id  3 | task 12538 | 
prompt eval time =     182.84 ms /    58 tokens (    3.15 ms per token,   317.22 tokens per second)
       eval time =    1517.00 ms /    56 tokens (   27.09 ms per token,    36.91 tokens per second)
      total time =    1699.84 ms /   114 tokens
slot      release: id  3 | task 12538 | stop processing: n_tokens = 27930, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.864 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12595 | processing task, is_child = 0
slot update_slots: id  3 | task 12595 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32281
slot update_slots: id  3 | task 12595 | n_tokens = 27875, memory_seq_rm [27875, end)
slot update_slots: id  3 | task 12595 | prompt processing progress, n_tokens = 29923, batch.n_tokens = 2048, progress = 0.926954
slot update_slots: id  3 | task 12595 | n_tokens = 29923, memory_seq_rm [29923, end)
slot update_slots: id  3 | task 12595 | prompt processing progress, n_tokens = 31971, batch.n_tokens = 2048, progress = 0.990397
slot update_slots: id  3 | task 12595 | n_tokens = 31971, memory_seq_rm [31971, end)
slot update_slots: id  3 | task 12595 | prompt processing progress, n_tokens = 32217, batch.n_tokens = 246, progress = 0.998017
slot update_slots: id  3 | task 12595 | n_tokens = 32217, memory_seq_rm [32217, end)
slot update_slots: id  3 | task 12595 | prompt processing progress, n_tokens = 32281, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12595 | prompt done, n_tokens = 32281, batch.n_tokens = 64
slot init_sampler: id  3 | task 12595 | init sampler, took 5.29 ms, tokens: text = 32281, total = 32281
slot update_slots: id  3 | task 12595 | erasing old context checkpoint (pos_min = 23338, pos_max = 24177, size = 19.697 MiB)
slot update_slots: id  3 | task 12595 | created context checkpoint 8 of 8 (pos_min = 31193, pos_max = 32216, size = 24.012 MiB)
slot print_timing: id  3 | task 12595 | 
prompt eval time =    6249.41 ms /  4406 tokens (    1.42 ms per token,   705.03 tokens per second)
       eval time =    1598.03 ms /    58 tokens (   27.55 ms per token,    36.29 tokens per second)
      total time =    7847.44 ms /  4464 tokens
slot      release: id  3 | task 12595 | stop processing: n_tokens = 32338, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.973 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12657 | processing task, is_child = 0
slot update_slots: id  3 | task 12657 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 33173
slot update_slots: id  3 | task 12657 | n_tokens = 32281, memory_seq_rm [32281, end)
slot update_slots: id  3 | task 12657 | prompt processing progress, n_tokens = 33109, batch.n_tokens = 828, progress = 0.998071
slot update_slots: id  3 | task 12657 | n_tokens = 33109, memory_seq_rm [33109, end)
slot update_slots: id  3 | task 12657 | prompt processing progress, n_tokens = 33173, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12657 | prompt done, n_tokens = 33173, batch.n_tokens = 64
slot init_sampler: id  3 | task 12657 | init sampler, took 4.97 ms, tokens: text = 33173, total = 33173
slot update_slots: id  3 | task 12657 | erasing old context checkpoint (pos_min = 23937, pos_max = 24802, size = 20.307 MiB)
slot update_slots: id  3 | task 12657 | created context checkpoint 8 of 8 (pos_min = 32085, pos_max = 33108, size = 24.012 MiB)
slot print_timing: id  3 | task 12657 | 
prompt eval time =    1459.86 ms /   892 tokens (    1.64 ms per token,   611.02 tokens per second)
       eval time =   13701.40 ms /   506 tokens (   27.08 ms per token,    36.93 tokens per second)
      total time =   15161.25 ms /  1398 tokens
slot      release: id  3 | task 12657 | stop processing: n_tokens = 33678, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 13165 | processing task, is_child = 0
slot update_slots: id  3 | task 13165 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 33520
slot update_slots: id  3 | task 13165 | n_tokens = 33173, memory_seq_rm [33173, end)
slot update_slots: id  3 | task 13165 | prompt processing progress, n_tokens = 33456, batch.n_tokens = 283, progress = 0.998091
slot update_slots: id  3 | task 13165 | n_tokens = 33456, memory_seq_rm [33456, end)
slot update_slots: id  3 | task 13165 | prompt processing progress, n_tokens = 33520, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 13165 | prompt done, n_tokens = 33520, batch.n_tokens = 64
slot init_sampler: id  3 | task 13165 | init sampler, took 4.68 ms, tokens: text = 33520, total = 33520
slot update_slots: id  3 | task 13165 | erasing old context checkpoint (pos_min = 24371, pos_max = 25165, size = 18.642 MiB)
slot update_slots: id  3 | task 13165 | created context checkpoint 8 of 8 (pos_min = 32654, pos_max = 33455, size = 18.806 MiB)
slot print_timing: id  3 | task 13165 | 
prompt eval time =     695.94 ms /   347 tokens (    2.01 ms per token,   498.61 tokens per second)
       eval time =    1501.25 ms /    55 tokens (   27.30 ms per token,    36.64 tokens per second)
      total time =    2197.19 ms /   402 tokens
slot      release: id  3 | task 13165 | stop processing: n_tokens = 33574, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 13222 | processing task, is_child = 0
slot update_slots: id  3 | task 13222 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 33578
slot update_slots: id  3 | task 13222 | n_tokens = 33520, memory_seq_rm [33520, end)
slot update_slots: id  3 | task 13222 | prompt processing progress, n_tokens = 33578, batch.n_tokens = 58, progress = 1.000000
slot update_slots: id  3 | task 13222 | prompt done, n_tokens = 33578, batch.n_tokens = 58
slot init_sampler: id  3 | task 13222 | init sampler, took 4.60 ms, tokens: text = 33578, total = 33578
slot print_timing: id  3 | task 13222 | 
prompt eval time =     186.02 ms /    58 tokens (    3.21 ms per token,   311.80 tokens per second)
       eval time =    1792.15 ms /    66 tokens (   27.15 ms per token,    36.83 tokens per second)
      total time =    1978.17 ms /   124 tokens
slot      release: id  3 | task 13222 | stop processing: n_tokens = 33643, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.981 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 13289 | processing task, is_child = 0
slot update_slots: id  3 | task 13289 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 34244
slot update_slots: id  3 | task 13289 | n_tokens = 33578, memory_seq_rm [33578, end)
slot update_slots: id  3 | task 13289 | prompt processing progress, n_tokens = 34180, batch.n_tokens = 602, progress = 0.998131
slot update_slots: id  3 | task 13289 | n_tokens = 34180, memory_seq_rm [34180, end)
slot update_slots: id  3 | task 13289 | prompt processing progress, n_tokens = 34244, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 13289 | prompt done, n_tokens = 34244, batch.n_tokens = 64
slot init_sampler: id  3 | task 13289 | init sampler, took 4.85 ms, tokens: text = 34244, total = 34244
slot update_slots: id  3 | task 13289 | erasing old context checkpoint (pos_min = 24842, pos_max = 25771, size = 21.808 MiB)
slot update_slots: id  3 | task 13289 | created context checkpoint 8 of 8 (pos_min = 33156, pos_max = 34179, size = 24.012 MiB)
slot print_timing: id  3 | task 13289 | 
prompt eval time =    1218.57 ms /   666 tokens (    1.83 ms per token,   546.54 tokens per second)
       eval time =    1547.14 ms /    56 tokens (   27.63 ms per token,    36.20 tokens per second)
      total time =    2765.71 ms /   722 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 13289 | stop processing: n_tokens = 34299, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 13347 | processing task, is_child = 0
slot update_slots: id  3 | task 13347 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 34299
slot update_slots: id  3 | task 13347 | n_tokens = 34244, memory_seq_rm [34244, end)
slot update_slots: id  3 | task 13347 | prompt processing progress, n_tokens = 34299, batch.n_tokens = 55, progress = 1.000000
slot update_slots: id  3 | task 13347 | prompt done, n_tokens = 34299, batch.n_tokens = 55
slot init_sampler: id  3 | task 13347 | init sampler, took 7.37 ms, tokens: text = 34299, total = 34299
slot print_timing: id  3 | task 13347 | 
prompt eval time =     189.05 ms /    55 tokens (    3.44 ms per token,   290.93 tokens per second)
       eval time =    4168.10 ms /   153 tokens (   27.24 ms per token,    36.71 tokens per second)
      total time =    4357.14 ms /   208 tokens
slot      release: id  3 | task 13347 | stop processing: n_tokens = 34451, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.972 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 13501 | processing task, is_child = 0
slot update_slots: id  3 | task 13501 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 35293
slot update_slots: id  3 | task 13501 | n_tokens = 34299, memory_seq_rm [34299, end)
slot update_slots: id  3 | task 13501 | prompt processing progress, n_tokens = 35229, batch.n_tokens = 930, progress = 0.998187
slot update_slots: id  3 | task 13501 | n_tokens = 35229, memory_seq_rm [35229, end)
slot update_slots: id  3 | task 13501 | prompt processing progress, n_tokens = 35293, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 13501 | prompt done, n_tokens = 35293, batch.n_tokens = 64
slot init_sampler: id  3 | task 13501 | init sampler, took 5.17 ms, tokens: text = 35293, total = 35293
slot update_slots: id  3 | task 13501 | erasing old context checkpoint (pos_min = 25479, pos_max = 26447, size = 22.722 MiB)
slot update_slots: id  3 | task 13501 | created context checkpoint 8 of 8 (pos_min = 34205, pos_max = 35228, size = 24.012 MiB)
slot print_timing: id  3 | task 13501 | 
prompt eval time =    1587.30 ms /   994 tokens (    1.60 ms per token,   626.22 tokens per second)
       eval time =    3902.26 ms /   143 tokens (   27.29 ms per token,    36.65 tokens per second)
      total time =    5489.55 ms /  1137 tokens
slot      release: id  3 | task 13501 | stop processing: n_tokens = 35435, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 13646 | processing task, is_child = 0
slot update_slots: id  3 | task 13646 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 35375
slot update_slots: id  3 | task 13646 | n_tokens = 35293, memory_seq_rm [35293, end)
slot update_slots: id  3 | task 13646 | prompt processing progress, n_tokens = 35311, batch.n_tokens = 18, progress = 0.998191
slot update_slots: id  3 | task 13646 | n_tokens = 35311, memory_seq_rm [35311, end)
slot update_slots: id  3 | task 13646 | prompt processing progress, n_tokens = 35375, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 13646 | prompt done, n_tokens = 35375, batch.n_tokens = 64
slot init_sampler: id  3 | task 13646 | init sampler, took 6.95 ms, tokens: text = 35375, total = 35375
slot update_slots: id  3 | task 13646 | erasing old context checkpoint (pos_min = 25897, pos_max = 26920, size = 24.012 MiB)
slot update_slots: id  3 | task 13646 | created context checkpoint 8 of 8 (pos_min = 34411, pos_max = 35310, size = 21.104 MiB)
slot print_timing: id  3 | task 13646 | 
prompt eval time =     325.43 ms /    82 tokens (    3.97 ms per token,   251.98 tokens per second)
       eval time =   79543.41 ms /  2875 tokens (   27.67 ms per token,    36.14 tokens per second)
      total time =   79868.84 ms /  2957 tokens
slot      release: id  3 | task 13646 | stop processing: n_tokens = 38249, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.928 (> 0.100 thold), f_keep = 0.925
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16523 | processing task, is_child = 0
slot update_slots: id  3 | task 16523 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 38135
slot update_slots: id  3 | task 16523 | n_past = 35375, slot.prompt.tokens.size() = 38249, seq_id = 3, pos_min = 37225, n_swa = 128
slot update_slots: id  3 | task 16523 | restored context checkpoint (pos_min = 34411, pos_max = 35310, size = 21.104 MiB)
slot update_slots: id  3 | task 16523 | n_tokens = 35310, memory_seq_rm [35310, end)
slot update_slots: id  3 | task 16523 | prompt processing progress, n_tokens = 37358, batch.n_tokens = 2048, progress = 0.979625
slot update_slots: id  3 | task 16523 | n_tokens = 37358, memory_seq_rm [37358, end)
slot update_slots: id  3 | task 16523 | prompt processing progress, n_tokens = 38071, batch.n_tokens = 713, progress = 0.998322
slot update_slots: id  3 | task 16523 | n_tokens = 38071, memory_seq_rm [38071, end)
slot update_slots: id  3 | task 16523 | prompt processing progress, n_tokens = 38135, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 16523 | prompt done, n_tokens = 38135, batch.n_tokens = 64
slot init_sampler: id  3 | task 16523 | init sampler, took 5.70 ms, tokens: text = 38135, total = 38135
slot update_slots: id  3 | task 16523 | erasing old context checkpoint (pos_min = 26409, pos_max = 27432, size = 24.012 MiB)
slot update_slots: id  3 | task 16523 | created context checkpoint 8 of 8 (pos_min = 37047, pos_max = 38070, size = 24.012 MiB)
slot print_timing: id  3 | task 16523 | 
prompt eval time =    4420.67 ms /  2825 tokens (    1.56 ms per token,   639.04 tokens per second)
       eval time =     937.16 ms /    35 tokens (   26.78 ms per token,    37.35 tokens per second)
      total time =    5357.84 ms /  2860 tokens
slot      release: id  3 | task 16523 | stop processing: n_tokens = 38169, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.362 (> 0.100 thold), f_keep = 0.007
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 38169, total state size = 919.035 MiB
srv          load:  - looking for better prompt, base f_keep = 0.007, sim = 0.362
srv        update:  - cache state: 3 prompts, 1597.912 MiB (limits: 8192.000 MiB, 64000 tokens, 246024 est)
srv        update:    - prompt 0x5a234b577500:    4873 tokens, checkpoints:  5,   235.945 MiB
srv        update:    - prompt 0x5a234d243b70:    4947 tokens, checkpoints:  7,   261.904 MiB
srv        update:    - prompt 0x5a234cfbeaa0:   38169 tokens, checkpoints:  8,  1100.063 MiB
srv  get_availabl: prompt cache update took 883.42 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16561 | processing task, is_child = 0
slot update_slots: id  3 | task 16561 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 740
slot update_slots: id  3 | task 16561 | n_past = 268, slot.prompt.tokens.size() = 38169, seq_id = 3, pos_min = 37145, n_swa = 128
slot update_slots: id  3 | task 16561 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  3 | task 16561 | erased invalidated context checkpoint (pos_min = 26855, pos_max = 27752, n_swa = 128, size = 21.057 MiB)
slot update_slots: id  3 | task 16561 | erased invalidated context checkpoint (pos_min = 31193, pos_max = 32216, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 16561 | erased invalidated context checkpoint (pos_min = 32085, pos_max = 33108, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 16561 | erased invalidated context checkpoint (pos_min = 32654, pos_max = 33455, n_swa = 128, size = 18.806 MiB)
slot update_slots: id  3 | task 16561 | erased invalidated context checkpoint (pos_min = 33156, pos_max = 34179, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 16561 | erased invalidated context checkpoint (pos_min = 34205, pos_max = 35228, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 16561 | erased invalidated context checkpoint (pos_min = 34411, pos_max = 35310, n_swa = 128, size = 21.104 MiB)
slot update_slots: id  3 | task 16561 | erased invalidated context checkpoint (pos_min = 37047, pos_max = 38070, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 16561 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  3 | task 16561 | prompt processing progress, n_tokens = 676, batch.n_tokens = 676, progress = 0.913514
slot update_slots: id  3 | task 16561 | n_tokens = 676, memory_seq_rm [676, end)
slot update_slots: id  3 | task 16561 | prompt processing progress, n_tokens = 740, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 16561 | prompt done, n_tokens = 740, batch.n_tokens = 64
slot init_sampler: id  3 | task 16561 | init sampler, took 0.14 ms, tokens: text = 740, total = 740
slot update_slots: id  3 | task 16561 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 675, size = 15.852 MiB)
slot print_timing: id  3 | task 16561 | 
prompt eval time =     910.24 ms /   740 tokens (    1.23 ms per token,   812.98 tokens per second)
       eval time =   33081.88 ms /  1384 tokens (   23.90 ms per token,    41.84 tokens per second)
      total time =   33992.12 ms /  2124 tokens
slot      release: id  3 | task 16561 | stop processing: n_tokens = 2123, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LRU, t_last = -1
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 17947 | processing task, is_child = 0
slot update_slots: id  2 | task 17947 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 11179
slot update_slots: id  2 | task 17947 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 17947 | prompt processing progress, n_tokens = 2048, batch.n_tokens = 2048, progress = 0.183201
slot update_slots: id  2 | task 17947 | n_tokens = 2048, memory_seq_rm [2048, end)
slot update_slots: id  2 | task 17947 | prompt processing progress, n_tokens = 4096, batch.n_tokens = 2048, progress = 0.366401
slot update_slots: id  2 | task 17947 | n_tokens = 4096, memory_seq_rm [4096, end)
slot update_slots: id  2 | task 17947 | prompt processing progress, n_tokens = 6144, batch.n_tokens = 2048, progress = 0.549602
slot update_slots: id  2 | task 17947 | n_tokens = 6144, memory_seq_rm [6144, end)
slot update_slots: id  2 | task 17947 | prompt processing progress, n_tokens = 8192, batch.n_tokens = 2048, progress = 0.732803
slot update_slots: id  2 | task 17947 | n_tokens = 8192, memory_seq_rm [8192, end)
slot update_slots: id  2 | task 17947 | prompt processing progress, n_tokens = 10240, batch.n_tokens = 2048, progress = 0.916003
slot update_slots: id  2 | task 17947 | n_tokens = 10240, memory_seq_rm [10240, end)
slot update_slots: id  2 | task 17947 | prompt processing progress, n_tokens = 11115, batch.n_tokens = 875, progress = 0.994275
slot update_slots: id  2 | task 17947 | n_tokens = 11115, memory_seq_rm [11115, end)
slot update_slots: id  2 | task 17947 | prompt processing progress, n_tokens = 11179, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 17947 | prompt done, n_tokens = 11179, batch.n_tokens = 64
slot init_sampler: id  2 | task 17947 | init sampler, took 1.95 ms, tokens: text = 11179, total = 11179
slot update_slots: id  2 | task 17947 | created context checkpoint 1 of 8 (pos_min = 10218, pos_max = 11114, size = 21.034 MiB)
slot print_timing: id  2 | task 17947 | 
prompt eval time =   11690.70 ms / 11179 tokens (    1.05 ms per token,   956.23 tokens per second)
       eval time =    1155.08 ms /    47 tokens (   24.58 ms per token,    40.69 tokens per second)
      total time =   12845.78 ms / 11226 tokens
slot      release: id  2 | task 17947 | stop processing: n_tokens = 11225, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 18001 | processing task, is_child = 0
slot update_slots: id  2 | task 18001 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 11353
slot update_slots: id  2 | task 18001 | n_tokens = 11179, memory_seq_rm [11179, end)
slot update_slots: id  2 | task 18001 | prompt processing progress, n_tokens = 11289, batch.n_tokens = 110, progress = 0.994363
slot update_slots: id  2 | task 18001 | n_tokens = 11289, memory_seq_rm [11289, end)
slot update_slots: id  2 | task 18001 | prompt processing progress, n_tokens = 11353, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 18001 | prompt done, n_tokens = 11353, batch.n_tokens = 64
slot init_sampler: id  2 | task 18001 | init sampler, took 2.19 ms, tokens: text = 11353, total = 11353
slot update_slots: id  2 | task 18001 | created context checkpoint 2 of 8 (pos_min = 10392, pos_max = 11288, size = 21.034 MiB)
slot print_timing: id  2 | task 18001 | 
prompt eval time =     514.57 ms /   174 tokens (    2.96 ms per token,   338.15 tokens per second)
       eval time =    1724.65 ms /    69 tokens (   24.99 ms per token,    40.01 tokens per second)
      total time =    2239.22 ms /   243 tokens
slot      release: id  2 | task 18001 | stop processing: n_tokens = 11421, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.974 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 18072 | processing task, is_child = 0
slot update_slots: id  2 | task 18072 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 11661
slot update_slots: id  2 | task 18072 | n_tokens = 11353, memory_seq_rm [11353, end)
slot update_slots: id  2 | task 18072 | prompt processing progress, n_tokens = 11597, batch.n_tokens = 244, progress = 0.994512
slot update_slots: id  2 | task 18072 | n_tokens = 11597, memory_seq_rm [11597, end)
slot update_slots: id  2 | task 18072 | prompt processing progress, n_tokens = 11661, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 18072 | prompt done, n_tokens = 11661, batch.n_tokens = 64
slot init_sampler: id  2 | task 18072 | init sampler, took 1.76 ms, tokens: text = 11661, total = 11661
slot update_slots: id  2 | task 18072 | created context checkpoint 3 of 8 (pos_min = 10700, pos_max = 11596, size = 21.034 MiB)
slot print_timing: id  2 | task 18072 | 
prompt eval time =     554.04 ms /   308 tokens (    1.80 ms per token,   555.91 tokens per second)
       eval time =    1833.84 ms /    72 tokens (   25.47 ms per token,    39.26 tokens per second)
      total time =    2387.88 ms /   380 tokens
slot      release: id  2 | task 18072 | stop processing: n_tokens = 11732, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.966 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 18146 | processing task, is_child = 0
slot update_slots: id  2 | task 18146 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 12076
slot update_slots: id  2 | task 18146 | n_tokens = 11661, memory_seq_rm [11661, end)
slot update_slots: id  2 | task 18146 | prompt processing progress, n_tokens = 12012, batch.n_tokens = 351, progress = 0.994700
slot update_slots: id  2 | task 18146 | n_tokens = 12012, memory_seq_rm [12012, end)
slot update_slots: id  2 | task 18146 | prompt processing progress, n_tokens = 12076, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 18146 | prompt done, n_tokens = 12076, batch.n_tokens = 64
slot init_sampler: id  2 | task 18146 | init sampler, took 1.72 ms, tokens: text = 12076, total = 12076
slot update_slots: id  2 | task 18146 | created context checkpoint 4 of 8 (pos_min = 11115, pos_max = 12011, size = 21.034 MiB)
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.540 (> 0.100 thold), f_keep = 0.216
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 2123, total state size = 52.761 MiB
srv          load:  - looking for better prompt, base f_keep = 0.216, sim = 0.540
srv        update:  - cache state: 4 prompts, 1666.525 MiB (limits: 8192.000 MiB, 64000 tokens, 246331 est)
srv        update:    - prompt 0x5a234b577500:    4873 tokens, checkpoints:  5,   235.945 MiB
srv        update:    - prompt 0x5a234d243b70:    4947 tokens, checkpoints:  7,   261.904 MiB
srv        update:    - prompt 0x5a234cfbeaa0:   38169 tokens, checkpoints:  8,  1100.063 MiB
srv        update:    - prompt 0x5a234dc80090:    2123 tokens, checkpoints:  1,    68.612 MiB
srv  get_availabl: prompt cache update took 30.77 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 18246 | processing task, is_child = 0
slot update_slots: id  3 | task 18246 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 850
slot update_slots: id  3 | task 18246 | n_past = 459, slot.prompt.tokens.size() = 2123, seq_id = 3, pos_min = 1996, n_swa = 128
slot update_slots: id  3 | task 18246 | restored context checkpoint (pos_min = 0, pos_max = 675, size = 15.852 MiB)
slot update_slots: id  3 | task 18246 | n_tokens = 459, memory_seq_rm [459, end)
slot update_slots: id  3 | task 18246 | prompt processing progress, n_tokens = 786, batch.n_tokens = 328, progress = 0.924706
slot update_slots: id  3 | task 18246 | n_tokens = 786, memory_seq_rm [786, end)
slot update_slots: id  3 | task 18246 | prompt processing progress, n_tokens = 850, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  3 | task 18246 | prompt done, n_tokens = 850, batch.n_tokens = 65
slot init_sampler: id  3 | task 18246 | init sampler, took 0.14 ms, tokens: text = 850, total = 850
slot update_slots: id  3 | task 18246 | created context checkpoint 2 of 8 (pos_min = 0, pos_max = 785, size = 18.431 MiB)
slot print_timing: id  2 | task 18146 | 
prompt eval time =     635.70 ms /   415 tokens (    1.53 ms per token,   652.83 tokens per second)
       eval time =    5456.45 ms /   144 tokens (   37.89 ms per token,    26.39 tokens per second)
      total time =    6092.14 ms /   559 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 18146 | stop processing: n_tokens = 12219, truncated = 0
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 18396 | processing task, is_child = 0
slot update_slots: id  2 | task 18396 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 12192
slot update_slots: id  2 | task 18396 | n_past = 12076, slot.prompt.tokens.size() = 12219, seq_id = 2, pos_min = 12046, n_swa = 128
slot update_slots: id  2 | task 18396 | restored context checkpoint (pos_min = 11115, pos_max = 12011, size = 21.034 MiB)
slot update_slots: id  2 | task 18396 | n_tokens = 12011, memory_seq_rm [12011, end)
slot update_slots: id  2 | task 18396 | prompt processing progress, n_tokens = 12128, batch.n_tokens = 118, progress = 0.994751
slot update_slots: id  2 | task 18396 | n_tokens = 12128, memory_seq_rm [12128, end)
slot update_slots: id  2 | task 18396 | prompt processing progress, n_tokens = 12192, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  2 | task 18396 | prompt done, n_tokens = 12192, batch.n_tokens = 65
slot init_sampler: id  2 | task 18396 | init sampler, took 2.17 ms, tokens: text = 12192, total = 12192
slot update_slots: id  2 | task 18396 | created context checkpoint 5 of 8 (pos_min = 11232, pos_max = 12127, size = 21.011 MiB)
slot print_timing: id  2 | task 18396 | 
prompt eval time =     674.18 ms /   181 tokens (    3.72 ms per token,   268.48 tokens per second)
       eval time =    2325.52 ms /    51 tokens (   45.60 ms per token,    21.93 tokens per second)
      total time =    2999.70 ms /   232 tokens
slot      release: id  2 | task 18396 | stop processing: n_tokens = 12242, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.958 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 18527 | processing task, is_child = 0
slot update_slots: id  2 | task 18527 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 12724
slot update_slots: id  2 | task 18527 | n_tokens = 12192, memory_seq_rm [12192, end)
slot update_slots: id  2 | task 18527 | prompt processing progress, n_tokens = 12660, batch.n_tokens = 469, progress = 0.994970
slot update_slots: id  2 | task 18527 | n_tokens = 12660, memory_seq_rm [12660, end)
slot update_slots: id  2 | task 18527 | prompt processing progress, n_tokens = 12724, batch.n_tokens = 65, progress = 1.000000
slot update_slots: id  2 | task 18527 | prompt done, n_tokens = 12724, batch.n_tokens = 65
slot init_sampler: id  2 | task 18527 | init sampler, took 2.26 ms, tokens: text = 12724, total = 12724
slot update_slots: id  2 | task 18527 | created context checkpoint 6 of 8 (pos_min = 11766, pos_max = 12659, size = 20.964 MiB)
slot print_timing: id  2 | task 18527 | 
prompt eval time =     776.25 ms /   532 tokens (    1.46 ms per token,   685.34 tokens per second)
       eval time =    3014.33 ms /    66 tokens (   45.67 ms per token,    21.90 tokens per second)
      total time =    3790.59 ms /   598 tokens
slot      release: id  2 | task 18527 | stop processing: n_tokens = 12789, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  3 | task 18246 | 
prompt eval time =     762.25 ms /   391 tokens (    1.95 ms per token,   512.95 tokens per second)
       eval time =   16589.91 ms /   457 tokens (   36.30 ms per token,    27.55 tokens per second)
      total time =   17352.17 ms /   848 tokens
slot      release: id  3 | task 18246 | stop processing: n_tokens = 1306, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.977 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 18707 | processing task, is_child = 0
slot update_slots: id  2 | task 18707 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13018
slot update_slots: id  2 | task 18707 | n_tokens = 12724, memory_seq_rm [12724, end)
slot update_slots: id  2 | task 18707 | prompt processing progress, n_tokens = 12954, batch.n_tokens = 230, progress = 0.995084
slot update_slots: id  2 | task 18707 | n_tokens = 12954, memory_seq_rm [12954, end)
slot update_slots: id  2 | task 18707 | prompt processing progress, n_tokens = 13018, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 18707 | prompt done, n_tokens = 13018, batch.n_tokens = 64
slot init_sampler: id  2 | task 18707 | init sampler, took 2.57 ms, tokens: text = 13018, total = 13018
slot update_slots: id  2 | task 18707 | created context checkpoint 7 of 8 (pos_min = 12186, pos_max = 12953, size = 18.009 MiB)
slot print_timing: id  2 | task 18707 | 
prompt eval time =     585.18 ms /   294 tokens (    1.99 ms per token,   502.41 tokens per second)
       eval time =    2919.38 ms /   116 tokens (   25.17 ms per token,    39.73 tokens per second)
      total time =    3504.56 ms /   410 tokens
slot      release: id  2 | task 18707 | stop processing: n_tokens = 13133, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 18825 | processing task, is_child = 0
slot update_slots: id  2 | task 18825 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13075
slot update_slots: id  2 | task 18825 | n_tokens = 13018, memory_seq_rm [13018, end)
slot update_slots: id  2 | task 18825 | prompt processing progress, n_tokens = 13075, batch.n_tokens = 57, progress = 1.000000
slot update_slots: id  2 | task 18825 | prompt done, n_tokens = 13075, batch.n_tokens = 57
slot init_sampler: id  2 | task 18825 | init sampler, took 1.95 ms, tokens: text = 13075, total = 13075
slot print_timing: id  2 | task 18825 | 
prompt eval time =     164.03 ms /    57 tokens (    2.88 ms per token,   347.50 tokens per second)
       eval time =    4103.77 ms /   164 tokens (   25.02 ms per token,    39.96 tokens per second)
      total time =    4267.80 ms /   221 tokens
slot      release: id  2 | task 18825 | stop processing: n_tokens = 13238, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 18990 | processing task, is_child = 0
slot update_slots: id  2 | task 18990 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13171
slot update_slots: id  2 | task 18990 | n_tokens = 13075, memory_seq_rm [13075, end)
slot update_slots: id  2 | task 18990 | prompt processing progress, n_tokens = 13107, batch.n_tokens = 32, progress = 0.995141
slot update_slots: id  2 | task 18990 | n_tokens = 13107, memory_seq_rm [13107, end)
slot update_slots: id  2 | task 18990 | prompt processing progress, n_tokens = 13171, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 18990 | prompt done, n_tokens = 13171, batch.n_tokens = 64
slot init_sampler: id  2 | task 18990 | init sampler, took 1.88 ms, tokens: text = 13171, total = 13171
slot update_slots: id  2 | task 18990 | created context checkpoint 8 of 8 (pos_min = 12342, pos_max = 13106, size = 17.939 MiB)
slot print_timing: id  2 | task 18990 | 
prompt eval time =     304.14 ms /    96 tokens (    3.17 ms per token,   315.65 tokens per second)
       eval time =    1700.06 ms /    67 tokens (   25.37 ms per token,    39.41 tokens per second)
      total time =    2004.20 ms /   163 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 18990 | stop processing: n_tokens = 13237, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 19059 | processing task, is_child = 0
slot update_slots: id  2 | task 19059 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13228
slot update_slots: id  2 | task 19059 | n_tokens = 13171, memory_seq_rm [13171, end)
slot update_slots: id  2 | task 19059 | prompt processing progress, n_tokens = 13228, batch.n_tokens = 57, progress = 1.000000
slot update_slots: id  2 | task 19059 | prompt done, n_tokens = 13228, batch.n_tokens = 57
slot init_sampler: id  2 | task 19059 | init sampler, took 2.80 ms, tokens: text = 13228, total = 13228
slot print_timing: id  2 | task 19059 | 
prompt eval time =     257.62 ms /    57 tokens (    4.52 ms per token,   221.26 tokens per second)
       eval time =    2370.78 ms /    94 tokens (   25.22 ms per token,    39.65 tokens per second)
      total time =    2628.39 ms /   151 tokens
slot      release: id  2 | task 19059 | stop processing: n_tokens = 13321, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.873 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 19154 | processing task, is_child = 0
slot update_slots: id  2 | task 19154 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15160
slot update_slots: id  2 | task 19154 | n_tokens = 13228, memory_seq_rm [13228, end)
slot update_slots: id  2 | task 19154 | prompt processing progress, n_tokens = 15096, batch.n_tokens = 1868, progress = 0.995778
slot update_slots: id  2 | task 19154 | n_tokens = 15096, memory_seq_rm [15096, end)
slot update_slots: id  2 | task 19154 | prompt processing progress, n_tokens = 15160, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 19154 | prompt done, n_tokens = 15160, batch.n_tokens = 64
slot init_sampler: id  2 | task 19154 | init sampler, took 2.23 ms, tokens: text = 15160, total = 15160
slot update_slots: id  2 | task 19154 | erasing old context checkpoint (pos_min = 10218, pos_max = 11114, size = 21.034 MiB)
slot update_slots: id  2 | task 19154 | created context checkpoint 8 of 8 (pos_min = 14199, pos_max = 15095, size = 21.034 MiB)
slot print_timing: id  2 | task 19154 | 
prompt eval time =    2367.80 ms /  1932 tokens (    1.23 ms per token,   815.95 tokens per second)
       eval time =    1722.61 ms /    69 tokens (   24.97 ms per token,    40.06 tokens per second)
      total time =    4090.41 ms /  2001 tokens
slot      release: id  2 | task 19154 | stop processing: n_tokens = 15228, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.943 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 19225 | processing task, is_child = 0
slot update_slots: id  2 | task 19225 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16083
slot update_slots: id  2 | task 19225 | n_tokens = 15160, memory_seq_rm [15160, end)
slot update_slots: id  2 | task 19225 | prompt processing progress, n_tokens = 16019, batch.n_tokens = 859, progress = 0.996021
slot update_slots: id  2 | task 19225 | n_tokens = 16019, memory_seq_rm [16019, end)
slot update_slots: id  2 | task 19225 | prompt processing progress, n_tokens = 16083, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 19225 | prompt done, n_tokens = 16083, batch.n_tokens = 64
slot init_sampler: id  2 | task 19225 | init sampler, took 2.27 ms, tokens: text = 16083, total = 16083
slot update_slots: id  2 | task 19225 | erasing old context checkpoint (pos_min = 10392, pos_max = 11288, size = 21.034 MiB)
slot update_slots: id  2 | task 19225 | created context checkpoint 8 of 8 (pos_min = 15122, pos_max = 16018, size = 21.034 MiB)
slot print_timing: id  2 | task 19225 | 
prompt eval time =    1231.90 ms /   923 tokens (    1.33 ms per token,   749.25 tokens per second)
       eval time =    3134.11 ms /   123 tokens (   25.48 ms per token,    39.25 tokens per second)
      total time =    4366.01 ms /  1046 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 19225 | stop processing: n_tokens = 16205, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 19350 | processing task, is_child = 0
slot update_slots: id  2 | task 19350 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16140
slot update_slots: id  2 | task 19350 | n_tokens = 16083, memory_seq_rm [16083, end)
slot update_slots: id  2 | task 19350 | prompt processing progress, n_tokens = 16140, batch.n_tokens = 57, progress = 1.000000
slot update_slots: id  2 | task 19350 | prompt done, n_tokens = 16140, batch.n_tokens = 57
slot init_sampler: id  2 | task 19350 | init sampler, took 2.36 ms, tokens: text = 16140, total = 16140
slot print_timing: id  2 | task 19350 | 
prompt eval time =     200.17 ms /    57 tokens (    3.51 ms per token,   284.76 tokens per second)
       eval time =    1025.86 ms /    41 tokens (   25.02 ms per token,    39.97 tokens per second)
      total time =    1226.02 ms /    98 tokens
slot      release: id  2 | task 19350 | stop processing: n_tokens = 16180, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 19392 | processing task, is_child = 0
slot update_slots: id  2 | task 19392 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16314
slot update_slots: id  2 | task 19392 | n_tokens = 16140, memory_seq_rm [16140, end)
slot update_slots: id  2 | task 19392 | prompt processing progress, n_tokens = 16250, batch.n_tokens = 110, progress = 0.996077
slot update_slots: id  2 | task 19392 | n_tokens = 16250, memory_seq_rm [16250, end)
slot update_slots: id  2 | task 19392 | prompt processing progress, n_tokens = 16314, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 19392 | prompt done, n_tokens = 16314, batch.n_tokens = 64
slot init_sampler: id  2 | task 19392 | init sampler, took 2.46 ms, tokens: text = 16314, total = 16314
slot update_slots: id  2 | task 19392 | erasing old context checkpoint (pos_min = 10700, pos_max = 11596, size = 21.034 MiB)
slot update_slots: id  2 | task 19392 | created context checkpoint 8 of 8 (pos_min = 15353, pos_max = 16249, size = 21.034 MiB)
slot print_timing: id  2 | task 19392 | 
prompt eval time =     454.98 ms /   174 tokens (    2.61 ms per token,   382.43 tokens per second)
       eval time =    1532.79 ms /    61 tokens (   25.13 ms per token,    39.80 tokens per second)
      total time =    1987.77 ms /   235 tokens
slot      release: id  2 | task 19392 | stop processing: n_tokens = 16374, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.981 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 19455 | processing task, is_child = 0
slot update_slots: id  2 | task 19455 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16622
slot update_slots: id  2 | task 19455 | n_tokens = 16314, memory_seq_rm [16314, end)
slot update_slots: id  2 | task 19455 | prompt processing progress, n_tokens = 16558, batch.n_tokens = 244, progress = 0.996150
slot update_slots: id  2 | task 19455 | n_tokens = 16558, memory_seq_rm [16558, end)
slot update_slots: id  2 | task 19455 | prompt processing progress, n_tokens = 16622, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 19455 | prompt done, n_tokens = 16622, batch.n_tokens = 64
slot init_sampler: id  2 | task 19455 | init sampler, took 2.42 ms, tokens: text = 16622, total = 16622
slot update_slots: id  2 | task 19455 | erasing old context checkpoint (pos_min = 11115, pos_max = 12011, size = 21.034 MiB)
slot update_slots: id  2 | task 19455 | created context checkpoint 8 of 8 (pos_min = 15661, pos_max = 16557, size = 21.034 MiB)
slot print_timing: id  2 | task 19455 | 
prompt eval time =     570.58 ms /   308 tokens (    1.85 ms per token,   539.80 tokens per second)
       eval time =    1471.13 ms /    58 tokens (   25.36 ms per token,    39.43 tokens per second)
      total time =    2041.71 ms /   366 tokens
slot      release: id  2 | task 19455 | stop processing: n_tokens = 16679, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.982 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 19515 | processing task, is_child = 0
slot update_slots: id  2 | task 19515 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16930
slot update_slots: id  2 | task 19515 | n_tokens = 16622, memory_seq_rm [16622, end)
slot update_slots: id  2 | task 19515 | prompt processing progress, n_tokens = 16866, batch.n_tokens = 244, progress = 0.996220
slot update_slots: id  2 | task 19515 | n_tokens = 16866, memory_seq_rm [16866, end)
slot update_slots: id  2 | task 19515 | prompt processing progress, n_tokens = 16930, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 19515 | prompt done, n_tokens = 16930, batch.n_tokens = 64
slot init_sampler: id  2 | task 19515 | init sampler, took 2.37 ms, tokens: text = 16930, total = 16930
slot update_slots: id  2 | task 19515 | erasing old context checkpoint (pos_min = 11232, pos_max = 12127, size = 21.011 MiB)
slot update_slots: id  2 | task 19515 | created context checkpoint 8 of 8 (pos_min = 15969, pos_max = 16865, size = 21.034 MiB)
slot print_timing: id  2 | task 19515 | 
prompt eval time =     576.21 ms /   308 tokens (    1.87 ms per token,   534.53 tokens per second)
       eval time =    1503.72 ms /    58 tokens (   25.93 ms per token,    38.57 tokens per second)
      total time =    2079.93 ms /   366 tokens
slot      release: id  2 | task 19515 | stop processing: n_tokens = 16987, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.977 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 19575 | processing task, is_child = 0
slot update_slots: id  2 | task 19575 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 17336
slot update_slots: id  2 | task 19575 | n_tokens = 16930, memory_seq_rm [16930, end)
slot update_slots: id  2 | task 19575 | prompt processing progress, n_tokens = 17272, batch.n_tokens = 342, progress = 0.996308
slot update_slots: id  2 | task 19575 | n_tokens = 17272, memory_seq_rm [17272, end)
slot update_slots: id  2 | task 19575 | prompt processing progress, n_tokens = 17336, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 19575 | prompt done, n_tokens = 17336, batch.n_tokens = 64
slot init_sampler: id  2 | task 19575 | init sampler, took 2.75 ms, tokens: text = 17336, total = 17336
slot update_slots: id  2 | task 19575 | erasing old context checkpoint (pos_min = 11766, pos_max = 12659, size = 20.964 MiB)
slot update_slots: id  2 | task 19575 | created context checkpoint 8 of 8 (pos_min = 16375, pos_max = 17271, size = 21.034 MiB)
slot print_timing: id  2 | task 19575 | 
prompt eval time =     715.11 ms /   406 tokens (    1.76 ms per token,   567.75 tokens per second)
       eval time =    1944.99 ms /    76 tokens (   25.59 ms per token,    39.07 tokens per second)
      total time =    2660.10 ms /   482 tokens
slot      release: id  2 | task 19575 | stop processing: n_tokens = 17411, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 19653 | processing task, is_child = 0
slot update_slots: id  2 | task 19653 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 17405
slot update_slots: id  2 | task 19653 | n_tokens = 17336, memory_seq_rm [17336, end)
slot update_slots: id  2 | task 19653 | prompt processing progress, n_tokens = 17341, batch.n_tokens = 5, progress = 0.996323
slot update_slots: id  2 | task 19653 | n_tokens = 17341, memory_seq_rm [17341, end)
slot update_slots: id  2 | task 19653 | prompt processing progress, n_tokens = 17405, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 19653 | prompt done, n_tokens = 17405, batch.n_tokens = 64
slot init_sampler: id  2 | task 19653 | init sampler, took 2.42 ms, tokens: text = 17405, total = 17405
slot update_slots: id  2 | task 19653 | erasing old context checkpoint (pos_min = 12186, pos_max = 12953, size = 18.009 MiB)
slot update_slots: id  2 | task 19653 | created context checkpoint 8 of 8 (pos_min = 16514, pos_max = 17340, size = 19.393 MiB)
slot print_timing: id  2 | task 19653 | 
prompt eval time =     246.77 ms /    69 tokens (    3.58 ms per token,   279.61 tokens per second)
       eval time =    1162.53 ms /    47 tokens (   24.73 ms per token,    40.43 tokens per second)
      total time =    1409.30 ms /   116 tokens
slot      release: id  2 | task 19653 | stop processing: n_tokens = 17451, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.660 (> 0.100 thold), f_keep = 0.639
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 19702 | processing task, is_child = 0
slot update_slots: id  3 | task 19702 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1263
slot update_slots: id  3 | task 19702 | n_past = 834, slot.prompt.tokens.size() = 1306, seq_id = 3, pos_min = 1179, n_swa = 128
slot update_slots: id  3 | task 19702 | restored context checkpoint (pos_min = 0, pos_max = 785, size = 18.431 MiB)
slot update_slots: id  3 | task 19702 | n_tokens = 785, memory_seq_rm [785, end)
slot update_slots: id  3 | task 19702 | prompt processing progress, n_tokens = 1199, batch.n_tokens = 414, progress = 0.949327
slot update_slots: id  3 | task 19702 | n_tokens = 1199, memory_seq_rm [1199, end)
slot update_slots: id  3 | task 19702 | prompt processing progress, n_tokens = 1263, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 19702 | prompt done, n_tokens = 1263, batch.n_tokens = 64
slot init_sampler: id  3 | task 19702 | init sampler, took 0.21 ms, tokens: text = 1263, total = 1263
slot update_slots: id  3 | task 19702 | created context checkpoint 3 of 8 (pos_min = 302, pos_max = 1198, size = 21.034 MiB)
slot print_timing: id  3 | task 19702 | 
prompt eval time =     903.10 ms /   478 tokens (    1.89 ms per token,   529.29 tokens per second)
       eval time =   16960.41 ms /   659 tokens (   25.74 ms per token,    38.86 tokens per second)
      total time =   17863.51 ms /  1137 tokens
slot      release: id  3 | task 19702 | stop processing: n_tokens = 1921, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.919 (> 0.100 thold), f_keep = 0.640
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 20363 | processing task, is_child = 0
slot update_slots: id  2 | task 20363 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 12141
slot update_slots: id  2 | task 20363 | n_past = 11163, slot.prompt.tokens.size() = 17451, seq_id = 2, pos_min = 17324, n_swa = 128
slot update_slots: id  2 | task 20363 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  2 | task 20363 | erased invalidated context checkpoint (pos_min = 12342, pos_max = 13106, n_swa = 128, size = 17.939 MiB)
slot update_slots: id  2 | task 20363 | erased invalidated context checkpoint (pos_min = 14199, pos_max = 15095, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 20363 | erased invalidated context checkpoint (pos_min = 15122, pos_max = 16018, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 20363 | erased invalidated context checkpoint (pos_min = 15353, pos_max = 16249, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 20363 | erased invalidated context checkpoint (pos_min = 15661, pos_max = 16557, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 20363 | erased invalidated context checkpoint (pos_min = 15969, pos_max = 16865, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 20363 | erased invalidated context checkpoint (pos_min = 16375, pos_max = 17271, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 20363 | erased invalidated context checkpoint (pos_min = 16514, pos_max = 17340, n_swa = 128, size = 19.393 MiB)
slot update_slots: id  2 | task 20363 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 20363 | prompt processing progress, n_tokens = 2048, batch.n_tokens = 2048, progress = 0.168685
slot update_slots: id  2 | task 20363 | n_tokens = 2048, memory_seq_rm [2048, end)
slot update_slots: id  2 | task 20363 | prompt processing progress, n_tokens = 4096, batch.n_tokens = 2048, progress = 0.337369
slot update_slots: id  2 | task 20363 | n_tokens = 4096, memory_seq_rm [4096, end)
slot update_slots: id  2 | task 20363 | prompt processing progress, n_tokens = 6144, batch.n_tokens = 2048, progress = 0.506054
slot update_slots: id  2 | task 20363 | n_tokens = 6144, memory_seq_rm [6144, end)
slot update_slots: id  2 | task 20363 | prompt processing progress, n_tokens = 8192, batch.n_tokens = 2048, progress = 0.674738
slot update_slots: id  2 | task 20363 | n_tokens = 8192, memory_seq_rm [8192, end)
slot update_slots: id  2 | task 20363 | prompt processing progress, n_tokens = 10240, batch.n_tokens = 2048, progress = 0.843423
slot update_slots: id  2 | task 20363 | n_tokens = 10240, memory_seq_rm [10240, end)
slot update_slots: id  2 | task 20363 | prompt processing progress, n_tokens = 12077, batch.n_tokens = 1837, progress = 0.994729
slot update_slots: id  2 | task 20363 | n_tokens = 12077, memory_seq_rm [12077, end)
slot update_slots: id  2 | task 20363 | prompt processing progress, n_tokens = 12141, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 20363 | prompt done, n_tokens = 12141, batch.n_tokens = 64
slot init_sampler: id  2 | task 20363 | init sampler, took 1.82 ms, tokens: text = 12141, total = 12141
slot update_slots: id  2 | task 20363 | created context checkpoint 1 of 8 (pos_min = 11180, pos_max = 12076, size = 21.034 MiB)
slot print_timing: id  2 | task 20363 | 
prompt eval time =   14940.70 ms / 12141 tokens (    1.23 ms per token,   812.61 tokens per second)
       eval time =   71021.48 ms /  2767 tokens (   25.67 ms per token,    38.96 tokens per second)
      total time =   85962.18 ms / 14908 tokens
slot      release: id  2 | task 20363 | stop processing: n_tokens = 14907, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.815 (> 0.100 thold), f_keep = 0.814
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 23137 | processing task, is_child = 0
slot update_slots: id  2 | task 23137 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 14900
slot update_slots: id  2 | task 23137 | n_past = 12141, slot.prompt.tokens.size() = 14907, seq_id = 2, pos_min = 14010, n_swa = 128
slot update_slots: id  2 | task 23137 | restored context checkpoint (pos_min = 11180, pos_max = 12076, size = 21.034 MiB)
slot update_slots: id  2 | task 23137 | n_tokens = 12076, memory_seq_rm [12076, end)
slot update_slots: id  2 | task 23137 | prompt processing progress, n_tokens = 14124, batch.n_tokens = 2048, progress = 0.947919
slot update_slots: id  2 | task 23137 | n_tokens = 14124, memory_seq_rm [14124, end)
slot update_slots: id  2 | task 23137 | prompt processing progress, n_tokens = 14836, batch.n_tokens = 712, progress = 0.995705
slot update_slots: id  2 | task 23137 | n_tokens = 14836, memory_seq_rm [14836, end)
slot update_slots: id  2 | task 23137 | prompt processing progress, n_tokens = 14900, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 23137 | prompt done, n_tokens = 14900, batch.n_tokens = 64
slot init_sampler: id  2 | task 23137 | init sampler, took 3.81 ms, tokens: text = 14900, total = 14900
slot update_slots: id  2 | task 23137 | created context checkpoint 2 of 8 (pos_min = 13939, pos_max = 14835, size = 21.034 MiB)
slot print_timing: id  2 | task 23137 | 
prompt eval time =    3781.26 ms /  2824 tokens (    1.34 ms per token,   746.84 tokens per second)
       eval time =     779.84 ms /    31 tokens (   25.16 ms per token,    39.75 tokens per second)
      total time =    4561.10 ms /  2855 tokens
slot      release: id  2 | task 23137 | stop processing: n_tokens = 14930, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LRU, t_last = -1
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 23171 | processing task, is_child = 0
slot update_slots: id  1 | task 23171 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15029
slot update_slots: id  1 | task 23171 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  1 | task 23171 | prompt processing progress, n_tokens = 2048, batch.n_tokens = 2048, progress = 0.136270
slot update_slots: id  1 | task 23171 | n_tokens = 2048, memory_seq_rm [2048, end)
slot update_slots: id  1 | task 23171 | prompt processing progress, n_tokens = 4096, batch.n_tokens = 2048, progress = 0.272540
slot update_slots: id  1 | task 23171 | n_tokens = 4096, memory_seq_rm [4096, end)
slot update_slots: id  1 | task 23171 | prompt processing progress, n_tokens = 6144, batch.n_tokens = 2048, progress = 0.408810
slot update_slots: id  1 | task 23171 | n_tokens = 6144, memory_seq_rm [6144, end)
slot update_slots: id  1 | task 23171 | prompt processing progress, n_tokens = 8192, batch.n_tokens = 2048, progress = 0.545080
slot update_slots: id  1 | task 23171 | n_tokens = 8192, memory_seq_rm [8192, end)
slot update_slots: id  1 | task 23171 | prompt processing progress, n_tokens = 10240, batch.n_tokens = 2048, progress = 0.681349
slot update_slots: id  1 | task 23171 | n_tokens = 10240, memory_seq_rm [10240, end)
slot update_slots: id  1 | task 23171 | prompt processing progress, n_tokens = 12288, batch.n_tokens = 2048, progress = 0.817619
slot update_slots: id  1 | task 23171 | n_tokens = 12288, memory_seq_rm [12288, end)
slot update_slots: id  1 | task 23171 | prompt processing progress, n_tokens = 14336, batch.n_tokens = 2048, progress = 0.953889
slot update_slots: id  1 | task 23171 | n_tokens = 14336, memory_seq_rm [14336, end)
slot update_slots: id  1 | task 23171 | prompt processing progress, n_tokens = 14965, batch.n_tokens = 629, progress = 0.995742
slot update_slots: id  1 | task 23171 | n_tokens = 14965, memory_seq_rm [14965, end)
slot update_slots: id  1 | task 23171 | prompt processing progress, n_tokens = 15029, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 23171 | prompt done, n_tokens = 15029, batch.n_tokens = 64
slot init_sampler: id  1 | task 23171 | init sampler, took 2.15 ms, tokens: text = 15029, total = 15029
slot update_slots: id  1 | task 23171 | created context checkpoint 1 of 8 (pos_min = 14195, pos_max = 14964, size = 18.056 MiB)
slot print_timing: id  1 | task 23171 | 
prompt eval time =   19671.69 ms / 15029 tokens (    1.31 ms per token,   763.99 tokens per second)
       eval time =     753.97 ms /    26 tokens (   29.00 ms per token,    34.48 tokens per second)
      total time =   20425.66 ms / 15055 tokens
slot      release: id  1 | task 23171 | stop processing: n_tokens = 15054, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 23206 | processing task, is_child = 0
slot update_slots: id  1 | task 23206 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15095
slot update_slots: id  1 | task 23206 | n_tokens = 15029, memory_seq_rm [15029, end)
slot update_slots: id  1 | task 23206 | prompt processing progress, n_tokens = 15031, batch.n_tokens = 2, progress = 0.995760
slot update_slots: id  1 | task 23206 | n_tokens = 15031, memory_seq_rm [15031, end)
slot update_slots: id  1 | task 23206 | prompt processing progress, n_tokens = 15095, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 23206 | prompt done, n_tokens = 15095, batch.n_tokens = 64
slot init_sampler: id  1 | task 23206 | init sampler, took 2.25 ms, tokens: text = 15095, total = 15095
slot update_slots: id  1 | task 23206 | created context checkpoint 2 of 8 (pos_min = 14284, pos_max = 15030, size = 17.517 MiB)
slot print_timing: id  1 | task 23206 | 
prompt eval time =     340.05 ms /    66 tokens (    5.15 ms per token,   194.09 tokens per second)
       eval time =     718.57 ms /    28 tokens (   25.66 ms per token,    38.97 tokens per second)
      total time =    1058.63 ms /    94 tokens
slot      release: id  1 | task 23206 | stop processing: n_tokens = 15122, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 23236 | processing task, is_child = 0
slot update_slots: id  1 | task 23236 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15092
slot update_slots: id  1 | task 23236 | n_tokens = 15020, memory_seq_rm [15020, end)
slot update_slots: id  1 | task 23236 | prompt processing progress, n_tokens = 15028, batch.n_tokens = 8, progress = 0.995759
slot update_slots: id  1 | task 23236 | n_tokens = 15028, memory_seq_rm [15028, end)
slot update_slots: id  1 | task 23236 | prompt processing progress, n_tokens = 15092, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 23236 | prompt done, n_tokens = 15092, batch.n_tokens = 64
slot init_sampler: id  1 | task 23236 | init sampler, took 2.60 ms, tokens: text = 15092, total = 15092
slot print_timing: id  1 | task 23236 | 
prompt eval time =     383.12 ms /    72 tokens (    5.32 ms per token,   187.93 tokens per second)
       eval time =    4167.86 ms /   156 tokens (   26.72 ms per token,    37.43 tokens per second)
      total time =    4550.98 ms /   228 tokens
slot      release: id  1 | task 23236 | stop processing: n_tokens = 15247, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.990
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 23394 | processing task, is_child = 0
slot update_slots: id  1 | task 23394 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15175
slot update_slots: id  1 | task 23394 | n_tokens = 15092, memory_seq_rm [15092, end)
slot update_slots: id  1 | task 23394 | prompt processing progress, n_tokens = 15111, batch.n_tokens = 19, progress = 0.995783
slot update_slots: id  1 | task 23394 | n_tokens = 15111, memory_seq_rm [15111, end)
slot update_slots: id  1 | task 23394 | prompt processing progress, n_tokens = 15175, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 23394 | prompt done, n_tokens = 15175, batch.n_tokens = 64
slot init_sampler: id  1 | task 23394 | init sampler, took 3.02 ms, tokens: text = 15175, total = 15175
slot update_slots: id  1 | task 23394 | created context checkpoint 3 of 8 (pos_min = 14477, pos_max = 15110, size = 14.867 MiB)
slot print_timing: id  1 | task 23394 | 
prompt eval time =     390.63 ms /    83 tokens (    4.71 ms per token,   212.48 tokens per second)
       eval time =     847.47 ms /    32 tokens (   26.48 ms per token,    37.76 tokens per second)
      total time =    1238.10 ms /   115 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 23394 | stop processing: n_tokens = 15206, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.305 (> 0.100 thold), f_keep = 0.037
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 15206, total state size = 373.660 MiB
srv          load:  - looking for better prompt, base f_keep = 0.037, sim = 0.305
srv        update:  - cache state: 5 prompts, 2090.624 MiB (limits: 8192.000 MiB, 64000 tokens, 255945 est)
srv        update:    - prompt 0x5a234b577500:    4873 tokens, checkpoints:  5,   235.945 MiB
srv        update:    - prompt 0x5a234d243b70:    4947 tokens, checkpoints:  7,   261.904 MiB
srv        update:    - prompt 0x5a234cfbeaa0:   38169 tokens, checkpoints:  8,  1100.063 MiB
srv        update:    - prompt 0x5a234dc80090:    2123 tokens, checkpoints:  1,    68.612 MiB
srv        update:    - prompt 0x5a234ccbfee0:   15206 tokens, checkpoints:  3,   424.099 MiB
srv  get_availabl: prompt cache update took 303.77 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 23428 | processing task, is_child = 0
slot update_slots: id  1 | task 23428 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1861
slot update_slots: id  1 | task 23428 | n_past = 567, slot.prompt.tokens.size() = 15206, seq_id = 1, pos_min = 14477, n_swa = 128
slot update_slots: id  1 | task 23428 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  1 | task 23428 | erased invalidated context checkpoint (pos_min = 14195, pos_max = 14964, n_swa = 128, size = 18.056 MiB)
slot update_slots: id  1 | task 23428 | erased invalidated context checkpoint (pos_min = 14284, pos_max = 15030, n_swa = 128, size = 17.517 MiB)
slot update_slots: id  1 | task 23428 | erased invalidated context checkpoint (pos_min = 14477, pos_max = 15110, n_swa = 128, size = 14.867 MiB)
slot update_slots: id  1 | task 23428 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  1 | task 23428 | prompt processing progress, n_tokens = 1797, batch.n_tokens = 1797, progress = 0.965610
slot update_slots: id  1 | task 23428 | n_tokens = 1797, memory_seq_rm [1797, end)
slot update_slots: id  1 | task 23428 | prompt processing progress, n_tokens = 1861, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 23428 | prompt done, n_tokens = 1861, batch.n_tokens = 64
slot init_sampler: id  1 | task 23428 | init sampler, took 0.35 ms, tokens: text = 1861, total = 1861
slot update_slots: id  1 | task 23428 | created context checkpoint 1 of 8 (pos_min = 1027, pos_max = 1796, size = 18.056 MiB)
slot print_timing: id  1 | task 23428 | 
prompt eval time =    2474.79 ms /  1861 tokens (    1.33 ms per token,   751.98 tokens per second)
       eval time =   13632.35 ms /   525 tokens (   25.97 ms per token,    38.51 tokens per second)
      total time =   16107.14 ms /  2386 tokens
slot      release: id  1 | task 23428 | stop processing: n_tokens = 2385, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.790 (> 0.100 thold), f_keep = 0.776
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 23955 | processing task, is_child = 0
slot update_slots: id  1 | task 23955 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2343
slot update_slots: id  1 | task 23955 | n_tokens = 1850, memory_seq_rm [1850, end)
slot update_slots: id  1 | task 23955 | prompt processing progress, n_tokens = 2279, batch.n_tokens = 429, progress = 0.972685
slot update_slots: id  1 | task 23955 | n_tokens = 2279, memory_seq_rm [2279, end)
slot update_slots: id  1 | task 23955 | prompt processing progress, n_tokens = 2343, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 23955 | prompt done, n_tokens = 2343, batch.n_tokens = 64
slot init_sampler: id  1 | task 23955 | init sampler, took 0.40 ms, tokens: text = 2343, total = 2343
slot update_slots: id  1 | task 23955 | created context checkpoint 2 of 8 (pos_min = 1723, pos_max = 2278, size = 13.038 MiB)
slot print_timing: id  1 | task 23955 | 
prompt eval time =     820.39 ms /   493 tokens (    1.66 ms per token,   600.93 tokens per second)
       eval time =   15150.27 ms /   582 tokens (   26.03 ms per token,    38.42 tokens per second)
      total time =   15970.66 ms /  1075 tokens
slot      release: id  1 | task 23955 | stop processing: n_tokens = 2924, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.194
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 2924, total state size = 86.621 MiB
srv          load:  - looking for better prompt, base f_keep = 0.194, sim = 0.984
srv        update:  - cache state: 6 prompts, 2208.339 MiB (limits: 8192.000 MiB, 64000 tokens, 253148 est)
srv        update:    - prompt 0x5a234b577500:    4873 tokens, checkpoints:  5,   235.945 MiB
srv        update:    - prompt 0x5a234d243b70:    4947 tokens, checkpoints:  7,   261.904 MiB
srv        update:    - prompt 0x5a234cfbeaa0:   38169 tokens, checkpoints:  8,  1100.063 MiB
srv        update:    - prompt 0x5a234dc80090:    2123 tokens, checkpoints:  1,    68.612 MiB
srv        update:    - prompt 0x5a234ccbfee0:   15206 tokens, checkpoints:  3,   424.099 MiB
srv        update:    - prompt 0x5a234dbdca00:    2924 tokens, checkpoints:  2,   117.715 MiB
srv  get_availabl: prompt cache update took 107.75 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 24539 | processing task, is_child = 0
slot update_slots: id  1 | task 24539 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 575
slot update_slots: id  1 | task 24539 | n_past = 566, slot.prompt.tokens.size() = 2924, seq_id = 1, pos_min = 2154, n_swa = 128
slot update_slots: id  1 | task 24539 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  1 | task 24539 | erased invalidated context checkpoint (pos_min = 1027, pos_max = 1796, n_swa = 128, size = 18.056 MiB)
slot update_slots: id  1 | task 24539 | erased invalidated context checkpoint (pos_min = 1723, pos_max = 2278, n_swa = 128, size = 13.038 MiB)
slot update_slots: id  1 | task 24539 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  1 | task 24539 | prompt processing progress, n_tokens = 511, batch.n_tokens = 511, progress = 0.888696
slot update_slots: id  1 | task 24539 | n_tokens = 511, memory_seq_rm [511, end)
slot update_slots: id  1 | task 24539 | prompt processing progress, n_tokens = 575, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 24539 | prompt done, n_tokens = 575, batch.n_tokens = 64
slot init_sampler: id  1 | task 24539 | init sampler, took 0.21 ms, tokens: text = 575, total = 575
slot update_slots: id  1 | task 24539 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 510, size = 11.983 MiB)
slot print_timing: id  1 | task 24539 | 
prompt eval time =     846.79 ms /   575 tokens (    1.47 ms per token,   679.03 tokens per second)
       eval time =    1441.34 ms /    59 tokens (   24.43 ms per token,    40.93 tokens per second)
      total time =    2288.13 ms /   634 tokens
slot      release: id  1 | task 24539 | stop processing: n_tokens = 633, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.897 (> 0.100 thold), f_keep = 0.908
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 24600 | processing task, is_child = 0
slot update_slots: id  1 | task 24600 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 641
slot update_slots: id  1 | task 24600 | n_tokens = 575, memory_seq_rm [575, end)
slot update_slots: id  1 | task 24600 | prompt processing progress, n_tokens = 577, batch.n_tokens = 2, progress = 0.900156
slot update_slots: id  1 | task 24600 | n_tokens = 577, memory_seq_rm [577, end)
slot update_slots: id  1 | task 24600 | prompt processing progress, n_tokens = 641, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 24600 | prompt done, n_tokens = 641, batch.n_tokens = 64
slot init_sampler: id  1 | task 24600 | init sampler, took 0.13 ms, tokens: text = 641, total = 641
slot update_slots: id  1 | task 24600 | created context checkpoint 2 of 8 (pos_min = 0, pos_max = 576, size = 13.530 MiB)
slot print_timing: id  1 | task 24600 | 
prompt eval time =     303.51 ms /    66 tokens (    4.60 ms per token,   217.46 tokens per second)
       eval time =    1447.97 ms /    62 tokens (   23.35 ms per token,    42.82 tokens per second)
      total time =    1751.48 ms /   128 tokens
slot      release: id  1 | task 24600 | stop processing: n_tokens = 702, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.891 (> 0.100 thold), f_keep = 0.806
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 24664 | processing task, is_child = 0
slot update_slots: id  1 | task 24664 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 635
slot update_slots: id  1 | task 24664 | n_tokens = 566, memory_seq_rm [566, end)
slot update_slots: id  1 | task 24664 | prompt processing progress, n_tokens = 571, batch.n_tokens = 5, progress = 0.899213
slot update_slots: id  1 | task 24664 | n_tokens = 571, memory_seq_rm [571, end)
slot update_slots: id  1 | task 24664 | prompt processing progress, n_tokens = 635, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 24664 | prompt done, n_tokens = 635, batch.n_tokens = 64
slot init_sampler: id  1 | task 24664 | init sampler, took 0.13 ms, tokens: text = 635, total = 635
slot print_timing: id  1 | task 24664 | 
prompt eval time =     306.23 ms /    69 tokens (    4.44 ms per token,   225.32 tokens per second)
       eval time =    7130.89 ms /   298 tokens (   23.93 ms per token,    41.79 tokens per second)
      total time =    7437.12 ms /   367 tokens
slot      release: id  1 | task 24664 | stop processing: n_tokens = 932, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.479 (> 0.100 thold), f_keep = 0.681
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 24964 | processing task, is_child = 0
slot update_slots: id  1 | task 24964 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1325
slot update_slots: id  1 | task 24964 | n_tokens = 635, memory_seq_rm [635, end)
slot update_slots: id  1 | task 24964 | prompt processing progress, n_tokens = 1261, batch.n_tokens = 626, progress = 0.951698
slot update_slots: id  1 | task 24964 | n_tokens = 1261, memory_seq_rm [1261, end)
slot update_slots: id  1 | task 24964 | prompt processing progress, n_tokens = 1325, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 24964 | prompt done, n_tokens = 1325, batch.n_tokens = 64
slot init_sampler: id  1 | task 24964 | init sampler, took 0.24 ms, tokens: text = 1325, total = 1325
slot update_slots: id  1 | task 24964 | created context checkpoint 3 of 8 (pos_min = 508, pos_max = 1260, size = 17.657 MiB)
slot print_timing: id  1 | task 24964 | 
prompt eval time =    1039.57 ms /   690 tokens (    1.51 ms per token,   663.74 tokens per second)
       eval time =   14969.98 ms /   624 tokens (   23.99 ms per token,    41.68 tokens per second)
      total time =   16009.56 ms /  1314 tokens
slot      release: id  1 | task 24964 | stop processing: n_tokens = 1948, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.517 (> 0.100 thold), f_keep = 0.320
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 1948, total state size = 63.735 MiB
srv          load:  - looking for better prompt, base f_keep = 0.320, sim = 0.517
srv        update:  - cache state: 7 prompts, 2315.244 MiB (limits: 8192.000 MiB, 64000 tokens, 248352 est)
srv        update:    - prompt 0x5a234b577500:    4873 tokens, checkpoints:  5,   235.945 MiB
srv        update:    - prompt 0x5a234d243b70:    4947 tokens, checkpoints:  7,   261.904 MiB
srv        update:    - prompt 0x5a234cfbeaa0:   38169 tokens, checkpoints:  8,  1100.063 MiB
srv        update:    - prompt 0x5a234dc80090:    2123 tokens, checkpoints:  1,    68.612 MiB
srv        update:    - prompt 0x5a234ccbfee0:   15206 tokens, checkpoints:  3,   424.099 MiB
srv        update:    - prompt 0x5a234dbdca00:    2924 tokens, checkpoints:  2,   117.715 MiB
srv        update:    - prompt 0x5a234cfa37d0:    1948 tokens, checkpoints:  3,   106.905 MiB
srv  get_availabl: prompt cache update took 84.72 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 25590 | processing task, is_child = 0
slot update_slots: id  1 | task 25590 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1205
slot update_slots: id  1 | task 25590 | n_past = 623, slot.prompt.tokens.size() = 1948, seq_id = 1, pos_min = 1178, n_swa = 128
slot update_slots: id  1 | task 25590 | restored context checkpoint (pos_min = 0, pos_max = 576, size = 13.530 MiB)
slot update_slots: id  1 | task 25590 | erased invalidated context checkpoint (pos_min = 508, pos_max = 1260, n_swa = 128, size = 17.657 MiB)
slot update_slots: id  1 | task 25590 | n_tokens = 576, memory_seq_rm [576, end)
slot update_slots: id  1 | task 25590 | prompt processing progress, n_tokens = 1141, batch.n_tokens = 565, progress = 0.946888
slot update_slots: id  1 | task 25590 | n_tokens = 1141, memory_seq_rm [1141, end)
slot update_slots: id  1 | task 25590 | prompt processing progress, n_tokens = 1205, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 25590 | prompt done, n_tokens = 1205, batch.n_tokens = 64
slot init_sampler: id  1 | task 25590 | init sampler, took 0.24 ms, tokens: text = 1205, total = 1205
slot update_slots: id  1 | task 25590 | created context checkpoint 3 of 8 (pos_min = 371, pos_max = 1140, size = 18.056 MiB)
slot print_timing: id  1 | task 25590 | 
prompt eval time =    1136.77 ms /   629 tokens (    1.81 ms per token,   553.32 tokens per second)
       eval time =    3591.24 ms /   149 tokens (   24.10 ms per token,    41.49 tokens per second)
      total time =    4728.01 ms /   778 tokens
slot      release: id  1 | task 25590 | stop processing: n_tokens = 1353, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.940 (> 0.100 thold), f_keep = 0.891
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 25741 | processing task, is_child = 0
slot update_slots: id  1 | task 25741 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1282
slot update_slots: id  1 | task 25741 | n_tokens = 1205, memory_seq_rm [1205, end)
slot update_slots: id  1 | task 25741 | prompt processing progress, n_tokens = 1218, batch.n_tokens = 13, progress = 0.950078
slot update_slots: id  1 | task 25741 | n_tokens = 1218, memory_seq_rm [1218, end)
slot update_slots: id  1 | task 25741 | prompt processing progress, n_tokens = 1282, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 25741 | prompt done, n_tokens = 1282, batch.n_tokens = 64
slot init_sampler: id  1 | task 25741 | init sampler, took 0.24 ms, tokens: text = 1282, total = 1282
slot update_slots: id  1 | task 25741 | created context checkpoint 4 of 8 (pos_min = 583, pos_max = 1217, size = 14.890 MiB)
slot print_timing: id  1 | task 25741 | 
prompt eval time =     260.91 ms /    77 tokens (    3.39 ms per token,   295.12 tokens per second)
       eval time =    4656.64 ms /   196 tokens (   23.76 ms per token,    42.09 tokens per second)
      total time =    4917.55 ms /   273 tokens
slot      release: id  1 | task 25741 | stop processing: n_tokens = 1477, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.913 (> 0.100 thold), f_keep = 0.868
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 25939 | processing task, is_child = 0
slot update_slots: id  1 | task 25939 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1404
slot update_slots: id  1 | task 25939 | n_tokens = 1282, memory_seq_rm [1282, end)
slot update_slots: id  1 | task 25939 | prompt processing progress, n_tokens = 1340, batch.n_tokens = 58, progress = 0.954416
slot update_slots: id  1 | task 25939 | n_tokens = 1340, memory_seq_rm [1340, end)
slot update_slots: id  1 | task 25939 | prompt processing progress, n_tokens = 1404, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 25939 | prompt done, n_tokens = 1404, batch.n_tokens = 64
slot init_sampler: id  1 | task 25939 | init sampler, took 0.23 ms, tokens: text = 1404, total = 1404
slot update_slots: id  1 | task 25939 | created context checkpoint 5 of 8 (pos_min = 707, pos_max = 1339, size = 14.843 MiB)
slot print_timing: id  1 | task 25939 | 
prompt eval time =     349.29 ms /   122 tokens (    2.86 ms per token,   349.28 tokens per second)
       eval time =    4098.16 ms /   171 tokens (   23.97 ms per token,    41.73 tokens per second)
      total time =    4447.45 ms /   293 tokens
slot      release: id  1 | task 25939 | stop processing: n_tokens = 1574, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.951 (> 0.100 thold), f_keep = 0.892
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 26112 | processing task, is_child = 0
slot update_slots: id  1 | task 26112 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1477
slot update_slots: id  1 | task 26112 | n_tokens = 1404, memory_seq_rm [1404, end)
slot update_slots: id  1 | task 26112 | prompt processing progress, n_tokens = 1413, batch.n_tokens = 9, progress = 0.956669
slot update_slots: id  1 | task 26112 | n_tokens = 1413, memory_seq_rm [1413, end)
slot update_slots: id  1 | task 26112 | prompt processing progress, n_tokens = 1477, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 26112 | prompt done, n_tokens = 1477, batch.n_tokens = 64
slot init_sampler: id  1 | task 26112 | init sampler, took 0.27 ms, tokens: text = 1477, total = 1477
slot update_slots: id  1 | task 26112 | created context checkpoint 6 of 8 (pos_min = 804, pos_max = 1412, size = 14.281 MiB)
slot print_timing: id  1 | task 26112 | 
prompt eval time =     248.26 ms /    73 tokens (    3.40 ms per token,   294.05 tokens per second)
       eval time =    2831.06 ms /   117 tokens (   24.20 ms per token,    41.33 tokens per second)
      total time =    3079.32 ms /   190 tokens
slot      release: id  1 | task 26112 | stop processing: n_tokens = 1593, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.834 (> 0.100 thold), f_keep = 0.927
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 26231 | processing task, is_child = 0
slot update_slots: id  1 | task 26231 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1770
slot update_slots: id  1 | task 26231 | n_tokens = 1477, memory_seq_rm [1477, end)
slot update_slots: id  1 | task 26231 | prompt processing progress, n_tokens = 1706, batch.n_tokens = 229, progress = 0.963842
slot update_slots: id  1 | task 26231 | n_tokens = 1706, memory_seq_rm [1706, end)
slot update_slots: id  1 | task 26231 | prompt processing progress, n_tokens = 1770, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 26231 | prompt done, n_tokens = 1770, batch.n_tokens = 64
slot init_sampler: id  1 | task 26231 | init sampler, took 0.28 ms, tokens: text = 1770, total = 1770
slot update_slots: id  1 | task 26231 | created context checkpoint 7 of 8 (pos_min = 1072, pos_max = 1705, size = 14.867 MiB)
slot print_timing: id  1 | task 26231 | 
prompt eval time =     552.86 ms /   293 tokens (    1.89 ms per token,   529.98 tokens per second)
       eval time =    6046.28 ms /   253 tokens (   23.90 ms per token,    41.84 tokens per second)
      total time =    6599.13 ms /   546 tokens
slot      release: id  1 | task 26231 | stop processing: n_tokens = 2022, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.707 (> 0.100 thold), f_keep = 0.587
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 26486 | processing task, is_child = 0
slot update_slots: id  1 | task 26486 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1678
slot update_slots: id  1 | task 26486 | n_past = 1186, slot.prompt.tokens.size() = 2022, seq_id = 1, pos_min = 1388, n_swa = 128
slot update_slots: id  1 | task 26486 | restored context checkpoint (pos_min = 804, pos_max = 1412, size = 14.281 MiB)
slot update_slots: id  1 | task 26486 | erased invalidated context checkpoint (pos_min = 1072, pos_max = 1705, n_swa = 128, size = 14.867 MiB)
slot update_slots: id  1 | task 26486 | n_tokens = 1186, memory_seq_rm [1186, end)
slot update_slots: id  1 | task 26486 | prompt processing progress, n_tokens = 1614, batch.n_tokens = 428, progress = 0.961859
slot update_slots: id  1 | task 26486 | n_tokens = 1614, memory_seq_rm [1614, end)
slot update_slots: id  1 | task 26486 | prompt processing progress, n_tokens = 1678, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 26486 | prompt done, n_tokens = 1678, batch.n_tokens = 64
slot init_sampler: id  1 | task 26486 | init sampler, took 0.39 ms, tokens: text = 1678, total = 1678
slot update_slots: id  1 | task 26486 | created context checkpoint 7 of 8 (pos_min = 1059, pos_max = 1613, size = 13.014 MiB)
slot print_timing: id  1 | task 26486 | 
prompt eval time =     883.20 ms /   492 tokens (    1.80 ms per token,   557.06 tokens per second)
       eval time =    2068.00 ms /    83 tokens (   24.92 ms per token,    40.14 tokens per second)
      total time =    2951.20 ms /   575 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 26486 | stop processing: n_tokens = 1760, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.964 (> 0.100 thold), f_keep = 0.953
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 26571 | processing task, is_child = 0
slot update_slots: id  1 | task 26571 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1740
slot update_slots: id  1 | task 26571 | n_tokens = 1678, memory_seq_rm [1678, end)
slot update_slots: id  1 | task 26571 | prompt processing progress, n_tokens = 1740, batch.n_tokens = 62, progress = 1.000000
slot update_slots: id  1 | task 26571 | prompt done, n_tokens = 1740, batch.n_tokens = 62
slot init_sampler: id  1 | task 26571 | init sampler, took 0.31 ms, tokens: text = 1740, total = 1740
slot print_timing: id  1 | task 26571 | 
prompt eval time =     262.66 ms /    62 tokens (    4.24 ms per token,   236.05 tokens per second)
       eval time =    2008.29 ms /    81 tokens (   24.79 ms per token,    40.33 tokens per second)
      total time =    2270.95 ms /   143 tokens
slot      release: id  1 | task 26571 | stop processing: n_tokens = 1820, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.957 (> 0.100 thold), f_keep = 0.956
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 26653 | processing task, is_child = 0
slot update_slots: id  1 | task 26653 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1819
slot update_slots: id  1 | task 26653 | n_tokens = 1740, memory_seq_rm [1740, end)
slot update_slots: id  1 | task 26653 | prompt processing progress, n_tokens = 1755, batch.n_tokens = 15, progress = 0.964816
slot update_slots: id  1 | task 26653 | n_tokens = 1755, memory_seq_rm [1755, end)
slot update_slots: id  1 | task 26653 | prompt processing progress, n_tokens = 1819, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 26653 | prompt done, n_tokens = 1819, batch.n_tokens = 64
slot init_sampler: id  1 | task 26653 | init sampler, took 0.34 ms, tokens: text = 1819, total = 1819
slot update_slots: id  1 | task 26653 | created context checkpoint 8 of 8 (pos_min = 1059, pos_max = 1754, size = 16.321 MiB)
slot print_timing: id  1 | task 26653 | 
prompt eval time =     265.31 ms /    79 tokens (    3.36 ms per token,   297.76 tokens per second)
       eval time =    2201.75 ms /    89 tokens (   24.74 ms per token,    40.42 tokens per second)
      total time =    2467.06 ms /   168 tokens
slot      release: id  1 | task 26653 | stop processing: n_tokens = 1907, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.284 (> 0.100 thold), f_keep = 0.954
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 26744 | processing task, is_child = 0
slot update_slots: id  1 | task 26744 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6398
slot update_slots: id  1 | task 26744 | n_tokens = 1819, memory_seq_rm [1819, end)
slot update_slots: id  1 | task 26744 | prompt processing progress, n_tokens = 3867, batch.n_tokens = 2048, progress = 0.604408
slot update_slots: id  1 | task 26744 | n_tokens = 3867, memory_seq_rm [3867, end)
slot update_slots: id  1 | task 26744 | prompt processing progress, n_tokens = 5915, batch.n_tokens = 2048, progress = 0.924508
slot update_slots: id  1 | task 26744 | n_tokens = 5915, memory_seq_rm [5915, end)
slot update_slots: id  1 | task 26744 | prompt processing progress, n_tokens = 6334, batch.n_tokens = 419, progress = 0.989997
slot update_slots: id  1 | task 26744 | n_tokens = 6334, memory_seq_rm [6334, end)
slot update_slots: id  1 | task 26744 | prompt processing progress, n_tokens = 6398, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 26744 | prompt done, n_tokens = 6398, batch.n_tokens = 64
slot init_sampler: id  1 | task 26744 | init sampler, took 1.00 ms, tokens: text = 6398, total = 6398
slot update_slots: id  1 | task 26744 | erasing old context checkpoint (pos_min = 0, pos_max = 510, size = 11.983 MiB)
slot update_slots: id  1 | task 26744 | created context checkpoint 8 of 8 (pos_min = 5564, pos_max = 6333, size = 18.056 MiB)
slot print_timing: id  1 | task 26744 | 
prompt eval time =    5211.52 ms /  4579 tokens (    1.14 ms per token,   878.63 tokens per second)
       eval time =    2628.88 ms /   106 tokens (   24.80 ms per token,    40.32 tokens per second)
      total time =    7840.40 ms /  4685 tokens
slot      release: id  1 | task 26744 | stop processing: n_tokens = 6503, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.984
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 26854 | processing task, is_child = 0
slot update_slots: id  1 | task 26854 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6490
slot update_slots: id  1 | task 26854 | n_tokens = 6398, memory_seq_rm [6398, end)
slot update_slots: id  1 | task 26854 | prompt processing progress, n_tokens = 6426, batch.n_tokens = 28, progress = 0.990139
slot update_slots: id  1 | task 26854 | n_tokens = 6426, memory_seq_rm [6426, end)
slot update_slots: id  1 | task 26854 | prompt processing progress, n_tokens = 6490, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 26854 | prompt done, n_tokens = 6490, batch.n_tokens = 64
slot init_sampler: id  1 | task 26854 | init sampler, took 1.31 ms, tokens: text = 6490, total = 6490
slot update_slots: id  1 | task 26854 | erasing old context checkpoint (pos_min = 0, pos_max = 576, size = 13.530 MiB)
slot update_slots: id  1 | task 26854 | created context checkpoint 8 of 8 (pos_min = 5733, pos_max = 6425, size = 16.250 MiB)
slot print_timing: id  1 | task 26854 | 
prompt eval time =     309.11 ms /    92 tokens (    3.36 ms per token,   297.63 tokens per second)
       eval time =    3370.19 ms /   135 tokens (   24.96 ms per token,    40.06 tokens per second)
      total time =    3679.30 ms /   227 tokens
slot      release: id  1 | task 26854 | stop processing: n_tokens = 6624, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.967 (> 0.100 thold), f_keep = 0.980
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 26991 | processing task, is_child = 0
slot update_slots: id  1 | task 26991 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6711
slot update_slots: id  1 | task 26991 | n_tokens = 6490, memory_seq_rm [6490, end)
slot update_slots: id  1 | task 26991 | prompt processing progress, n_tokens = 6647, batch.n_tokens = 157, progress = 0.990463
slot update_slots: id  1 | task 26991 | n_tokens = 6647, memory_seq_rm [6647, end)
slot update_slots: id  1 | task 26991 | prompt processing progress, n_tokens = 6711, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 26991 | prompt done, n_tokens = 6711, batch.n_tokens = 64
slot init_sampler: id  1 | task 26991 | init sampler, took 1.27 ms, tokens: text = 6711, total = 6711
slot update_slots: id  1 | task 26991 | erasing old context checkpoint (pos_min = 371, pos_max = 1140, size = 18.056 MiB)
slot update_slots: id  1 | task 26991 | created context checkpoint 8 of 8 (pos_min = 5918, pos_max = 6646, size = 17.095 MiB)
slot print_timing: id  1 | task 26991 | 
prompt eval time =     509.24 ms /   221 tokens (    2.30 ms per token,   433.98 tokens per second)
       eval time =    2951.53 ms /   113 tokens (   26.12 ms per token,    38.29 tokens per second)
      total time =    3460.77 ms /   334 tokens
slot      release: id  1 | task 26991 | stop processing: n_tokens = 6823, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  0 | task -1 | selected slot by LRU, t_last = -1
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 27106 | processing task, is_child = 0
slot update_slots: id  0 | task 27106 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 117555
srv    send_error: task id = 27106, error: request (117555 tokens) exceeds the available context size (64000 tokens), try increasing it
slot      release: id  0 | task 27106 | stop processing: n_tokens = 0, truncated = 0
srv  update_slots: no tokens to decode
srv  update_slots: all slots are idle
srv          stop: cancel task, id_task = 27106
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 400
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.953 (> 0.100 thold), f_keep = 0.083
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 6823, total state size = 177.087 MiB
srv          load:  - looking for better prompt, base f_keep = 0.083, sim = 0.953
srv        update:  - cache state: 8 prompts, 2617.082 MiB (limits: 8192.000 MiB, 64000 tokens, 241066 est)
srv        update:    - prompt 0x5a234b577500:    4873 tokens, checkpoints:  5,   235.945 MiB
srv        update:    - prompt 0x5a234d243b70:    4947 tokens, checkpoints:  7,   261.904 MiB
srv        update:    - prompt 0x5a234cfbeaa0:   38169 tokens, checkpoints:  8,  1100.063 MiB
srv        update:    - prompt 0x5a234dc80090:    2123 tokens, checkpoints:  1,    68.612 MiB
srv        update:    - prompt 0x5a234ccbfee0:   15206 tokens, checkpoints:  3,   424.099 MiB
srv        update:    - prompt 0x5a234dbdca00:    2924 tokens, checkpoints:  2,   117.715 MiB
srv        update:    - prompt 0x5a234cfa37d0:    1948 tokens, checkpoints:  3,   106.905 MiB
srv        update:    - prompt 0x5a234cce4d20:    6823 tokens, checkpoints:  8,   301.838 MiB
srv  get_availabl: prompt cache update took 281.27 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 27109 | processing task, is_child = 0
slot update_slots: id  1 | task 27109 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 594
slot update_slots: id  1 | task 27109 | n_past = 566, slot.prompt.tokens.size() = 6823, seq_id = 1, pos_min = 6094, n_swa = 128
slot update_slots: id  1 | task 27109 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  1 | task 27109 | erased invalidated context checkpoint (pos_min = 583, pos_max = 1217, n_swa = 128, size = 14.890 MiB)
slot update_slots: id  1 | task 27109 | erased invalidated context checkpoint (pos_min = 707, pos_max = 1339, n_swa = 128, size = 14.843 MiB)
slot update_slots: id  1 | task 27109 | erased invalidated context checkpoint (pos_min = 804, pos_max = 1412, n_swa = 128, size = 14.281 MiB)
slot update_slots: id  1 | task 27109 | erased invalidated context checkpoint (pos_min = 1059, pos_max = 1613, n_swa = 128, size = 13.014 MiB)
slot update_slots: id  1 | task 27109 | erased invalidated context checkpoint (pos_min = 1059, pos_max = 1754, n_swa = 128, size = 16.321 MiB)
slot update_slots: id  1 | task 27109 | erased invalidated context checkpoint (pos_min = 5564, pos_max = 6333, n_swa = 128, size = 18.056 MiB)
slot update_slots: id  1 | task 27109 | erased invalidated context checkpoint (pos_min = 5733, pos_max = 6425, n_swa = 128, size = 16.250 MiB)
slot update_slots: id  1 | task 27109 | erased invalidated context checkpoint (pos_min = 5918, pos_max = 6646, n_swa = 128, size = 17.095 MiB)
slot update_slots: id  1 | task 27109 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  1 | task 27109 | prompt processing progress, n_tokens = 530, batch.n_tokens = 530, progress = 0.892256
slot update_slots: id  1 | task 27109 | n_tokens = 530, memory_seq_rm [530, end)
slot update_slots: id  1 | task 27109 | prompt processing progress, n_tokens = 594, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 27109 | prompt done, n_tokens = 594, batch.n_tokens = 64
slot init_sampler: id  1 | task 27109 | init sampler, took 0.12 ms, tokens: text = 594, total = 594
slot update_slots: id  1 | task 27109 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 529, size = 12.428 MiB)
slot print_timing: id  1 | task 27109 | 
prompt eval time =     931.31 ms /   594 tokens (    1.57 ms per token,   637.81 tokens per second)
       eval time =    1202.50 ms /    51 tokens (   23.58 ms per token,    42.41 tokens per second)
      total time =    2133.81 ms /   645 tokens
slot      release: id  1 | task 27109 | stop processing: n_tokens = 644, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.464 (> 0.100 thold), f_keep = 0.922
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 27162 | processing task, is_child = 0
slot update_slots: id  1 | task 27162 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1281
slot update_slots: id  1 | task 27162 | n_tokens = 594, memory_seq_rm [594, end)
slot update_slots: id  1 | task 27162 | prompt processing progress, n_tokens = 1217, batch.n_tokens = 623, progress = 0.950039
slot update_slots: id  1 | task 27162 | n_tokens = 1217, memory_seq_rm [1217, end)
slot update_slots: id  1 | task 27162 | prompt processing progress, n_tokens = 1281, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 27162 | prompt done, n_tokens = 1281, batch.n_tokens = 64
slot init_sampler: id  1 | task 27162 | init sampler, took 0.25 ms, tokens: text = 1281, total = 1281
slot update_slots: id  1 | task 27162 | created context checkpoint 2 of 8 (pos_min = 447, pos_max = 1216, size = 18.056 MiB)
slot print_timing: id  1 | task 27162 | 
prompt eval time =     983.22 ms /   687 tokens (    1.43 ms per token,   698.72 tokens per second)
       eval time =    1520.56 ms /    63 tokens (   24.14 ms per token,    41.43 tokens per second)
      total time =    2503.78 ms /   750 tokens
slot      release: id  1 | task 27162 | stop processing: n_tokens = 1343, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.398 (> 0.100 thold), f_keep = 0.954
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 27227 | processing task, is_child = 0
slot update_slots: id  1 | task 27227 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3217
slot update_slots: id  1 | task 27227 | n_tokens = 1281, memory_seq_rm [1281, end)
slot update_slots: id  1 | task 27227 | prompt processing progress, n_tokens = 3153, batch.n_tokens = 1872, progress = 0.980106
slot update_slots: id  1 | task 27227 | n_tokens = 3153, memory_seq_rm [3153, end)
slot update_slots: id  1 | task 27227 | prompt processing progress, n_tokens = 3217, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 27227 | prompt done, n_tokens = 3217, batch.n_tokens = 64
slot init_sampler: id  1 | task 27227 | init sampler, took 0.60 ms, tokens: text = 3217, total = 3217
slot update_slots: id  1 | task 27227 | created context checkpoint 3 of 8 (pos_min = 2383, pos_max = 3152, size = 18.056 MiB)
slot print_timing: id  1 | task 27227 | 
prompt eval time =    2338.07 ms /  1936 tokens (    1.21 ms per token,   828.03 tokens per second)
       eval time =    2347.43 ms /    94 tokens (   24.97 ms per token,    40.04 tokens per second)
      total time =    4685.50 ms /  2030 tokens
slot      release: id  1 | task 27227 | stop processing: n_tokens = 3310, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.785 (> 0.100 thold), f_keep = 0.972
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 27323 | processing task, is_child = 0
slot update_slots: id  1 | task 27323 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4099
slot update_slots: id  1 | task 27323 | n_tokens = 3217, memory_seq_rm [3217, end)
slot update_slots: id  1 | task 27323 | prompt processing progress, n_tokens = 4035, batch.n_tokens = 818, progress = 0.984386
slot update_slots: id  1 | task 27323 | n_tokens = 4035, memory_seq_rm [4035, end)
slot update_slots: id  1 | task 27323 | prompt processing progress, n_tokens = 4099, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 27323 | prompt done, n_tokens = 4099, batch.n_tokens = 64
slot init_sampler: id  1 | task 27323 | init sampler, took 0.79 ms, tokens: text = 4099, total = 4099
slot update_slots: id  1 | task 27323 | created context checkpoint 4 of 8 (pos_min = 3265, pos_max = 4034, size = 18.056 MiB)
slot print_timing: id  1 | task 27323 | 
prompt eval time =    1198.56 ms /   882 tokens (    1.36 ms per token,   735.88 tokens per second)
       eval time =    1743.50 ms /    70 tokens (   24.91 ms per token,    40.15 tokens per second)
      total time =    2942.06 ms /   952 tokens
slot      release: id  1 | task 27323 | stop processing: n_tokens = 4168, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.814 (> 0.100 thold), f_keep = 0.983
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 27395 | processing task, is_child = 0
slot update_slots: id  1 | task 27395 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5038
slot update_slots: id  1 | task 27395 | n_tokens = 4099, memory_seq_rm [4099, end)
slot update_slots: id  1 | task 27395 | prompt processing progress, n_tokens = 4974, batch.n_tokens = 875, progress = 0.987297
slot update_slots: id  1 | task 27395 | n_tokens = 4974, memory_seq_rm [4974, end)
slot update_slots: id  1 | task 27395 | prompt processing progress, n_tokens = 5038, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 27395 | prompt done, n_tokens = 5038, batch.n_tokens = 64
slot init_sampler: id  1 | task 27395 | init sampler, took 0.94 ms, tokens: text = 5038, total = 5038
slot update_slots: id  1 | task 27395 | created context checkpoint 5 of 8 (pos_min = 4204, pos_max = 4973, size = 18.056 MiB)
slot print_timing: id  1 | task 27395 | 
prompt eval time =    1287.38 ms /   939 tokens (    1.37 ms per token,   729.39 tokens per second)
       eval time =    8592.19 ms /   336 tokens (   25.57 ms per token,    39.11 tokens per second)
      total time =    9879.57 ms /  1275 tokens
slot      release: id  1 | task 27395 | stop processing: n_tokens = 5373, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.835 (> 0.100 thold), f_keep = 0.938
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 27733 | processing task, is_child = 0
slot update_slots: id  1 | task 27733 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6035
slot update_slots: id  1 | task 27733 | n_tokens = 5038, memory_seq_rm [5038, end)
slot update_slots: id  1 | task 27733 | prompt processing progress, n_tokens = 5971, batch.n_tokens = 933, progress = 0.989395
slot update_slots: id  1 | task 27733 | n_tokens = 5971, memory_seq_rm [5971, end)
slot update_slots: id  1 | task 27733 | prompt processing progress, n_tokens = 6035, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 27733 | prompt done, n_tokens = 6035, batch.n_tokens = 64
slot init_sampler: id  1 | task 27733 | init sampler, took 1.41 ms, tokens: text = 6035, total = 6035
slot update_slots: id  1 | task 27733 | created context checkpoint 6 of 8 (pos_min = 5201, pos_max = 5970, size = 18.056 MiB)
slot print_timing: id  1 | task 27733 | 
prompt eval time =    1365.31 ms /   997 tokens (    1.37 ms per token,   730.24 tokens per second)
       eval time =    8825.69 ms /   347 tokens (   25.43 ms per token,    39.32 tokens per second)
      total time =   10191.00 ms /  1344 tokens
slot      release: id  1 | task 27733 | stop processing: n_tokens = 6381, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.946
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 28082 | processing task, is_child = 0
slot update_slots: id  1 | task 28082 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6101
slot update_slots: id  1 | task 28082 | n_tokens = 6035, memory_seq_rm [6035, end)
slot update_slots: id  1 | task 28082 | prompt processing progress, n_tokens = 6037, batch.n_tokens = 2, progress = 0.989510
slot update_slots: id  1 | task 28082 | n_tokens = 6037, memory_seq_rm [6037, end)
slot update_slots: id  1 | task 28082 | prompt processing progress, n_tokens = 6101, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 28082 | prompt done, n_tokens = 6101, batch.n_tokens = 64
slot init_sampler: id  1 | task 28082 | init sampler, took 1.16 ms, tokens: text = 6101, total = 6101
slot update_slots: id  1 | task 28082 | created context checkpoint 7 of 8 (pos_min = 5611, pos_max = 6036, size = 9.990 MiB)
slot print_timing: id  1 | task 28082 | 
prompt eval time =     324.78 ms /    66 tokens (    4.92 ms per token,   203.21 tokens per second)
       eval time =    2588.89 ms /   105 tokens (   24.66 ms per token,    40.56 tokens per second)
      total time =    2913.68 ms /   171 tokens
slot      release: id  1 | task 28082 | stop processing: n_tokens = 6205, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.868 (> 0.100 thold), f_keep = 0.983
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 28189 | processing task, is_child = 0
slot update_slots: id  1 | task 28189 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7028
slot update_slots: id  1 | task 28189 | n_tokens = 6101, memory_seq_rm [6101, end)
slot update_slots: id  1 | task 28189 | prompt processing progress, n_tokens = 6964, batch.n_tokens = 863, progress = 0.990894
slot update_slots: id  1 | task 28189 | n_tokens = 6964, memory_seq_rm [6964, end)
slot update_slots: id  1 | task 28189 | prompt processing progress, n_tokens = 7028, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 28189 | prompt done, n_tokens = 7028, batch.n_tokens = 64
slot init_sampler: id  1 | task 28189 | init sampler, took 1.73 ms, tokens: text = 7028, total = 7028
slot update_slots: id  1 | task 28189 | created context checkpoint 8 of 8 (pos_min = 6194, pos_max = 6963, size = 18.056 MiB)
slot print_timing: id  1 | task 28189 | 
prompt eval time =    1272.19 ms /   927 tokens (    1.37 ms per token,   728.66 tokens per second)
       eval time =    9689.23 ms /   380 tokens (   25.50 ms per token,    39.22 tokens per second)
      total time =   10961.42 ms /  1307 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 28189 | stop processing: n_tokens = 7407, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.954 (> 0.100 thold), f_keep = 0.949
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 28571 | processing task, is_child = 0
slot update_slots: id  1 | task 28571 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7367
slot update_slots: id  1 | task 28571 | n_tokens = 7028, memory_seq_rm [7028, end)
slot update_slots: id  1 | task 28571 | prompt processing progress, n_tokens = 7303, batch.n_tokens = 275, progress = 0.991313
slot update_slots: id  1 | task 28571 | n_tokens = 7303, memory_seq_rm [7303, end)
slot update_slots: id  1 | task 28571 | prompt processing progress, n_tokens = 7367, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 28571 | prompt done, n_tokens = 7367, batch.n_tokens = 64
slot init_sampler: id  1 | task 28571 | init sampler, took 1.25 ms, tokens: text = 7367, total = 7367
slot update_slots: id  1 | task 28571 | erasing old context checkpoint (pos_min = 0, pos_max = 529, size = 12.428 MiB)
slot update_slots: id  1 | task 28571 | created context checkpoint 8 of 8 (pos_min = 6637, pos_max = 7302, size = 15.617 MiB)
slot print_timing: id  1 | task 28571 | 
prompt eval time =     580.96 ms /   339 tokens (    1.71 ms per token,   583.51 tokens per second)
       eval time =    5001.51 ms /   199 tokens (   25.13 ms per token,    39.79 tokens per second)
      total time =    5582.47 ms /   538 tokens
slot      release: id  1 | task 28571 | stop processing: n_tokens = 7565, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.887 (> 0.100 thold), f_keep = 0.974
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 28772 | processing task, is_child = 0
slot update_slots: id  1 | task 28772 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8309
slot update_slots: id  1 | task 28772 | n_tokens = 7367, memory_seq_rm [7367, end)
slot update_slots: id  1 | task 28772 | prompt processing progress, n_tokens = 8245, batch.n_tokens = 878, progress = 0.992298
slot update_slots: id  1 | task 28772 | n_tokens = 8245, memory_seq_rm [8245, end)
slot update_slots: id  1 | task 28772 | prompt processing progress, n_tokens = 8309, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 28772 | prompt done, n_tokens = 8309, batch.n_tokens = 64
slot init_sampler: id  1 | task 28772 | init sampler, took 1.59 ms, tokens: text = 8309, total = 8309
slot update_slots: id  1 | task 28772 | erasing old context checkpoint (pos_min = 447, pos_max = 1216, size = 18.056 MiB)
slot update_slots: id  1 | task 28772 | created context checkpoint 8 of 8 (pos_min = 7475, pos_max = 8244, size = 18.056 MiB)
slot print_timing: id  1 | task 28772 | 
prompt eval time =    1329.07 ms /   942 tokens (    1.41 ms per token,   708.77 tokens per second)
       eval time =   29747.57 ms /  1129 tokens (   26.35 ms per token,    37.95 tokens per second)
      total time =   31076.64 ms /  2071 tokens
slot      release: id  1 | task 28772 | stop processing: n_tokens = 9437, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.966 (> 0.100 thold), f_keep = 0.880
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 29903 | processing task, is_child = 0
slot update_slots: id  1 | task 29903 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8600
slot update_slots: id  1 | task 29903 | n_past = 8309, slot.prompt.tokens.size() = 9437, seq_id = 1, pos_min = 8667, n_swa = 128
slot update_slots: id  1 | task 29903 | restored context checkpoint (pos_min = 7475, pos_max = 8244, size = 18.056 MiB)
slot update_slots: id  1 | task 29903 | n_tokens = 8244, memory_seq_rm [8244, end)
slot update_slots: id  1 | task 29903 | prompt processing progress, n_tokens = 8536, batch.n_tokens = 292, progress = 0.992558
slot update_slots: id  1 | task 29903 | n_tokens = 8536, memory_seq_rm [8536, end)
slot update_slots: id  1 | task 29903 | prompt processing progress, n_tokens = 8600, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 29903 | prompt done, n_tokens = 8600, batch.n_tokens = 64
slot init_sampler: id  1 | task 29903 | init sampler, took 1.61 ms, tokens: text = 8600, total = 8600
slot update_slots: id  1 | task 29903 | erasing old context checkpoint (pos_min = 2383, pos_max = 3152, size = 18.056 MiB)
slot update_slots: id  1 | task 29903 | created context checkpoint 8 of 8 (pos_min = 7766, pos_max = 8535, size = 18.056 MiB)
slot print_timing: id  1 | task 29903 | 
prompt eval time =     780.53 ms /   356 tokens (    2.19 ms per token,   456.10 tokens per second)
       eval time =    2958.89 ms /   105 tokens (   28.18 ms per token,    35.49 tokens per second)
      total time =    3739.42 ms /   461 tokens
slot      release: id  1 | task 29903 | stop processing: n_tokens = 8704, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 30010 | processing task, is_child = 0
slot update_slots: id  1 | task 30010 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8712
slot update_slots: id  1 | task 30010 | n_tokens = 8600, memory_seq_rm [8600, end)
slot update_slots: id  1 | task 30010 | prompt processing progress, n_tokens = 8648, batch.n_tokens = 48, progress = 0.992654
slot update_slots: id  1 | task 30010 | n_tokens = 8648, memory_seq_rm [8648, end)
slot update_slots: id  1 | task 30010 | prompt processing progress, n_tokens = 8712, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 30010 | prompt done, n_tokens = 8712, batch.n_tokens = 64
slot init_sampler: id  1 | task 30010 | init sampler, took 1.88 ms, tokens: text = 8712, total = 8712
slot update_slots: id  1 | task 30010 | erasing old context checkpoint (pos_min = 3265, pos_max = 4034, size = 18.056 MiB)
slot update_slots: id  1 | task 30010 | created context checkpoint 8 of 8 (pos_min = 7934, pos_max = 8647, size = 16.743 MiB)
slot print_timing: id  1 | task 30010 | 
prompt eval time =     532.36 ms /   112 tokens (    4.75 ms per token,   210.38 tokens per second)
       eval time =   17111.10 ms /   638 tokens (   26.82 ms per token,    37.29 tokens per second)
      total time =   17643.46 ms /   750 tokens
slot      release: id  1 | task 30010 | stop processing: n_tokens = 9349, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.964 (> 0.100 thold), f_keep = 0.932
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 30650 | processing task, is_child = 0
slot update_slots: id  1 | task 30650 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 9033
slot update_slots: id  1 | task 30650 | n_tokens = 8712, memory_seq_rm [8712, end)
slot update_slots: id  1 | task 30650 | prompt processing progress, n_tokens = 8969, batch.n_tokens = 257, progress = 0.992915
slot update_slots: id  1 | task 30650 | n_tokens = 8969, memory_seq_rm [8969, end)
slot update_slots: id  1 | task 30650 | prompt processing progress, n_tokens = 9033, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 30650 | prompt done, n_tokens = 9033, batch.n_tokens = 64
slot init_sampler: id  1 | task 30650 | init sampler, took 1.87 ms, tokens: text = 9033, total = 9033
slot update_slots: id  1 | task 30650 | erasing old context checkpoint (pos_min = 4204, pos_max = 4973, size = 18.056 MiB)
slot update_slots: id  1 | task 30650 | created context checkpoint 8 of 8 (pos_min = 8585, pos_max = 8968, size = 9.005 MiB)
slot print_timing: id  1 | task 30650 | 
prompt eval time =     598.47 ms /   321 tokens (    1.86 ms per token,   536.36 tokens per second)
       eval time =   72462.25 ms /  2687 tokens (   26.97 ms per token,    37.08 tokens per second)
      total time =   73060.72 ms /  3008 tokens
slot      release: id  1 | task 30650 | stop processing: n_tokens = 11719, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.796 (> 0.100 thold), f_keep = 0.771
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 33339 | processing task, is_child = 0
slot update_slots: id  1 | task 33339 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 11349
slot update_slots: id  1 | task 33339 | n_past = 9033, slot.prompt.tokens.size() = 11719, seq_id = 1, pos_min = 10949, n_swa = 128
slot update_slots: id  1 | task 33339 | restored context checkpoint (pos_min = 8585, pos_max = 8968, size = 9.005 MiB)
slot update_slots: id  1 | task 33339 | n_tokens = 8968, memory_seq_rm [8968, end)
slot update_slots: id  1 | task 33339 | prompt processing progress, n_tokens = 11016, batch.n_tokens = 2048, progress = 0.970658
slot update_slots: id  1 | task 33339 | n_tokens = 11016, memory_seq_rm [11016, end)
slot update_slots: id  1 | task 33339 | prompt processing progress, n_tokens = 11285, batch.n_tokens = 269, progress = 0.994361
slot update_slots: id  1 | task 33339 | n_tokens = 11285, memory_seq_rm [11285, end)
slot update_slots: id  1 | task 33339 | prompt processing progress, n_tokens = 11349, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 33339 | prompt done, n_tokens = 11349, batch.n_tokens = 64
slot init_sampler: id  1 | task 33339 | init sampler, took 1.65 ms, tokens: text = 11349, total = 11349
slot update_slots: id  1 | task 33339 | erasing old context checkpoint (pos_min = 5201, pos_max = 5970, size = 18.056 MiB)
slot update_slots: id  1 | task 33339 | created context checkpoint 8 of 8 (pos_min = 10515, pos_max = 11284, size = 18.056 MiB)
slot print_timing: id  1 | task 33339 | 
prompt eval time =    3379.30 ms /  2381 tokens (    1.42 ms per token,   704.58 tokens per second)
       eval time =    9548.94 ms /   357 tokens (   26.75 ms per token,    37.39 tokens per second)
      total time =   12928.24 ms /  2738 tokens
slot      release: id  1 | task 33339 | stop processing: n_tokens = 11705, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.963 (> 0.100 thold), f_keep = 0.970
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 33699 | processing task, is_child = 0
slot update_slots: id  1 | task 33699 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 11791
slot update_slots: id  1 | task 33699 | n_tokens = 11349, memory_seq_rm [11349, end)
slot update_slots: id  1 | task 33699 | prompt processing progress, n_tokens = 11727, batch.n_tokens = 378, progress = 0.994572
slot update_slots: id  1 | task 33699 | n_tokens = 11727, memory_seq_rm [11727, end)
slot update_slots: id  1 | task 33699 | prompt processing progress, n_tokens = 11791, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 33699 | prompt done, n_tokens = 11791, batch.n_tokens = 64
slot init_sampler: id  1 | task 33699 | init sampler, took 1.74 ms, tokens: text = 11791, total = 11791
slot update_slots: id  1 | task 33699 | erasing old context checkpoint (pos_min = 5611, pos_max = 6036, size = 9.990 MiB)
slot update_slots: id  1 | task 33699 | created context checkpoint 8 of 8 (pos_min = 11222, pos_max = 11726, size = 11.842 MiB)
slot print_timing: id  1 | task 33699 | 
prompt eval time =     785.55 ms /   442 tokens (    1.78 ms per token,   562.66 tokens per second)
       eval time =    2591.16 ms /    96 tokens (   26.99 ms per token,    37.05 tokens per second)
      total time =    3376.71 ms /   538 tokens
slot      release: id  1 | task 33699 | stop processing: n_tokens = 11886, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 33797 | processing task, is_child = 0
slot update_slots: id  1 | task 33797 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 11857
slot update_slots: id  1 | task 33797 | n_tokens = 11791, memory_seq_rm [11791, end)
slot update_slots: id  1 | task 33797 | prompt processing progress, n_tokens = 11793, batch.n_tokens = 2, progress = 0.994602
slot update_slots: id  1 | task 33797 | n_tokens = 11793, memory_seq_rm [11793, end)
slot update_slots: id  1 | task 33797 | prompt processing progress, n_tokens = 11857, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 33797 | prompt done, n_tokens = 11857, batch.n_tokens = 64
slot init_sampler: id  1 | task 33797 | init sampler, took 1.66 ms, tokens: text = 11857, total = 11857
slot update_slots: id  1 | task 33797 | erasing old context checkpoint (pos_min = 6194, pos_max = 6963, size = 18.056 MiB)
slot update_slots: id  1 | task 33797 | created context checkpoint 8 of 8 (pos_min = 11222, pos_max = 11792, size = 13.390 MiB)
slot print_timing: id  1 | task 33797 | 
prompt eval time =     338.72 ms /    66 tokens (    5.13 ms per token,   194.85 tokens per second)
       eval time =    2966.64 ms /   114 tokens (   26.02 ms per token,    38.43 tokens per second)
      total time =    3305.36 ms /   180 tokens
slot      release: id  1 | task 33797 | stop processing: n_tokens = 11970, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.419 (> 0.100 thold), f_keep = 0.022
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 11970, total state size = 298.224 MiB
srv          load:  - looking for better prompt, base f_keep = 0.022, sim = 0.419
srv        update:  - cache state: 9 prompts, 3036.070 MiB (limits: 8192.000 MiB, 64000 tokens, 240096 est)
srv        update:    - prompt 0x5a234b577500:    4873 tokens, checkpoints:  5,   235.945 MiB
srv        update:    - prompt 0x5a234d243b70:    4947 tokens, checkpoints:  7,   261.904 MiB
srv        update:    - prompt 0x5a234cfbeaa0:   38169 tokens, checkpoints:  8,  1100.063 MiB
srv        update:    - prompt 0x5a234dc80090:    2123 tokens, checkpoints:  1,    68.612 MiB
srv        update:    - prompt 0x5a234ccbfee0:   15206 tokens, checkpoints:  3,   424.099 MiB
srv        update:    - prompt 0x5a234dbdca00:    2924 tokens, checkpoints:  2,   117.715 MiB
srv        update:    - prompt 0x5a234cfa37d0:    1948 tokens, checkpoints:  3,   106.905 MiB
srv        update:    - prompt 0x5a234cce4d20:    6823 tokens, checkpoints:  8,   301.838 MiB
srv        update:    - prompt 0x5a237670b520:   11970 tokens, checkpoints:  8,   418.989 MiB
srv  get_availabl: prompt cache update took 336.12 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 33913 | processing task, is_child = 0
slot update_slots: id  1 | task 33913 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 639
slot update_slots: id  1 | task 33913 | n_past = 268, slot.prompt.tokens.size() = 11970, seq_id = 1, pos_min = 11222, n_swa = 128
slot update_slots: id  1 | task 33913 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  1 | task 33913 | erased invalidated context checkpoint (pos_min = 6637, pos_max = 7302, n_swa = 128, size = 15.617 MiB)
slot update_slots: id  1 | task 33913 | erased invalidated context checkpoint (pos_min = 7475, pos_max = 8244, n_swa = 128, size = 18.056 MiB)
slot update_slots: id  1 | task 33913 | erased invalidated context checkpoint (pos_min = 7766, pos_max = 8535, n_swa = 128, size = 18.056 MiB)
slot update_slots: id  1 | task 33913 | erased invalidated context checkpoint (pos_min = 7934, pos_max = 8647, n_swa = 128, size = 16.743 MiB)
slot update_slots: id  1 | task 33913 | erased invalidated context checkpoint (pos_min = 8585, pos_max = 8968, n_swa = 128, size = 9.005 MiB)
slot update_slots: id  1 | task 33913 | erased invalidated context checkpoint (pos_min = 10515, pos_max = 11284, n_swa = 128, size = 18.056 MiB)
slot update_slots: id  1 | task 33913 | erased invalidated context checkpoint (pos_min = 11222, pos_max = 11726, n_swa = 128, size = 11.842 MiB)
slot update_slots: id  1 | task 33913 | erased invalidated context checkpoint (pos_min = 11222, pos_max = 11792, n_swa = 128, size = 13.390 MiB)
slot update_slots: id  1 | task 33913 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  1 | task 33913 | prompt processing progress, n_tokens = 575, batch.n_tokens = 575, progress = 0.899844
slot update_slots: id  1 | task 33913 | n_tokens = 575, memory_seq_rm [575, end)
slot update_slots: id  1 | task 33913 | prompt processing progress, n_tokens = 639, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 33913 | prompt done, n_tokens = 639, batch.n_tokens = 64
slot init_sampler: id  1 | task 33913 | init sampler, took 0.12 ms, tokens: text = 639, total = 639
slot update_slots: id  1 | task 33913 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 574, size = 13.483 MiB)
slot print_timing: id  1 | task 33913 | 
prompt eval time =    1078.69 ms /   639 tokens (    1.69 ms per token,   592.38 tokens per second)
       eval time =    8986.34 ms /   350 tokens (   25.68 ms per token,    38.95 tokens per second)
      total time =   10065.03 ms /   989 tokens
slot      release: id  1 | task 33913 | stop processing: n_tokens = 988, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.889 (> 0.100 thold), f_keep = 0.647
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 34265 | processing task, is_child = 0
slot update_slots: id  1 | task 34265 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 719
slot update_slots: id  1 | task 34265 | n_tokens = 639, memory_seq_rm [639, end)
slot update_slots: id  1 | task 34265 | prompt processing progress, n_tokens = 655, batch.n_tokens = 16, progress = 0.910987
slot update_slots: id  1 | task 34265 | n_tokens = 655, memory_seq_rm [655, end)
slot update_slots: id  1 | task 34265 | prompt processing progress, n_tokens = 719, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 34265 | prompt done, n_tokens = 719, batch.n_tokens = 64
slot init_sampler: id  1 | task 34265 | init sampler, took 0.14 ms, tokens: text = 719, total = 719
slot update_slots: id  1 | task 34265 | created context checkpoint 2 of 8 (pos_min = 218, pos_max = 654, size = 10.247 MiB)
slot print_timing: id  1 | task 34265 | 
prompt eval time =     274.80 ms /    80 tokens (    3.43 ms per token,   291.12 tokens per second)
       eval time =    5052.90 ms /   197 tokens (   25.65 ms per token,    38.99 tokens per second)
      total time =    5327.69 ms /   277 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 34265 | stop processing: n_tokens = 915, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.901 (> 0.100 thold), f_keep = 0.786
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 34464 | processing task, is_child = 0
slot update_slots: id  1 | task 34464 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 798
slot update_slots: id  1 | task 34464 | n_tokens = 719, memory_seq_rm [719, end)
slot update_slots: id  1 | task 34464 | prompt processing progress, n_tokens = 734, batch.n_tokens = 15, progress = 0.919800
slot update_slots: id  1 | task 34464 | n_tokens = 734, memory_seq_rm [734, end)
slot update_slots: id  1 | task 34464 | prompt processing progress, n_tokens = 798, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 34464 | prompt done, n_tokens = 798, batch.n_tokens = 64
slot init_sampler: id  1 | task 34464 | init sampler, took 0.14 ms, tokens: text = 798, total = 798
slot update_slots: id  1 | task 34464 | created context checkpoint 3 of 8 (pos_min = 276, pos_max = 733, size = 10.740 MiB)
slot print_timing: id  1 | task 34464 | 
prompt eval time =     281.91 ms /    79 tokens (    3.57 ms per token,   280.23 tokens per second)
       eval time =    4470.50 ms /   171 tokens (   26.14 ms per token,    38.25 tokens per second)
      total time =    4752.41 ms /   250 tokens
slot      release: id  1 | task 34464 | stop processing: n_tokens = 968, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.891 (> 0.100 thold), f_keep = 0.824
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 34637 | processing task, is_child = 0
slot update_slots: id  1 | task 34637 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 896
slot update_slots: id  1 | task 34637 | n_tokens = 798, memory_seq_rm [798, end)
slot update_slots: id  1 | task 34637 | prompt processing progress, n_tokens = 832, batch.n_tokens = 34, progress = 0.928571
slot update_slots: id  1 | task 34637 | n_tokens = 832, memory_seq_rm [832, end)
slot update_slots: id  1 | task 34637 | prompt processing progress, n_tokens = 896, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 34637 | prompt done, n_tokens = 896, batch.n_tokens = 64
slot init_sampler: id  1 | task 34637 | init sampler, took 0.17 ms, tokens: text = 896, total = 896
slot update_slots: id  1 | task 34637 | created context checkpoint 4 of 8 (pos_min = 329, pos_max = 831, size = 11.795 MiB)
slot print_timing: id  1 | task 34637 | 
prompt eval time =     339.99 ms /    98 tokens (    3.47 ms per token,   288.24 tokens per second)
       eval time =    4423.11 ms /   169 tokens (   26.17 ms per token,    38.21 tokens per second)
      total time =    4763.10 ms /   267 tokens
slot      release: id  1 | task 34637 | stop processing: n_tokens = 1064, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.802 (> 0.100 thold), f_keep = 0.842
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 34808 | processing task, is_child = 0
slot update_slots: id  1 | task 34808 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1117
slot update_slots: id  1 | task 34808 | n_tokens = 896, memory_seq_rm [896, end)
slot update_slots: id  1 | task 34808 | prompt processing progress, n_tokens = 1053, batch.n_tokens = 157, progress = 0.942704
slot update_slots: id  1 | task 34808 | n_tokens = 1053, memory_seq_rm [1053, end)
slot update_slots: id  1 | task 34808 | prompt processing progress, n_tokens = 1117, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 34808 | prompt done, n_tokens = 1117, batch.n_tokens = 64
slot init_sampler: id  1 | task 34808 | init sampler, took 0.20 ms, tokens: text = 1117, total = 1117
slot update_slots: id  1 | task 34808 | created context checkpoint 5 of 8 (pos_min = 425, pos_max = 1052, size = 14.726 MiB)
slot print_timing: id  1 | task 34808 | 
prompt eval time =     499.56 ms /   221 tokens (    2.26 ms per token,   442.39 tokens per second)
       eval time =    7515.61 ms /   290 tokens (   25.92 ms per token,    38.59 tokens per second)
      total time =    8015.17 ms /   511 tokens
slot      release: id  1 | task 34808 | stop processing: n_tokens = 1406, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.550 (> 0.100 thold), f_keep = 0.442
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 1406, total state size = 50.955 MiB
srv          load:  - looking for better prompt, base f_keep = 0.442, sim = 0.550
srv        update:  - cache state: 10 prompts, 3148.018 MiB (limits: 8192.000 MiB, 64000 tokens, 235216 est)
srv        update:    - prompt 0x5a234b577500:    4873 tokens, checkpoints:  5,   235.945 MiB
srv        update:    - prompt 0x5a234d243b70:    4947 tokens, checkpoints:  7,   261.904 MiB
srv        update:    - prompt 0x5a234cfbeaa0:   38169 tokens, checkpoints:  8,  1100.063 MiB
srv        update:    - prompt 0x5a234dc80090:    2123 tokens, checkpoints:  1,    68.612 MiB
srv        update:    - prompt 0x5a234ccbfee0:   15206 tokens, checkpoints:  3,   424.099 MiB
srv        update:    - prompt 0x5a234dbdca00:    2924 tokens, checkpoints:  2,   117.715 MiB
srv        update:    - prompt 0x5a234cfa37d0:    1948 tokens, checkpoints:  3,   106.905 MiB
srv        update:    - prompt 0x5a234cce4d20:    6823 tokens, checkpoints:  8,   301.838 MiB
srv        update:    - prompt 0x5a237670b520:   11970 tokens, checkpoints:  8,   418.989 MiB
srv        update:    - prompt 0x5a234d356c00:    1406 tokens, checkpoints:  5,   111.947 MiB
srv  get_availabl: prompt cache update took 81.62 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 35100 | processing task, is_child = 0
slot update_slots: id  1 | task 35100 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1130
slot update_slots: id  1 | task 35100 | n_past = 621, slot.prompt.tokens.size() = 1406, seq_id = 1, pos_min = 639, n_swa = 128
slot update_slots: id  1 | task 35100 | restored context checkpoint (pos_min = 425, pos_max = 1052, size = 14.726 MiB)
slot update_slots: id  1 | task 35100 | n_tokens = 621, memory_seq_rm [621, end)
slot update_slots: id  1 | task 35100 | prompt processing progress, n_tokens = 1066, batch.n_tokens = 445, progress = 0.943363
slot update_slots: id  1 | task 35100 | n_tokens = 1066, memory_seq_rm [1066, end)
slot update_slots: id  1 | task 35100 | prompt processing progress, n_tokens = 1130, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 35100 | prompt done, n_tokens = 1130, batch.n_tokens = 64
slot init_sampler: id  1 | task 35100 | init sampler, took 0.20 ms, tokens: text = 1130, total = 1130
slot print_timing: id  1 | task 35100 | 
prompt eval time =     939.33 ms /   509 tokens (    1.85 ms per token,   541.88 tokens per second)
       eval time =    2143.66 ms /    83 tokens (   25.83 ms per token,    38.72 tokens per second)
      total time =    3082.99 ms /   592 tokens
slot      release: id  1 | task 35100 | stop processing: n_tokens = 1212, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.933 (> 0.100 thold), f_keep = 0.932
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 35185 | processing task, is_child = 0
slot update_slots: id  1 | task 35185 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1211
slot update_slots: id  1 | task 35185 | n_tokens = 1130, memory_seq_rm [1130, end)
slot update_slots: id  1 | task 35185 | prompt processing progress, n_tokens = 1147, batch.n_tokens = 17, progress = 0.947151
slot update_slots: id  1 | task 35185 | n_tokens = 1147, memory_seq_rm [1147, end)
slot update_slots: id  1 | task 35185 | prompt processing progress, n_tokens = 1211, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 35185 | prompt done, n_tokens = 1211, batch.n_tokens = 64
slot init_sampler: id  1 | task 35185 | init sampler, took 0.24 ms, tokens: text = 1211, total = 1211
slot update_slots: id  1 | task 35185 | created context checkpoint 6 of 8 (pos_min = 602, pos_max = 1146, size = 12.780 MiB)
slot print_timing: id  1 | task 35185 | 
prompt eval time =     289.87 ms /    81 tokens (    3.58 ms per token,   279.44 tokens per second)
       eval time =    1386.88 ms /    56 tokens (   24.77 ms per token,    40.38 tokens per second)
      total time =    1676.75 ms /   137 tokens
slot      release: id  1 | task 35185 | stop processing: n_tokens = 1266, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LRU, t_last = 1663905208
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 1921, total state size = 48.024 MiB
srv          load:  - looking for better prompt, base f_keep = 0.140, sim = 0.021
srv          load:  - found better prompt with f_keep = 0.442, sim = 0.049
srv        update:  - cache state: 10 prompts, 3139.411 MiB (limits: 8192.000 MiB, 64000 tokens, 237205 est)
srv        update:    - prompt 0x5a234b577500:    4873 tokens, checkpoints:  5,   235.945 MiB
srv        update:    - prompt 0x5a234d243b70:    4947 tokens, checkpoints:  7,   261.904 MiB
srv        update:    - prompt 0x5a234cfbeaa0:   38169 tokens, checkpoints:  8,  1100.063 MiB
srv        update:    - prompt 0x5a234dc80090:    2123 tokens, checkpoints:  1,    68.612 MiB
srv        update:    - prompt 0x5a234ccbfee0:   15206 tokens, checkpoints:  3,   424.099 MiB
srv        update:    - prompt 0x5a234dbdca00:    2924 tokens, checkpoints:  2,   117.715 MiB
srv        update:    - prompt 0x5a234cfa37d0:    1948 tokens, checkpoints:  3,   106.905 MiB
srv        update:    - prompt 0x5a234cce4d20:    6823 tokens, checkpoints:  8,   301.838 MiB
srv        update:    - prompt 0x5a237670b520:   11970 tokens, checkpoints:  8,   418.989 MiB
srv        update:    - prompt 0x5a234f21f8f0:    1921 tokens, checkpoints:  3,   103.341 MiB
srv  get_availabl: prompt cache update took 456.77 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 35243 | processing task, is_child = 0
slot update_slots: id  3 | task 35243 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 12546
slot update_slots: id  3 | task 35243 | n_past = 621, slot.prompt.tokens.size() = 1406, seq_id = 3, pos_min = 639, n_swa = 128
slot update_slots: id  3 | task 35243 | restored context checkpoint (pos_min = 425, pos_max = 1052, size = 14.726 MiB)
slot update_slots: id  3 | task 35243 | n_tokens = 621, memory_seq_rm [621, end)
slot update_slots: id  3 | task 35243 | prompt processing progress, n_tokens = 2669, batch.n_tokens = 2048, progress = 0.212737
slot update_slots: id  3 | task 35243 | n_tokens = 2669, memory_seq_rm [2669, end)
slot update_slots: id  3 | task 35243 | prompt processing progress, n_tokens = 4717, batch.n_tokens = 2048, progress = 0.375976
slot update_slots: id  3 | task 35243 | n_tokens = 4717, memory_seq_rm [4717, end)
slot update_slots: id  3 | task 35243 | prompt processing progress, n_tokens = 6765, batch.n_tokens = 2048, progress = 0.539216
slot update_slots: id  3 | task 35243 | n_tokens = 6765, memory_seq_rm [6765, end)
slot update_slots: id  3 | task 35243 | prompt processing progress, n_tokens = 8813, batch.n_tokens = 2048, progress = 0.702455
slot update_slots: id  3 | task 35243 | n_tokens = 8813, memory_seq_rm [8813, end)
slot update_slots: id  3 | task 35243 | prompt processing progress, n_tokens = 10861, batch.n_tokens = 2048, progress = 0.865694
slot update_slots: id  3 | task 35243 | n_tokens = 10861, memory_seq_rm [10861, end)
slot update_slots: id  3 | task 35243 | prompt processing progress, n_tokens = 12482, batch.n_tokens = 1621, progress = 0.994899
slot update_slots: id  3 | task 35243 | n_tokens = 12482, memory_seq_rm [12482, end)
slot update_slots: id  3 | task 35243 | prompt processing progress, n_tokens = 12546, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 35243 | prompt done, n_tokens = 12546, batch.n_tokens = 64
slot init_sampler: id  3 | task 35243 | init sampler, took 1.84 ms, tokens: text = 12546, total = 12546
slot update_slots: id  3 | task 35243 | created context checkpoint 6 of 8 (pos_min = 11712, pos_max = 12481, size = 18.056 MiB)
slot print_timing: id  3 | task 35243 | 
prompt eval time =   14804.22 ms / 11925 tokens (    1.24 ms per token,   805.51 tokens per second)
       eval time =    3124.12 ms /   120 tokens (   26.03 ms per token,    38.41 tokens per second)
      total time =   17928.35 ms / 12045 tokens
slot      release: id  3 | task 35243 | stop processing: n_tokens = 12665, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.823 (> 0.100 thold), f_keep = 0.876
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 35370 | processing task, is_child = 0
slot update_slots: id  1 | task 35370 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1347
slot update_slots: id  1 | task 35370 | n_past = 1109, slot.prompt.tokens.size() = 1266, seq_id = 1, pos_min = 1139, n_swa = 128
slot update_slots: id  1 | task 35370 | restored context checkpoint (pos_min = 602, pos_max = 1146, size = 12.780 MiB)
slot update_slots: id  1 | task 35370 | n_tokens = 1109, memory_seq_rm [1109, end)
slot update_slots: id  1 | task 35370 | prompt processing progress, n_tokens = 1283, batch.n_tokens = 174, progress = 0.952487
slot update_slots: id  1 | task 35370 | n_tokens = 1283, memory_seq_rm [1283, end)
slot update_slots: id  1 | task 35370 | prompt processing progress, n_tokens = 1347, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 35370 | prompt done, n_tokens = 1347, batch.n_tokens = 64
slot init_sampler: id  1 | task 35370 | init sampler, took 0.26 ms, tokens: text = 1347, total = 1347
slot update_slots: id  1 | task 35370 | created context checkpoint 7 of 8 (pos_min = 621, pos_max = 1282, size = 15.523 MiB)
slot print_timing: id  1 | task 35370 | 
prompt eval time =     713.38 ms /   238 tokens (    3.00 ms per token,   333.62 tokens per second)
       eval time =    3072.67 ms /   119 tokens (   25.82 ms per token,    38.73 tokens per second)
      total time =    3786.04 ms /   357 tokens
slot      release: id  1 | task 35370 | stop processing: n_tokens = 1465, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.395 (> 0.100 thold), f_keep = 0.919
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 35491 | processing task, is_child = 0
slot update_slots: id  1 | task 35491 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3410
slot update_slots: id  1 | task 35491 | n_tokens = 1347, memory_seq_rm [1347, end)
slot update_slots: id  1 | task 35491 | prompt processing progress, n_tokens = 3346, batch.n_tokens = 1999, progress = 0.981232
slot update_slots: id  1 | task 35491 | n_tokens = 3346, memory_seq_rm [3346, end)
slot update_slots: id  1 | task 35491 | prompt processing progress, n_tokens = 3410, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 35491 | prompt done, n_tokens = 3410, batch.n_tokens = 64
slot init_sampler: id  1 | task 35491 | init sampler, took 0.62 ms, tokens: text = 3410, total = 3410
slot update_slots: id  1 | task 35491 | created context checkpoint 8 of 8 (pos_min = 2576, pos_max = 3345, size = 18.056 MiB)
slot print_timing: id  1 | task 35491 | 
prompt eval time =    2734.03 ms /  2063 tokens (    1.33 ms per token,   754.56 tokens per second)
       eval time =    1888.96 ms /    70 tokens (   26.99 ms per token,    37.06 tokens per second)
      total time =    4622.99 ms /  2133 tokens
slot      release: id  1 | task 35491 | stop processing: n_tokens = 3479, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.942 (> 0.100 thold), f_keep = 0.980
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 35563 | processing task, is_child = 0
slot update_slots: id  1 | task 35563 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3621
slot update_slots: id  1 | task 35563 | n_tokens = 3410, memory_seq_rm [3410, end)
slot update_slots: id  1 | task 35563 | prompt processing progress, n_tokens = 3557, batch.n_tokens = 147, progress = 0.982325
slot update_slots: id  1 | task 35563 | n_tokens = 3557, memory_seq_rm [3557, end)
slot update_slots: id  1 | task 35563 | prompt processing progress, n_tokens = 3621, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 35563 | prompt done, n_tokens = 3621, batch.n_tokens = 64
slot init_sampler: id  1 | task 35563 | init sampler, took 0.83 ms, tokens: text = 3621, total = 3621
slot update_slots: id  1 | task 35563 | erasing old context checkpoint (pos_min = 0, pos_max = 574, size = 13.483 MiB)
slot update_slots: id  1 | task 35563 | created context checkpoint 8 of 8 (pos_min = 2787, pos_max = 3556, size = 18.056 MiB)
slot print_timing: id  1 | task 35563 | 
prompt eval time =     515.30 ms /   211 tokens (    2.44 ms per token,   409.47 tokens per second)
       eval time =    1241.10 ms /    45 tokens (   27.58 ms per token,    36.26 tokens per second)
      total time =    1756.41 ms /   256 tokens
slot      release: id  1 | task 35563 | stop processing: n_tokens = 3665, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.947 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 35610 | processing task, is_child = 0
slot update_slots: id  1 | task 35610 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3824
slot update_slots: id  1 | task 35610 | n_tokens = 3621, memory_seq_rm [3621, end)
slot update_slots: id  1 | task 35610 | prompt processing progress, n_tokens = 3760, batch.n_tokens = 139, progress = 0.983264
slot update_slots: id  1 | task 35610 | n_tokens = 3760, memory_seq_rm [3760, end)
slot update_slots: id  1 | task 35610 | prompt processing progress, n_tokens = 3824, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 35610 | prompt done, n_tokens = 3824, batch.n_tokens = 64
slot init_sampler: id  1 | task 35610 | init sampler, took 0.61 ms, tokens: text = 3824, total = 3824
slot update_slots: id  1 | task 35610 | erasing old context checkpoint (pos_min = 218, pos_max = 654, size = 10.247 MiB)
slot update_slots: id  1 | task 35610 | created context checkpoint 8 of 8 (pos_min = 2990, pos_max = 3759, size = 18.056 MiB)
slot print_timing: id  1 | task 35610 | 
prompt eval time =     507.14 ms /   203 tokens (    2.50 ms per token,   400.29 tokens per second)
       eval time =    8998.63 ms /   335 tokens (   26.86 ms per token,    37.23 tokens per second)
      total time =    9505.77 ms /   538 tokens
slot      release: id  1 | task 35610 | stop processing: n_tokens = 4158, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.883 (> 0.100 thold), f_keep = 0.920
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 35947 | processing task, is_child = 0
slot update_slots: id  1 | task 35947 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4331
slot update_slots: id  1 | task 35947 | n_tokens = 3824, memory_seq_rm [3824, end)
slot update_slots: id  1 | task 35947 | prompt processing progress, n_tokens = 4267, batch.n_tokens = 443, progress = 0.985223
slot update_slots: id  1 | task 35947 | n_tokens = 4267, memory_seq_rm [4267, end)
slot update_slots: id  1 | task 35947 | prompt processing progress, n_tokens = 4331, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 35947 | prompt done, n_tokens = 4331, batch.n_tokens = 64
slot init_sampler: id  1 | task 35947 | init sampler, took 0.67 ms, tokens: text = 4331, total = 4331
slot update_slots: id  1 | task 35947 | erasing old context checkpoint (pos_min = 276, pos_max = 733, size = 10.740 MiB)
slot update_slots: id  1 | task 35947 | created context checkpoint 8 of 8 (pos_min = 3650, pos_max = 4266, size = 14.468 MiB)
slot print_timing: id  1 | task 35947 | 
prompt eval time =     936.67 ms /   507 tokens (    1.85 ms per token,   541.28 tokens per second)
       eval time =    6933.85 ms /   255 tokens (   27.19 ms per token,    36.78 tokens per second)
      total time =    7870.52 ms /   762 tokens
slot      release: id  1 | task 35947 | stop processing: n_tokens = 4585, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.536 (> 0.100 thold), f_keep = 0.945
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 36204 | processing task, is_child = 0
slot update_slots: id  1 | task 36204 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8080
slot update_slots: id  1 | task 36204 | n_tokens = 4331, memory_seq_rm [4331, end)
slot update_slots: id  1 | task 36204 | prompt processing progress, n_tokens = 6379, batch.n_tokens = 2048, progress = 0.789480
slot update_slots: id  1 | task 36204 | n_tokens = 6379, memory_seq_rm [6379, end)
slot update_slots: id  1 | task 36204 | prompt processing progress, n_tokens = 8016, batch.n_tokens = 1637, progress = 0.992079
slot update_slots: id  1 | task 36204 | n_tokens = 8016, memory_seq_rm [8016, end)
slot update_slots: id  1 | task 36204 | prompt processing progress, n_tokens = 8080, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 36204 | prompt done, n_tokens = 8080, batch.n_tokens = 64
slot init_sampler: id  1 | task 36204 | init sampler, took 1.30 ms, tokens: text = 8080, total = 8080
slot update_slots: id  1 | task 36204 | erasing old context checkpoint (pos_min = 329, pos_max = 831, size = 11.795 MiB)
slot update_slots: id  1 | task 36204 | created context checkpoint 8 of 8 (pos_min = 7246, pos_max = 8015, size = 18.056 MiB)
slot print_timing: id  1 | task 36204 | 
prompt eval time =    5581.26 ms /  3749 tokens (    1.49 ms per token,   671.71 tokens per second)
       eval time =   29249.21 ms /  1052 tokens (   27.80 ms per token,    35.97 tokens per second)
      total time =   34830.48 ms /  4801 tokens
slot      release: id  1 | task 36204 | stop processing: n_tokens = 9131, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.440 (> 0.100 thold), f_keep = 0.143
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 9131, total state size = 232.169 MiB
srv          load:  - looking for better prompt, base f_keep = 0.143, sim = 0.440
srv        update:  - cache state: 11 prompts, 3501.302 MiB (limits: 8192.000 MiB, 64000 tokens, 234052 est)
srv        update:    - prompt 0x5a234b577500:    4873 tokens, checkpoints:  5,   235.945 MiB
srv        update:    - prompt 0x5a234d243b70:    4947 tokens, checkpoints:  7,   261.904 MiB
srv        update:    - prompt 0x5a234cfbeaa0:   38169 tokens, checkpoints:  8,  1100.063 MiB
srv        update:    - prompt 0x5a234dc80090:    2123 tokens, checkpoints:  1,    68.612 MiB
srv        update:    - prompt 0x5a234ccbfee0:   15206 tokens, checkpoints:  3,   424.099 MiB
srv        update:    - prompt 0x5a234dbdca00:    2924 tokens, checkpoints:  2,   117.715 MiB
srv        update:    - prompt 0x5a234cfa37d0:    1948 tokens, checkpoints:  3,   106.905 MiB
srv        update:    - prompt 0x5a234cce4d20:    6823 tokens, checkpoints:  8,   301.838 MiB
srv        update:    - prompt 0x5a237670b520:   11970 tokens, checkpoints:  8,   418.989 MiB
srv        update:    - prompt 0x5a234f21f8f0:    1921 tokens, checkpoints:  3,   103.341 MiB
srv        update:    - prompt 0x5a237670b330:    9131 tokens, checkpoints:  8,   361.890 MiB
srv  get_availabl: prompt cache update took 282.90 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 37259 | processing task, is_child = 0
slot update_slots: id  1 | task 37259 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2974
slot update_slots: id  1 | task 37259 | n_past = 1308, slot.prompt.tokens.size() = 9131, seq_id = 1, pos_min = 8361, n_swa = 128
slot update_slots: id  1 | task 37259 | restored context checkpoint (pos_min = 621, pos_max = 1282, size = 15.523 MiB)
slot update_slots: id  1 | task 37259 | erased invalidated context checkpoint (pos_min = 2576, pos_max = 3345, n_swa = 128, size = 18.056 MiB)
slot update_slots: id  1 | task 37259 | erased invalidated context checkpoint (pos_min = 2787, pos_max = 3556, n_swa = 128, size = 18.056 MiB)
slot update_slots: id  1 | task 37259 | erased invalidated context checkpoint (pos_min = 2990, pos_max = 3759, n_swa = 128, size = 18.056 MiB)
slot update_slots: id  1 | task 37259 | erased invalidated context checkpoint (pos_min = 3650, pos_max = 4266, n_swa = 128, size = 14.468 MiB)
slot update_slots: id  1 | task 37259 | erased invalidated context checkpoint (pos_min = 7246, pos_max = 8015, n_swa = 128, size = 18.056 MiB)
slot update_slots: id  1 | task 37259 | n_tokens = 1282, memory_seq_rm [1282, end)
slot update_slots: id  1 | task 37259 | prompt processing progress, n_tokens = 2910, batch.n_tokens = 1628, progress = 0.978480
slot update_slots: id  1 | task 37259 | n_tokens = 2910, memory_seq_rm [2910, end)
slot update_slots: id  1 | task 37259 | prompt processing progress, n_tokens = 2974, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 37259 | prompt done, n_tokens = 2974, batch.n_tokens = 64
slot init_sampler: id  1 | task 37259 | init sampler, took 0.51 ms, tokens: text = 2974, total = 2974
slot update_slots: id  1 | task 37259 | created context checkpoint 4 of 8 (pos_min = 2140, pos_max = 2909, size = 18.056 MiB)
slot print_timing: id  1 | task 37259 | 
prompt eval time =    2670.42 ms /  1692 tokens (    1.58 ms per token,   633.61 tokens per second)
       eval time =    4318.15 ms /   163 tokens (   26.49 ms per token,    37.75 tokens per second)
      total time =    6988.57 ms /  1855 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 37259 | stop processing: n_tokens = 3136, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.973 (> 0.100 thold), f_keep = 0.948
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 37424 | processing task, is_child = 0
slot update_slots: id  1 | task 37424 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3055
slot update_slots: id  1 | task 37424 | n_tokens = 2974, memory_seq_rm [2974, end)
slot update_slots: id  1 | task 37424 | prompt processing progress, n_tokens = 2991, batch.n_tokens = 17, progress = 0.979051
slot update_slots: id  1 | task 37424 | n_tokens = 2991, memory_seq_rm [2991, end)
slot update_slots: id  1 | task 37424 | prompt processing progress, n_tokens = 3055, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 37424 | prompt done, n_tokens = 3055, batch.n_tokens = 64
slot init_sampler: id  1 | task 37424 | init sampler, took 0.59 ms, tokens: text = 3055, total = 3055
slot update_slots: id  1 | task 37424 | created context checkpoint 5 of 8 (pos_min = 2366, pos_max = 2990, size = 14.656 MiB)
slot print_timing: id  1 | task 37424 | 
prompt eval time =     313.16 ms /    81 tokens (    3.87 ms per token,   258.65 tokens per second)
       eval time =    1541.60 ms /    58 tokens (   26.58 ms per token,    37.62 tokens per second)
      total time =    1854.76 ms /   139 tokens
slot      release: id  1 | task 37424 | stop processing: n_tokens = 3112, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.212 (> 0.100 thold), f_keep = 0.982
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 37484 | processing task, is_child = 0
slot update_slots: id  1 | task 37484 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 14396
slot update_slots: id  1 | task 37484 | n_tokens = 3055, memory_seq_rm [3055, end)
slot update_slots: id  1 | task 37484 | prompt processing progress, n_tokens = 5103, batch.n_tokens = 2048, progress = 0.354473
slot update_slots: id  1 | task 37484 | n_tokens = 5103, memory_seq_rm [5103, end)
slot update_slots: id  1 | task 37484 | prompt processing progress, n_tokens = 7151, batch.n_tokens = 2048, progress = 0.496735
slot update_slots: id  1 | task 37484 | n_tokens = 7151, memory_seq_rm [7151, end)
slot update_slots: id  1 | task 37484 | prompt processing progress, n_tokens = 9199, batch.n_tokens = 2048, progress = 0.638997
slot update_slots: id  1 | task 37484 | n_tokens = 9199, memory_seq_rm [9199, end)
slot update_slots: id  1 | task 37484 | prompt processing progress, n_tokens = 11247, batch.n_tokens = 2048, progress = 0.781259
slot update_slots: id  1 | task 37484 | n_tokens = 11247, memory_seq_rm [11247, end)
slot update_slots: id  1 | task 37484 | prompt processing progress, n_tokens = 13295, batch.n_tokens = 2048, progress = 0.923520
slot update_slots: id  1 | task 37484 | n_tokens = 13295, memory_seq_rm [13295, end)
slot update_slots: id  1 | task 37484 | prompt processing progress, n_tokens = 14332, batch.n_tokens = 1037, progress = 0.995554
slot update_slots: id  1 | task 37484 | n_tokens = 14332, memory_seq_rm [14332, end)
slot update_slots: id  1 | task 37484 | prompt processing progress, n_tokens = 14396, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 37484 | prompt done, n_tokens = 14396, batch.n_tokens = 64
slot init_sampler: id  1 | task 37484 | init sampler, took 2.36 ms, tokens: text = 14396, total = 14396
slot update_slots: id  1 | task 37484 | created context checkpoint 6 of 8 (pos_min = 13562, pos_max = 14331, size = 18.056 MiB)
slot print_timing: id  1 | task 37484 | 
prompt eval time =   16490.37 ms / 11341 tokens (    1.45 ms per token,   687.73 tokens per second)
       eval time =    1889.40 ms /    67 tokens (   28.20 ms per token,    35.46 tokens per second)
      total time =   18379.77 ms / 11408 tokens
slot      release: id  1 | task 37484 | stop processing: n_tokens = 14462, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.886 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 37558 | processing task, is_child = 0
slot update_slots: id  1 | task 37558 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16241
slot update_slots: id  1 | task 37558 | n_tokens = 14396, memory_seq_rm [14396, end)
slot update_slots: id  1 | task 37558 | prompt processing progress, n_tokens = 16177, batch.n_tokens = 1781, progress = 0.996059
slot update_slots: id  1 | task 37558 | n_tokens = 16177, memory_seq_rm [16177, end)
slot update_slots: id  1 | task 37558 | prompt processing progress, n_tokens = 16241, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 37558 | prompt done, n_tokens = 16241, batch.n_tokens = 64
slot init_sampler: id  1 | task 37558 | init sampler, took 2.35 ms, tokens: text = 16241, total = 16241
slot update_slots: id  1 | task 37558 | created context checkpoint 7 of 8 (pos_min = 15407, pos_max = 16176, size = 18.056 MiB)
slot print_timing: id  1 | task 37558 | 
prompt eval time =    3122.32 ms /  1845 tokens (    1.69 ms per token,   590.91 tokens per second)
       eval time =    9406.12 ms /   323 tokens (   29.12 ms per token,    34.34 tokens per second)
      total time =   12528.44 ms /  2168 tokens
slot      release: id  1 | task 37558 | stop processing: n_tokens = 16563, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.894 (> 0.100 thold), f_keep = 0.981
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 37883 | processing task, is_child = 0
slot update_slots: id  1 | task 37883 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 18173
slot update_slots: id  1 | task 37883 | n_tokens = 16241, memory_seq_rm [16241, end)
slot update_slots: id  1 | task 37883 | prompt processing progress, n_tokens = 18109, batch.n_tokens = 1868, progress = 0.996478
slot update_slots: id  1 | task 37883 | n_tokens = 18109, memory_seq_rm [18109, end)
slot update_slots: id  1 | task 37883 | prompt processing progress, n_tokens = 18173, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 37883 | prompt done, n_tokens = 18173, batch.n_tokens = 64
slot init_sampler: id  1 | task 37883 | init sampler, took 3.89 ms, tokens: text = 18173, total = 18173
slot update_slots: id  1 | task 37883 | created context checkpoint 8 of 8 (pos_min = 17339, pos_max = 18108, size = 18.056 MiB)
slot print_timing: id  1 | task 37883 | 
prompt eval time =    3322.57 ms /  1932 tokens (    1.72 ms per token,   581.48 tokens per second)
       eval time =   21214.81 ms /   735 tokens (   28.86 ms per token,    34.65 tokens per second)
      total time =   24537.38 ms /  2667 tokens
slot      release: id  1 | task 37883 | stop processing: n_tokens = 18907, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.730 (> 0.100 thold), f_keep = 0.156
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 18907, total state size = 461.405 MiB
srv          load:  - looking for better prompt, base f_keep = 0.156, sim = 0.730
srv        update:  - cache state: 12 prompts, 4092.617 MiB (limits: 8192.000 MiB, 64000 tokens, 238080 est)
srv        update:    - prompt 0x5a234b577500:    4873 tokens, checkpoints:  5,   235.945 MiB
srv        update:    - prompt 0x5a234d243b70:    4947 tokens, checkpoints:  7,   261.904 MiB
srv        update:    - prompt 0x5a234cfbeaa0:   38169 tokens, checkpoints:  8,  1100.063 MiB
srv        update:    - prompt 0x5a234dc80090:    2123 tokens, checkpoints:  1,    68.612 MiB
srv        update:    - prompt 0x5a234ccbfee0:   15206 tokens, checkpoints:  3,   424.099 MiB
srv        update:    - prompt 0x5a234dbdca00:    2924 tokens, checkpoints:  2,   117.715 MiB
srv        update:    - prompt 0x5a234cfa37d0:    1948 tokens, checkpoints:  3,   106.905 MiB
srv        update:    - prompt 0x5a234cce4d20:    6823 tokens, checkpoints:  8,   301.838 MiB
srv        update:    - prompt 0x5a237670b520:   11970 tokens, checkpoints:  8,   418.989 MiB
srv        update:    - prompt 0x5a234f21f8f0:    1921 tokens, checkpoints:  3,   103.341 MiB
srv        update:    - prompt 0x5a237670b330:    9131 tokens, checkpoints:  8,   361.890 MiB
srv        update:    - prompt 0x5a23757875b0:   18907 tokens, checkpoints:  8,   591.315 MiB
srv  get_availabl: prompt cache update took 509.03 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 38620 | processing task, is_child = 0
slot update_slots: id  1 | task 38620 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4033
slot update_slots: id  1 | task 38620 | n_past = 2943, slot.prompt.tokens.size() = 18907, seq_id = 1, pos_min = 18137, n_swa = 128
slot update_slots: id  1 | task 38620 | restored context checkpoint (pos_min = 2366, pos_max = 2990, size = 14.656 MiB)
slot update_slots: id  1 | task 38620 | erased invalidated context checkpoint (pos_min = 13562, pos_max = 14331, n_swa = 128, size = 18.056 MiB)
slot update_slots: id  1 | task 38620 | erased invalidated context checkpoint (pos_min = 15407, pos_max = 16176, n_swa = 128, size = 18.056 MiB)
slot update_slots: id  1 | task 38620 | erased invalidated context checkpoint (pos_min = 17339, pos_max = 18108, n_swa = 128, size = 18.056 MiB)
slot update_slots: id  1 | task 38620 | n_tokens = 2943, memory_seq_rm [2943, end)
slot update_slots: id  1 | task 38620 | prompt processing progress, n_tokens = 3969, batch.n_tokens = 1026, progress = 0.984131
slot update_slots: id  1 | task 38620 | n_tokens = 3969, memory_seq_rm [3969, end)
slot update_slots: id  1 | task 38620 | prompt processing progress, n_tokens = 4033, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 38620 | prompt done, n_tokens = 4033, batch.n_tokens = 64
slot init_sampler: id  1 | task 38620 | init sampler, took 0.65 ms, tokens: text = 4033, total = 4033
slot update_slots: id  1 | task 38620 | created context checkpoint 6 of 8 (pos_min = 3199, pos_max = 3968, size = 18.056 MiB)
slot print_timing: id  1 | task 38620 | 
prompt eval time =    1834.62 ms /  1090 tokens (    1.68 ms per token,   594.13 tokens per second)
       eval time =   12571.49 ms /   469 tokens (   26.80 ms per token,    37.31 tokens per second)
      total time =   14406.11 ms /  1559 tokens
slot      release: id  1 | task 38620 | stop processing: n_tokens = 4501, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.921 (> 0.100 thold), f_keep = 0.896
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 39091 | processing task, is_child = 0
slot update_slots: id  1 | task 39091 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4380
slot update_slots: id  1 | task 39091 | n_tokens = 4033, memory_seq_rm [4033, end)
slot update_slots: id  1 | task 39091 | prompt processing progress, n_tokens = 4316, batch.n_tokens = 283, progress = 0.985388
slot update_slots: id  1 | task 39091 | n_tokens = 4316, memory_seq_rm [4316, end)
slot update_slots: id  1 | task 39091 | prompt processing progress, n_tokens = 4380, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 39091 | prompt done, n_tokens = 4380, batch.n_tokens = 64
slot init_sampler: id  1 | task 39091 | init sampler, took 0.95 ms, tokens: text = 4380, total = 4380
slot update_slots: id  1 | task 39091 | created context checkpoint 7 of 8 (pos_min = 3731, pos_max = 4315, size = 13.718 MiB)
slot print_timing: id  1 | task 39091 | 
prompt eval time =     755.52 ms /   347 tokens (    2.18 ms per token,   459.29 tokens per second)
       eval time =   12321.45 ms /   454 tokens (   27.14 ms per token,    36.85 tokens per second)
      total time =   13076.97 ms /   801 tokens
slot      release: id  1 | task 39091 | stop processing: n_tokens = 4833, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.867 (> 0.100 thold), f_keep = 0.829
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 39547 | processing task, is_child = 0
slot update_slots: id  1 | task 39547 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4624
slot update_slots: id  1 | task 39547 | n_past = 4008, slot.prompt.tokens.size() = 4833, seq_id = 1, pos_min = 4063, n_swa = 128
slot update_slots: id  1 | task 39547 | restored context checkpoint (pos_min = 3731, pos_max = 4315, size = 13.718 MiB)
slot update_slots: id  1 | task 39547 | n_tokens = 4008, memory_seq_rm [4008, end)
slot update_slots: id  1 | task 39547 | prompt processing progress, n_tokens = 4560, batch.n_tokens = 552, progress = 0.986159
slot update_slots: id  1 | task 39547 | n_tokens = 4560, memory_seq_rm [4560, end)
slot update_slots: id  1 | task 39547 | prompt processing progress, n_tokens = 4624, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 39547 | prompt done, n_tokens = 4624, batch.n_tokens = 64
slot init_sampler: id  1 | task 39547 | init sampler, took 0.71 ms, tokens: text = 4624, total = 4624
slot update_slots: id  1 | task 39547 | created context checkpoint 8 of 8 (pos_min = 3881, pos_max = 4559, size = 15.922 MiB)
slot print_timing: id  1 | task 39547 | 
prompt eval time =    1288.40 ms /   616 tokens (    2.09 ms per token,   478.11 tokens per second)
       eval time =    7780.96 ms /   283 tokens (   27.49 ms per token,    36.37 tokens per second)
      total time =    9069.36 ms /   899 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 39547 | stop processing: n_tokens = 4906, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.945 (> 0.100 thold), f_keep = 0.943
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 39832 | processing task, is_child = 0
slot update_slots: id  1 | task 39832 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4895
slot update_slots: id  1 | task 39832 | n_tokens = 4624, memory_seq_rm [4624, end)
slot update_slots: id  1 | task 39832 | prompt processing progress, n_tokens = 4831, batch.n_tokens = 207, progress = 0.986925
slot update_slots: id  1 | task 39832 | n_tokens = 4831, memory_seq_rm [4831, end)
slot update_slots: id  1 | task 39832 | prompt processing progress, n_tokens = 4895, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 39832 | prompt done, n_tokens = 4895, batch.n_tokens = 64
slot init_sampler: id  1 | task 39832 | init sampler, took 0.74 ms, tokens: text = 4895, total = 4895
slot update_slots: id  1 | task 39832 | erasing old context checkpoint (pos_min = 425, pos_max = 1052, size = 14.726 MiB)
slot update_slots: id  1 | task 39832 | created context checkpoint 8 of 8 (pos_min = 4232, pos_max = 4830, size = 14.046 MiB)
slot print_timing: id  1 | task 39832 | 
prompt eval time =     711.25 ms /   271 tokens (    2.62 ms per token,   381.02 tokens per second)
       eval time =    9582.28 ms /   356 tokens (   26.92 ms per token,    37.15 tokens per second)
      total time =   10293.52 ms /   627 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 39832 | stop processing: n_tokens = 5250, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.946 (> 0.100 thold), f_keep = 0.932
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 40190 | processing task, is_child = 0
slot update_slots: id  1 | task 40190 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5176
slot update_slots: id  1 | task 40190 | n_tokens = 4895, memory_seq_rm [4895, end)
slot update_slots: id  1 | task 40190 | prompt processing progress, n_tokens = 5112, batch.n_tokens = 217, progress = 0.987635
slot update_slots: id  1 | task 40190 | n_tokens = 5112, memory_seq_rm [5112, end)
slot update_slots: id  1 | task 40190 | prompt processing progress, n_tokens = 5176, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 40190 | prompt done, n_tokens = 5176, batch.n_tokens = 64
slot init_sampler: id  1 | task 40190 | init sampler, took 0.81 ms, tokens: text = 5176, total = 5176
slot update_slots: id  1 | task 40190 | erasing old context checkpoint (pos_min = 602, pos_max = 1146, size = 12.780 MiB)
slot update_slots: id  1 | task 40190 | created context checkpoint 8 of 8 (pos_min = 4507, pos_max = 5111, size = 14.187 MiB)
slot print_timing: id  1 | task 40190 | 
prompt eval time =     706.59 ms /   281 tokens (    2.51 ms per token,   397.69 tokens per second)
       eval time =    8046.58 ms /   297 tokens (   27.09 ms per token,    36.91 tokens per second)
      total time =    8753.17 ms /   578 tokens
slot      release: id  1 | task 40190 | stop processing: n_tokens = 5472, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.949 (> 0.100 thold), f_keep = 0.946
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 40489 | processing task, is_child = 0
slot update_slots: id  1 | task 40489 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5456
slot update_slots: id  1 | task 40489 | n_tokens = 5176, memory_seq_rm [5176, end)
slot update_slots: id  1 | task 40489 | prompt processing progress, n_tokens = 5392, batch.n_tokens = 216, progress = 0.988270
slot update_slots: id  1 | task 40489 | n_tokens = 5392, memory_seq_rm [5392, end)
slot update_slots: id  1 | task 40489 | prompt processing progress, n_tokens = 5456, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 40489 | prompt done, n_tokens = 5456, batch.n_tokens = 64
slot init_sampler: id  1 | task 40489 | init sampler, took 1.10 ms, tokens: text = 5456, total = 5456
slot update_slots: id  1 | task 40489 | erasing old context checkpoint (pos_min = 621, pos_max = 1282, size = 15.523 MiB)
slot update_slots: id  1 | task 40489 | created context checkpoint 8 of 8 (pos_min = 4840, pos_max = 5391, size = 12.944 MiB)
slot print_timing: id  1 | task 40489 | 
prompt eval time =     737.65 ms /   280 tokens (    2.63 ms per token,   379.59 tokens per second)
       eval time =   12360.91 ms /   452 tokens (   27.35 ms per token,    36.57 tokens per second)
      total time =   13098.56 ms /   732 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 40489 | stop processing: n_tokens = 5907, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.941 (> 0.100 thold), f_keep = 0.924
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 40943 | processing task, is_child = 0
slot update_slots: id  1 | task 40943 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5796
slot update_slots: id  1 | task 40943 | n_tokens = 5456, memory_seq_rm [5456, end)
slot update_slots: id  1 | task 40943 | prompt processing progress, n_tokens = 5732, batch.n_tokens = 276, progress = 0.988958
slot update_slots: id  1 | task 40943 | n_tokens = 5732, memory_seq_rm [5732, end)
slot update_slots: id  1 | task 40943 | prompt processing progress, n_tokens = 5796, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 40943 | prompt done, n_tokens = 5796, batch.n_tokens = 64
slot init_sampler: id  1 | task 40943 | init sampler, took 1.00 ms, tokens: text = 5796, total = 5796
slot update_slots: id  1 | task 40943 | erasing old context checkpoint (pos_min = 2140, pos_max = 2909, size = 18.056 MiB)
slot update_slots: id  1 | task 40943 | created context checkpoint 8 of 8 (pos_min = 5176, pos_max = 5731, size = 13.038 MiB)
slot print_timing: id  1 | task 40943 | 
prompt eval time =     795.34 ms /   340 tokens (    2.34 ms per token,   427.49 tokens per second)
       eval time =    4472.38 ms /   162 tokens (   27.61 ms per token,    36.22 tokens per second)
      total time =    5267.72 ms /   502 tokens
slot      release: id  1 | task 40943 | stop processing: n_tokens = 5957, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.977 (> 0.100 thold), f_keep = 0.973
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 41107 | processing task, is_child = 0
slot update_slots: id  1 | task 41107 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5930
slot update_slots: id  1 | task 41107 | n_tokens = 5796, memory_seq_rm [5796, end)
slot update_slots: id  1 | task 41107 | prompt processing progress, n_tokens = 5866, batch.n_tokens = 70, progress = 0.989207
slot update_slots: id  1 | task 41107 | n_tokens = 5866, memory_seq_rm [5866, end)
slot update_slots: id  1 | task 41107 | prompt processing progress, n_tokens = 5930, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 41107 | prompt done, n_tokens = 5930, batch.n_tokens = 64
slot init_sampler: id  1 | task 41107 | init sampler, took 0.91 ms, tokens: text = 5930, total = 5930
slot update_slots: id  1 | task 41107 | erasing old context checkpoint (pos_min = 2366, pos_max = 2990, size = 14.656 MiB)
slot update_slots: id  1 | task 41107 | created context checkpoint 8 of 8 (pos_min = 5246, pos_max = 5865, size = 14.539 MiB)
slot print_timing: id  1 | task 41107 | 
prompt eval time =     448.35 ms /   134 tokens (    3.35 ms per token,   298.88 tokens per second)
       eval time =   13165.90 ms /   476 tokens (   27.66 ms per token,    36.15 tokens per second)
      total time =   13614.25 ms /   610 tokens
slot      release: id  1 | task 41107 | stop processing: n_tokens = 6405, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.932 (> 0.100 thold), f_keep = 0.926
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 41585 | processing task, is_child = 0
slot update_slots: id  1 | task 41585 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6361
slot update_slots: id  1 | task 41585 | n_tokens = 5930, memory_seq_rm [5930, end)
slot update_slots: id  1 | task 41585 | prompt processing progress, n_tokens = 6297, batch.n_tokens = 367, progress = 0.989939
slot update_slots: id  1 | task 41585 | n_tokens = 6297, memory_seq_rm [6297, end)
slot update_slots: id  1 | task 41585 | prompt processing progress, n_tokens = 6361, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 41585 | prompt done, n_tokens = 6361, batch.n_tokens = 64
slot init_sampler: id  1 | task 41585 | init sampler, took 1.41 ms, tokens: text = 6361, total = 6361
slot update_slots: id  1 | task 41585 | erasing old context checkpoint (pos_min = 3199, pos_max = 3968, size = 18.056 MiB)
slot update_slots: id  1 | task 41585 | created context checkpoint 8 of 8 (pos_min = 5785, pos_max = 6296, size = 12.006 MiB)
slot print_timing: id  1 | task 41585 | 
prompt eval time =     920.36 ms /   431 tokens (    2.14 ms per token,   468.29 tokens per second)
       eval time =    5928.71 ms /   215 tokens (   27.58 ms per token,    36.26 tokens per second)
      total time =    6849.07 ms /   646 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 41585 | stop processing: n_tokens = 6575, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.773 (> 0.100 thold), f_keep = 0.967
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 41802 | processing task, is_child = 0
slot update_slots: id  1 | task 41802 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8230
slot update_slots: id  1 | task 41802 | n_tokens = 6361, memory_seq_rm [6361, end)
slot update_slots: id  1 | task 41802 | prompt processing progress, n_tokens = 8166, batch.n_tokens = 1805, progress = 0.992224
slot update_slots: id  1 | task 41802 | n_tokens = 8166, memory_seq_rm [8166, end)
slot update_slots: id  1 | task 41802 | prompt processing progress, n_tokens = 8230, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 41802 | prompt done, n_tokens = 8230, batch.n_tokens = 64
slot init_sampler: id  1 | task 41802 | init sampler, took 1.35 ms, tokens: text = 8230, total = 8230
slot update_slots: id  1 | task 41802 | erasing old context checkpoint (pos_min = 3731, pos_max = 4315, size = 13.718 MiB)
slot update_slots: id  1 | task 41802 | created context checkpoint 8 of 8 (pos_min = 7396, pos_max = 8165, size = 18.056 MiB)
slot print_timing: id  1 | task 41802 | 
prompt eval time =    2864.50 ms /  1869 tokens (    1.53 ms per token,   652.47 tokens per second)
       eval time =   11033.46 ms /   400 tokens (   27.58 ms per token,    36.25 tokens per second)
      total time =   13897.96 ms /  2269 tokens
slot      release: id  1 | task 41802 | stop processing: n_tokens = 8629, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.967 (> 0.100 thold), f_keep = 0.954
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 42204 | processing task, is_child = 0
slot update_slots: id  1 | task 42204 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8513
slot update_slots: id  1 | task 42204 | n_tokens = 8230, memory_seq_rm [8230, end)
slot update_slots: id  1 | task 42204 | prompt processing progress, n_tokens = 8449, batch.n_tokens = 219, progress = 0.992482
slot update_slots: id  1 | task 42204 | n_tokens = 8449, memory_seq_rm [8449, end)
slot update_slots: id  1 | task 42204 | prompt processing progress, n_tokens = 8513, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 42204 | prompt done, n_tokens = 8513, batch.n_tokens = 64
slot init_sampler: id  1 | task 42204 | init sampler, took 1.69 ms, tokens: text = 8513, total = 8513
slot update_slots: id  1 | task 42204 | erasing old context checkpoint (pos_min = 3881, pos_max = 4559, size = 15.922 MiB)
slot update_slots: id  1 | task 42204 | created context checkpoint 8 of 8 (pos_min = 7993, pos_max = 8448, size = 10.693 MiB)
slot print_timing: id  1 | task 42204 | 
prompt eval time =     748.16 ms /   283 tokens (    2.64 ms per token,   378.26 tokens per second)
       eval time =    6327.47 ms /   232 tokens (   27.27 ms per token,    36.67 tokens per second)
      total time =    7075.63 ms /   515 tokens
slot      release: id  1 | task 42204 | stop processing: n_tokens = 8744, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.974
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 42438 | processing task, is_child = 0
slot update_slots: id  1 | task 42438 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8600
slot update_slots: id  1 | task 42438 | n_tokens = 8513, memory_seq_rm [8513, end)
slot update_slots: id  1 | task 42438 | prompt processing progress, n_tokens = 8536, batch.n_tokens = 23, progress = 0.992558
slot update_slots: id  1 | task 42438 | n_tokens = 8536, memory_seq_rm [8536, end)
slot update_slots: id  1 | task 42438 | prompt processing progress, n_tokens = 8600, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 42438 | prompt done, n_tokens = 8600, batch.n_tokens = 64
slot init_sampler: id  1 | task 42438 | init sampler, took 1.53 ms, tokens: text = 8600, total = 8600
slot update_slots: id  1 | task 42438 | erasing old context checkpoint (pos_min = 4232, pos_max = 4830, size = 14.046 MiB)
slot update_slots: id  1 | task 42438 | created context checkpoint 8 of 8 (pos_min = 8230, pos_max = 8535, size = 7.176 MiB)
slot print_timing: id  1 | task 42438 | 
prompt eval time =     337.28 ms /    87 tokens (    3.88 ms per token,   257.94 tokens per second)
       eval time =    5473.45 ms /   200 tokens (   27.37 ms per token,    36.54 tokens per second)
      total time =    5810.74 ms /   287 tokens
slot      release: id  1 | task 42438 | stop processing: n_tokens = 8799, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.969 (> 0.100 thold), f_keep = 0.977
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 42640 | processing task, is_child = 0
slot update_slots: id  1 | task 42640 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8874
slot update_slots: id  1 | task 42640 | n_tokens = 8600, memory_seq_rm [8600, end)
slot update_slots: id  1 | task 42640 | prompt processing progress, n_tokens = 8810, batch.n_tokens = 210, progress = 0.992788
slot update_slots: id  1 | task 42640 | n_tokens = 8810, memory_seq_rm [8810, end)
slot update_slots: id  1 | task 42640 | prompt processing progress, n_tokens = 8874, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 42640 | prompt done, n_tokens = 8874, batch.n_tokens = 64
slot init_sampler: id  1 | task 42640 | init sampler, took 1.65 ms, tokens: text = 8874, total = 8874
slot update_slots: id  1 | task 42640 | erasing old context checkpoint (pos_min = 4507, pos_max = 5111, size = 14.187 MiB)
slot update_slots: id  1 | task 42640 | created context checkpoint 8 of 8 (pos_min = 8230, pos_max = 8809, size = 13.601 MiB)
slot print_timing: id  1 | task 42640 | 
prompt eval time =     590.67 ms /   274 tokens (    2.16 ms per token,   463.88 tokens per second)
       eval time =    6122.56 ms /   221 tokens (   27.70 ms per token,    36.10 tokens per second)
      total time =    6713.22 ms /   495 tokens
slot      release: id  1 | task 42640 | stop processing: n_tokens = 9094, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.654 (> 0.100 thold), f_keep = 0.507
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 42863 | processing task, is_child = 0
slot update_slots: id  1 | task 42863 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7049
slot update_slots: id  1 | task 42863 | n_past = 4613, slot.prompt.tokens.size() = 9094, seq_id = 1, pos_min = 8324, n_swa = 128
slot update_slots: id  1 | task 42863 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  1 | task 42863 | erased invalidated context checkpoint (pos_min = 4840, pos_max = 5391, n_swa = 128, size = 12.944 MiB)
slot update_slots: id  1 | task 42863 | erased invalidated context checkpoint (pos_min = 5176, pos_max = 5731, n_swa = 128, size = 13.038 MiB)
slot update_slots: id  1 | task 42863 | erased invalidated context checkpoint (pos_min = 5246, pos_max = 5865, n_swa = 128, size = 14.539 MiB)
slot update_slots: id  1 | task 42863 | erased invalidated context checkpoint (pos_min = 5785, pos_max = 6296, n_swa = 128, size = 12.006 MiB)
slot update_slots: id  1 | task 42863 | erased invalidated context checkpoint (pos_min = 7396, pos_max = 8165, n_swa = 128, size = 18.056 MiB)
slot update_slots: id  1 | task 42863 | erased invalidated context checkpoint (pos_min = 7993, pos_max = 8448, n_swa = 128, size = 10.693 MiB)
slot update_slots: id  1 | task 42863 | erased invalidated context checkpoint (pos_min = 8230, pos_max = 8535, n_swa = 128, size = 7.176 MiB)
slot update_slots: id  1 | task 42863 | erased invalidated context checkpoint (pos_min = 8230, pos_max = 8809, n_swa = 128, size = 13.601 MiB)
slot update_slots: id  1 | task 42863 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  1 | task 42863 | prompt processing progress, n_tokens = 2048, batch.n_tokens = 2048, progress = 0.290538
slot update_slots: id  1 | task 42863 | n_tokens = 2048, memory_seq_rm [2048, end)
slot update_slots: id  1 | task 42863 | prompt processing progress, n_tokens = 4096, batch.n_tokens = 2048, progress = 0.581075
slot update_slots: id  1 | task 42863 | n_tokens = 4096, memory_seq_rm [4096, end)
slot update_slots: id  1 | task 42863 | prompt processing progress, n_tokens = 6144, batch.n_tokens = 2048, progress = 0.871613
slot update_slots: id  1 | task 42863 | n_tokens = 6144, memory_seq_rm [6144, end)
slot update_slots: id  1 | task 42863 | prompt processing progress, n_tokens = 6985, batch.n_tokens = 841, progress = 0.990921
slot update_slots: id  1 | task 42863 | n_tokens = 6985, memory_seq_rm [6985, end)
slot update_slots: id  1 | task 42863 | prompt processing progress, n_tokens = 7049, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 42863 | prompt done, n_tokens = 7049, batch.n_tokens = 64
slot init_sampler: id  1 | task 42863 | init sampler, took 1.43 ms, tokens: text = 7049, total = 7049
slot update_slots: id  1 | task 42863 | created context checkpoint 1 of 8 (pos_min = 6215, pos_max = 6984, size = 18.056 MiB)
slot print_timing: id  1 | task 42863 | 
prompt eval time =    9772.84 ms /  7049 tokens (    1.39 ms per token,   721.28 tokens per second)
       eval time =    3311.66 ms /   123 tokens (   26.92 ms per token,    37.14 tokens per second)
      total time =   13084.50 ms /  7172 tokens
slot      release: id  1 | task 42863 | stop processing: n_tokens = 7171, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.168 (> 0.100 thold), f_keep = 0.983
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 42991 | processing task, is_child = 0
slot update_slots: id  1 | task 42991 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 41983
slot update_slots: id  1 | task 42991 | n_tokens = 7049, memory_seq_rm [7049, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 9097, batch.n_tokens = 2048, progress = 0.216683
slot update_slots: id  1 | task 42991 | n_tokens = 9097, memory_seq_rm [9097, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 11145, batch.n_tokens = 2048, progress = 0.265465
slot update_slots: id  1 | task 42991 | n_tokens = 11145, memory_seq_rm [11145, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 13193, batch.n_tokens = 2048, progress = 0.314246
slot update_slots: id  1 | task 42991 | n_tokens = 13193, memory_seq_rm [13193, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 15241, batch.n_tokens = 2048, progress = 0.363028
slot update_slots: id  1 | task 42991 | n_tokens = 15241, memory_seq_rm [15241, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 17289, batch.n_tokens = 2048, progress = 0.411810
slot update_slots: id  1 | task 42991 | n_tokens = 17289, memory_seq_rm [17289, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 19337, batch.n_tokens = 2048, progress = 0.460591
slot update_slots: id  1 | task 42991 | n_tokens = 19337, memory_seq_rm [19337, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 21385, batch.n_tokens = 2048, progress = 0.509373
slot update_slots: id  1 | task 42991 | n_tokens = 21385, memory_seq_rm [21385, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 23433, batch.n_tokens = 2048, progress = 0.558154
slot update_slots: id  1 | task 42991 | n_tokens = 23433, memory_seq_rm [23433, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 25481, batch.n_tokens = 2048, progress = 0.606936
slot update_slots: id  1 | task 42991 | n_tokens = 25481, memory_seq_rm [25481, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 27529, batch.n_tokens = 2048, progress = 0.655718
slot update_slots: id  1 | task 42991 | n_tokens = 27529, memory_seq_rm [27529, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 29577, batch.n_tokens = 2048, progress = 0.704499
slot update_slots: id  1 | task 42991 | n_tokens = 29577, memory_seq_rm [29577, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 31625, batch.n_tokens = 2048, progress = 0.753281
slot update_slots: id  1 | task 42991 | n_tokens = 31625, memory_seq_rm [31625, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 33673, batch.n_tokens = 2048, progress = 0.802063
slot update_slots: id  1 | task 42991 | n_tokens = 33673, memory_seq_rm [33673, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 35721, batch.n_tokens = 2048, progress = 0.850844
slot update_slots: id  1 | task 42991 | n_tokens = 35721, memory_seq_rm [35721, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 37769, batch.n_tokens = 2048, progress = 0.899626
decode: failed to find a memory slot for batch of size 2048
srv  try_clear_id: purging slot 2 with 14930 tokens
slot prompt_clear: id  2 | task -1 | clearing prompt with 14930 tokens
srv  update_slots: failed to find free space in the KV cache, retrying with smaller batch size, i = 0, n_batch = 2048, ret = 1
slot update_slots: id  1 | task 42991 | n_tokens = 37769, memory_seq_rm [37769, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 39817, batch.n_tokens = 2048, progress = 0.948408
slot update_slots: id  1 | task 42991 | n_tokens = 39817, memory_seq_rm [39817, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 41865, batch.n_tokens = 2048, progress = 0.997189
slot update_slots: id  1 | task 42991 | n_tokens = 41865, memory_seq_rm [41865, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 41919, batch.n_tokens = 54, progress = 0.998476
slot update_slots: id  1 | task 42991 | n_tokens = 41919, memory_seq_rm [41919, end)
slot update_slots: id  1 | task 42991 | prompt processing progress, n_tokens = 41983, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 42991 | prompt done, n_tokens = 41983, batch.n_tokens = 64
slot init_sampler: id  1 | task 42991 | init sampler, took 5.98 ms, tokens: text = 41983, total = 41983
slot update_slots: id  1 | task 42991 | created context checkpoint 2 of 8 (pos_min = 41022, pos_max = 41918, size = 21.034 MiB)
slot print_timing: id  1 | task 42991 | 
prompt eval time =   56026.96 ms / 34934 tokens (    1.60 ms per token,   623.52 tokens per second)
       eval time =    2821.36 ms /    94 tokens (   30.01 ms per token,    33.32 tokens per second)
      total time =   58848.32 ms / 35028 tokens
slot      release: id  1 | task 42991 | stop processing: n_tokens = 42076, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.968 (> 0.100 thold), f_keep = 0.165
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 42076, total state size = 1007.672 MiB
srv          load:  - looking for better prompt, base f_keep = 0.165, sim = 0.968
srv        update:  - cache state: 13 prompts, 5139.379 MiB (limits: 8192.000 MiB, 64000 tokens, 256657 est)
srv        update:    - prompt 0x5a234b577500:    4873 tokens, checkpoints:  5,   235.945 MiB
srv        update:    - prompt 0x5a234d243b70:    4947 tokens, checkpoints:  7,   261.904 MiB
srv        update:    - prompt 0x5a234cfbeaa0:   38169 tokens, checkpoints:  8,  1100.063 MiB
srv        update:    - prompt 0x5a234dc80090:    2123 tokens, checkpoints:  1,    68.612 MiB
srv        update:    - prompt 0x5a234ccbfee0:   15206 tokens, checkpoints:  3,   424.099 MiB
srv        update:    - prompt 0x5a234dbdca00:    2924 tokens, checkpoints:  2,   117.715 MiB
srv        update:    - prompt 0x5a234cfa37d0:    1948 tokens, checkpoints:  3,   106.905 MiB
srv        update:    - prompt 0x5a234cce4d20:    6823 tokens, checkpoints:  8,   301.838 MiB
srv        update:    - prompt 0x5a237670b520:   11970 tokens, checkpoints:  8,   418.989 MiB
srv        update:    - prompt 0x5a234f21f8f0:    1921 tokens, checkpoints:  3,   103.341 MiB
srv        update:    - prompt 0x5a237670b330:    9131 tokens, checkpoints:  8,   361.890 MiB
srv        update:    - prompt 0x5a23757875b0:   18907 tokens, checkpoints:  8,   591.315 MiB
srv        update:    - prompt 0x5a2351b39e00:   42076 tokens, checkpoints:  2,  1046.762 MiB
srv  get_availabl: prompt cache update took 1238.40 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 43104 | processing task, is_child = 0
slot update_slots: id  1 | task 43104 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7184
slot update_slots: id  1 | task 43104 | n_past = 6955, slot.prompt.tokens.size() = 42076, seq_id = 1, pos_min = 41179, n_swa = 128
slot update_slots: id  1 | task 43104 | restored context checkpoint (pos_min = 6215, pos_max = 6984, size = 18.056 MiB)
slot update_slots: id  1 | task 43104 | erased invalidated context checkpoint (pos_min = 41022, pos_max = 41918, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  1 | task 43104 | n_tokens = 6955, memory_seq_rm [6955, end)
slot update_slots: id  1 | task 43104 | prompt processing progress, n_tokens = 7120, batch.n_tokens = 165, progress = 0.991091
slot update_slots: id  1 | task 43104 | n_tokens = 7120, memory_seq_rm [7120, end)
slot update_slots: id  1 | task 43104 | prompt processing progress, n_tokens = 7184, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 43104 | prompt done, n_tokens = 7184, batch.n_tokens = 64
slot init_sampler: id  1 | task 43104 | init sampler, took 1.86 ms, tokens: text = 7184, total = 7184
slot update_slots: id  1 | task 43104 | created context checkpoint 2 of 8 (pos_min = 6350, pos_max = 7119, size = 18.056 MiB)
slot print_timing: id  1 | task 43104 | 
prompt eval time =     822.43 ms /   229 tokens (    3.59 ms per token,   278.44 tokens per second)
       eval time =    2651.41 ms /   101 tokens (   26.25 ms per token,    38.09 tokens per second)
      total time =    3473.84 ms /   330 tokens
slot      release: id  1 | task 43104 | stop processing: n_tokens = 7284, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.982 (> 0.100 thold), f_keep = 0.975
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 43207 | processing task, is_child = 0
slot update_slots: id  1 | task 43207 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7226
slot update_slots: id  1 | task 43207 | n_tokens = 7099, memory_seq_rm [7099, end)
slot update_slots: id  1 | task 43207 | prompt processing progress, n_tokens = 7162, batch.n_tokens = 63, progress = 0.991143
slot update_slots: id  1 | task 43207 | n_tokens = 7162, memory_seq_rm [7162, end)
slot update_slots: id  1 | task 43207 | prompt processing progress, n_tokens = 7226, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 43207 | prompt done, n_tokens = 7226, batch.n_tokens = 64
slot init_sampler: id  1 | task 43207 | init sampler, took 1.03 ms, tokens: text = 7226, total = 7226
slot print_timing: id  1 | task 43207 | 
prompt eval time =     511.55 ms /   127 tokens (    4.03 ms per token,   248.27 tokens per second)
       eval time =    4084.77 ms /   154 tokens (   26.52 ms per token,    37.70 tokens per second)
      total time =    4596.31 ms /   281 tokens
slot      release: id  1 | task 43207 | stop processing: n_tokens = 7379, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.964
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 43363 | processing task, is_child = 0
slot update_slots: id  1 | task 43363 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7150
slot update_slots: id  1 | task 43363 | n_tokens = 7117, memory_seq_rm [7117, end)
slot update_slots: id  1 | task 43363 | prompt processing progress, n_tokens = 7150, batch.n_tokens = 33, progress = 1.000000
slot update_slots: id  1 | task 43363 | prompt done, n_tokens = 7150, batch.n_tokens = 33
slot init_sampler: id  1 | task 43363 | init sampler, took 1.18 ms, tokens: text = 7150, total = 7150
slot print_timing: id  1 | task 43363 | 
prompt eval time =     226.63 ms /    33 tokens (    6.87 ms per token,   145.61 tokens per second)
       eval time =    2126.81 ms /    80 tokens (   26.59 ms per token,    37.62 tokens per second)
      total time =    2353.44 ms /   113 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 43363 | stop processing: n_tokens = 7229, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 43444 | processing task, is_child = 0
slot update_slots: id  1 | task 43444 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7199
slot update_slots: id  1 | task 43444 | n_tokens = 7135, memory_seq_rm [7135, end)
slot update_slots: id  1 | task 43444 | prompt processing progress, n_tokens = 7199, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 43444 | prompt done, n_tokens = 7199, batch.n_tokens = 64
slot init_sampler: id  1 | task 43444 | init sampler, took 1.09 ms, tokens: text = 7199, total = 7199
slot print_timing: id  1 | task 43444 | 
prompt eval time =     303.36 ms /    64 tokens (    4.74 ms per token,   210.97 tokens per second)
       eval time =     933.10 ms /    36 tokens (   25.92 ms per token,    38.58 tokens per second)
      total time =    1236.46 ms /   100 tokens
slot      release: id  1 | task 43444 | stop processing: n_tokens = 7234, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.989
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 43481 | processing task, is_child = 0
slot update_slots: id  1 | task 43481 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7185
slot update_slots: id  1 | task 43481 | n_tokens = 7153, memory_seq_rm [7153, end)
slot update_slots: id  1 | task 43481 | prompt processing progress, n_tokens = 7185, batch.n_tokens = 32, progress = 1.000000
slot update_slots: id  1 | task 43481 | prompt done, n_tokens = 7185, batch.n_tokens = 32
slot init_sampler: id  1 | task 43481 | init sampler, took 1.07 ms, tokens: text = 7185, total = 7185
slot print_timing: id  1 | task 43481 | 
prompt eval time =     212.14 ms /    32 tokens (    6.63 ms per token,   150.84 tokens per second)
       eval time =    1034.04 ms /    39 tokens (   26.51 ms per token,    37.72 tokens per second)
      total time =    1246.18 ms /    71 tokens
slot      release: id  1 | task 43481 | stop processing: n_tokens = 7223, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 43521 | processing task, is_child = 0
slot update_slots: id  1 | task 43521 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7203
slot update_slots: id  1 | task 43521 | n_tokens = 7171, memory_seq_rm [7171, end)
slot update_slots: id  1 | task 43521 | prompt processing progress, n_tokens = 7203, batch.n_tokens = 32, progress = 1.000000
slot update_slots: id  1 | task 43521 | prompt done, n_tokens = 7203, batch.n_tokens = 32
slot init_sampler: id  1 | task 43521 | init sampler, took 1.04 ms, tokens: text = 7203, total = 7203
slot print_timing: id  1 | task 43521 | 
prompt eval time =     193.76 ms /    32 tokens (    6.06 ms per token,   165.15 tokens per second)
       eval time =    2054.74 ms /    77 tokens (   26.68 ms per token,    37.47 tokens per second)
      total time =    2248.51 ms /   109 tokens
slot      release: id  1 | task 43521 | stop processing: n_tokens = 7279, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 43599 | processing task, is_child = 0
slot update_slots: id  1 | task 43599 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7221
slot update_slots: id  1 | task 43599 | n_tokens = 7189, memory_seq_rm [7189, end)
slot update_slots: id  1 | task 43599 | prompt processing progress, n_tokens = 7221, batch.n_tokens = 32, progress = 1.000000
slot update_slots: id  1 | task 43599 | prompt done, n_tokens = 7221, batch.n_tokens = 32
slot init_sampler: id  1 | task 43599 | init sampler, took 1.41 ms, tokens: text = 7221, total = 7221
slot update_slots: id  1 | task 43599 | created context checkpoint 3 of 8 (pos_min = 6609, pos_max = 7188, size = 13.601 MiB)
slot print_timing: id  1 | task 43599 | 
prompt eval time =     222.13 ms /    32 tokens (    6.94 ms per token,   144.06 tokens per second)
       eval time =    1331.13 ms /    50 tokens (   26.62 ms per token,    37.56 tokens per second)
      total time =    1553.26 ms /    82 tokens
slot      release: id  1 | task 43599 | stop processing: n_tokens = 7270, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 43650 | processing task, is_child = 0
slot update_slots: id  1 | task 43650 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7239
slot update_slots: id  1 | task 43650 | n_tokens = 7207, memory_seq_rm [7207, end)
slot update_slots: id  1 | task 43650 | prompt processing progress, n_tokens = 7239, batch.n_tokens = 32, progress = 1.000000
slot update_slots: id  1 | task 43650 | prompt done, n_tokens = 7239, batch.n_tokens = 32
slot init_sampler: id  1 | task 43650 | init sampler, took 1.11 ms, tokens: text = 7239, total = 7239
slot print_timing: id  1 | task 43650 | 
prompt eval time =     142.53 ms /    32 tokens (    4.45 ms per token,   224.52 tokens per second)
       eval time =     779.10 ms /    30 tokens (   25.97 ms per token,    38.51 tokens per second)
      total time =     921.63 ms /    62 tokens
slot      release: id  1 | task 43650 | stop processing: n_tokens = 7268, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 43681 | processing task, is_child = 0
slot update_slots: id  1 | task 43681 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7263
slot update_slots: id  1 | task 43681 | n_tokens = 7225, memory_seq_rm [7225, end)
slot update_slots: id  1 | task 43681 | prompt processing progress, n_tokens = 7263, batch.n_tokens = 38, progress = 1.000000
slot update_slots: id  1 | task 43681 | prompt done, n_tokens = 7263, batch.n_tokens = 38
slot init_sampler: id  1 | task 43681 | init sampler, took 1.08 ms, tokens: text = 7263, total = 7263
slot print_timing: id  1 | task 43681 | 
prompt eval time =     235.52 ms /    38 tokens (    6.20 ms per token,   161.35 tokens per second)
       eval time =    3950.38 ms /   145 tokens (   27.24 ms per token,    36.71 tokens per second)
      total time =    4185.89 ms /   183 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 43681 | stop processing: n_tokens = 7407, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.969 (> 0.100 thold), f_keep = 0.978
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 43827 | processing task, is_child = 0
slot update_slots: id  1 | task 43827 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7473
slot update_slots: id  1 | task 43827 | n_tokens = 7243, memory_seq_rm [7243, end)
slot update_slots: id  1 | task 43827 | prompt processing progress, n_tokens = 7409, batch.n_tokens = 166, progress = 0.991436
slot update_slots: id  1 | task 43827 | n_tokens = 7409, memory_seq_rm [7409, end)
slot update_slots: id  1 | task 43827 | prompt processing progress, n_tokens = 7473, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 43827 | prompt done, n_tokens = 7473, batch.n_tokens = 64
slot init_sampler: id  1 | task 43827 | init sampler, took 1.14 ms, tokens: text = 7473, total = 7473
slot update_slots: id  1 | task 43827 | created context checkpoint 4 of 8 (pos_min = 6639, pos_max = 7408, size = 18.056 MiB)
slot print_timing: id  1 | task 43827 | 
prompt eval time =     633.10 ms /   230 tokens (    2.75 ms per token,   363.29 tokens per second)
       eval time =   17731.20 ms /   643 tokens (   27.58 ms per token,    36.26 tokens per second)
      total time =   18364.30 ms /   873 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 43827 | stop processing: n_tokens = 8115, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.891 (> 0.100 thold), f_keep = 0.895
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 44472 | processing task, is_child = 0
slot update_slots: id  1 | task 44472 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8148
slot update_slots: id  1 | task 44472 | n_past = 7261, slot.prompt.tokens.size() = 8115, seq_id = 1, pos_min = 7218, n_swa = 128
slot update_slots: id  1 | task 44472 | restored context checkpoint (pos_min = 6639, pos_max = 7408, size = 18.056 MiB)
slot update_slots: id  1 | task 44472 | n_tokens = 7261, memory_seq_rm [7261, end)
slot update_slots: id  1 | task 44472 | prompt processing progress, n_tokens = 8084, batch.n_tokens = 823, progress = 0.992145
slot update_slots: id  1 | task 44472 | n_tokens = 8084, memory_seq_rm [8084, end)
slot update_slots: id  1 | task 44472 | prompt processing progress, n_tokens = 8148, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 44472 | prompt done, n_tokens = 8148, batch.n_tokens = 64
slot init_sampler: id  1 | task 44472 | init sampler, took 1.23 ms, tokens: text = 8148, total = 8148
slot update_slots: id  1 | task 44472 | created context checkpoint 5 of 8 (pos_min = 7187, pos_max = 8083, size = 21.034 MiB)
slot print_timing: id  1 | task 44472 | 
prompt eval time =    1654.67 ms /   887 tokens (    1.87 ms per token,   536.06 tokens per second)
       eval time =   24079.04 ms /   872 tokens (   27.61 ms per token,    36.21 tokens per second)
      total time =   25733.71 ms /  1759 tokens
slot      release: id  1 | task 44472 | stop processing: n_tokens = 9019, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.875 (> 0.100 thold), f_keep = 0.877
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 45346 | processing task, is_child = 0
slot update_slots: id  1 | task 45346 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 9036
slot update_slots: id  1 | task 45346 | n_past = 7906, slot.prompt.tokens.size() = 9019, seq_id = 1, pos_min = 8122, n_swa = 128
slot update_slots: id  1 | task 45346 | restored context checkpoint (pos_min = 7187, pos_max = 8083, size = 21.034 MiB)
slot update_slots: id  1 | task 45346 | n_tokens = 7906, memory_seq_rm [7906, end)
slot update_slots: id  1 | task 45346 | prompt processing progress, n_tokens = 8972, batch.n_tokens = 1066, progress = 0.992917
slot update_slots: id  1 | task 45346 | n_tokens = 8972, memory_seq_rm [8972, end)
slot update_slots: id  1 | task 45346 | prompt processing progress, n_tokens = 9036, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 45346 | prompt done, n_tokens = 9036, batch.n_tokens = 64
slot init_sampler: id  1 | task 45346 | init sampler, took 1.31 ms, tokens: text = 9036, total = 9036
slot update_slots: id  1 | task 45346 | created context checkpoint 6 of 8 (pos_min = 8075, pos_max = 8971, size = 21.034 MiB)
slot print_timing: id  1 | task 45346 | 
prompt eval time =    2032.71 ms /  1130 tokens (    1.80 ms per token,   555.91 tokens per second)
       eval time =   31729.87 ms /  1149 tokens (   27.62 ms per token,    36.21 tokens per second)
      total time =   33762.57 ms /  2279 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 45346 | stop processing: n_tokens = 10184, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.882 (> 0.100 thold), f_keep = 0.862
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 46497 | processing task, is_child = 0
slot update_slots: id  1 | task 46497 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 9954
slot update_slots: id  1 | task 46497 | n_past = 8780, slot.prompt.tokens.size() = 10184, seq_id = 1, pos_min = 9287, n_swa = 128
slot update_slots: id  1 | task 46497 | restored context checkpoint (pos_min = 8075, pos_max = 8971, size = 21.034 MiB)
slot update_slots: id  1 | task 46497 | n_tokens = 8780, memory_seq_rm [8780, end)
slot update_slots: id  1 | task 46497 | prompt processing progress, n_tokens = 9890, batch.n_tokens = 1110, progress = 0.993570
slot update_slots: id  1 | task 46497 | n_tokens = 9890, memory_seq_rm [9890, end)
slot update_slots: id  1 | task 46497 | prompt processing progress, n_tokens = 9954, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 46497 | prompt done, n_tokens = 9954, batch.n_tokens = 64
slot init_sampler: id  1 | task 46497 | init sampler, took 2.13 ms, tokens: text = 9954, total = 9954
slot update_slots: id  1 | task 46497 | created context checkpoint 7 of 8 (pos_min = 8993, pos_max = 9889, size = 21.034 MiB)
slot print_timing: id  1 | task 46497 | 
prompt eval time =    2227.61 ms /  1174 tokens (    1.90 ms per token,   527.02 tokens per second)
       eval time =    2426.03 ms /    88 tokens (   27.57 ms per token,    36.27 tokens per second)
      total time =    4653.64 ms /  1262 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 46497 | stop processing: n_tokens = 10041, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 46587 | processing task, is_child = 0
slot update_slots: id  1 | task 46587 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 10018
slot update_slots: id  1 | task 46587 | n_tokens = 9954, memory_seq_rm [9954, end)
slot update_slots: id  1 | task 46587 | prompt processing progress, n_tokens = 10018, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 46587 | prompt done, n_tokens = 10018, batch.n_tokens = 64
slot init_sampler: id  1 | task 46587 | init sampler, took 1.47 ms, tokens: text = 10018, total = 10018
slot print_timing: id  1 | task 46587 | 
prompt eval time =     216.84 ms /    64 tokens (    3.39 ms per token,   295.15 tokens per second)
       eval time =   17332.52 ms /   631 tokens (   27.47 ms per token,    36.41 tokens per second)
      total time =   17549.36 ms /   695 tokens
slot      release: id  1 | task 46587 | stop processing: n_tokens = 10648, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.942 (> 0.100 thold), f_keep = 0.941
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 47219 | processing task, is_child = 0
slot update_slots: id  1 | task 47219 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 10635
slot update_slots: id  1 | task 47219 | n_tokens = 10018, memory_seq_rm [10018, end)
slot update_slots: id  1 | task 47219 | prompt processing progress, n_tokens = 10571, batch.n_tokens = 553, progress = 0.993982
slot update_slots: id  1 | task 47219 | n_tokens = 10571, memory_seq_rm [10571, end)
slot update_slots: id  1 | task 47219 | prompt processing progress, n_tokens = 10635, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 47219 | prompt done, n_tokens = 10635, batch.n_tokens = 64
slot init_sampler: id  1 | task 47219 | init sampler, took 1.58 ms, tokens: text = 10635, total = 10635
slot update_slots: id  1 | task 47219 | created context checkpoint 8 of 8 (pos_min = 9891, pos_max = 10570, size = 15.946 MiB)
slot print_timing: id  1 | task 47219 | 
prompt eval time =    1189.30 ms /   617 tokens (    1.93 ms per token,   518.79 tokens per second)
       eval time =    3188.54 ms /   115 tokens (   27.73 ms per token,    36.07 tokens per second)
      total time =    4377.83 ms /   732 tokens
slot      release: id  1 | task 47219 | stop processing: n_tokens = 10749, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.185 (> 0.100 thold), f_keep = 0.989
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 47336 | processing task, is_child = 0
slot update_slots: id  1 | task 47336 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 57410
slot update_slots: id  1 | task 47336 | n_tokens = 10635, memory_seq_rm [10635, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 12683, batch.n_tokens = 2048, progress = 0.220920
slot update_slots: id  1 | task 47336 | n_tokens = 12683, memory_seq_rm [12683, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 14731, batch.n_tokens = 2048, progress = 0.256593
slot update_slots: id  1 | task 47336 | n_tokens = 14731, memory_seq_rm [14731, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 16779, batch.n_tokens = 2048, progress = 0.292266
slot update_slots: id  1 | task 47336 | n_tokens = 16779, memory_seq_rm [16779, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 18827, batch.n_tokens = 2048, progress = 0.327939
slot update_slots: id  1 | task 47336 | n_tokens = 18827, memory_seq_rm [18827, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 20875, batch.n_tokens = 2048, progress = 0.363613
slot update_slots: id  1 | task 47336 | n_tokens = 20875, memory_seq_rm [20875, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 22923, batch.n_tokens = 2048, progress = 0.399286
slot update_slots: id  1 | task 47336 | n_tokens = 22923, memory_seq_rm [22923, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 24971, batch.n_tokens = 2048, progress = 0.434959
slot update_slots: id  1 | task 47336 | n_tokens = 24971, memory_seq_rm [24971, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 27019, batch.n_tokens = 2048, progress = 0.470632
slot update_slots: id  1 | task 47336 | n_tokens = 27019, memory_seq_rm [27019, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 29067, batch.n_tokens = 2048, progress = 0.506306
slot update_slots: id  1 | task 47336 | n_tokens = 29067, memory_seq_rm [29067, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 31115, batch.n_tokens = 2048, progress = 0.541979
slot update_slots: id  1 | task 47336 | n_tokens = 31115, memory_seq_rm [31115, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 33163, batch.n_tokens = 2048, progress = 0.577652
slot update_slots: id  1 | task 47336 | n_tokens = 33163, memory_seq_rm [33163, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 35211, batch.n_tokens = 2048, progress = 0.613325
slot update_slots: id  1 | task 47336 | n_tokens = 35211, memory_seq_rm [35211, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 37259, batch.n_tokens = 2048, progress = 0.648998
slot update_slots: id  1 | task 47336 | n_tokens = 37259, memory_seq_rm [37259, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 39307, batch.n_tokens = 2048, progress = 0.684672
slot update_slots: id  1 | task 47336 | n_tokens = 39307, memory_seq_rm [39307, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 41355, batch.n_tokens = 2048, progress = 0.720345
slot update_slots: id  1 | task 47336 | n_tokens = 41355, memory_seq_rm [41355, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 43403, batch.n_tokens = 2048, progress = 0.756018
slot update_slots: id  1 | task 47336 | n_tokens = 43403, memory_seq_rm [43403, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 45451, batch.n_tokens = 2048, progress = 0.791691
slot update_slots: id  1 | task 47336 | n_tokens = 45451, memory_seq_rm [45451, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 47499, batch.n_tokens = 2048, progress = 0.827365
slot update_slots: id  1 | task 47336 | n_tokens = 47499, memory_seq_rm [47499, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 49547, batch.n_tokens = 2048, progress = 0.863038
slot update_slots: id  1 | task 47336 | n_tokens = 49547, memory_seq_rm [49547, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 51595, batch.n_tokens = 2048, progress = 0.898711
decode: failed to find a memory slot for batch of size 2048
srv  try_clear_id: purging slot 3 with 12665 tokens
slot prompt_clear: id  3 | task -1 | clearing prompt with 12665 tokens
srv  update_slots: failed to find free space in the KV cache, retrying with smaller batch size, i = 0, n_batch = 2048, ret = 1
slot update_slots: id  1 | task 47336 | n_tokens = 51595, memory_seq_rm [51595, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 53643, batch.n_tokens = 2048, progress = 0.934384
slot update_slots: id  1 | task 47336 | n_tokens = 53643, memory_seq_rm [53643, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 55691, batch.n_tokens = 2048, progress = 0.970057
slot update_slots: id  1 | task 47336 | n_tokens = 55691, memory_seq_rm [55691, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 57346, batch.n_tokens = 1655, progress = 0.998885
slot update_slots: id  1 | task 47336 | n_tokens = 57346, memory_seq_rm [57346, end)
slot update_slots: id  1 | task 47336 | prompt processing progress, n_tokens = 57410, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 47336 | prompt done, n_tokens = 57410, batch.n_tokens = 64
slot init_sampler: id  1 | task 47336 | init sampler, took 7.96 ms, tokens: text = 57410, total = 57410
slot update_slots: id  1 | task 47336 | erasing old context checkpoint (pos_min = 6215, pos_max = 6984, size = 18.056 MiB)
slot update_slots: id  1 | task 47336 | created context checkpoint 8 of 8 (pos_min = 56322, pos_max = 57345, size = 24.012 MiB)
slot print_timing: id  1 | task 47336 | 
prompt eval time =   76182.98 ms / 46775 tokens (    1.63 ms per token,   613.98 tokens per second)
       eval time =   37404.80 ms /  1223 tokens (   30.58 ms per token,    32.70 tokens per second)
      total time =  113587.78 ms / 47998 tokens
slot      release: id  1 | task 47336 | stop processing: n_tokens = 58632, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.815 (> 0.100 thold), f_keep = 0.169
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 58632, total state size = 1398.871 MiB
srv          load:  - looking for better prompt, base f_keep = 0.169, sim = 0.815
srv        update:  - cache state: 14 prompts, 6691.022 MiB (limits: 8192.000 MiB, 64000 tokens, 268923 est)
srv        update:    - prompt 0x5a234b577500:    4873 tokens, checkpoints:  5,   235.945 MiB
srv        update:    - prompt 0x5a234d243b70:    4947 tokens, checkpoints:  7,   261.904 MiB
srv        update:    - prompt 0x5a234cfbeaa0:   38169 tokens, checkpoints:  8,  1100.063 MiB
srv        update:    - prompt 0x5a234dc80090:    2123 tokens, checkpoints:  1,    68.612 MiB
srv        update:    - prompt 0x5a234ccbfee0:   15206 tokens, checkpoints:  3,   424.099 MiB
srv        update:    - prompt 0x5a234dbdca00:    2924 tokens, checkpoints:  2,   117.715 MiB
srv        update:    - prompt 0x5a234cfa37d0:    1948 tokens, checkpoints:  3,   106.905 MiB
srv        update:    - prompt 0x5a234cce4d20:    6823 tokens, checkpoints:  8,   301.838 MiB
srv        update:    - prompt 0x5a237670b520:   11970 tokens, checkpoints:  8,   418.989 MiB
srv        update:    - prompt 0x5a234f21f8f0:    1921 tokens, checkpoints:  3,   103.341 MiB
srv        update:    - prompt 0x5a237670b330:    9131 tokens, checkpoints:  8,   361.890 MiB
srv        update:    - prompt 0x5a23757875b0:   18907 tokens, checkpoints:  8,   591.315 MiB
srv        update:    - prompt 0x5a2351b39e00:   42076 tokens, checkpoints:  2,  1046.762 MiB
srv        update:    - prompt 0x5a234dc71f40:   58632 tokens, checkpoints:  8,  1551.643 MiB
srv  get_availabl: prompt cache update took 1370.72 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 48583 | processing task, is_child = 0
slot update_slots: id  1 | task 48583 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 12192
slot update_slots: id  1 | task 48583 | n_past = 9931, slot.prompt.tokens.size() = 58632, seq_id = 1, pos_min = 57608, n_swa = 128
slot update_slots: id  1 | task 48583 | restored context checkpoint (pos_min = 8993, pos_max = 9889, size = 21.034 MiB)
slot update_slots: id  1 | task 48583 | erased invalidated context checkpoint (pos_min = 9891, pos_max = 10570, n_swa = 128, size = 15.946 MiB)
slot update_slots: id  1 | task 48583 | erased invalidated context checkpoint (pos_min = 56322, pos_max = 57345, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  1 | task 48583 | n_tokens = 9889, memory_seq_rm [9889, end)
slot update_slots: id  1 | task 48583 | prompt processing progress, n_tokens = 11937, batch.n_tokens = 2048, progress = 0.979085
slot update_slots: id  1 | task 48583 | n_tokens = 11937, memory_seq_rm [11937, end)
slot update_slots: id  1 | task 48583 | prompt processing progress, n_tokens = 12128, batch.n_tokens = 191, progress = 0.994751
slot update_slots: id  1 | task 48583 | n_tokens = 12128, memory_seq_rm [12128, end)
slot update_slots: id  1 | task 48583 | prompt processing progress, n_tokens = 12192, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 48583 | prompt done, n_tokens = 12192, batch.n_tokens = 64
slot init_sampler: id  1 | task 48583 | init sampler, took 2.64 ms, tokens: text = 12192, total = 12192
slot update_slots: id  1 | task 48583 | created context checkpoint 7 of 8 (pos_min = 11104, pos_max = 12127, size = 24.012 MiB)
slot print_timing: id  1 | task 48583 | 
prompt eval time =    3573.32 ms /  2303 tokens (    1.55 ms per token,   644.50 tokens per second)
       eval time =   18578.74 ms /   673 tokens (   27.61 ms per token,    36.22 tokens per second)
      total time =   22152.06 ms /  2976 tokens
slot      release: id  1 | task 48583 | stop processing: n_tokens = 12864, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.944 (> 0.100 thold), f_keep = 0.920
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 49259 | processing task, is_child = 0
slot update_slots: id  1 | task 49259 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 12534
slot update_slots: id  1 | task 49259 | n_past = 11832, slot.prompt.tokens.size() = 12864, seq_id = 1, pos_min = 11840, n_swa = 128
slot update_slots: id  1 | task 49259 | restored context checkpoint (pos_min = 11104, pos_max = 12127, size = 24.012 MiB)
slot update_slots: id  1 | task 49259 | n_tokens = 11832, memory_seq_rm [11832, end)
slot update_slots: id  1 | task 49259 | prompt processing progress, n_tokens = 12470, batch.n_tokens = 638, progress = 0.994894
slot update_slots: id  1 | task 49259 | n_tokens = 12470, memory_seq_rm [12470, end)
slot update_slots: id  1 | task 49259 | prompt processing progress, n_tokens = 12534, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 49259 | prompt done, n_tokens = 12534, batch.n_tokens = 64
slot init_sampler: id  1 | task 49259 | init sampler, took 1.76 ms, tokens: text = 12534, total = 12534
slot update_slots: id  1 | task 49259 | created context checkpoint 8 of 8 (pos_min = 11446, pos_max = 12469, size = 24.012 MiB)
slot print_timing: id  1 | task 49259 | 
prompt eval time =    1456.64 ms /   702 tokens (    2.07 ms per token,   481.93 tokens per second)
       eval time =   16172.12 ms /   590 tokens (   27.41 ms per token,    36.48 tokens per second)
      total time =   17628.77 ms /  1292 tokens
slot      release: id  1 | task 49259 | stop processing: n_tokens = 13123, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.968 (> 0.100 thold), f_keep = 0.955
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 49851 | processing task, is_child = 0
slot update_slots: id  1 | task 49851 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 12954
slot update_slots: id  1 | task 49851 | n_tokens = 12534, memory_seq_rm [12534, end)
slot update_slots: id  1 | task 49851 | prompt processing progress, n_tokens = 12890, batch.n_tokens = 356, progress = 0.995059
slot update_slots: id  1 | task 49851 | n_tokens = 12890, memory_seq_rm [12890, end)
slot update_slots: id  1 | task 49851 | prompt processing progress, n_tokens = 12954, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 49851 | prompt done, n_tokens = 12954, batch.n_tokens = 64
slot init_sampler: id  1 | task 49851 | init sampler, took 2.55 ms, tokens: text = 12954, total = 12954
slot update_slots: id  1 | task 49851 | erasing old context checkpoint (pos_min = 6350, pos_max = 7119, size = 18.056 MiB)
slot update_slots: id  1 | task 49851 | created context checkpoint 8 of 8 (pos_min = 12099, pos_max = 12889, size = 18.548 MiB)
slot print_timing: id  1 | task 49851 | 
prompt eval time =     846.50 ms /   420 tokens (    2.02 ms per token,   496.16 tokens per second)
       eval time =    1576.77 ms /    56 tokens (   28.16 ms per token,    35.52 tokens per second)
      total time =    2423.26 ms /   476 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 49851 | stop processing: n_tokens = 13009, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 49909 | processing task, is_child = 0
slot update_slots: id  1 | task 49909 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13018
slot update_slots: id  1 | task 49909 | n_tokens = 12954, memory_seq_rm [12954, end)
slot update_slots: id  1 | task 49909 | prompt processing progress, n_tokens = 13018, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 49909 | prompt done, n_tokens = 13018, batch.n_tokens = 64
slot init_sampler: id  1 | task 49909 | init sampler, took 1.90 ms, tokens: text = 13018, total = 13018
slot print_timing: id  1 | task 49909 | 
prompt eval time =     231.78 ms /    64 tokens (    3.62 ms per token,   276.12 tokens per second)
       eval time =    3753.35 ms /   137 tokens (   27.40 ms per token,    36.50 tokens per second)
      total time =    3985.13 ms /   201 tokens
slot      release: id  1 | task 49909 | stop processing: n_tokens = 13154, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.959 (> 0.100 thold), f_keep = 0.951
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 50047 | processing task, is_child = 0
slot update_slots: id  1 | task 50047 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13047
slot update_slots: id  1 | task 50047 | n_tokens = 12507, memory_seq_rm [12507, end)
slot update_slots: id  1 | task 50047 | prompt processing progress, n_tokens = 12983, batch.n_tokens = 476, progress = 0.995095
slot update_slots: id  1 | task 50047 | n_tokens = 12983, memory_seq_rm [12983, end)
slot update_slots: id  1 | task 50047 | prompt processing progress, n_tokens = 13047, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 50047 | prompt done, n_tokens = 13047, batch.n_tokens = 64
slot init_sampler: id  1 | task 50047 | init sampler, took 3.09 ms, tokens: text = 13047, total = 13047
slot update_slots: id  1 | task 50047 | erasing old context checkpoint (pos_min = 6609, pos_max = 7188, size = 13.601 MiB)
slot update_slots: id  1 | task 50047 | created context checkpoint 8 of 8 (pos_min = 12289, pos_max = 12982, size = 16.274 MiB)
slot print_timing: id  1 | task 50047 | 
prompt eval time =    1028.15 ms /   540 tokens (    1.90 ms per token,   525.21 tokens per second)
       eval time =    2108.29 ms /    77 tokens (   27.38 ms per token,    36.52 tokens per second)
      total time =    3136.44 ms /   617 tokens
slot      release: id  1 | task 50047 | stop processing: n_tokens = 13123, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 50126 | processing task, is_child = 0
slot update_slots: id  1 | task 50126 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13111
slot update_slots: id  1 | task 50126 | n_tokens = 13047, memory_seq_rm [13047, end)
slot update_slots: id  1 | task 50126 | prompt processing progress, n_tokens = 13111, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 50126 | prompt done, n_tokens = 13111, batch.n_tokens = 64
slot init_sampler: id  1 | task 50126 | init sampler, took 1.86 ms, tokens: text = 13111, total = 13111
slot print_timing: id  1 | task 50126 | 
prompt eval time =     224.65 ms /    64 tokens (    3.51 ms per token,   284.89 tokens per second)
       eval time =    7056.85 ms /   261 tokens (   27.04 ms per token,    36.99 tokens per second)
      total time =    7281.50 ms /   325 tokens
slot      release: id  1 | task 50126 | stop processing: n_tokens = 13371, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.981 (> 0.100 thold), f_keep = 0.975
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 50388 | processing task, is_child = 0
slot update_slots: id  1 | task 50388 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13292
slot update_slots: id  1 | task 50388 | n_tokens = 13035, memory_seq_rm [13035, end)
slot update_slots: id  1 | task 50388 | prompt processing progress, n_tokens = 13228, batch.n_tokens = 193, progress = 0.995185
slot update_slots: id  1 | task 50388 | n_tokens = 13228, memory_seq_rm [13228, end)
slot update_slots: id  1 | task 50388 | prompt processing progress, n_tokens = 13292, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 50388 | prompt done, n_tokens = 13292, batch.n_tokens = 64
slot init_sampler: id  1 | task 50388 | init sampler, took 1.87 ms, tokens: text = 13292, total = 13292
slot update_slots: id  1 | task 50388 | erasing old context checkpoint (pos_min = 6639, pos_max = 7408, size = 18.056 MiB)
slot update_slots: id  1 | task 50388 | created context checkpoint 8 of 8 (pos_min = 12507, pos_max = 13227, size = 16.907 MiB)
slot print_timing: id  1 | task 50388 | 
prompt eval time =     727.57 ms /   257 tokens (    2.83 ms per token,   353.23 tokens per second)
       eval time =    3996.06 ms /   145 tokens (   27.56 ms per token,    36.29 tokens per second)
      total time =    4723.62 ms /   402 tokens
slot      release: id  1 | task 50388 | stop processing: n_tokens = 13436, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.989
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 50535 | processing task, is_child = 0
slot update_slots: id  1 | task 50535 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13390
slot update_slots: id  1 | task 50535 | n_tokens = 13292, memory_seq_rm [13292, end)
slot update_slots: id  1 | task 50535 | prompt processing progress, n_tokens = 13326, batch.n_tokens = 34, progress = 0.995220
slot update_slots: id  1 | task 50535 | n_tokens = 13326, memory_seq_rm [13326, end)
slot update_slots: id  1 | task 50535 | prompt processing progress, n_tokens = 13390, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 50535 | prompt done, n_tokens = 13390, batch.n_tokens = 64
slot init_sampler: id  1 | task 50535 | init sampler, took 2.93 ms, tokens: text = 13390, total = 13390
slot update_slots: id  1 | task 50535 | erasing old context checkpoint (pos_min = 7187, pos_max = 8083, size = 21.034 MiB)
slot update_slots: id  1 | task 50535 | created context checkpoint 8 of 8 (pos_min = 12507, pos_max = 13325, size = 19.205 MiB)
slot print_timing: id  1 | task 50535 | 
prompt eval time =     384.79 ms /    98 tokens (    3.93 ms per token,   254.68 tokens per second)
       eval time =    4518.19 ms /   163 tokens (   27.72 ms per token,    36.08 tokens per second)
      total time =    4902.98 ms /   261 tokens
slot      release: id  1 | task 50535 | stop processing: n_tokens = 13552, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 50700 | processing task, is_child = 0
slot update_slots: id  1 | task 50700 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13448
slot update_slots: id  1 | task 50700 | n_tokens = 13390, memory_seq_rm [13390, end)
slot update_slots: id  1 | task 50700 | prompt processing progress, n_tokens = 13448, batch.n_tokens = 58, progress = 1.000000
slot update_slots: id  1 | task 50700 | prompt done, n_tokens = 13448, batch.n_tokens = 58
slot init_sampler: id  1 | task 50700 | init sampler, took 1.93 ms, tokens: text = 13448, total = 13448
slot print_timing: id  1 | task 50700 | 
prompt eval time =     196.63 ms /    58 tokens (    3.39 ms per token,   294.97 tokens per second)
       eval time =    1837.07 ms /    66 tokens (   27.83 ms per token,    35.93 tokens per second)
      total time =    2033.70 ms /   124 tokens
slot      release: id  1 | task 50700 | stop processing: n_tokens = 13513, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.587 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 50767 | processing task, is_child = 0
slot update_slots: id  1 | task 50767 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 22924
slot update_slots: id  1 | task 50767 | n_tokens = 13448, memory_seq_rm [13448, end)
slot update_slots: id  1 | task 50767 | prompt processing progress, n_tokens = 15496, batch.n_tokens = 2048, progress = 0.675973
slot update_slots: id  1 | task 50767 | n_tokens = 15496, memory_seq_rm [15496, end)
slot update_slots: id  1 | task 50767 | prompt processing progress, n_tokens = 17544, batch.n_tokens = 2048, progress = 0.765311
slot update_slots: id  1 | task 50767 | n_tokens = 17544, memory_seq_rm [17544, end)
slot update_slots: id  1 | task 50767 | prompt processing progress, n_tokens = 19592, batch.n_tokens = 2048, progress = 0.854650
slot update_slots: id  1 | task 50767 | n_tokens = 19592, memory_seq_rm [19592, end)
slot update_slots: id  1 | task 50767 | prompt processing progress, n_tokens = 21640, batch.n_tokens = 2048, progress = 0.943989
slot update_slots: id  1 | task 50767 | n_tokens = 21640, memory_seq_rm [21640, end)
slot update_slots: id  1 | task 50767 | prompt processing progress, n_tokens = 22860, batch.n_tokens = 1220, progress = 0.997208
slot update_slots: id  1 | task 50767 | n_tokens = 22860, memory_seq_rm [22860, end)
slot update_slots: id  1 | task 50767 | prompt processing progress, n_tokens = 22924, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 50767 | prompt done, n_tokens = 22924, batch.n_tokens = 64
slot init_sampler: id  1 | task 50767 | init sampler, took 3.23 ms, tokens: text = 22924, total = 22924
slot update_slots: id  1 | task 50767 | erasing old context checkpoint (pos_min = 8075, pos_max = 8971, size = 21.034 MiB)
slot update_slots: id  1 | task 50767 | created context checkpoint 8 of 8 (pos_min = 21836, pos_max = 22859, size = 24.012 MiB)
slot print_timing: id  1 | task 50767 | 
prompt eval time =   13981.75 ms /  9476 tokens (    1.48 ms per token,   677.74 tokens per second)
       eval time =   30220.33 ms /  1105 tokens (   27.35 ms per token,    36.56 tokens per second)
      total time =   44202.09 ms / 10581 tokens
slot      release: id  1 | task 50767 | stop processing: n_tokens = 24028, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.931 (> 0.100 thold), f_keep = 0.553
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 51878 | processing task, is_child = 0
slot update_slots: id  1 | task 51878 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 14264
slot update_slots: id  1 | task 51878 | n_past = 13277, slot.prompt.tokens.size() = 24028, seq_id = 1, pos_min = 23004, n_swa = 128
slot update_slots: id  1 | task 51878 | restored context checkpoint (pos_min = 12507, pos_max = 13325, size = 19.205 MiB)
slot update_slots: id  1 | task 51878 | erased invalidated context checkpoint (pos_min = 21836, pos_max = 22859, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  1 | task 51878 | n_tokens = 13277, memory_seq_rm [13277, end)
slot update_slots: id  1 | task 51878 | prompt processing progress, n_tokens = 14200, batch.n_tokens = 923, progress = 0.995513
slot update_slots: id  1 | task 51878 | n_tokens = 14200, memory_seq_rm [14200, end)
slot update_slots: id  1 | task 51878 | prompt processing progress, n_tokens = 14264, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 51878 | prompt done, n_tokens = 14264, batch.n_tokens = 64
slot init_sampler: id  1 | task 51878 | init sampler, took 2.02 ms, tokens: text = 14264, total = 14264
slot update_slots: id  1 | task 51878 | created context checkpoint 8 of 8 (pos_min = 13176, pos_max = 14199, size = 24.012 MiB)
slot print_timing: id  1 | task 51878 | 
prompt eval time =    1617.90 ms /   987 tokens (    1.64 ms per token,   610.05 tokens per second)
       eval time =    7053.26 ms /   264 tokens (   26.72 ms per token,    37.43 tokens per second)
      total time =    8671.15 ms /  1251 tokens
slot      release: id  1 | task 51878 | stop processing: n_tokens = 14527, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.601 (> 0.100 thold), f_keep = 0.982
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 52144 | processing task, is_child = 0
slot update_slots: id  1 | task 52144 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23740
slot update_slots: id  1 | task 52144 | n_tokens = 14264, memory_seq_rm [14264, end)
slot update_slots: id  1 | task 52144 | prompt processing progress, n_tokens = 16312, batch.n_tokens = 2048, progress = 0.687110
slot update_slots: id  1 | task 52144 | n_tokens = 16312, memory_seq_rm [16312, end)
slot update_slots: id  1 | task 52144 | prompt processing progress, n_tokens = 18360, batch.n_tokens = 2048, progress = 0.773378
slot update_slots: id  1 | task 52144 | n_tokens = 18360, memory_seq_rm [18360, end)
slot update_slots: id  1 | task 52144 | prompt processing progress, n_tokens = 20408, batch.n_tokens = 2048, progress = 0.859646
slot update_slots: id  1 | task 52144 | n_tokens = 20408, memory_seq_rm [20408, end)
slot update_slots: id  1 | task 52144 | prompt processing progress, n_tokens = 22456, batch.n_tokens = 2048, progress = 0.945914
slot update_slots: id  1 | task 52144 | n_tokens = 22456, memory_seq_rm [22456, end)
slot update_slots: id  1 | task 52144 | prompt processing progress, n_tokens = 23676, batch.n_tokens = 1220, progress = 0.997304
slot update_slots: id  1 | task 52144 | n_tokens = 23676, memory_seq_rm [23676, end)
slot update_slots: id  1 | task 52144 | prompt processing progress, n_tokens = 23740, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 52144 | prompt done, n_tokens = 23740, batch.n_tokens = 64
slot init_sampler: id  1 | task 52144 | init sampler, took 4.98 ms, tokens: text = 23740, total = 23740
slot update_slots: id  1 | task 52144 | erasing old context checkpoint (pos_min = 8993, pos_max = 9889, size = 21.034 MiB)
slot update_slots: id  1 | task 52144 | created context checkpoint 8 of 8 (pos_min = 22652, pos_max = 23675, size = 24.012 MiB)
slot print_timing: id  1 | task 52144 | 
prompt eval time =   13630.53 ms /  9476 tokens (    1.44 ms per token,   695.20 tokens per second)
       eval time =    7795.70 ms /   281 tokens (   27.74 ms per token,    36.05 tokens per second)
      total time =   21426.23 ms /  9757 tokens
slot      release: id  1 | task 52144 | stop processing: n_tokens = 24020, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.593
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 52431 | processing task, is_child = 0
slot update_slots: id  1 | task 52431 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 14414
slot update_slots: id  1 | task 52431 | n_past = 14239, slot.prompt.tokens.size() = 24020, seq_id = 1, pos_min = 22996, n_swa = 128
slot update_slots: id  1 | task 52431 | restored context checkpoint (pos_min = 13176, pos_max = 14199, size = 24.012 MiB)
slot update_slots: id  1 | task 52431 | erased invalidated context checkpoint (pos_min = 22652, pos_max = 23675, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  1 | task 52431 | n_tokens = 14199, memory_seq_rm [14199, end)
slot update_slots: id  1 | task 52431 | prompt processing progress, n_tokens = 14350, batch.n_tokens = 151, progress = 0.995560
slot update_slots: id  1 | task 52431 | n_tokens = 14350, memory_seq_rm [14350, end)
slot update_slots: id  1 | task 52431 | prompt processing progress, n_tokens = 14414, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 52431 | prompt done, n_tokens = 14414, batch.n_tokens = 64
slot init_sampler: id  1 | task 52431 | init sampler, took 2.10 ms, tokens: text = 14414, total = 14414
slot update_slots: id  1 | task 52431 | created context checkpoint 8 of 8 (pos_min = 13326, pos_max = 14349, size = 24.012 MiB)
slot print_timing: id  1 | task 52431 | 
prompt eval time =     620.76 ms /   215 tokens (    2.89 ms per token,   346.35 tokens per second)
       eval time =   27489.87 ms /  1000 tokens (   27.49 ms per token,    36.38 tokens per second)
      total time =   28110.63 ms /  1215 tokens
slot      release: id  1 | task 52431 | stop processing: n_tokens = 15413, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.935
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 53433 | processing task, is_child = 0
slot update_slots: id  1 | task 53433 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 14653
slot update_slots: id  1 | task 53433 | n_past = 14414, slot.prompt.tokens.size() = 15413, seq_id = 1, pos_min = 14389, n_swa = 128
slot update_slots: id  1 | task 53433 | restored context checkpoint (pos_min = 13326, pos_max = 14349, size = 24.012 MiB)
slot update_slots: id  1 | task 53433 | n_tokens = 14349, memory_seq_rm [14349, end)
slot update_slots: id  1 | task 53433 | prompt processing progress, n_tokens = 14589, batch.n_tokens = 240, progress = 0.995632
slot update_slots: id  1 | task 53433 | n_tokens = 14589, memory_seq_rm [14589, end)
slot update_slots: id  1 | task 53433 | prompt processing progress, n_tokens = 14653, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 53433 | prompt done, n_tokens = 14653, batch.n_tokens = 64
slot init_sampler: id  1 | task 53433 | init sampler, took 3.06 ms, tokens: text = 14653, total = 14653
slot update_slots: id  1 | task 53433 | erasing old context checkpoint (pos_min = 11104, pos_max = 12127, size = 24.012 MiB)
slot update_slots: id  1 | task 53433 | created context checkpoint 8 of 8 (pos_min = 13565, pos_max = 14588, size = 24.012 MiB)
slot print_timing: id  1 | task 53433 | 
prompt eval time =     746.68 ms /   304 tokens (    2.46 ms per token,   407.13 tokens per second)
       eval time =    6755.44 ms /   244 tokens (   27.69 ms per token,    36.12 tokens per second)
      total time =    7502.13 ms /   548 tokens
slot      release: id  1 | task 53433 | stop processing: n_tokens = 14896, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.974 (> 0.100 thold), f_keep = 0.964
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 53679 | processing task, is_child = 0
slot update_slots: id  1 | task 53679 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 14738
slot update_slots: id  1 | task 53679 | n_tokens = 14362, memory_seq_rm [14362, end)
slot update_slots: id  1 | task 53679 | prompt processing progress, n_tokens = 14674, batch.n_tokens = 312, progress = 0.995658
slot update_slots: id  1 | task 53679 | n_tokens = 14674, memory_seq_rm [14674, end)
slot update_slots: id  1 | task 53679 | prompt processing progress, n_tokens = 14738, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 53679 | prompt done, n_tokens = 14738, batch.n_tokens = 64
slot init_sampler: id  1 | task 53679 | init sampler, took 3.03 ms, tokens: text = 14738, total = 14738
slot update_slots: id  1 | task 53679 | erasing old context checkpoint (pos_min = 11446, pos_max = 12469, size = 24.012 MiB)
slot update_slots: id  1 | task 53679 | created context checkpoint 8 of 8 (pos_min = 13872, pos_max = 14673, size = 18.806 MiB)
slot print_timing: id  1 | task 53679 | 
prompt eval time =     828.88 ms /   376 tokens (    2.20 ms per token,   453.63 tokens per second)
       eval time =    3908.22 ms /   145 tokens (   26.95 ms per token,    37.10 tokens per second)
      total time =    4737.10 ms /   521 tokens
slot      release: id  1 | task 53679 | stop processing: n_tokens = 14882, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.990
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 53826 | processing task, is_child = 0
slot update_slots: id  1 | task 53826 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 14795
slot update_slots: id  1 | task 53826 | n_tokens = 14738, memory_seq_rm [14738, end)
slot update_slots: id  1 | task 53826 | prompt processing progress, n_tokens = 14795, batch.n_tokens = 57, progress = 1.000000
slot update_slots: id  1 | task 53826 | prompt done, n_tokens = 14795, batch.n_tokens = 57
slot init_sampler: id  1 | task 53826 | init sampler, took 2.15 ms, tokens: text = 14795, total = 14795
slot print_timing: id  1 | task 53826 | 
prompt eval time =     190.80 ms /    57 tokens (    3.35 ms per token,   298.75 tokens per second)
       eval time =    1170.54 ms /    44 tokens (   26.60 ms per token,    37.59 tokens per second)
      total time =    1361.34 ms /   101 tokens
slot      release: id  1 | task 53826 | stop processing: n_tokens = 14838, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 53871 | processing task, is_child = 0
slot update_slots: id  1 | task 53871 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 14848
slot update_slots: id  1 | task 53871 | n_tokens = 14795, memory_seq_rm [14795, end)
slot update_slots: id  1 | task 53871 | prompt processing progress, n_tokens = 14848, batch.n_tokens = 53, progress = 1.000000
slot update_slots: id  1 | task 53871 | prompt done, n_tokens = 14848, batch.n_tokens = 53
slot init_sampler: id  1 | task 53871 | init sampler, took 2.76 ms, tokens: text = 14848, total = 14848
slot update_slots: id  1 | task 53871 | erasing old context checkpoint (pos_min = 12099, pos_max = 12889, size = 18.548 MiB)
slot update_slots: id  1 | task 53871 | created context checkpoint 8 of 8 (pos_min = 14051, pos_max = 14794, size = 17.446 MiB)
slot print_timing: id  1 | task 53871 | 
prompt eval time =     312.63 ms /    53 tokens (    5.90 ms per token,   169.53 tokens per second)
       eval time =    1036.15 ms /    36 tokens (   28.78 ms per token,    34.74 tokens per second)
      total time =    1348.78 ms /    89 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 53871 | stop processing: n_tokens = 14883, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.990
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 53908 | processing task, is_child = 0
slot update_slots: id  1 | task 53908 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 14831
slot update_slots: id  1 | task 53908 | n_tokens = 14729, memory_seq_rm [14729, end)
slot update_slots: id  1 | task 53908 | prompt processing progress, n_tokens = 14767, batch.n_tokens = 38, progress = 0.995685
slot update_slots: id  1 | task 53908 | n_tokens = 14767, memory_seq_rm [14767, end)
slot update_slots: id  1 | task 53908 | prompt processing progress, n_tokens = 14831, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 53908 | prompt done, n_tokens = 14831, batch.n_tokens = 64
slot init_sampler: id  1 | task 53908 | init sampler, took 2.80 ms, tokens: text = 14831, total = 14831
slot print_timing: id  1 | task 53908 | 
prompt eval time =     418.52 ms /   102 tokens (    4.10 ms per token,   243.72 tokens per second)
       eval time =   17128.49 ms /   629 tokens (   27.23 ms per token,    36.72 tokens per second)
      total time =   17547.00 ms /   731 tokens
slot      release: id  1 | task 53908 | stop processing: n_tokens = 15459, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.967 (> 0.100 thold), f_keep = 0.959
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 54539 | processing task, is_child = 0
slot update_slots: id  1 | task 54539 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15332
slot update_slots: id  1 | task 54539 | n_tokens = 14823, memory_seq_rm [14823, end)
slot update_slots: id  1 | task 54539 | prompt processing progress, n_tokens = 15268, batch.n_tokens = 445, progress = 0.995826
slot update_slots: id  1 | task 54539 | n_tokens = 15268, memory_seq_rm [15268, end)
slot update_slots: id  1 | task 54539 | prompt processing progress, n_tokens = 15332, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 54539 | prompt done, n_tokens = 15332, batch.n_tokens = 64
slot init_sampler: id  1 | task 54539 | init sampler, took 2.27 ms, tokens: text = 15332, total = 15332
slot update_slots: id  1 | task 54539 | erasing old context checkpoint (pos_min = 12289, pos_max = 12982, size = 16.274 MiB)
slot update_slots: id  1 | task 54539 | created context checkpoint 8 of 8 (pos_min = 14696, pos_max = 15267, size = 13.413 MiB)
slot print_timing: id  1 | task 54539 | 
prompt eval time =     946.58 ms /   509 tokens (    1.86 ms per token,   537.73 tokens per second)
       eval time =    1674.01 ms /    62 tokens (   27.00 ms per token,    37.04 tokens per second)
      total time =    2620.58 ms /   571 tokens
slot      release: id  1 | task 54539 | stop processing: n_tokens = 15393, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 54603 | processing task, is_child = 0
slot update_slots: id  1 | task 54603 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15398
slot update_slots: id  1 | task 54603 | n_tokens = 15332, memory_seq_rm [15332, end)
slot update_slots: id  1 | task 54603 | prompt processing progress, n_tokens = 15334, batch.n_tokens = 2, progress = 0.995844
slot update_slots: id  1 | task 54603 | n_tokens = 15334, memory_seq_rm [15334, end)
slot update_slots: id  1 | task 54603 | prompt processing progress, n_tokens = 15398, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 54603 | prompt done, n_tokens = 15398, batch.n_tokens = 64
slot init_sampler: id  1 | task 54603 | init sampler, took 2.16 ms, tokens: text = 15398, total = 15398
slot update_slots: id  1 | task 54603 | erasing old context checkpoint (pos_min = 12507, pos_max = 13227, size = 16.907 MiB)
slot update_slots: id  1 | task 54603 | created context checkpoint 8 of 8 (pos_min = 14696, pos_max = 15333, size = 14.961 MiB)
slot print_timing: id  1 | task 54603 | 
prompt eval time =     263.94 ms /    66 tokens (    4.00 ms per token,   250.05 tokens per second)
       eval time =    4723.40 ms /   173 tokens (   27.30 ms per token,    36.63 tokens per second)
      total time =    4987.35 ms /   239 tokens
slot      release: id  1 | task 54603 | stop processing: n_tokens = 15570, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.983
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 54778 | processing task, is_child = 0
slot update_slots: id  1 | task 54778 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15512
slot update_slots: id  1 | task 54778 | n_tokens = 15305, memory_seq_rm [15305, end)
slot update_slots: id  1 | task 54778 | prompt processing progress, n_tokens = 15448, batch.n_tokens = 143, progress = 0.995874
slot update_slots: id  1 | task 54778 | n_tokens = 15448, memory_seq_rm [15448, end)
slot update_slots: id  1 | task 54778 | prompt processing progress, n_tokens = 15512, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 54778 | prompt done, n_tokens = 15512, batch.n_tokens = 64
slot init_sampler: id  1 | task 54778 | init sampler, took 2.22 ms, tokens: text = 15512, total = 15512
slot update_slots: id  1 | task 54778 | erasing old context checkpoint (pos_min = 12507, pos_max = 13325, size = 19.205 MiB)
slot update_slots: id  1 | task 54778 | created context checkpoint 8 of 8 (pos_min = 14696, pos_max = 15447, size = 17.634 MiB)
slot print_timing: id  1 | task 54778 | 
prompt eval time =     615.06 ms /   207 tokens (    2.97 ms per token,   336.55 tokens per second)
       eval time =    6509.93 ms /   239 tokens (   27.24 ms per token,    36.71 tokens per second)
      total time =    7124.99 ms /   446 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 54778 | stop processing: n_tokens = 15750, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.307 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 55019 | processing task, is_child = 0
slot update_slots: id  1 | task 55019 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 50448
slot update_slots: id  1 | task 55019 | n_tokens = 15512, memory_seq_rm [15512, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 17560, batch.n_tokens = 2048, progress = 0.348081
slot update_slots: id  1 | task 55019 | n_tokens = 17560, memory_seq_rm [17560, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 19608, batch.n_tokens = 2048, progress = 0.388677
slot update_slots: id  1 | task 55019 | n_tokens = 19608, memory_seq_rm [19608, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 21656, batch.n_tokens = 2048, progress = 0.429274
slot update_slots: id  1 | task 55019 | n_tokens = 21656, memory_seq_rm [21656, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 23704, batch.n_tokens = 2048, progress = 0.469870
slot update_slots: id  1 | task 55019 | n_tokens = 23704, memory_seq_rm [23704, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 25752, batch.n_tokens = 2048, progress = 0.510466
slot update_slots: id  1 | task 55019 | n_tokens = 25752, memory_seq_rm [25752, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 27800, batch.n_tokens = 2048, progress = 0.551062
slot update_slots: id  1 | task 55019 | n_tokens = 27800, memory_seq_rm [27800, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 29848, batch.n_tokens = 2048, progress = 0.591659
slot update_slots: id  1 | task 55019 | n_tokens = 29848, memory_seq_rm [29848, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 31896, batch.n_tokens = 2048, progress = 0.632255
slot update_slots: id  1 | task 55019 | n_tokens = 31896, memory_seq_rm [31896, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 33944, batch.n_tokens = 2048, progress = 0.672851
slot update_slots: id  1 | task 55019 | n_tokens = 33944, memory_seq_rm [33944, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 35992, batch.n_tokens = 2048, progress = 0.713448
slot update_slots: id  1 | task 55019 | n_tokens = 35992, memory_seq_rm [35992, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 38040, batch.n_tokens = 2048, progress = 0.754044
slot update_slots: id  1 | task 55019 | n_tokens = 38040, memory_seq_rm [38040, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 40088, batch.n_tokens = 2048, progress = 0.794640
slot update_slots: id  1 | task 55019 | n_tokens = 40088, memory_seq_rm [40088, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 42136, batch.n_tokens = 2048, progress = 0.835236
slot update_slots: id  1 | task 55019 | n_tokens = 42136, memory_seq_rm [42136, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 44184, batch.n_tokens = 2048, progress = 0.875833
slot update_slots: id  1 | task 55019 | n_tokens = 44184, memory_seq_rm [44184, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 46232, batch.n_tokens = 2048, progress = 0.916429
slot update_slots: id  1 | task 55019 | n_tokens = 46232, memory_seq_rm [46232, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 48280, batch.n_tokens = 2048, progress = 0.957025
slot update_slots: id  1 | task 55019 | n_tokens = 48280, memory_seq_rm [48280, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 50328, batch.n_tokens = 2048, progress = 0.997621
slot update_slots: id  1 | task 55019 | n_tokens = 50328, memory_seq_rm [50328, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 50384, batch.n_tokens = 56, progress = 0.998731
slot update_slots: id  1 | task 55019 | n_tokens = 50384, memory_seq_rm [50384, end)
slot update_slots: id  1 | task 55019 | prompt processing progress, n_tokens = 50448, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 55019 | prompt done, n_tokens = 50448, batch.n_tokens = 64
slot init_sampler: id  1 | task 55019 | init sampler, took 7.06 ms, tokens: text = 50448, total = 50448
slot update_slots: id  1 | task 55019 | erasing old context checkpoint (pos_min = 13176, pos_max = 14199, size = 24.012 MiB)
slot update_slots: id  1 | task 55019 | created context checkpoint 8 of 8 (pos_min = 49360, pos_max = 50383, size = 24.012 MiB)
slot print_timing: id  1 | task 55019 | 
prompt eval time =   48715.82 ms / 34936 tokens (    1.39 ms per token,   717.14 tokens per second)
       eval time =   34093.65 ms /  1161 tokens (   29.37 ms per token,    34.05 tokens per second)
      total time =   82809.48 ms / 36097 tokens
slot      release: id  1 | task 55019 | stop processing: n_tokens = 51608, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.940 (> 0.100 thold), f_keep = 0.300
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 51608, total state size = 1234.165 MiB
srv          load:  - looking for better prompt, base f_keep = 0.300, sim = 0.940
srv        update:  - cache state: 15 prompts, 8079.483 MiB (limits: 8192.000 MiB, 64000 tokens, 275035 est)
srv        update:    - prompt 0x5a234b577500:    4873 tokens, checkpoints:  5,   235.945 MiB
srv        update:    - prompt 0x5a234d243b70:    4947 tokens, checkpoints:  7,   261.904 MiB
srv        update:    - prompt 0x5a234cfbeaa0:   38169 tokens, checkpoints:  8,  1100.063 MiB
srv        update:    - prompt 0x5a234dc80090:    2123 tokens, checkpoints:  1,    68.612 MiB
srv        update:    - prompt 0x5a234ccbfee0:   15206 tokens, checkpoints:  3,   424.099 MiB
srv        update:    - prompt 0x5a234dbdca00:    2924 tokens, checkpoints:  2,   117.715 MiB
srv        update:    - prompt 0x5a234cfa37d0:    1948 tokens, checkpoints:  3,   106.905 MiB
srv        update:    - prompt 0x5a234cce4d20:    6823 tokens, checkpoints:  8,   301.838 MiB
srv        update:    - prompt 0x5a237670b520:   11970 tokens, checkpoints:  8,   418.989 MiB
srv        update:    - prompt 0x5a234f21f8f0:    1921 tokens, checkpoints:  3,   103.341 MiB
srv        update:    - prompt 0x5a237670b330:    9131 tokens, checkpoints:  8,   361.890 MiB
srv        update:    - prompt 0x5a23757875b0:   18907 tokens, checkpoints:  8,   591.315 MiB
srv        update:    - prompt 0x5a2351b39e00:   42076 tokens, checkpoints:  2,  1046.762 MiB
srv        update:    - prompt 0x5a234dc71f40:   58632 tokens, checkpoints:  8,  1551.643 MiB
srv        update:    - prompt 0x5a2351ca7450:   51608 tokens, checkpoints:  8,  1388.462 MiB
srv  get_availabl: prompt cache update took 1330.95 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 56199 | processing task, is_child = 0
slot update_slots: id  1 | task 56199 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16487
slot update_slots: id  1 | task 56199 | n_past = 15493, slot.prompt.tokens.size() = 51608, seq_id = 1, pos_min = 50584, n_swa = 128
slot update_slots: id  1 | task 56199 | restored context checkpoint (pos_min = 14696, pos_max = 15447, size = 17.634 MiB)
slot update_slots: id  1 | task 56199 | erased invalidated context checkpoint (pos_min = 49360, pos_max = 50383, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  1 | task 56199 | n_tokens = 15447, memory_seq_rm [15447, end)
slot update_slots: id  1 | task 56199 | prompt processing progress, n_tokens = 16423, batch.n_tokens = 976, progress = 0.996118
slot update_slots: id  1 | task 56199 | n_tokens = 16423, memory_seq_rm [16423, end)
slot update_slots: id  1 | task 56199 | prompt processing progress, n_tokens = 16487, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 56199 | prompt done, n_tokens = 16487, batch.n_tokens = 64
slot init_sampler: id  1 | task 56199 | init sampler, took 2.40 ms, tokens: text = 16487, total = 16487
slot update_slots: id  1 | task 56199 | created context checkpoint 8 of 8 (pos_min = 15399, pos_max = 16422, size = 24.012 MiB)
slot print_timing: id  1 | task 56199 | 
prompt eval time =    1734.84 ms /  1040 tokens (    1.67 ms per token,   599.48 tokens per second)
       eval time =   22857.45 ms /   830 tokens (   27.54 ms per token,    36.31 tokens per second)
      total time =   24592.29 ms /  1870 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 56199 | stop processing: n_tokens = 17316, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.949 (> 0.100 thold), f_keep = 0.951
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 57031 | processing task, is_child = 0
slot update_slots: id  1 | task 57031 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 17341
slot update_slots: id  1 | task 57031 | n_tokens = 16465, memory_seq_rm [16465, end)
slot update_slots: id  1 | task 57031 | prompt processing progress, n_tokens = 17277, batch.n_tokens = 812, progress = 0.996309
slot update_slots: id  1 | task 57031 | n_tokens = 17277, memory_seq_rm [17277, end)
slot update_slots: id  1 | task 57031 | prompt processing progress, n_tokens = 17341, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 57031 | prompt done, n_tokens = 17341, batch.n_tokens = 64
slot init_sampler: id  1 | task 57031 | init sampler, took 2.52 ms, tokens: text = 17341, total = 17341
slot update_slots: id  1 | task 57031 | erasing old context checkpoint (pos_min = 13326, pos_max = 14349, size = 24.012 MiB)
slot update_slots: id  1 | task 57031 | created context checkpoint 8 of 8 (pos_min = 16465, pos_max = 17276, size = 19.041 MiB)
slot print_timing: id  1 | task 57031 | 
prompt eval time =    1506.65 ms /   876 tokens (    1.72 ms per token,   581.42 tokens per second)
       eval time =   22081.83 ms /   804 tokens (   27.46 ms per token,    36.41 tokens per second)
      total time =   23588.49 ms /  1680 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 57031 | stop processing: n_tokens = 18144, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.945 (> 0.100 thold), f_keep = 0.944
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 57837 | processing task, is_child = 0
slot update_slots: id  1 | task 57837 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 18133
slot update_slots: id  1 | task 57837 | n_past = 17129, slot.prompt.tokens.size() = 18144, seq_id = 1, pos_min = 17120, n_swa = 128
slot update_slots: id  1 | task 57837 | restored context checkpoint (pos_min = 16465, pos_max = 17276, size = 19.041 MiB)
slot update_slots: id  1 | task 57837 | n_tokens = 17129, memory_seq_rm [17129, end)
slot update_slots: id  1 | task 57837 | prompt processing progress, n_tokens = 18069, batch.n_tokens = 940, progress = 0.996471
slot update_slots: id  1 | task 57837 | n_tokens = 18069, memory_seq_rm [18069, end)
slot update_slots: id  1 | task 57837 | prompt processing progress, n_tokens = 18133, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 57837 | prompt done, n_tokens = 18133, batch.n_tokens = 64
slot init_sampler: id  1 | task 57837 | init sampler, took 2.58 ms, tokens: text = 18133, total = 18133
slot update_slots: id  1 | task 57837 | erasing old context checkpoint (pos_min = 13565, pos_max = 14588, size = 24.012 MiB)
slot update_slots: id  1 | task 57837 | created context checkpoint 8 of 8 (pos_min = 17045, pos_max = 18068, size = 24.012 MiB)
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv          stop: cancel task, id_task = 57837
slot      release: id  1 | task 57837 | stop processing: n_tokens = 18497, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.970
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 58205 | processing task, is_child = 0
slot update_slots: id  1 | task 58205 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 18138
slot update_slots: id  1 | task 58205 | n_tokens = 17940, memory_seq_rm [17940, end)
slot update_slots: id  1 | task 58205 | prompt processing progress, n_tokens = 18074, batch.n_tokens = 134, progress = 0.996472
slot update_slots: id  1 | task 58205 | n_tokens = 18074, memory_seq_rm [18074, end)
slot update_slots: id  1 | task 58205 | prompt processing progress, n_tokens = 18138, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 58205 | prompt done, n_tokens = 18138, batch.n_tokens = 64
slot init_sampler: id  1 | task 58205 | init sampler, took 3.58 ms, tokens: text = 18138, total = 18138
slot print_timing: id  1 | task 58205 | 
prompt eval time =     552.76 ms /   198 tokens (    2.79 ms per token,   358.20 tokens per second)
       eval time =   21684.32 ms /   782 tokens (   27.73 ms per token,    36.06 tokens per second)
      total time =   22237.08 ms /   980 tokens
slot      release: id  1 | task 58205 | stop processing: n_tokens = 18919, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.946 (> 0.100 thold), f_keep = 0.948
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 58989 | processing task, is_child = 0
slot update_slots: id  1 | task 58989 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 18954
slot update_slots: id  1 | task 58989 | n_past = 17935, slot.prompt.tokens.size() = 18919, seq_id = 1, pos_min = 17895, n_swa = 128
slot update_slots: id  1 | task 58989 | restored context checkpoint (pos_min = 17045, pos_max = 18068, size = 24.012 MiB)
slot update_slots: id  1 | task 58989 | n_tokens = 17935, memory_seq_rm [17935, end)
slot update_slots: id  1 | task 58989 | prompt processing progress, n_tokens = 18890, batch.n_tokens = 955, progress = 0.996623
slot update_slots: id  1 | task 58989 | n_tokens = 18890, memory_seq_rm [18890, end)
slot update_slots: id  1 | task 58989 | prompt processing progress, n_tokens = 18954, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 58989 | prompt done, n_tokens = 18954, batch.n_tokens = 64
slot init_sampler: id  1 | task 58989 | init sampler, took 3.65 ms, tokens: text = 18954, total = 18954
slot update_slots: id  1 | task 58989 | erasing old context checkpoint (pos_min = 13872, pos_max = 14673, size = 18.806 MiB)
slot update_slots: id  1 | task 58989 | created context checkpoint 8 of 8 (pos_min = 17866, pos_max = 18889, size = 24.012 MiB)
slot print_timing: id  1 | task 58989 | 
prompt eval time =    1663.73 ms /  1019 tokens (    1.63 ms per token,   612.48 tokens per second)
       eval time =   18541.55 ms /   675 tokens (   27.47 ms per token,    36.40 tokens per second)
      total time =   20205.27 ms /  1694 tokens
slot      release: id  1 | task 58989 | stop processing: n_tokens = 19628, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.971 (> 0.100 thold), f_keep = 0.966
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 59666 | processing task, is_child = 0
slot update_slots: id  1 | task 59666 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 19518
slot update_slots: id  1 | task 59666 | n_tokens = 18954, memory_seq_rm [18954, end)
slot update_slots: id  1 | task 59666 | prompt processing progress, n_tokens = 19454, batch.n_tokens = 500, progress = 0.996721
slot update_slots: id  1 | task 59666 | n_tokens = 19454, memory_seq_rm [19454, end)
slot update_slots: id  1 | task 59666 | prompt processing progress, n_tokens = 19518, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 59666 | prompt done, n_tokens = 19518, batch.n_tokens = 64
slot init_sampler: id  1 | task 59666 | init sampler, took 2.84 ms, tokens: text = 19518, total = 19518
slot update_slots: id  1 | task 59666 | erasing old context checkpoint (pos_min = 14051, pos_max = 14794, size = 17.446 MiB)
slot update_slots: id  1 | task 59666 | created context checkpoint 8 of 8 (pos_min = 18827, pos_max = 19453, size = 14.703 MiB)
slot print_timing: id  1 | task 59666 | 
prompt eval time =    1002.04 ms /   564 tokens (    1.78 ms per token,   562.85 tokens per second)
       eval time =   17918.01 ms /   643 tokens (   27.87 ms per token,    35.89 tokens per second)
      total time =   18920.05 ms /  1207 tokens
slot      release: id  1 | task 59666 | stop processing: n_tokens = 20160, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.970 (> 0.100 thold), f_keep = 0.968
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 60311 | processing task, is_child = 0
slot update_slots: id  1 | task 60311 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20124
slot update_slots: id  1 | task 60311 | n_tokens = 19518, memory_seq_rm [19518, end)
slot update_slots: id  1 | task 60311 | prompt processing progress, n_tokens = 20060, batch.n_tokens = 542, progress = 0.996820
slot update_slots: id  1 | task 60311 | n_tokens = 20060, memory_seq_rm [20060, end)
slot update_slots: id  1 | task 60311 | prompt processing progress, n_tokens = 20124, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 60311 | prompt done, n_tokens = 20124, batch.n_tokens = 64
slot init_sampler: id  1 | task 60311 | init sampler, took 3.15 ms, tokens: text = 20124, total = 20124
slot update_slots: id  1 | task 60311 | erasing old context checkpoint (pos_min = 14696, pos_max = 15267, size = 13.413 MiB)
slot update_slots: id  1 | task 60311 | created context checkpoint 8 of 8 (pos_min = 19369, pos_max = 20059, size = 16.204 MiB)
slot print_timing: id  1 | task 60311 | 
prompt eval time =    1152.84 ms /   606 tokens (    1.90 ms per token,   525.66 tokens per second)
       eval time =   17649.96 ms /   644 tokens (   27.41 ms per token,    36.49 tokens per second)
      total time =   18802.80 ms /  1250 tokens
slot      release: id  1 | task 60311 | stop processing: n_tokens = 20767, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.971 (> 0.100 thold), f_keep = 0.969
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 60957 | processing task, is_child = 0
slot update_slots: id  1 | task 60957 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20730
slot update_slots: id  1 | task 60957 | n_tokens = 20124, memory_seq_rm [20124, end)
slot update_slots: id  1 | task 60957 | prompt processing progress, n_tokens = 20666, batch.n_tokens = 542, progress = 0.996913
slot update_slots: id  1 | task 60957 | n_tokens = 20666, memory_seq_rm [20666, end)
slot update_slots: id  1 | task 60957 | prompt processing progress, n_tokens = 20730, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 60957 | prompt done, n_tokens = 20730, batch.n_tokens = 64
slot init_sampler: id  1 | task 60957 | init sampler, took 3.02 ms, tokens: text = 20730, total = 20730
slot update_slots: id  1 | task 60957 | erasing old context checkpoint (pos_min = 14696, pos_max = 15333, size = 14.961 MiB)
slot update_slots: id  1 | task 60957 | created context checkpoint 8 of 8 (pos_min = 19997, pos_max = 20665, size = 15.688 MiB)
slot print_timing: id  1 | task 60957 | 
prompt eval time =    1127.30 ms /   606 tokens (    1.86 ms per token,   537.57 tokens per second)
       eval time =   17642.86 ms /   646 tokens (   27.31 ms per token,    36.62 tokens per second)
      total time =   18770.16 ms /  1252 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 60957 | stop processing: n_tokens = 21375, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.972 (> 0.100 thold), f_keep = 0.970
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 61605 | processing task, is_child = 0
slot update_slots: id  1 | task 61605 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 21336
slot update_slots: id  1 | task 61605 | n_tokens = 20730, memory_seq_rm [20730, end)
slot update_slots: id  1 | task 61605 | prompt processing progress, n_tokens = 21272, batch.n_tokens = 542, progress = 0.997000
slot update_slots: id  1 | task 61605 | n_tokens = 21272, memory_seq_rm [21272, end)
slot update_slots: id  1 | task 61605 | prompt processing progress, n_tokens = 21336, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 61605 | prompt done, n_tokens = 21336, batch.n_tokens = 64
slot init_sampler: id  1 | task 61605 | init sampler, took 3.97 ms, tokens: text = 21336, total = 21336
slot update_slots: id  1 | task 61605 | erasing old context checkpoint (pos_min = 14696, pos_max = 15447, size = 17.634 MiB)
slot update_slots: id  1 | task 61605 | created context checkpoint 8 of 8 (pos_min = 20603, pos_max = 21271, size = 15.688 MiB)
slot print_timing: id  1 | task 61605 | 
prompt eval time =    1124.70 ms /   606 tokens (    1.86 ms per token,   538.81 tokens per second)
       eval time =   16923.50 ms /   618 tokens (   27.38 ms per token,    36.52 tokens per second)
      total time =   18048.20 ms /  1224 tokens
slot      release: id  1 | task 61605 | stop processing: n_tokens = 21953, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.973 (> 0.100 thold), f_keep = 0.972
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 62225 | processing task, is_child = 0
slot update_slots: id  1 | task 62225 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 21935
slot update_slots: id  1 | task 62225 | n_tokens = 21336, memory_seq_rm [21336, end)
slot update_slots: id  1 | task 62225 | prompt processing progress, n_tokens = 21871, batch.n_tokens = 535, progress = 0.997082
slot update_slots: id  1 | task 62225 | n_tokens = 21871, memory_seq_rm [21871, end)
slot update_slots: id  1 | task 62225 | prompt processing progress, n_tokens = 21935, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 62225 | prompt done, n_tokens = 21935, batch.n_tokens = 64
slot init_sampler: id  1 | task 62225 | init sampler, took 3.11 ms, tokens: text = 21935, total = 21935
slot update_slots: id  1 | task 62225 | erasing old context checkpoint (pos_min = 15399, pos_max = 16422, size = 24.012 MiB)
slot update_slots: id  1 | task 62225 | created context checkpoint 8 of 8 (pos_min = 21209, pos_max = 21870, size = 15.523 MiB)
slot print_timing: id  1 | task 62225 | 
prompt eval time =    1109.93 ms /   599 tokens (    1.85 ms per token,   539.67 tokens per second)
       eval time =   16798.27 ms /   611 tokens (   27.49 ms per token,    36.37 tokens per second)
      total time =   17908.20 ms /  1210 tokens
slot      release: id  1 | task 62225 | stop processing: n_tokens = 22545, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.973 (> 0.100 thold), f_keep = 0.973
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 62838 | processing task, is_child = 0
slot update_slots: id  1 | task 62838 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 22541
slot update_slots: id  1 | task 62838 | n_tokens = 21935, memory_seq_rm [21935, end)
slot update_slots: id  1 | task 62838 | prompt processing progress, n_tokens = 22477, batch.n_tokens = 542, progress = 0.997161
slot update_slots: id  1 | task 62838 | n_tokens = 22477, memory_seq_rm [22477, end)
slot update_slots: id  1 | task 62838 | prompt processing progress, n_tokens = 22541, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 62838 | prompt done, n_tokens = 22541, batch.n_tokens = 64
slot init_sampler: id  1 | task 62838 | init sampler, took 4.29 ms, tokens: text = 22541, total = 22541
slot update_slots: id  1 | task 62838 | erasing old context checkpoint (pos_min = 16465, pos_max = 17276, size = 19.041 MiB)
slot update_slots: id  1 | task 62838 | created context checkpoint 8 of 8 (pos_min = 21808, pos_max = 22476, size = 15.688 MiB)
slot print_timing: id  1 | task 62838 | 
prompt eval time =    1121.97 ms /   606 tokens (    1.85 ms per token,   540.12 tokens per second)
       eval time =   19643.12 ms /   714 tokens (   27.51 ms per token,    36.35 tokens per second)
      total time =   20765.09 ms /  1320 tokens
slot      release: id  1 | task 62838 | stop processing: n_tokens = 23254, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.974 (> 0.100 thold), f_keep = 0.969
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 63554 | processing task, is_child = 0
slot update_slots: id  1 | task 63554 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23144
slot update_slots: id  1 | task 63554 | n_past = 22541, slot.prompt.tokens.size() = 23254, seq_id = 1, pos_min = 22532, n_swa = 128
slot update_slots: id  1 | task 63554 | restored context checkpoint (pos_min = 21808, pos_max = 22476, size = 15.688 MiB)
slot update_slots: id  1 | task 63554 | n_tokens = 22476, memory_seq_rm [22476, end)
slot update_slots: id  1 | task 63554 | prompt processing progress, n_tokens = 23080, batch.n_tokens = 604, progress = 0.997235
slot update_slots: id  1 | task 63554 | n_tokens = 23080, memory_seq_rm [23080, end)
slot update_slots: id  1 | task 63554 | prompt processing progress, n_tokens = 23144, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 63554 | prompt done, n_tokens = 23144, batch.n_tokens = 64
slot init_sampler: id  1 | task 63554 | init sampler, took 4.81 ms, tokens: text = 23144, total = 23144
slot update_slots: id  1 | task 63554 | erasing old context checkpoint (pos_min = 17045, pos_max = 18068, size = 24.012 MiB)
slot update_slots: id  1 | task 63554 | created context checkpoint 8 of 8 (pos_min = 22063, pos_max = 23079, size = 23.848 MiB)
slot print_timing: id  1 | task 63554 | 
prompt eval time =    1260.48 ms /   668 tokens (    1.89 ms per token,   529.96 tokens per second)
       eval time =   33522.18 ms /  1224 tokens (   27.39 ms per token,    36.51 tokens per second)
      total time =   34782.66 ms /  1892 tokens
slot      release: id  1 | task 63554 | stop processing: n_tokens = 24367, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.974 (> 0.100 thold), f_keep = 0.950
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 64780 | processing task, is_child = 0
slot update_slots: id  1 | task 64780 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23752
slot update_slots: id  1 | task 64780 | n_past = 23144, slot.prompt.tokens.size() = 24367, seq_id = 1, pos_min = 23343, n_swa = 128
slot update_slots: id  1 | task 64780 | restored context checkpoint (pos_min = 22063, pos_max = 23079, size = 23.848 MiB)
slot update_slots: id  1 | task 64780 | n_tokens = 23079, memory_seq_rm [23079, end)
slot update_slots: id  1 | task 64780 | prompt processing progress, n_tokens = 23688, batch.n_tokens = 609, progress = 0.997306
slot update_slots: id  1 | task 64780 | n_tokens = 23688, memory_seq_rm [23688, end)
slot update_slots: id  1 | task 64780 | prompt processing progress, n_tokens = 23752, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 64780 | prompt done, n_tokens = 23752, batch.n_tokens = 64
slot init_sampler: id  1 | task 64780 | init sampler, took 3.44 ms, tokens: text = 23752, total = 23752
slot update_slots: id  1 | task 64780 | erasing old context checkpoint (pos_min = 17866, pos_max = 18889, size = 24.012 MiB)
slot update_slots: id  1 | task 64780 | created context checkpoint 8 of 8 (pos_min = 22671, pos_max = 23687, size = 23.848 MiB)
slot print_timing: id  1 | task 64780 | 
prompt eval time =    1272.07 ms /   673 tokens (    1.89 ms per token,   529.06 tokens per second)
       eval time =   18764.54 ms /   687 tokens (   27.31 ms per token,    36.61 tokens per second)
      total time =   20036.60 ms /  1360 tokens
slot      release: id  1 | task 64780 | stop processing: n_tokens = 24438, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.975 (> 0.100 thold), f_keep = 0.972
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 65469 | processing task, is_child = 0
slot update_slots: id  1 | task 65469 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 24360
slot update_slots: id  1 | task 65469 | n_tokens = 23752, memory_seq_rm [23752, end)
slot update_slots: id  1 | task 65469 | prompt processing progress, n_tokens = 24296, batch.n_tokens = 544, progress = 0.997373
slot update_slots: id  1 | task 65469 | n_tokens = 24296, memory_seq_rm [24296, end)
slot update_slots: id  1 | task 65469 | prompt processing progress, n_tokens = 24360, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 65469 | prompt done, n_tokens = 24360, batch.n_tokens = 64
slot init_sampler: id  1 | task 65469 | init sampler, took 3.50 ms, tokens: text = 24360, total = 24360
slot update_slots: id  1 | task 65469 | erasing old context checkpoint (pos_min = 18827, pos_max = 19453, size = 14.703 MiB)
slot update_slots: id  1 | task 65469 | created context checkpoint 8 of 8 (pos_min = 23496, pos_max = 24295, size = 18.759 MiB)
slot print_timing: id  1 | task 65469 | 
prompt eval time =    1143.31 ms /   608 tokens (    1.88 ms per token,   531.79 tokens per second)
       eval time =   19586.83 ms /   711 tokens (   27.55 ms per token,    36.30 tokens per second)
      total time =   20730.15 ms /  1319 tokens
slot      release: id  1 | task 65469 | stop processing: n_tokens = 25070, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.976 (> 0.100 thold), f_keep = 0.972
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 66182 | processing task, is_child = 0
slot update_slots: id  1 | task 66182 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 24968
slot update_slots: id  1 | task 66182 | n_tokens = 24360, memory_seq_rm [24360, end)
slot update_slots: id  1 | task 66182 | prompt processing progress, n_tokens = 24904, batch.n_tokens = 544, progress = 0.997437
slot update_slots: id  1 | task 66182 | n_tokens = 24904, memory_seq_rm [24904, end)
slot update_slots: id  1 | task 66182 | prompt processing progress, n_tokens = 24968, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 66182 | prompt done, n_tokens = 24968, batch.n_tokens = 64
slot init_sampler: id  1 | task 66182 | init sampler, took 3.54 ms, tokens: text = 24968, total = 24968
slot update_slots: id  1 | task 66182 | erasing old context checkpoint (pos_min = 19369, pos_max = 20059, size = 16.204 MiB)
slot update_slots: id  1 | task 66182 | created context checkpoint 8 of 8 (pos_min = 24233, pos_max = 24903, size = 15.735 MiB)
slot print_timing: id  1 | task 66182 | 
prompt eval time =    1137.86 ms /   608 tokens (    1.87 ms per token,   534.33 tokens per second)
       eval time =   19637.74 ms /   717 tokens (   27.39 ms per token,    36.51 tokens per second)
      total time =   20775.60 ms /  1325 tokens
slot      release: id  1 | task 66182 | stop processing: n_tokens = 25684, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.976 (> 0.100 thold), f_keep = 0.972
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 66901 | processing task, is_child = 0
slot update_slots: id  1 | task 66901 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 25576
slot update_slots: id  1 | task 66901 | n_tokens = 24968, memory_seq_rm [24968, end)
slot update_slots: id  1 | task 66901 | prompt processing progress, n_tokens = 25512, batch.n_tokens = 544, progress = 0.997498
slot update_slots: id  1 | task 66901 | n_tokens = 25512, memory_seq_rm [25512, end)
slot update_slots: id  1 | task 66901 | prompt processing progress, n_tokens = 25576, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 66901 | prompt done, n_tokens = 25576, batch.n_tokens = 64
slot init_sampler: id  1 | task 66901 | init sampler, took 3.64 ms, tokens: text = 25576, total = 25576
slot update_slots: id  1 | task 66901 | erasing old context checkpoint (pos_min = 19997, pos_max = 20665, size = 15.688 MiB)
slot update_slots: id  1 | task 66901 | created context checkpoint 8 of 8 (pos_min = 24841, pos_max = 25511, size = 15.735 MiB)
slot print_timing: id  1 | task 66901 | 
prompt eval time =    1131.49 ms /   608 tokens (    1.86 ms per token,   537.34 tokens per second)
       eval time =   38884.01 ms /  1407 tokens (   27.64 ms per token,    36.18 tokens per second)
      total time =   40015.50 ms /  2015 tokens
slot      release: id  1 | task 66901 | stop processing: n_tokens = 26982, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.950 (> 0.100 thold), f_keep = 0.948
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 68310 | processing task, is_child = 0
slot update_slots: id  1 | task 68310 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 26911
slot update_slots: id  1 | task 68310 | n_past = 25576, slot.prompt.tokens.size() = 26982, seq_id = 1, pos_min = 25958, n_swa = 128
slot update_slots: id  1 | task 68310 | restored context checkpoint (pos_min = 24841, pos_max = 25511, size = 15.735 MiB)
slot update_slots: id  1 | task 68310 | n_tokens = 25511, memory_seq_rm [25511, end)
slot update_slots: id  1 | task 68310 | prompt processing progress, n_tokens = 26847, batch.n_tokens = 1336, progress = 0.997622
slot update_slots: id  1 | task 68310 | n_tokens = 26847, memory_seq_rm [26847, end)
slot update_slots: id  1 | task 68310 | prompt processing progress, n_tokens = 26911, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 68310 | prompt done, n_tokens = 26911, batch.n_tokens = 64
slot init_sampler: id  1 | task 68310 | init sampler, took 3.79 ms, tokens: text = 26911, total = 26911
slot update_slots: id  1 | task 68310 | erasing old context checkpoint (pos_min = 20603, pos_max = 21271, size = 15.688 MiB)
slot update_slots: id  1 | task 68310 | created context checkpoint 8 of 8 (pos_min = 25823, pos_max = 26846, size = 24.012 MiB)
slot print_timing: id  1 | task 68310 | 
prompt eval time =    2199.13 ms /  1400 tokens (    1.57 ms per token,   636.62 tokens per second)
       eval time =    7366.94 ms /   267 tokens (   27.59 ms per token,    36.24 tokens per second)
      total time =    9566.07 ms /  1667 tokens
slot      release: id  1 | task 68310 | stop processing: n_tokens = 27177, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.990
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 68579 | processing task, is_child = 0
slot update_slots: id  1 | task 68579 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 27003
slot update_slots: id  1 | task 68579 | n_tokens = 26911, memory_seq_rm [26911, end)
slot update_slots: id  1 | task 68579 | prompt processing progress, n_tokens = 26939, batch.n_tokens = 28, progress = 0.997630
slot update_slots: id  1 | task 68579 | n_tokens = 26939, memory_seq_rm [26939, end)
slot update_slots: id  1 | task 68579 | prompt processing progress, n_tokens = 27003, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 68579 | prompt done, n_tokens = 27003, batch.n_tokens = 64
slot init_sampler: id  1 | task 68579 | init sampler, took 5.64 ms, tokens: text = 27003, total = 27003
slot update_slots: id  1 | task 68579 | erasing old context checkpoint (pos_min = 21209, pos_max = 21870, size = 15.523 MiB)
slot update_slots: id  1 | task 68579 | created context checkpoint 8 of 8 (pos_min = 26153, pos_max = 26938, size = 18.431 MiB)
slot print_timing: id  1 | task 68579 | 
prompt eval time =     355.07 ms /    92 tokens (    3.86 ms per token,   259.11 tokens per second)
       eval time =   16446.51 ms /   597 tokens (   27.55 ms per token,    36.30 tokens per second)
      total time =   16801.57 ms /   689 tokens
slot      release: id  1 | task 68579 | stop processing: n_tokens = 27599, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.978 (> 0.100 thold), f_keep = 0.978
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 69178 | processing task, is_child = 0
slot update_slots: id  1 | task 69178 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 27611
slot update_slots: id  1 | task 69178 | n_tokens = 27003, memory_seq_rm [27003, end)
slot update_slots: id  1 | task 69178 | prompt processing progress, n_tokens = 27547, batch.n_tokens = 544, progress = 0.997682
slot update_slots: id  1 | task 69178 | n_tokens = 27547, memory_seq_rm [27547, end)
slot update_slots: id  1 | task 69178 | prompt processing progress, n_tokens = 27611, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 69178 | prompt done, n_tokens = 27611, batch.n_tokens = 64
slot init_sampler: id  1 | task 69178 | init sampler, took 3.86 ms, tokens: text = 27611, total = 27611
slot update_slots: id  1 | task 69178 | erasing old context checkpoint (pos_min = 21808, pos_max = 22476, size = 15.688 MiB)
slot update_slots: id  1 | task 69178 | created context checkpoint 8 of 8 (pos_min = 26680, pos_max = 27546, size = 20.331 MiB)
slot print_timing: id  1 | task 69178 | 
prompt eval time =    1128.98 ms /   608 tokens (    1.86 ms per token,   538.54 tokens per second)
       eval time =   18403.53 ms /   672 tokens (   27.39 ms per token,    36.51 tokens per second)
      total time =   19532.51 ms /  1280 tokens
slot      release: id  1 | task 69178 | stop processing: n_tokens = 28282, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.978 (> 0.100 thold), f_keep = 0.976
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 69852 | processing task, is_child = 0
slot update_slots: id  1 | task 69852 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 28219
slot update_slots: id  1 | task 69852 | n_tokens = 27611, memory_seq_rm [27611, end)
slot update_slots: id  1 | task 69852 | prompt processing progress, n_tokens = 28155, batch.n_tokens = 544, progress = 0.997732
slot update_slots: id  1 | task 69852 | n_tokens = 28155, memory_seq_rm [28155, end)
slot update_slots: id  1 | task 69852 | prompt processing progress, n_tokens = 28219, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 69852 | prompt done, n_tokens = 28219, batch.n_tokens = 64
slot init_sampler: id  1 | task 69852 | init sampler, took 3.99 ms, tokens: text = 28219, total = 28219
slot update_slots: id  1 | task 69852 | erasing old context checkpoint (pos_min = 22063, pos_max = 23079, size = 23.848 MiB)
slot update_slots: id  1 | task 69852 | created context checkpoint 8 of 8 (pos_min = 27455, pos_max = 28154, size = 16.415 MiB)
slot print_timing: id  1 | task 69852 | 
prompt eval time =    1123.08 ms /   608 tokens (    1.85 ms per token,   541.37 tokens per second)
       eval time =   15728.57 ms /   574 tokens (   27.40 ms per token,    36.49 tokens per second)
      total time =   16851.65 ms /  1182 tokens
slot      release: id  1 | task 69852 | stop processing: n_tokens = 28792, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.982 (> 0.100 thold), f_keep = 0.980
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 70428 | processing task, is_child = 0
slot update_slots: id  1 | task 70428 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 28729
slot update_slots: id  1 | task 70428 | n_tokens = 28219, memory_seq_rm [28219, end)
slot update_slots: id  1 | task 70428 | prompt processing progress, n_tokens = 28665, batch.n_tokens = 446, progress = 0.997772
slot update_slots: id  1 | task 70428 | n_tokens = 28665, memory_seq_rm [28665, end)
slot update_slots: id  1 | task 70428 | prompt processing progress, n_tokens = 28729, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 70428 | prompt done, n_tokens = 28729, batch.n_tokens = 64
slot init_sampler: id  1 | task 70428 | init sampler, took 4.01 ms, tokens: text = 28729, total = 28729
slot update_slots: id  1 | task 70428 | erasing old context checkpoint (pos_min = 22671, pos_max = 23687, size = 23.848 MiB)
slot update_slots: id  1 | task 70428 | created context checkpoint 8 of 8 (pos_min = 28057, pos_max = 28664, size = 14.257 MiB)
slot print_timing: id  1 | task 70428 | 
prompt eval time =     872.77 ms /   510 tokens (    1.71 ms per token,   584.35 tokens per second)
       eval time =   15550.65 ms /   566 tokens (   27.47 ms per token,    36.40 tokens per second)
      total time =   16423.42 ms /  1076 tokens
slot      release: id  1 | task 70428 | stop processing: n_tokens = 29294, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.981 (> 0.100 thold), f_keep = 0.981
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 70996 | processing task, is_child = 0
slot update_slots: id  1 | task 70996 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 29285
slot update_slots: id  1 | task 70996 | n_tokens = 28729, memory_seq_rm [28729, end)
slot update_slots: id  1 | task 70996 | prompt processing progress, n_tokens = 29221, batch.n_tokens = 492, progress = 0.997815
slot update_slots: id  1 | task 70996 | n_tokens = 29221, memory_seq_rm [29221, end)
slot update_slots: id  1 | task 70996 | prompt processing progress, n_tokens = 29285, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 70996 | prompt done, n_tokens = 29285, batch.n_tokens = 64
slot init_sampler: id  1 | task 70996 | init sampler, took 5.81 ms, tokens: text = 29285, total = 29285
slot update_slots: id  1 | task 70996 | erasing old context checkpoint (pos_min = 23496, pos_max = 24295, size = 18.759 MiB)
slot update_slots: id  1 | task 70996 | created context checkpoint 8 of 8 (pos_min = 28602, pos_max = 29220, size = 14.515 MiB)
slot print_timing: id  1 | task 70996 | 
prompt eval time =     974.74 ms /   556 tokens (    1.75 ms per token,   570.41 tokens per second)
       eval time =   18406.58 ms /   668 tokens (   27.55 ms per token,    36.29 tokens per second)
      total time =   19381.32 ms /  1224 tokens
slot      release: id  1 | task 70996 | stop processing: n_tokens = 29952, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.643 (> 0.100 thold), f_keep = 0.625
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 71666 | processing task, is_child = 0
slot update_slots: id  1 | task 71666 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 29111
slot update_slots: id  1 | task 71666 | n_past = 18719, slot.prompt.tokens.size() = 29952, seq_id = 1, pos_min = 29055, n_swa = 128
slot update_slots: id  1 | task 71666 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  1 | task 71666 | erased invalidated context checkpoint (pos_min = 24233, pos_max = 24903, n_swa = 128, size = 15.735 MiB)
slot update_slots: id  1 | task 71666 | erased invalidated context checkpoint (pos_min = 24841, pos_max = 25511, n_swa = 128, size = 15.735 MiB)
slot update_slots: id  1 | task 71666 | erased invalidated context checkpoint (pos_min = 25823, pos_max = 26846, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  1 | task 71666 | erased invalidated context checkpoint (pos_min = 26153, pos_max = 26938, n_swa = 128, size = 18.431 MiB)
slot update_slots: id  1 | task 71666 | erased invalidated context checkpoint (pos_min = 26680, pos_max = 27546, n_swa = 128, size = 20.331 MiB)
slot update_slots: id  1 | task 71666 | erased invalidated context checkpoint (pos_min = 27455, pos_max = 28154, n_swa = 128, size = 16.415 MiB)
slot update_slots: id  1 | task 71666 | erased invalidated context checkpoint (pos_min = 28057, pos_max = 28664, n_swa = 128, size = 14.257 MiB)
slot update_slots: id  1 | task 71666 | erased invalidated context checkpoint (pos_min = 28602, pos_max = 29220, n_swa = 128, size = 14.515 MiB)
slot update_slots: id  1 | task 71666 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  1 | task 71666 | prompt processing progress, n_tokens = 2048, batch.n_tokens = 2048, progress = 0.070351
slot update_slots: id  1 | task 71666 | n_tokens = 2048, memory_seq_rm [2048, end)
slot update_slots: id  1 | task 71666 | prompt processing progress, n_tokens = 4096, batch.n_tokens = 2048, progress = 0.140703
slot update_slots: id  1 | task 71666 | n_tokens = 4096, memory_seq_rm [4096, end)
slot update_slots: id  1 | task 71666 | prompt processing progress, n_tokens = 6144, batch.n_tokens = 2048, progress = 0.211054
slot update_slots: id  1 | task 71666 | n_tokens = 6144, memory_seq_rm [6144, end)
slot update_slots: id  1 | task 71666 | prompt processing progress, n_tokens = 8192, batch.n_tokens = 2048, progress = 0.281406
slot update_slots: id  1 | task 71666 | n_tokens = 8192, memory_seq_rm [8192, end)
slot update_slots: id  1 | task 71666 | prompt processing progress, n_tokens = 10240, batch.n_tokens = 2048, progress = 0.351757
slot update_slots: id  1 | task 71666 | n_tokens = 10240, memory_seq_rm [10240, end)
slot update_slots: id  1 | task 71666 | prompt processing progress, n_tokens = 12288, batch.n_tokens = 2048, progress = 0.422108
slot update_slots: id  1 | task 71666 | n_tokens = 12288, memory_seq_rm [12288, end)
slot update_slots: id  1 | task 71666 | prompt processing progress, n_tokens = 14336, batch.n_tokens = 2048, progress = 0.492460
slot update_slots: id  1 | task 71666 | n_tokens = 14336, memory_seq_rm [14336, end)
slot update_slots: id  1 | task 71666 | prompt processing progress, n_tokens = 16384, batch.n_tokens = 2048, progress = 0.562811
slot update_slots: id  1 | task 71666 | n_tokens = 16384, memory_seq_rm [16384, end)
slot update_slots: id  1 | task 71666 | prompt processing progress, n_tokens = 18432, batch.n_tokens = 2048, progress = 0.633163
slot update_slots: id  1 | task 71666 | n_tokens = 18432, memory_seq_rm [18432, end)
slot update_slots: id  1 | task 71666 | prompt processing progress, n_tokens = 20480, batch.n_tokens = 2048, progress = 0.703514
slot update_slots: id  1 | task 71666 | n_tokens = 20480, memory_seq_rm [20480, end)
slot update_slots: id  1 | task 71666 | prompt processing progress, n_tokens = 22528, batch.n_tokens = 2048, progress = 0.773866
slot update_slots: id  1 | task 71666 | n_tokens = 22528, memory_seq_rm [22528, end)
slot update_slots: id  1 | task 71666 | prompt processing progress, n_tokens = 24576, batch.n_tokens = 2048, progress = 0.844217
slot update_slots: id  1 | task 71666 | n_tokens = 24576, memory_seq_rm [24576, end)
slot update_slots: id  1 | task 71666 | prompt processing progress, n_tokens = 26624, batch.n_tokens = 2048, progress = 0.914568
slot update_slots: id  1 | task 71666 | n_tokens = 26624, memory_seq_rm [26624, end)
slot update_slots: id  1 | task 71666 | prompt processing progress, n_tokens = 28672, batch.n_tokens = 2048, progress = 0.984920
slot update_slots: id  1 | task 71666 | n_tokens = 28672, memory_seq_rm [28672, end)
slot update_slots: id  1 | task 71666 | prompt processing progress, n_tokens = 29047, batch.n_tokens = 375, progress = 0.997802
slot update_slots: id  1 | task 71666 | n_tokens = 29047, memory_seq_rm [29047, end)
slot update_slots: id  1 | task 71666 | prompt processing progress, n_tokens = 29111, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 71666 | prompt done, n_tokens = 29111, batch.n_tokens = 64
slot init_sampler: id  1 | task 71666 | init sampler, took 4.16 ms, tokens: text = 29111, total = 29111
slot update_slots: id  1 | task 71666 | created context checkpoint 1 of 8 (pos_min = 28023, pos_max = 29046, size = 24.012 MiB)
slot print_timing: id  1 | task 71666 | 
prompt eval time =   33015.20 ms / 29111 tokens (    1.13 ms per token,   881.75 tokens per second)
       eval time =    1107.07 ms /    41 tokens (   27.00 ms per token,    37.03 tokens per second)
      total time =   34122.27 ms / 29152 tokens
slot      release: id  1 | task 71666 | stop processing: n_tokens = 29151, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 71723 | processing task, is_child = 0
slot update_slots: id  1 | task 71723 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 29213
slot update_slots: id  1 | task 71723 | n_tokens = 29111, memory_seq_rm [29111, end)
slot update_slots: id  1 | task 71723 | prompt processing progress, n_tokens = 29149, batch.n_tokens = 38, progress = 0.997809
slot update_slots: id  1 | task 71723 | n_tokens = 29149, memory_seq_rm [29149, end)
slot update_slots: id  1 | task 71723 | prompt processing progress, n_tokens = 29213, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 71723 | prompt done, n_tokens = 29213, batch.n_tokens = 64
slot init_sampler: id  1 | task 71723 | init sampler, took 4.12 ms, tokens: text = 29213, total = 29213
slot update_slots: id  1 | task 71723 | created context checkpoint 2 of 8 (pos_min = 28127, pos_max = 29148, size = 23.965 MiB)
slot print_timing: id  1 | task 71723 | 
prompt eval time =     354.88 ms /   102 tokens (    3.48 ms per token,   287.42 tokens per second)
       eval time =    5386.65 ms /   195 tokens (   27.62 ms per token,    36.20 tokens per second)
      total time =    5741.53 ms /   297 tokens
slot      release: id  1 | task 71723 | stop processing: n_tokens = 29407, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.981 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 71920 | processing task, is_child = 0
slot update_slots: id  1 | task 71920 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 29776
slot update_slots: id  1 | task 71920 | n_tokens = 29213, memory_seq_rm [29213, end)
slot update_slots: id  1 | task 71920 | prompt processing progress, n_tokens = 29712, batch.n_tokens = 499, progress = 0.997851
slot update_slots: id  1 | task 71920 | n_tokens = 29712, memory_seq_rm [29712, end)
slot update_slots: id  1 | task 71920 | prompt processing progress, n_tokens = 29776, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 71920 | prompt done, n_tokens = 29776, batch.n_tokens = 64
slot init_sampler: id  1 | task 71920 | init sampler, took 4.17 ms, tokens: text = 29776, total = 29776
slot update_slots: id  1 | task 71920 | created context checkpoint 3 of 8 (pos_min = 28688, pos_max = 29711, size = 24.012 MiB)
slot print_timing: id  1 | task 71920 | 
prompt eval time =     924.44 ms /   563 tokens (    1.64 ms per token,   609.02 tokens per second)
       eval time =   17689.85 ms /   652 tokens (   27.13 ms per token,    36.86 tokens per second)
      total time =   18614.28 ms /  1215 tokens
slot      release: id  1 | task 71920 | stop processing: n_tokens = 30427, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.967 (> 0.100 thold), f_keep = 0.949
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 72574 | processing task, is_child = 0
slot update_slots: id  1 | task 72574 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 29869
slot update_slots: id  1 | task 72574 | n_past = 28874, slot.prompt.tokens.size() = 30427, seq_id = 1, pos_min = 29403, n_swa = 128
slot update_slots: id  1 | task 72574 | restored context checkpoint (pos_min = 28688, pos_max = 29711, size = 24.012 MiB)
slot update_slots: id  1 | task 72574 | n_tokens = 28874, memory_seq_rm [28874, end)
slot update_slots: id  1 | task 72574 | prompt processing progress, n_tokens = 29805, batch.n_tokens = 931, progress = 0.997857
slot update_slots: id  1 | task 72574 | n_tokens = 29805, memory_seq_rm [29805, end)
slot update_slots: id  1 | task 72574 | prompt processing progress, n_tokens = 29869, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 72574 | prompt done, n_tokens = 29869, batch.n_tokens = 64
slot init_sampler: id  1 | task 72574 | init sampler, took 4.50 ms, tokens: text = 29869, total = 29869
slot update_slots: id  1 | task 72574 | created context checkpoint 4 of 8 (pos_min = 28908, pos_max = 29804, size = 21.034 MiB)
slot print_timing: id  1 | task 72574 | 
prompt eval time =    1536.77 ms /   995 tokens (    1.54 ms per token,   647.46 tokens per second)
       eval time =   18380.78 ms /   686 tokens (   26.79 ms per token,    37.32 tokens per second)
      total time =   19917.56 ms /  1681 tokens
slot      release: id  1 | task 72574 | stop processing: n_tokens = 30554, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.978 (> 0.100 thold), f_keep = 0.970
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 73262 | processing task, is_child = 0
slot update_slots: id  1 | task 73262 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 30292
slot update_slots: id  1 | task 73262 | n_past = 29632, slot.prompt.tokens.size() = 30554, seq_id = 1, pos_min = 29530, n_swa = 128
slot update_slots: id  1 | task 73262 | restored context checkpoint (pos_min = 28908, pos_max = 29804, size = 21.034 MiB)
slot update_slots: id  1 | task 73262 | n_tokens = 29632, memory_seq_rm [29632, end)
slot update_slots: id  1 | task 73262 | prompt processing progress, n_tokens = 30228, batch.n_tokens = 596, progress = 0.997887
slot update_slots: id  1 | task 73262 | n_tokens = 30228, memory_seq_rm [30228, end)
slot update_slots: id  1 | task 73262 | prompt processing progress, n_tokens = 30292, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 73262 | prompt done, n_tokens = 30292, batch.n_tokens = 64
slot init_sampler: id  1 | task 73262 | init sampler, took 4.22 ms, tokens: text = 30292, total = 30292
slot update_slots: id  1 | task 73262 | created context checkpoint 5 of 8 (pos_min = 29470, pos_max = 30227, size = 17.775 MiB)
slot print_timing: id  1 | task 73262 | 
prompt eval time =    1315.54 ms /   660 tokens (    1.99 ms per token,   501.70 tokens per second)
       eval time =    2287.27 ms /    86 tokens (   26.60 ms per token,    37.60 tokens per second)
      total time =    3602.81 ms /   746 tokens
slot      release: id  1 | task 73262 | stop processing: n_tokens = 30377, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 73350 | processing task, is_child = 0
slot update_slots: id  1 | task 73350 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 30394
slot update_slots: id  1 | task 73350 | n_tokens = 30292, memory_seq_rm [30292, end)
slot update_slots: id  1 | task 73350 | prompt processing progress, n_tokens = 30330, batch.n_tokens = 38, progress = 0.997894
slot update_slots: id  1 | task 73350 | n_tokens = 30330, memory_seq_rm [30330, end)
slot update_slots: id  1 | task 73350 | prompt processing progress, n_tokens = 30394, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 73350 | prompt done, n_tokens = 30394, batch.n_tokens = 64
slot init_sampler: id  1 | task 73350 | init sampler, took 4.34 ms, tokens: text = 30394, total = 30394
slot update_slots: id  1 | task 73350 | created context checkpoint 6 of 8 (pos_min = 29619, pos_max = 30329, size = 16.672 MiB)
slot print_timing: id  1 | task 73350 | 
prompt eval time =     359.51 ms /   102 tokens (    3.52 ms per token,   283.72 tokens per second)
       eval time =    5413.27 ms /   200 tokens (   27.07 ms per token,    36.95 tokens per second)
      total time =    5772.78 ms /   302 tokens
slot      release: id  1 | task 73350 | stop processing: n_tokens = 30593, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 73552 | processing task, is_child = 0
slot update_slots: id  1 | task 73552 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 30564
slot update_slots: id  1 | task 73552 | n_tokens = 30394, memory_seq_rm [30394, end)
slot update_slots: id  1 | task 73552 | prompt processing progress, n_tokens = 30500, batch.n_tokens = 106, progress = 0.997906
slot update_slots: id  1 | task 73552 | n_tokens = 30500, memory_seq_rm [30500, end)
slot update_slots: id  1 | task 73552 | prompt processing progress, n_tokens = 30564, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 73552 | prompt done, n_tokens = 30564, batch.n_tokens = 64
slot init_sampler: id  1 | task 73552 | init sampler, took 6.11 ms, tokens: text = 30564, total = 30564
slot update_slots: id  1 | task 73552 | created context checkpoint 7 of 8 (pos_min = 29632, pos_max = 30499, size = 20.354 MiB)
slot print_timing: id  1 | task 73552 | 
prompt eval time =     526.88 ms /   170 tokens (    3.10 ms per token,   322.65 tokens per second)
       eval time =    2327.89 ms /    86 tokens (   27.07 ms per token,    36.94 tokens per second)
      total time =    2854.77 ms /   256 tokens
slot      release: id  1 | task 73552 | stop processing: n_tokens = 30649, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 73640 | processing task, is_child = 0
slot update_slots: id  1 | task 73640 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 30666
slot update_slots: id  1 | task 73640 | n_tokens = 30564, memory_seq_rm [30564, end)
slot update_slots: id  1 | task 73640 | prompt processing progress, n_tokens = 30602, batch.n_tokens = 38, progress = 0.997913
slot update_slots: id  1 | task 73640 | n_tokens = 30602, memory_seq_rm [30602, end)
slot update_slots: id  1 | task 73640 | prompt processing progress, n_tokens = 30666, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 73640 | prompt done, n_tokens = 30666, batch.n_tokens = 64
slot init_sampler: id  1 | task 73640 | init sampler, took 4.29 ms, tokens: text = 30666, total = 30666
slot update_slots: id  1 | task 73640 | created context checkpoint 8 of 8 (pos_min = 29632, pos_max = 30601, size = 22.746 MiB)
slot print_timing: id  1 | task 73640 | 
prompt eval time =     365.32 ms /   102 tokens (    3.58 ms per token,   279.21 tokens per second)
       eval time =    1486.96 ms /    55 tokens (   27.04 ms per token,    36.99 tokens per second)
      total time =    1852.28 ms /   157 tokens
slot      release: id  1 | task 73640 | stop processing: n_tokens = 30720, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.982 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 73697 | processing task, is_child = 0
slot update_slots: id  1 | task 73697 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 31229
slot update_slots: id  1 | task 73697 | n_tokens = 30666, memory_seq_rm [30666, end)
slot update_slots: id  1 | task 73697 | prompt processing progress, n_tokens = 31165, batch.n_tokens = 499, progress = 0.997951
slot update_slots: id  1 | task 73697 | n_tokens = 31165, memory_seq_rm [31165, end)
slot update_slots: id  1 | task 73697 | prompt processing progress, n_tokens = 31229, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 73697 | prompt done, n_tokens = 31229, batch.n_tokens = 64
slot init_sampler: id  1 | task 73697 | init sampler, took 4.53 ms, tokens: text = 31229, total = 31229
slot update_slots: id  1 | task 73697 | erasing old context checkpoint (pos_min = 28023, pos_max = 29046, size = 24.012 MiB)
slot update_slots: id  1 | task 73697 | created context checkpoint 8 of 8 (pos_min = 30141, pos_max = 31164, size = 24.012 MiB)
slot print_timing: id  1 | task 73697 | 
prompt eval time =     938.40 ms /   563 tokens (    1.67 ms per token,   599.96 tokens per second)
       eval time =    3291.19 ms /   121 tokens (   27.20 ms per token,    36.76 tokens per second)
      total time =    4229.59 ms /   684 tokens
slot      release: id  1 | task 73697 | stop processing: n_tokens = 31349, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 73820 | processing task, is_child = 0
slot update_slots: id  1 | task 73820 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 31331
slot update_slots: id  1 | task 73820 | n_tokens = 31229, memory_seq_rm [31229, end)
slot update_slots: id  1 | task 73820 | prompt processing progress, n_tokens = 31267, batch.n_tokens = 38, progress = 0.997957
slot update_slots: id  1 | task 73820 | n_tokens = 31267, memory_seq_rm [31267, end)
slot update_slots: id  1 | task 73820 | prompt processing progress, n_tokens = 31331, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 73820 | prompt done, n_tokens = 31331, batch.n_tokens = 64
slot init_sampler: id  1 | task 73820 | init sampler, took 6.10 ms, tokens: text = 31331, total = 31331
slot update_slots: id  1 | task 73820 | erasing old context checkpoint (pos_min = 28127, pos_max = 29148, size = 23.965 MiB)
slot update_slots: id  1 | task 73820 | created context checkpoint 8 of 8 (pos_min = 30325, pos_max = 31266, size = 22.089 MiB)
slot print_timing: id  1 | task 73820 | 
prompt eval time =     374.95 ms /   102 tokens (    3.68 ms per token,   272.03 tokens per second)
       eval time =    1168.28 ms /    41 tokens (   28.49 ms per token,    35.09 tokens per second)
      total time =    1543.23 ms /   143 tokens
slot      release: id  1 | task 73820 | stop processing: n_tokens = 31371, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 73863 | processing task, is_child = 0
slot update_slots: id  1 | task 73863 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 31433
slot update_slots: id  1 | task 73863 | n_tokens = 31331, memory_seq_rm [31331, end)
slot update_slots: id  1 | task 73863 | prompt processing progress, n_tokens = 31369, batch.n_tokens = 38, progress = 0.997964
slot update_slots: id  1 | task 73863 | n_tokens = 31369, memory_seq_rm [31369, end)
slot update_slots: id  1 | task 73863 | prompt processing progress, n_tokens = 31433, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 73863 | prompt done, n_tokens = 31433, batch.n_tokens = 64
slot init_sampler: id  1 | task 73863 | init sampler, took 6.51 ms, tokens: text = 31433, total = 31433
slot update_slots: id  1 | task 73863 | erasing old context checkpoint (pos_min = 28688, pos_max = 29711, size = 24.012 MiB)
slot update_slots: id  1 | task 73863 | created context checkpoint 8 of 8 (pos_min = 30347, pos_max = 31368, size = 23.965 MiB)
slot print_timing: id  1 | task 73863 | 
prompt eval time =     453.64 ms /   102 tokens (    4.45 ms per token,   224.85 tokens per second)
       eval time =    3413.75 ms /   124 tokens (   27.53 ms per token,    36.32 tokens per second)
      total time =    3867.38 ms /   226 tokens
slot      release: id  1 | task 73863 | stop processing: n_tokens = 31556, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 73989 | processing task, is_child = 0
slot update_slots: id  1 | task 73989 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 31515
slot update_slots: id  1 | task 73989 | n_tokens = 31433, memory_seq_rm [31433, end)
slot update_slots: id  1 | task 73989 | prompt processing progress, n_tokens = 31451, batch.n_tokens = 18, progress = 0.997969
slot update_slots: id  1 | task 73989 | n_tokens = 31451, memory_seq_rm [31451, end)
slot update_slots: id  1 | task 73989 | prompt processing progress, n_tokens = 31515, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 73989 | prompt done, n_tokens = 31515, batch.n_tokens = 64
slot init_sampler: id  1 | task 73989 | init sampler, took 4.33 ms, tokens: text = 31515, total = 31515
slot update_slots: id  1 | task 73989 | erasing old context checkpoint (pos_min = 28908, pos_max = 29804, size = 21.034 MiB)
slot update_slots: id  1 | task 73989 | created context checkpoint 8 of 8 (pos_min = 30532, pos_max = 31450, size = 21.550 MiB)
slot print_timing: id  1 | task 73989 | 
prompt eval time =     325.54 ms /    82 tokens (    3.97 ms per token,   251.89 tokens per second)
       eval time =    4151.52 ms /   152 tokens (   27.31 ms per token,    36.61 tokens per second)
      total time =    4477.07 ms /   234 tokens
slot      release: id  1 | task 73989 | stop processing: n_tokens = 31666, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.977 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 74143 | processing task, is_child = 0
slot update_slots: id  1 | task 74143 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32273
slot update_slots: id  1 | task 74143 | n_tokens = 31515, memory_seq_rm [31515, end)
slot update_slots: id  1 | task 74143 | prompt processing progress, n_tokens = 32209, batch.n_tokens = 694, progress = 0.998017
slot update_slots: id  1 | task 74143 | n_tokens = 32209, memory_seq_rm [32209, end)
slot update_slots: id  1 | task 74143 | prompt processing progress, n_tokens = 32273, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 74143 | prompt done, n_tokens = 32273, batch.n_tokens = 64
slot init_sampler: id  1 | task 74143 | init sampler, took 4.58 ms, tokens: text = 32273, total = 32273
slot update_slots: id  1 | task 74143 | erasing old context checkpoint (pos_min = 29470, pos_max = 30227, size = 17.775 MiB)
slot update_slots: id  1 | task 74143 | created context checkpoint 8 of 8 (pos_min = 31185, pos_max = 32208, size = 24.012 MiB)
slot print_timing: id  1 | task 74143 | 
prompt eval time =    1294.94 ms /   758 tokens (    1.71 ms per token,   585.35 tokens per second)
       eval time =    3137.49 ms /   114 tokens (   27.52 ms per token,    36.33 tokens per second)
      total time =    4432.43 ms /   872 tokens
slot      release: id  1 | task 74143 | stop processing: n_tokens = 32386, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 74259 | processing task, is_child = 0
slot update_slots: id  1 | task 74259 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32383
slot update_slots: id  1 | task 74259 | n_tokens = 32273, memory_seq_rm [32273, end)
slot update_slots: id  1 | task 74259 | prompt processing progress, n_tokens = 32319, batch.n_tokens = 46, progress = 0.998024
slot update_slots: id  1 | task 74259 | n_tokens = 32319, memory_seq_rm [32319, end)
slot update_slots: id  1 | task 74259 | prompt processing progress, n_tokens = 32383, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 74259 | prompt done, n_tokens = 32383, batch.n_tokens = 64
slot init_sampler: id  1 | task 74259 | init sampler, took 5.22 ms, tokens: text = 32383, total = 32383
slot update_slots: id  1 | task 74259 | erasing old context checkpoint (pos_min = 29619, pos_max = 30329, size = 16.672 MiB)
slot update_slots: id  1 | task 74259 | created context checkpoint 8 of 8 (pos_min = 31362, pos_max = 32318, size = 22.441 MiB)
slot print_timing: id  1 | task 74259 | 
prompt eval time =     384.01 ms /   110 tokens (    3.49 ms per token,   286.45 tokens per second)
       eval time =    1378.46 ms /    51 tokens (   27.03 ms per token,    37.00 tokens per second)
      total time =    1762.47 ms /   161 tokens
slot      release: id  1 | task 74259 | stop processing: n_tokens = 32433, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 74312 | processing task, is_child = 0
slot update_slots: id  1 | task 74312 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32497
slot update_slots: id  1 | task 74312 | n_tokens = 32383, memory_seq_rm [32383, end)
slot update_slots: id  1 | task 74312 | prompt processing progress, n_tokens = 32433, batch.n_tokens = 50, progress = 0.998031
slot update_slots: id  1 | task 74312 | n_tokens = 32433, memory_seq_rm [32433, end)
slot update_slots: id  1 | task 74312 | prompt processing progress, n_tokens = 32497, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 74312 | prompt done, n_tokens = 32497, batch.n_tokens = 64
slot init_sampler: id  1 | task 74312 | init sampler, took 4.59 ms, tokens: text = 32497, total = 32497
slot update_slots: id  1 | task 74312 | erasing old context checkpoint (pos_min = 29632, pos_max = 30499, size = 20.354 MiB)
slot update_slots: id  1 | task 74312 | created context checkpoint 8 of 8 (pos_min = 31409, pos_max = 32432, size = 24.012 MiB)
slot print_timing: id  1 | task 74312 | 
prompt eval time =     407.42 ms /   114 tokens (    3.57 ms per token,   279.81 tokens per second)
       eval time =    4773.57 ms /   177 tokens (   26.97 ms per token,    37.08 tokens per second)
      total time =    5180.99 ms /   291 tokens
slot      release: id  1 | task 74312 | stop processing: n_tokens = 32673, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.972 (> 0.100 thold), f_keep = 0.927
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 74491 | processing task, is_child = 0
slot update_slots: id  1 | task 74491 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 31158
slot update_slots: id  1 | task 74491 | n_past = 30280, slot.prompt.tokens.size() = 32673, seq_id = 1, pos_min = 31649, n_swa = 128
slot update_slots: id  1 | task 74491 | restored context checkpoint (pos_min = 30141, pos_max = 31164, size = 24.012 MiB)
slot update_slots: id  1 | task 74491 | erased invalidated context checkpoint (pos_min = 30325, pos_max = 31266, n_swa = 128, size = 22.089 MiB)
slot update_slots: id  1 | task 74491 | erased invalidated context checkpoint (pos_min = 30347, pos_max = 31368, n_swa = 128, size = 23.965 MiB)
slot update_slots: id  1 | task 74491 | erased invalidated context checkpoint (pos_min = 30532, pos_max = 31450, n_swa = 128, size = 21.550 MiB)
slot update_slots: id  1 | task 74491 | erased invalidated context checkpoint (pos_min = 31185, pos_max = 32208, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  1 | task 74491 | erased invalidated context checkpoint (pos_min = 31362, pos_max = 32318, n_swa = 128, size = 22.441 MiB)
slot update_slots: id  1 | task 74491 | erased invalidated context checkpoint (pos_min = 31409, pos_max = 32432, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  1 | task 74491 | n_tokens = 30280, memory_seq_rm [30280, end)
slot update_slots: id  1 | task 74491 | prompt processing progress, n_tokens = 31094, batch.n_tokens = 814, progress = 0.997946
slot update_slots: id  1 | task 74491 | n_tokens = 31094, memory_seq_rm [31094, end)
slot update_slots: id  1 | task 74491 | prompt processing progress, n_tokens = 31158, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 74491 | prompt done, n_tokens = 31158, batch.n_tokens = 64
slot init_sampler: id  1 | task 74491 | init sampler, took 4.40 ms, tokens: text = 31158, total = 31158
slot print_timing: id  1 | task 74491 | 
prompt eval time =    1495.84 ms /   878 tokens (    1.70 ms per token,   586.96 tokens per second)
       eval time =   34223.36 ms /  1258 tokens (   27.20 ms per token,    36.76 tokens per second)
      total time =   35719.20 ms /  2136 tokens
slot      release: id  1 | task 74491 | stop processing: n_tokens = 32415, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.975 (> 0.100 thold), f_keep = 0.961
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 75751 | processing task, is_child = 0
slot update_slots: id  1 | task 75751 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 31929
slot update_slots: id  1 | task 75751 | n_past = 31136, slot.prompt.tokens.size() = 32415, seq_id = 1, pos_min = 31391, n_swa = 128
slot update_slots: id  1 | task 75751 | restored context checkpoint (pos_min = 30141, pos_max = 31164, size = 24.012 MiB)
slot update_slots: id  1 | task 75751 | n_tokens = 31136, memory_seq_rm [31136, end)
slot update_slots: id  1 | task 75751 | prompt processing progress, n_tokens = 31865, batch.n_tokens = 729, progress = 0.997996
slot update_slots: id  1 | task 75751 | n_tokens = 31865, memory_seq_rm [31865, end)
slot update_slots: id  1 | task 75751 | prompt processing progress, n_tokens = 31929, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 75751 | prompt done, n_tokens = 31929, batch.n_tokens = 64
slot init_sampler: id  1 | task 75751 | init sampler, took 5.28 ms, tokens: text = 31929, total = 31929
slot update_slots: id  1 | task 75751 | created context checkpoint 3 of 8 (pos_min = 30841, pos_max = 31864, size = 24.012 MiB)
slot print_timing: id  1 | task 75751 | 
prompt eval time =    1447.00 ms /   793 tokens (    1.82 ms per token,   548.03 tokens per second)
       eval time =    2344.68 ms /    88 tokens (   26.64 ms per token,    37.53 tokens per second)
      total time =    3791.68 ms /   881 tokens
slot      release: id  1 | task 75751 | stop processing: n_tokens = 32016, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 75841 | processing task, is_child = 0
slot update_slots: id  1 | task 75841 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32012
slot update_slots: id  1 | task 75841 | n_tokens = 31929, memory_seq_rm [31929, end)
slot update_slots: id  1 | task 75841 | prompt processing progress, n_tokens = 31948, batch.n_tokens = 19, progress = 0.998001
slot update_slots: id  1 | task 75841 | n_tokens = 31948, memory_seq_rm [31948, end)
slot update_slots: id  1 | task 75841 | prompt processing progress, n_tokens = 32012, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 75841 | prompt done, n_tokens = 32012, batch.n_tokens = 64
slot init_sampler: id  1 | task 75841 | init sampler, took 4.70 ms, tokens: text = 32012, total = 32012
slot update_slots: id  1 | task 75841 | created context checkpoint 4 of 8 (pos_min = 30992, pos_max = 31947, size = 22.417 MiB)
slot print_timing: id  1 | task 75841 | 
prompt eval time =     306.71 ms /    83 tokens (    3.70 ms per token,   270.61 tokens per second)
       eval time =    5238.35 ms /   193 tokens (   27.14 ms per token,    36.84 tokens per second)
      total time =    5545.06 ms /   276 tokens
slot      release: id  1 | task 75841 | stop processing: n_tokens = 32204, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 76036 | processing task, is_child = 0
slot update_slots: id  1 | task 76036 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32125
slot update_slots: id  1 | task 76036 | n_tokens = 32012, memory_seq_rm [32012, end)
slot update_slots: id  1 | task 76036 | prompt processing progress, n_tokens = 32061, batch.n_tokens = 49, progress = 0.998008
slot update_slots: id  1 | task 76036 | n_tokens = 32061, memory_seq_rm [32061, end)
slot update_slots: id  1 | task 76036 | prompt processing progress, n_tokens = 32125, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 76036 | prompt done, n_tokens = 32125, batch.n_tokens = 64
slot init_sampler: id  1 | task 76036 | init sampler, took 4.69 ms, tokens: text = 32125, total = 32125
slot update_slots: id  1 | task 76036 | created context checkpoint 5 of 8 (pos_min = 31180, pos_max = 32060, size = 20.659 MiB)
slot print_timing: id  1 | task 76036 | 
prompt eval time =     421.18 ms /   113 tokens (    3.73 ms per token,   268.29 tokens per second)
       eval time =    1213.46 ms /    45 tokens (   26.97 ms per token,    37.08 tokens per second)
      total time =    1634.64 ms /   158 tokens
slot      release: id  1 | task 76036 | stop processing: n_tokens = 32169, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 76083 | processing task, is_child = 0
slot update_slots: id  1 | task 76083 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32219
slot update_slots: id  1 | task 76083 | n_tokens = 32125, memory_seq_rm [32125, end)
slot update_slots: id  1 | task 76083 | prompt processing progress, n_tokens = 32155, batch.n_tokens = 30, progress = 0.998014
slot update_slots: id  1 | task 76083 | n_tokens = 32155, memory_seq_rm [32155, end)
slot update_slots: id  1 | task 76083 | prompt processing progress, n_tokens = 32219, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 76083 | prompt done, n_tokens = 32219, batch.n_tokens = 64
slot init_sampler: id  1 | task 76083 | init sampler, took 5.20 ms, tokens: text = 32219, total = 32219
slot update_slots: id  1 | task 76083 | created context checkpoint 6 of 8 (pos_min = 31180, pos_max = 32154, size = 22.863 MiB)
slot print_timing: id  1 | task 76083 | 
prompt eval time =     358.68 ms /    94 tokens (    3.82 ms per token,   262.07 tokens per second)
       eval time =    4477.97 ms /   166 tokens (   26.98 ms per token,    37.07 tokens per second)
      total time =    4836.64 ms /   260 tokens
slot      release: id  1 | task 76083 | stop processing: n_tokens = 32384, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.979 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 76251 | processing task, is_child = 0
slot update_slots: id  1 | task 76251 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32904
slot update_slots: id  1 | task 76251 | n_tokens = 32219, memory_seq_rm [32219, end)
slot update_slots: id  1 | task 76251 | prompt processing progress, n_tokens = 32840, batch.n_tokens = 621, progress = 0.998055
slot update_slots: id  1 | task 76251 | n_tokens = 32840, memory_seq_rm [32840, end)
slot update_slots: id  1 | task 76251 | prompt processing progress, n_tokens = 32904, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 76251 | prompt done, n_tokens = 32904, batch.n_tokens = 64
slot init_sampler: id  1 | task 76251 | init sampler, took 7.22 ms, tokens: text = 32904, total = 32904
slot update_slots: id  1 | task 76251 | created context checkpoint 7 of 8 (pos_min = 31816, pos_max = 32839, size = 24.012 MiB)
slot print_timing: id  1 | task 76251 | 
prompt eval time =    1237.57 ms /   685 tokens (    1.81 ms per token,   553.51 tokens per second)
       eval time =   10298.01 ms /   374 tokens (   27.53 ms per token,    36.32 tokens per second)
      total time =   11535.57 ms /  1059 tokens
slot      release: id  1 | task 76251 | stop processing: n_tokens = 33277, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.989
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 76627 | processing task, is_child = 0
slot update_slots: id  1 | task 76627 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 33141
slot update_slots: id  1 | task 76627 | n_tokens = 32904, memory_seq_rm [32904, end)
slot update_slots: id  1 | task 76627 | prompt processing progress, n_tokens = 33077, batch.n_tokens = 173, progress = 0.998069
slot update_slots: id  1 | task 76627 | n_tokens = 33077, memory_seq_rm [33077, end)
slot update_slots: id  1 | task 76627 | prompt processing progress, n_tokens = 33141, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 76627 | prompt done, n_tokens = 33141, batch.n_tokens = 64
slot init_sampler: id  1 | task 76627 | init sampler, took 4.68 ms, tokens: text = 33141, total = 33141
slot update_slots: id  1 | task 76627 | created context checkpoint 8 of 8 (pos_min = 32253, pos_max = 33076, size = 19.322 MiB)
slot print_timing: id  1 | task 76627 | 
prompt eval time =     588.33 ms /   237 tokens (    2.48 ms per token,   402.84 tokens per second)
       eval time =     744.34 ms /    27 tokens (   27.57 ms per token,    36.27 tokens per second)
      total time =    1332.66 ms /   264 tokens
slot      release: id  1 | task 76627 | stop processing: n_tokens = 33167, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 76656 | processing task, is_child = 0
slot update_slots: id  1 | task 76656 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 33195
slot update_slots: id  1 | task 76656 | n_tokens = 33141, memory_seq_rm [33141, end)
slot update_slots: id  1 | task 76656 | prompt processing progress, n_tokens = 33195, batch.n_tokens = 54, progress = 1.000000
slot update_slots: id  1 | task 76656 | prompt done, n_tokens = 33195, batch.n_tokens = 54
slot init_sampler: id  1 | task 76656 | init sampler, took 6.44 ms, tokens: text = 33195, total = 33195
slot print_timing: id  1 | task 76656 | 
prompt eval time =     186.80 ms /    54 tokens (    3.46 ms per token,   289.08 tokens per second)
       eval time =     721.29 ms /    25 tokens (   28.85 ms per token,    34.66 tokens per second)
      total time =     908.09 ms /    79 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 76656 | stop processing: n_tokens = 33219, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 76682 | processing task, is_child = 0
slot update_slots: id  1 | task 76682 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 33296
slot update_slots: id  1 | task 76682 | n_tokens = 33195, memory_seq_rm [33195, end)
slot update_slots: id  1 | task 76682 | prompt processing progress, n_tokens = 33232, batch.n_tokens = 37, progress = 0.998078
slot update_slots: id  1 | task 76682 | n_tokens = 33232, memory_seq_rm [33232, end)
slot update_slots: id  1 | task 76682 | prompt processing progress, n_tokens = 33296, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 76682 | prompt done, n_tokens = 33296, batch.n_tokens = 64
slot init_sampler: id  1 | task 76682 | init sampler, took 6.49 ms, tokens: text = 33296, total = 33296
slot update_slots: id  1 | task 76682 | erasing old context checkpoint (pos_min = 29632, pos_max = 30601, size = 22.746 MiB)
slot update_slots: id  1 | task 76682 | created context checkpoint 8 of 8 (pos_min = 32253, pos_max = 33231, size = 22.957 MiB)
slot print_timing: id  1 | task 76682 | 
prompt eval time =     453.00 ms /   101 tokens (    4.49 ms per token,   222.96 tokens per second)
       eval time =    7370.68 ms /   267 tokens (   27.61 ms per token,    36.22 tokens per second)
      total time =    7823.68 ms /   368 tokens
slot      release: id  1 | task 76682 | stop processing: n_tokens = 33562, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 76951 | processing task, is_child = 0
slot update_slots: id  1 | task 76951 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 33464
slot update_slots: id  1 | task 76951 | n_tokens = 33296, memory_seq_rm [33296, end)
slot update_slots: id  1 | task 76951 | prompt processing progress, n_tokens = 33400, batch.n_tokens = 104, progress = 0.998088
slot update_slots: id  1 | task 76951 | n_tokens = 33400, memory_seq_rm [33400, end)
slot update_slots: id  1 | task 76951 | prompt processing progress, n_tokens = 33464, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 76951 | prompt done, n_tokens = 33464, batch.n_tokens = 64
slot init_sampler: id  1 | task 76951 | init sampler, took 4.86 ms, tokens: text = 33464, total = 33464
slot update_slots: id  1 | task 76951 | erasing old context checkpoint (pos_min = 30141, pos_max = 31164, size = 24.012 MiB)
slot update_slots: id  1 | task 76951 | created context checkpoint 8 of 8 (pos_min = 32538, pos_max = 33399, size = 20.213 MiB)
slot print_timing: id  1 | task 76951 | 
prompt eval time =     516.36 ms /   168 tokens (    3.07 ms per token,   325.36 tokens per second)
       eval time =     691.10 ms /    25 tokens (   27.64 ms per token,    36.17 tokens per second)
      total time =    1207.46 ms /   193 tokens
slot      release: id  1 | task 76951 | stop processing: n_tokens = 33488, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 76978 | processing task, is_child = 0
slot update_slots: id  1 | task 76978 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 33565
slot update_slots: id  1 | task 76978 | n_tokens = 33464, memory_seq_rm [33464, end)
slot update_slots: id  1 | task 76978 | prompt processing progress, n_tokens = 33501, batch.n_tokens = 37, progress = 0.998093
slot update_slots: id  1 | task 76978 | n_tokens = 33501, memory_seq_rm [33501, end)
slot update_slots: id  1 | task 76978 | prompt processing progress, n_tokens = 33565, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 76978 | prompt done, n_tokens = 33565, batch.n_tokens = 64
slot init_sampler: id  1 | task 76978 | init sampler, took 4.61 ms, tokens: text = 33565, total = 33565
slot update_slots: id  1 | task 76978 | erasing old context checkpoint (pos_min = 30841, pos_max = 31864, size = 24.012 MiB)
slot update_slots: id  1 | task 76978 | created context checkpoint 8 of 8 (pos_min = 32538, pos_max = 33500, size = 22.582 MiB)
slot print_timing: id  1 | task 76978 | 
prompt eval time =     371.03 ms /   101 tokens (    3.67 ms per token,   272.22 tokens per second)
       eval time =    3897.57 ms /   140 tokens (   27.84 ms per token,    35.92 tokens per second)
      total time =    4268.60 ms /   241 tokens
slot      release: id  1 | task 76978 | stop processing: n_tokens = 33704, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 77120 | processing task, is_child = 0
slot update_slots: id  1 | task 77120 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 33708
slot update_slots: id  1 | task 77120 | n_tokens = 33565, memory_seq_rm [33565, end)
slot update_slots: id  1 | task 77120 | prompt processing progress, n_tokens = 33644, batch.n_tokens = 79, progress = 0.998101
slot update_slots: id  1 | task 77120 | n_tokens = 33644, memory_seq_rm [33644, end)
slot update_slots: id  1 | task 77120 | prompt processing progress, n_tokens = 33708, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 77120 | prompt done, n_tokens = 33708, batch.n_tokens = 64
slot init_sampler: id  1 | task 77120 | init sampler, took 4.66 ms, tokens: text = 33708, total = 33708
slot update_slots: id  1 | task 77120 | erasing old context checkpoint (pos_min = 30992, pos_max = 31947, size = 22.417 MiB)
slot update_slots: id  1 | task 77120 | created context checkpoint 8 of 8 (pos_min = 32680, pos_max = 33643, size = 22.605 MiB)
slot print_timing: id  1 | task 77120 | 
prompt eval time =     543.74 ms /   143 tokens (    3.80 ms per token,   262.99 tokens per second)
       eval time =     728.30 ms /    27 tokens (   26.97 ms per token,    37.07 tokens per second)
      total time =    1272.04 ms /   170 tokens
slot      release: id  1 | task 77120 | stop processing: n_tokens = 33734, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 77149 | processing task, is_child = 0
slot update_slots: id  1 | task 77149 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 33762
slot update_slots: id  1 | task 77149 | n_tokens = 33708, memory_seq_rm [33708, end)
slot update_slots: id  1 | task 77149 | prompt processing progress, n_tokens = 33762, batch.n_tokens = 54, progress = 1.000000
slot update_slots: id  1 | task 77149 | prompt done, n_tokens = 33762, batch.n_tokens = 54
slot init_sampler: id  1 | task 77149 | init sampler, took 4.78 ms, tokens: text = 33762, total = 33762
slot print_timing: id  1 | task 77149 | 
prompt eval time =     178.26 ms /    54 tokens (    3.30 ms per token,   302.94 tokens per second)
       eval time =     672.81 ms /    25 tokens (   26.91 ms per token,    37.16 tokens per second)
      total time =     851.07 ms /    79 tokens
slot      release: id  1 | task 77149 | stop processing: n_tokens = 33786, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 77175 | processing task, is_child = 0
slot update_slots: id  1 | task 77175 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 33841
slot update_slots: id  1 | task 77175 | n_tokens = 33762, memory_seq_rm [33762, end)
slot update_slots: id  1 | task 77175 | prompt processing progress, n_tokens = 33777, batch.n_tokens = 15, progress = 0.998109
slot update_slots: id  1 | task 77175 | n_tokens = 33777, memory_seq_rm [33777, end)
slot update_slots: id  1 | task 77175 | prompt processing progress, n_tokens = 33841, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 77175 | prompt done, n_tokens = 33841, batch.n_tokens = 64
slot init_sampler: id  1 | task 77175 | init sampler, took 4.72 ms, tokens: text = 33841, total = 33841
slot update_slots: id  1 | task 77175 | erasing old context checkpoint (pos_min = 31180, pos_max = 32060, size = 20.659 MiB)
slot update_slots: id  1 | task 77175 | created context checkpoint 8 of 8 (pos_min = 32782, pos_max = 33776, size = 23.332 MiB)
slot print_timing: id  1 | task 77175 | 
prompt eval time =     314.79 ms /    79 tokens (    3.98 ms per token,   250.96 tokens per second)
       eval time =    2256.26 ms /    83 tokens (   27.18 ms per token,    36.79 tokens per second)
      total time =    2571.05 ms /   162 tokens
slot      release: id  1 | task 77175 | stop processing: n_tokens = 33923, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.917 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 77260 | processing task, is_child = 0
slot update_slots: id  1 | task 77260 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 36895
slot update_slots: id  1 | task 77260 | n_tokens = 33841, memory_seq_rm [33841, end)
slot update_slots: id  1 | task 77260 | prompt processing progress, n_tokens = 35889, batch.n_tokens = 2048, progress = 0.972733
slot update_slots: id  1 | task 77260 | n_tokens = 35889, memory_seq_rm [35889, end)
slot update_slots: id  1 | task 77260 | prompt processing progress, n_tokens = 36831, batch.n_tokens = 942, progress = 0.998265
slot update_slots: id  1 | task 77260 | n_tokens = 36831, memory_seq_rm [36831, end)
slot update_slots: id  1 | task 77260 | prompt processing progress, n_tokens = 36895, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 77260 | prompt done, n_tokens = 36895, batch.n_tokens = 64
slot init_sampler: id  1 | task 77260 | init sampler, took 6.96 ms, tokens: text = 36895, total = 36895
slot update_slots: id  1 | task 77260 | erasing old context checkpoint (pos_min = 31180, pos_max = 32154, size = 22.863 MiB)
slot update_slots: id  1 | task 77260 | created context checkpoint 8 of 8 (pos_min = 35807, pos_max = 36830, size = 24.012 MiB)
slot print_timing: id  1 | task 77260 | 
prompt eval time =    4500.44 ms /  3054 tokens (    1.47 ms per token,   678.60 tokens per second)
       eval time =    7290.75 ms /   263 tokens (   27.72 ms per token,    36.07 tokens per second)
      total time =   11791.19 ms /  3317 tokens
slot      release: id  1 | task 77260 | stop processing: n_tokens = 37157, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 77526 | processing task, is_child = 0
slot update_slots: id  1 | task 77526 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 37509
slot update_slots: id  1 | task 77526 | n_tokens = 36895, memory_seq_rm [36895, end)
slot update_slots: id  1 | task 77526 | prompt processing progress, n_tokens = 37445, batch.n_tokens = 550, progress = 0.998294
slot update_slots: id  1 | task 77526 | n_tokens = 37445, memory_seq_rm [37445, end)
slot update_slots: id  1 | task 77526 | prompt processing progress, n_tokens = 37509, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 77526 | prompt done, n_tokens = 37509, batch.n_tokens = 64
slot init_sampler: id  1 | task 77526 | init sampler, took 5.28 ms, tokens: text = 37509, total = 37509
slot update_slots: id  1 | task 77526 | erasing old context checkpoint (pos_min = 31816, pos_max = 32839, size = 24.012 MiB)
slot update_slots: id  1 | task 77526 | created context checkpoint 8 of 8 (pos_min = 36421, pos_max = 37444, size = 24.012 MiB)
slot print_timing: id  1 | task 77526 | 
prompt eval time =    1153.72 ms /   614 tokens (    1.88 ms per token,   532.19 tokens per second)
       eval time =    9531.34 ms /   340 tokens (   28.03 ms per token,    35.67 tokens per second)
      total time =   10685.06 ms /   954 tokens
slot      release: id  1 | task 77526 | stop processing: n_tokens = 37848, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 77868 | processing task, is_child = 0
slot update_slots: id  1 | task 77868 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 37588
slot update_slots: id  1 | task 77868 | n_tokens = 37509, memory_seq_rm [37509, end)
slot update_slots: id  1 | task 77868 | prompt processing progress, n_tokens = 37524, batch.n_tokens = 15, progress = 0.998297
slot update_slots: id  1 | task 77868 | n_tokens = 37524, memory_seq_rm [37524, end)
slot update_slots: id  1 | task 77868 | prompt processing progress, n_tokens = 37588, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 77868 | prompt done, n_tokens = 37588, batch.n_tokens = 64
slot init_sampler: id  1 | task 77868 | init sampler, took 5.24 ms, tokens: text = 37588, total = 37588
slot update_slots: id  1 | task 77868 | erasing old context checkpoint (pos_min = 32253, pos_max = 33076, size = 19.322 MiB)
slot update_slots: id  1 | task 77868 | created context checkpoint 8 of 8 (pos_min = 36824, pos_max = 37523, size = 16.415 MiB)
slot print_timing: id  1 | task 77868 | 
prompt eval time =     317.42 ms /    79 tokens (    4.02 ms per token,   248.88 tokens per second)
       eval time =    2626.27 ms /    95 tokens (   27.64 ms per token,    36.17 tokens per second)
      total time =    2943.69 ms /   174 tokens
slot      release: id  1 | task 77868 | stop processing: n_tokens = 37682, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 77965 | processing task, is_child = 0
slot update_slots: id  1 | task 77965 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 38024
slot update_slots: id  1 | task 77965 | n_tokens = 37588, memory_seq_rm [37588, end)
slot update_slots: id  1 | task 77965 | prompt processing progress, n_tokens = 37960, batch.n_tokens = 372, progress = 0.998317
slot update_slots: id  1 | task 77965 | n_tokens = 37960, memory_seq_rm [37960, end)
slot update_slots: id  1 | task 77965 | prompt processing progress, n_tokens = 38024, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 77965 | prompt done, n_tokens = 38024, batch.n_tokens = 64
slot init_sampler: id  1 | task 77965 | init sampler, took 7.15 ms, tokens: text = 38024, total = 38024
slot update_slots: id  1 | task 77965 | erasing old context checkpoint (pos_min = 32253, pos_max = 33231, size = 22.957 MiB)
slot update_slots: id  1 | task 77965 | created context checkpoint 8 of 8 (pos_min = 37231, pos_max = 37959, size = 17.095 MiB)
slot print_timing: id  1 | task 77965 | 
prompt eval time =     834.84 ms /   436 tokens (    1.91 ms per token,   522.26 tokens per second)
       eval time =    8060.24 ms /   285 tokens (   28.28 ms per token,    35.36 tokens per second)
      total time =    8895.08 ms /   721 tokens
slot      release: id  1 | task 77965 | stop processing: n_tokens = 38308, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 78252 | processing task, is_child = 0
slot update_slots: id  1 | task 78252 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 38267
slot update_slots: id  1 | task 78252 | n_tokens = 38024, memory_seq_rm [38024, end)
slot update_slots: id  1 | task 78252 | prompt processing progress, n_tokens = 38203, batch.n_tokens = 179, progress = 0.998328
slot update_slots: id  1 | task 78252 | n_tokens = 38203, memory_seq_rm [38203, end)
slot update_slots: id  1 | task 78252 | prompt processing progress, n_tokens = 38267, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 78252 | prompt done, n_tokens = 38267, batch.n_tokens = 64
slot init_sampler: id  1 | task 78252 | init sampler, took 5.31 ms, tokens: text = 38267, total = 38267
slot update_slots: id  1 | task 78252 | erasing old context checkpoint (pos_min = 32538, pos_max = 33399, size = 20.213 MiB)
slot update_slots: id  1 | task 78252 | created context checkpoint 8 of 8 (pos_min = 37509, pos_max = 38202, size = 16.274 MiB)
slot print_timing: id  1 | task 78252 | 
prompt eval time =     612.17 ms /   243 tokens (    2.52 ms per token,   396.95 tokens per second)
       eval time =     742.85 ms /    27 tokens (   27.51 ms per token,    36.35 tokens per second)
      total time =    1355.02 ms /   270 tokens
slot      release: id  1 | task 78252 | stop processing: n_tokens = 38293, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.999 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 78281 | processing task, is_child = 0
slot update_slots: id  1 | task 78281 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 38321
slot update_slots: id  1 | task 78281 | n_tokens = 38267, memory_seq_rm [38267, end)
slot update_slots: id  1 | task 78281 | prompt processing progress, n_tokens = 38321, batch.n_tokens = 54, progress = 1.000000
slot update_slots: id  1 | task 78281 | prompt done, n_tokens = 38321, batch.n_tokens = 54
slot init_sampler: id  1 | task 78281 | init sampler, took 5.29 ms, tokens: text = 38321, total = 38321
slot print_timing: id  1 | task 78281 | 
prompt eval time =     182.77 ms /    54 tokens (    3.38 ms per token,   295.45 tokens per second)
       eval time =     607.91 ms /    22 tokens (   27.63 ms per token,    36.19 tokens per second)
      total time =     790.68 ms /    76 tokens
slot      release: id  1 | task 78281 | stop processing: n_tokens = 38342, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 78304 | processing task, is_child = 0
slot update_slots: id  1 | task 78304 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 38400
slot update_slots: id  1 | task 78304 | n_tokens = 38321, memory_seq_rm [38321, end)
slot update_slots: id  1 | task 78304 | prompt processing progress, n_tokens = 38336, batch.n_tokens = 15, progress = 0.998333
slot update_slots: id  1 | task 78304 | n_tokens = 38336, memory_seq_rm [38336, end)
slot update_slots: id  1 | task 78304 | prompt processing progress, n_tokens = 38400, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 78304 | prompt done, n_tokens = 38400, batch.n_tokens = 64
slot init_sampler: id  1 | task 78304 | init sampler, took 5.31 ms, tokens: text = 38400, total = 38400
slot update_slots: id  1 | task 78304 | erasing old context checkpoint (pos_min = 32538, pos_max = 33500, size = 22.582 MiB)
slot update_slots: id  1 | task 78304 | created context checkpoint 8 of 8 (pos_min = 37509, pos_max = 38335, size = 19.393 MiB)
slot print_timing: id  1 | task 78304 | 
prompt eval time =     326.61 ms /    79 tokens (    4.13 ms per token,   241.88 tokens per second)
       eval time =   12206.87 ms /   434 tokens (   28.13 ms per token,    35.55 tokens per second)
      total time =   12533.48 ms /   513 tokens
slot      release: id  1 | task 78304 | stop processing: n_tokens = 38833, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.989
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 78740 | processing task, is_child = 0
slot update_slots: id  1 | task 78740 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 38513
slot update_slots: id  1 | task 78740 | n_tokens = 38400, memory_seq_rm [38400, end)
slot update_slots: id  1 | task 78740 | prompt processing progress, n_tokens = 38449, batch.n_tokens = 49, progress = 0.998338
slot update_slots: id  1 | task 78740 | n_tokens = 38449, memory_seq_rm [38449, end)
slot update_slots: id  1 | task 78740 | prompt processing progress, n_tokens = 38513, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 78740 | prompt done, n_tokens = 38513, batch.n_tokens = 64
slot init_sampler: id  1 | task 78740 | init sampler, took 5.37 ms, tokens: text = 38513, total = 38513
slot update_slots: id  1 | task 78740 | erasing old context checkpoint (pos_min = 32680, pos_max = 33643, size = 22.605 MiB)
slot update_slots: id  1 | task 78740 | created context checkpoint 8 of 8 (pos_min = 37809, pos_max = 38448, size = 15.008 MiB)
slot print_timing: id  1 | task 78740 | 
prompt eval time =     421.69 ms /   113 tokens (    3.73 ms per token,   267.97 tokens per second)
       eval time =   20150.62 ms /   716 tokens (   28.14 ms per token,    35.53 tokens per second)
      total time =   20572.31 ms /   829 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 78740 | stop processing: n_tokens = 39228, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.930 (> 0.100 thold), f_keep = 0.814
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 79458 | processing task, is_child = 0
slot update_slots: id  1 | task 79458 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 34313
slot update_slots: id  1 | task 79458 | n_past = 31915, slot.prompt.tokens.size() = 39228, seq_id = 1, pos_min = 38337, n_swa = 128
slot update_slots: id  1 | task 79458 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  1 | task 79458 | erased invalidated context checkpoint (pos_min = 32782, pos_max = 33776, n_swa = 128, size = 23.332 MiB)
slot update_slots: id  1 | task 79458 | erased invalidated context checkpoint (pos_min = 35807, pos_max = 36830, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  1 | task 79458 | erased invalidated context checkpoint (pos_min = 36421, pos_max = 37444, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  1 | task 79458 | erased invalidated context checkpoint (pos_min = 36824, pos_max = 37523, n_swa = 128, size = 16.415 MiB)
slot update_slots: id  1 | task 79458 | erased invalidated context checkpoint (pos_min = 37231, pos_max = 37959, n_swa = 128, size = 17.095 MiB)
slot update_slots: id  1 | task 79458 | erased invalidated context checkpoint (pos_min = 37509, pos_max = 38202, n_swa = 128, size = 16.274 MiB)
slot update_slots: id  1 | task 79458 | erased invalidated context checkpoint (pos_min = 37509, pos_max = 38335, n_swa = 128, size = 19.393 MiB)
slot update_slots: id  1 | task 79458 | erased invalidated context checkpoint (pos_min = 37809, pos_max = 38448, n_swa = 128, size = 15.008 MiB)
slot update_slots: id  1 | task 79458 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 2048, batch.n_tokens = 2048, progress = 0.059686
slot update_slots: id  1 | task 79458 | n_tokens = 2048, memory_seq_rm [2048, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 4096, batch.n_tokens = 2048, progress = 0.119372
slot update_slots: id  1 | task 79458 | n_tokens = 4096, memory_seq_rm [4096, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 6144, batch.n_tokens = 2048, progress = 0.179057
slot update_slots: id  1 | task 79458 | n_tokens = 6144, memory_seq_rm [6144, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 8192, batch.n_tokens = 2048, progress = 0.238743
slot update_slots: id  1 | task 79458 | n_tokens = 8192, memory_seq_rm [8192, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 10240, batch.n_tokens = 2048, progress = 0.298429
slot update_slots: id  1 | task 79458 | n_tokens = 10240, memory_seq_rm [10240, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 12288, batch.n_tokens = 2048, progress = 0.358115
slot update_slots: id  1 | task 79458 | n_tokens = 12288, memory_seq_rm [12288, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 14336, batch.n_tokens = 2048, progress = 0.417801
slot update_slots: id  1 | task 79458 | n_tokens = 14336, memory_seq_rm [14336, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 16384, batch.n_tokens = 2048, progress = 0.477487
slot update_slots: id  1 | task 79458 | n_tokens = 16384, memory_seq_rm [16384, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 18432, batch.n_tokens = 2048, progress = 0.537172
slot update_slots: id  1 | task 79458 | n_tokens = 18432, memory_seq_rm [18432, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 20480, batch.n_tokens = 2048, progress = 0.596858
slot update_slots: id  1 | task 79458 | n_tokens = 20480, memory_seq_rm [20480, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 22528, batch.n_tokens = 2048, progress = 0.656544
slot update_slots: id  1 | task 79458 | n_tokens = 22528, memory_seq_rm [22528, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 24576, batch.n_tokens = 2048, progress = 0.716230
slot update_slots: id  1 | task 79458 | n_tokens = 24576, memory_seq_rm [24576, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 26624, batch.n_tokens = 2048, progress = 0.775916
slot update_slots: id  1 | task 79458 | n_tokens = 26624, memory_seq_rm [26624, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 28672, batch.n_tokens = 2048, progress = 0.835602
slot update_slots: id  1 | task 79458 | n_tokens = 28672, memory_seq_rm [28672, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 30720, batch.n_tokens = 2048, progress = 0.895288
slot update_slots: id  1 | task 79458 | n_tokens = 30720, memory_seq_rm [30720, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 32768, batch.n_tokens = 2048, progress = 0.954973
slot update_slots: id  1 | task 79458 | n_tokens = 32768, memory_seq_rm [32768, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 34249, batch.n_tokens = 1481, progress = 0.998135
slot update_slots: id  1 | task 79458 | n_tokens = 34249, memory_seq_rm [34249, end)
slot update_slots: id  1 | task 79458 | prompt processing progress, n_tokens = 34313, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 79458 | prompt done, n_tokens = 34313, batch.n_tokens = 64
slot init_sampler: id  1 | task 79458 | init sampler, took 4.96 ms, tokens: text = 34313, total = 34313
slot update_slots: id  1 | task 79458 | created context checkpoint 1 of 8 (pos_min = 33225, pos_max = 34248, size = 24.012 MiB)
slot print_timing: id  1 | task 79458 | 
prompt eval time =   40533.39 ms / 34313 tokens (    1.18 ms per token,   846.54 tokens per second)
       eval time =    2177.86 ms /    77 tokens (   28.28 ms per token,    35.36 tokens per second)
      total time =   42711.24 ms / 34390 tokens
slot      release: id  1 | task 79458 | stop processing: n_tokens = 34389, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.496 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 79553 | processing task, is_child = 0
slot update_slots: id  1 | task 79553 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 69247
srv    send_error: task id = 79553, error: request (69247 tokens) exceeds the available context size (64000 tokens), try increasing it
slot      release: id  1 | task 79553 | stop processing: n_tokens = 34389, truncated = 0
srv  update_slots: no tokens to decode
srv  update_slots: all slots are idle
srv          stop: cancel task, id_task = 79553
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 400
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 79556 | processing task, is_child = 0
slot update_slots: id  1 | task 79556 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 34361
slot update_slots: id  1 | task 79556 | n_tokens = 34262, memory_seq_rm [34262, end)
slot update_slots: id  1 | task 79556 | prompt processing progress, n_tokens = 34297, batch.n_tokens = 35, progress = 0.998137
slot update_slots: id  1 | task 79556 | n_tokens = 34297, memory_seq_rm [34297, end)
slot update_slots: id  1 | task 79556 | prompt processing progress, n_tokens = 34361, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 79556 | prompt done, n_tokens = 34361, batch.n_tokens = 64
slot init_sampler: id  1 | task 79556 | init sampler, took 4.88 ms, tokens: text = 34361, total = 34361
slot print_timing: id  1 | task 79556 | 
prompt eval time =     465.49 ms /    99 tokens (    4.70 ms per token,   212.68 tokens per second)
       eval time =    4011.74 ms /   148 tokens (   27.11 ms per token,    36.89 tokens per second)
      total time =    4477.22 ms /   247 tokens
slot      release: id  1 | task 79556 | stop processing: n_tokens = 34508, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 79706 | processing task, is_child = 0
slot update_slots: id  1 | task 79706 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 34475
slot update_slots: id  1 | task 79706 | n_tokens = 34361, memory_seq_rm [34361, end)
slot update_slots: id  1 | task 79706 | prompt processing progress, n_tokens = 34411, batch.n_tokens = 50, progress = 0.998144
slot update_slots: id  1 | task 79706 | n_tokens = 34411, memory_seq_rm [34411, end)
slot update_slots: id  1 | task 79706 | prompt processing progress, n_tokens = 34475, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 79706 | prompt done, n_tokens = 34475, batch.n_tokens = 64
slot init_sampler: id  1 | task 79706 | init sampler, took 9.28 ms, tokens: text = 34475, total = 34475
slot update_slots: id  1 | task 79706 | created context checkpoint 2 of 8 (pos_min = 33484, pos_max = 34410, size = 21.737 MiB)
slot print_timing: id  1 | task 79706 | 
prompt eval time =     530.17 ms /   114 tokens (    4.65 ms per token,   215.02 tokens per second)
       eval time =    1163.13 ms /    41 tokens (   28.37 ms per token,    35.25 tokens per second)
      total time =    1693.30 ms /   155 tokens
slot      release: id  1 | task 79706 | stop processing: n_tokens = 34515, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 79749 | processing task, is_child = 0
slot update_slots: id  1 | task 79749 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 34529
slot update_slots: id  1 | task 79749 | n_tokens = 34475, memory_seq_rm [34475, end)
slot update_slots: id  1 | task 79749 | prompt processing progress, n_tokens = 34529, batch.n_tokens = 54, progress = 1.000000
slot update_slots: id  1 | task 79749 | prompt done, n_tokens = 34529, batch.n_tokens = 54
slot init_sampler: id  1 | task 79749 | init sampler, took 5.27 ms, tokens: text = 34529, total = 34529
slot print_timing: id  1 | task 79749 | 
prompt eval time =     180.34 ms /    54 tokens (    3.34 ms per token,   299.44 tokens per second)
       eval time =     944.49 ms /    35 tokens (   26.99 ms per token,    37.06 tokens per second)
      total time =    1124.82 ms /    89 tokens
slot      release: id  1 | task 79749 | stop processing: n_tokens = 34563, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 79785 | processing task, is_child = 0
slot update_slots: id  1 | task 79785 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 34611
slot update_slots: id  1 | task 79785 | n_tokens = 34529, memory_seq_rm [34529, end)
slot update_slots: id  1 | task 79785 | prompt processing progress, n_tokens = 34547, batch.n_tokens = 18, progress = 0.998151
slot update_slots: id  1 | task 79785 | n_tokens = 34547, memory_seq_rm [34547, end)
slot update_slots: id  1 | task 79785 | prompt processing progress, n_tokens = 34611, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 79785 | prompt done, n_tokens = 34611, batch.n_tokens = 64
slot init_sampler: id  1 | task 79785 | init sampler, took 5.03 ms, tokens: text = 34611, total = 34611
slot update_slots: id  1 | task 79785 | created context checkpoint 3 of 8 (pos_min = 33539, pos_max = 34546, size = 23.637 MiB)
slot print_timing: id  1 | task 79785 | 
prompt eval time =     318.75 ms /    82 tokens (    3.89 ms per token,   257.25 tokens per second)
       eval time =    2462.73 ms /    91 tokens (   27.06 ms per token,    36.95 tokens per second)
      total time =    2781.48 ms /   173 tokens
slot      release: id  1 | task 79785 | stop processing: n_tokens = 34701, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.196 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 79878 | processing task, is_child = 0
slot update_slots: id  1 | task 79878 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 176790
srv    send_error: task id = 79878, error: request (176790 tokens) exceeds the available context size (64000 tokens), try increasing it
slot      release: id  1 | task 79878 | stop processing: n_tokens = 34701, truncated = 0
srv  update_slots: no tokens to decode
srv  update_slots: all slots are idle
srv          stop: cancel task, id_task = 79878
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 400
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.989
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 79881 | processing task, is_child = 0
slot update_slots: id  1 | task 79881 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 34611
slot update_slots: id  1 | task 79881 | n_tokens = 34310, memory_seq_rm [34310, end)
slot update_slots: id  1 | task 79881 | prompt processing progress, n_tokens = 34547, batch.n_tokens = 237, progress = 0.998151
slot update_slots: id  1 | task 79881 | n_tokens = 34547, memory_seq_rm [34547, end)
slot update_slots: id  1 | task 79881 | prompt processing progress, n_tokens = 34611, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 79881 | prompt done, n_tokens = 34611, batch.n_tokens = 64
slot init_sampler: id  1 | task 79881 | init sampler, took 4.97 ms, tokens: text = 34611, total = 34611
slot print_timing: id  1 | task 79881 | 
prompt eval time =     774.93 ms /   301 tokens (    2.57 ms per token,   388.42 tokens per second)
       eval time =    1050.24 ms /    39 tokens (   26.93 ms per token,    37.13 tokens per second)
      total time =    1825.17 ms /   340 tokens
slot      release: id  1 | task 79881 | stop processing: n_tokens = 34649, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.979 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 79922 | processing task, is_child = 0
slot update_slots: id  1 | task 79922 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 35354
slot update_slots: id  1 | task 79922 | n_tokens = 34611, memory_seq_rm [34611, end)
slot update_slots: id  1 | task 79922 | prompt processing progress, n_tokens = 35290, batch.n_tokens = 679, progress = 0.998190
slot update_slots: id  1 | task 79922 | n_tokens = 35290, memory_seq_rm [35290, end)
slot update_slots: id  1 | task 79922 | prompt processing progress, n_tokens = 35354, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 79922 | prompt done, n_tokens = 35354, batch.n_tokens = 64
slot init_sampler: id  1 | task 79922 | init sampler, took 6.86 ms, tokens: text = 35354, total = 35354
slot update_slots: id  1 | task 79922 | created context checkpoint 4 of 8 (pos_min = 34266, pos_max = 35289, size = 24.012 MiB)
slot print_timing: id  1 | task 79922 | 
prompt eval time =    1360.39 ms /   743 tokens (    1.83 ms per token,   546.17 tokens per second)
       eval time =    4498.92 ms /   164 tokens (   27.43 ms per token,    36.45 tokens per second)
      total time =    5859.31 ms /   907 tokens
slot      release: id  1 | task 79922 | stop processing: n_tokens = 35517, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 80088 | processing task, is_child = 0
slot update_slots: id  1 | task 80088 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 35414
slot update_slots: id  1 | task 80088 | n_tokens = 35354, memory_seq_rm [35354, end)
slot update_slots: id  1 | task 80088 | prompt processing progress, n_tokens = 35414, batch.n_tokens = 60, progress = 1.000000
slot update_slots: id  1 | task 80088 | prompt done, n_tokens = 35414, batch.n_tokens = 60
slot init_sampler: id  1 | task 80088 | init sampler, took 4.97 ms, tokens: text = 35414, total = 35414
slot print_timing: id  1 | task 80088 | 
prompt eval time =     188.03 ms /    60 tokens (    3.13 ms per token,   319.09 tokens per second)
       eval time =    2021.08 ms /    75 tokens (   26.95 ms per token,    37.11 tokens per second)
      total time =    2209.11 ms /   135 tokens
slot      release: id  1 | task 80088 | stop processing: n_tokens = 35488, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 80164 | processing task, is_child = 0
slot update_slots: id  1 | task 80164 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 35932
slot update_slots: id  1 | task 80164 | n_tokens = 35414, memory_seq_rm [35414, end)
slot update_slots: id  1 | task 80164 | prompt processing progress, n_tokens = 35868, batch.n_tokens = 454, progress = 0.998219
slot update_slots: id  1 | task 80164 | n_tokens = 35868, memory_seq_rm [35868, end)
slot update_slots: id  1 | task 80164 | prompt processing progress, n_tokens = 35932, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 80164 | prompt done, n_tokens = 35932, batch.n_tokens = 64
slot init_sampler: id  1 | task 80164 | init sampler, took 5.20 ms, tokens: text = 35932, total = 35932
slot update_slots: id  1 | task 80164 | created context checkpoint 5 of 8 (pos_min = 34844, pos_max = 35867, size = 24.012 MiB)
slot print_timing: id  1 | task 80164 | 
prompt eval time =     925.56 ms /   518 tokens (    1.79 ms per token,   559.66 tokens per second)
       eval time =    2140.26 ms /    79 tokens (   27.09 ms per token,    36.91 tokens per second)
      total time =    3065.83 ms /   597 tokens
slot      release: id  1 | task 80164 | stop processing: n_tokens = 36010, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 80245 | processing task, is_child = 0
slot update_slots: id  1 | task 80245 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 36268
slot update_slots: id  1 | task 80245 | n_tokens = 35932, memory_seq_rm [35932, end)
slot update_slots: id  1 | task 80245 | prompt processing progress, n_tokens = 36204, batch.n_tokens = 272, progress = 0.998235
slot update_slots: id  1 | task 80245 | n_tokens = 36204, memory_seq_rm [36204, end)
slot update_slots: id  1 | task 80245 | prompt processing progress, n_tokens = 36268, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 80245 | prompt done, n_tokens = 36268, batch.n_tokens = 64
slot init_sampler: id  1 | task 80245 | init sampler, took 15.12 ms, tokens: text = 36268, total = 36268
slot update_slots: id  1 | task 80245 | created context checkpoint 6 of 8 (pos_min = 35180, pos_max = 36203, size = 24.012 MiB)
slot print_timing: id  1 | task 80245 | 
prompt eval time =     764.94 ms /   336 tokens (    2.28 ms per token,   439.25 tokens per second)
       eval time =    2185.24 ms /    77 tokens (   28.38 ms per token,    35.24 tokens per second)
      total time =    2950.17 ms /   413 tokens
slot      release: id  1 | task 80245 | stop processing: n_tokens = 36344, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 80324 | processing task, is_child = 0
slot update_slots: id  1 | task 80324 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 36861
slot update_slots: id  1 | task 80324 | n_tokens = 36268, memory_seq_rm [36268, end)
slot update_slots: id  1 | task 80324 | prompt processing progress, n_tokens = 36797, batch.n_tokens = 529, progress = 0.998264
slot update_slots: id  1 | task 80324 | n_tokens = 36797, memory_seq_rm [36797, end)
slot update_slots: id  1 | task 80324 | prompt processing progress, n_tokens = 36861, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 80324 | prompt done, n_tokens = 36861, batch.n_tokens = 64
slot init_sampler: id  1 | task 80324 | init sampler, took 5.14 ms, tokens: text = 36861, total = 36861
slot update_slots: id  1 | task 80324 | created context checkpoint 7 of 8 (pos_min = 35773, pos_max = 36796, size = 24.012 MiB)
slot print_timing: id  1 | task 80324 | 
prompt eval time =    1121.09 ms /   593 tokens (    1.89 ms per token,   528.95 tokens per second)
       eval time =    4521.69 ms /   165 tokens (   27.40 ms per token,    36.49 tokens per second)
      total time =    5642.78 ms /   758 tokens
slot      release: id  1 | task 80324 | stop processing: n_tokens = 37025, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 80491 | processing task, is_child = 0
slot update_slots: id  1 | task 80491 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 37170
slot update_slots: id  1 | task 80491 | n_tokens = 36861, memory_seq_rm [36861, end)
slot update_slots: id  1 | task 80491 | prompt processing progress, n_tokens = 37106, batch.n_tokens = 245, progress = 0.998278
slot update_slots: id  1 | task 80491 | n_tokens = 37106, memory_seq_rm [37106, end)
slot update_slots: id  1 | task 80491 | prompt processing progress, n_tokens = 37170, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 80491 | prompt done, n_tokens = 37170, batch.n_tokens = 64
slot init_sampler: id  1 | task 80491 | init sampler, took 5.30 ms, tokens: text = 37170, total = 37170
slot update_slots: id  1 | task 80491 | created context checkpoint 8 of 8 (pos_min = 36085, pos_max = 37105, size = 23.942 MiB)
slot print_timing: id  1 | task 80491 | 
prompt eval time =     703.88 ms /   309 tokens (    2.28 ms per token,   439.00 tokens per second)
       eval time =   14900.14 ms /   529 tokens (   28.17 ms per token,    35.50 tokens per second)
      total time =   15604.01 ms /   838 tokens
slot      release: id  1 | task 80491 | stop processing: n_tokens = 37698, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.986
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 81022 | processing task, is_child = 0
slot update_slots: id  1 | task 81022 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 37241
slot update_slots: id  1 | task 81022 | n_tokens = 37170, memory_seq_rm [37170, end)
slot update_slots: id  1 | task 81022 | prompt processing progress, n_tokens = 37177, batch.n_tokens = 7, progress = 0.998281
slot update_slots: id  1 | task 81022 | n_tokens = 37177, memory_seq_rm [37177, end)
slot update_slots: id  1 | task 81022 | prompt processing progress, n_tokens = 37241, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 81022 | prompt done, n_tokens = 37241, batch.n_tokens = 64
slot init_sampler: id  1 | task 81022 | init sampler, took 7.22 ms, tokens: text = 37241, total = 37241
slot update_slots: id  1 | task 81022 | erasing old context checkpoint (pos_min = 33225, pos_max = 34248, size = 24.012 MiB)
slot update_slots: id  1 | task 81022 | created context checkpoint 8 of 8 (pos_min = 36677, pos_max = 37176, size = 11.725 MiB)
slot print_timing: id  1 | task 81022 | 
prompt eval time =     368.31 ms /    71 tokens (    5.19 ms per token,   192.77 tokens per second)
       eval time =   22512.96 ms /   796 tokens (   28.28 ms per token,    35.36 tokens per second)
      total time =   22881.27 ms /   867 tokens
slot      release: id  1 | task 81022 | stop processing: n_tokens = 38036, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.979
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 81820 | processing task, is_child = 0
slot update_slots: id  1 | task 81820 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 37674
slot update_slots: id  1 | task 81820 | n_tokens = 37241, memory_seq_rm [37241, end)
slot update_slots: id  1 | task 81820 | prompt processing progress, n_tokens = 37610, batch.n_tokens = 369, progress = 0.998301
slot update_slots: id  1 | task 81820 | n_tokens = 37610, memory_seq_rm [37610, end)
slot update_slots: id  1 | task 81820 | prompt processing progress, n_tokens = 37674, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 81820 | prompt done, n_tokens = 37674, batch.n_tokens = 64
slot init_sampler: id  1 | task 81820 | init sampler, took 5.34 ms, tokens: text = 37674, total = 37674
slot update_slots: id  1 | task 81820 | erasing old context checkpoint (pos_min = 33484, pos_max = 34410, size = 21.737 MiB)
slot update_slots: id  1 | task 81820 | created context checkpoint 8 of 8 (pos_min = 37114, pos_max = 37609, size = 11.631 MiB)
slot print_timing: id  1 | task 81820 | 
prompt eval time =     874.98 ms /   433 tokens (    2.02 ms per token,   494.87 tokens per second)
       eval time =   34130.87 ms /  1223 tokens (   27.91 ms per token,    35.83 tokens per second)
      total time =   35005.85 ms /  1656 tokens
slot      release: id  1 | task 81820 | stop processing: n_tokens = 38896, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.969
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 83045 | processing task, is_child = 0
slot update_slots: id  1 | task 83045 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 38294
slot update_slots: id  1 | task 83045 | n_past = 37674, slot.prompt.tokens.size() = 38896, seq_id = 1, pos_min = 37872, n_swa = 128
slot update_slots: id  1 | task 83045 | restored context checkpoint (pos_min = 37114, pos_max = 37609, size = 11.631 MiB)
slot update_slots: id  1 | task 83045 | n_tokens = 37609, memory_seq_rm [37609, end)
slot update_slots: id  1 | task 83045 | prompt processing progress, n_tokens = 38230, batch.n_tokens = 621, progress = 0.998329
slot update_slots: id  1 | task 83045 | n_tokens = 38230, memory_seq_rm [38230, end)
slot update_slots: id  1 | task 83045 | prompt processing progress, n_tokens = 38294, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 83045 | prompt done, n_tokens = 38294, batch.n_tokens = 64
slot init_sampler: id  1 | task 83045 | init sampler, took 7.29 ms, tokens: text = 38294, total = 38294
slot update_slots: id  1 | task 83045 | erasing old context checkpoint (pos_min = 33539, pos_max = 34546, size = 23.637 MiB)
slot update_slots: id  1 | task 83045 | created context checkpoint 8 of 8 (pos_min = 37333, pos_max = 38229, size = 21.034 MiB)
slot print_timing: id  1 | task 83045 | 
prompt eval time =    1422.86 ms /   685 tokens (    2.08 ms per token,   481.43 tokens per second)
       eval time =    1571.11 ms /    51 tokens (   30.81 ms per token,    32.46 tokens per second)
      total time =    2993.96 ms /   736 tokens
slot      release: id  1 | task 83045 | stop processing: n_tokens = 38344, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 83098 | processing task, is_child = 0
slot update_slots: id  1 | task 83098 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 38908
slot update_slots: id  1 | task 83098 | n_tokens = 38294, memory_seq_rm [38294, end)
slot update_slots: id  1 | task 83098 | prompt processing progress, n_tokens = 38844, batch.n_tokens = 550, progress = 0.998355
slot update_slots: id  1 | task 83098 | n_tokens = 38844, memory_seq_rm [38844, end)
slot update_slots: id  1 | task 83098 | prompt processing progress, n_tokens = 38908, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 83098 | prompt done, n_tokens = 38908, batch.n_tokens = 64
slot init_sampler: id  1 | task 83098 | init sampler, took 5.47 ms, tokens: text = 38908, total = 38908
slot update_slots: id  1 | task 83098 | erasing old context checkpoint (pos_min = 34266, pos_max = 35289, size = 24.012 MiB)
slot update_slots: id  1 | task 83098 | created context checkpoint 8 of 8 (pos_min = 37820, pos_max = 38843, size = 24.012 MiB)
slot print_timing: id  1 | task 83098 | 
prompt eval time =    1246.41 ms /   614 tokens (    2.03 ms per token,   492.62 tokens per second)
       eval time =   11297.13 ms /   404 tokens (   27.96 ms per token,    35.76 tokens per second)
      total time =   12543.54 ms /  1018 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 83098 | stop processing: n_tokens = 39311, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.990
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 83504 | processing task, is_child = 0
slot update_slots: id  1 | task 83504 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 39309
slot update_slots: id  1 | task 83504 | n_tokens = 38908, memory_seq_rm [38908, end)
slot update_slots: id  1 | task 83504 | prompt processing progress, n_tokens = 39245, batch.n_tokens = 337, progress = 0.998372
slot update_slots: id  1 | task 83504 | n_tokens = 39245, memory_seq_rm [39245, end)
slot update_slots: id  1 | task 83504 | prompt processing progress, n_tokens = 39309, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 83504 | prompt done, n_tokens = 39309, batch.n_tokens = 64
slot init_sampler: id  1 | task 83504 | init sampler, took 5.56 ms, tokens: text = 39309, total = 39309
slot update_slots: id  1 | task 83504 | erasing old context checkpoint (pos_min = 34844, pos_max = 35867, size = 24.012 MiB)
slot update_slots: id  1 | task 83504 | created context checkpoint 8 of 8 (pos_min = 38475, pos_max = 39244, size = 18.056 MiB)
slot print_timing: id  1 | task 83504 | 
prompt eval time =     915.07 ms /   401 tokens (    2.28 ms per token,   438.22 tokens per second)
       eval time =     921.16 ms /    33 tokens (   27.91 ms per token,    35.82 tokens per second)
      total time =    1836.23 ms /   434 tokens
slot      release: id  1 | task 83504 | stop processing: n_tokens = 39341, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 83539 | processing task, is_child = 0
slot update_slots: id  1 | task 83539 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 39936
slot update_slots: id  1 | task 83539 | n_tokens = 39309, memory_seq_rm [39309, end)
slot update_slots: id  1 | task 83539 | prompt processing progress, n_tokens = 39872, batch.n_tokens = 563, progress = 0.998397
slot update_slots: id  1 | task 83539 | n_tokens = 39872, memory_seq_rm [39872, end)
slot update_slots: id  1 | task 83539 | prompt processing progress, n_tokens = 39936, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 83539 | prompt done, n_tokens = 39936, batch.n_tokens = 64
slot init_sampler: id  1 | task 83539 | init sampler, took 5.71 ms, tokens: text = 39936, total = 39936
slot update_slots: id  1 | task 83539 | erasing old context checkpoint (pos_min = 35180, pos_max = 36203, size = 24.012 MiB)
slot update_slots: id  1 | task 83539 | created context checkpoint 8 of 8 (pos_min = 38908, pos_max = 39871, size = 22.605 MiB)
slot print_timing: id  1 | task 83539 | 
prompt eval time =    1242.76 ms /   627 tokens (    1.98 ms per token,   504.52 tokens per second)
       eval time =   15223.47 ms /   534 tokens (   28.51 ms per token,    35.08 tokens per second)
      total time =   16466.23 ms /  1161 tokens
slot      release: id  1 | task 83539 | stop processing: n_tokens = 40469, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 84075 | processing task, is_child = 0
slot update_slots: id  1 | task 84075 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 40433
slot update_slots: id  1 | task 84075 | n_tokens = 39936, memory_seq_rm [39936, end)
slot update_slots: id  1 | task 84075 | prompt processing progress, n_tokens = 40369, batch.n_tokens = 433, progress = 0.998417
slot update_slots: id  1 | task 84075 | n_tokens = 40369, memory_seq_rm [40369, end)
slot update_slots: id  1 | task 84075 | prompt processing progress, n_tokens = 40433, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 84075 | prompt done, n_tokens = 40433, batch.n_tokens = 64
slot init_sampler: id  1 | task 84075 | init sampler, took 5.67 ms, tokens: text = 40433, total = 40433
slot update_slots: id  1 | task 84075 | erasing old context checkpoint (pos_min = 35773, pos_max = 36796, size = 24.012 MiB)
slot update_slots: id  1 | task 84075 | created context checkpoint 8 of 8 (pos_min = 39445, pos_max = 40368, size = 21.667 MiB)
slot print_timing: id  1 | task 84075 | 
prompt eval time =     947.71 ms /   497 tokens (    1.91 ms per token,   524.42 tokens per second)
       eval time =    1546.57 ms /    55 tokens (   28.12 ms per token,    35.56 tokens per second)
      total time =    2494.28 ms /   552 tokens
slot      release: id  1 | task 84075 | stop processing: n_tokens = 40487, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 84132 | processing task, is_child = 0
slot update_slots: id  1 | task 84132 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 40859
slot update_slots: id  1 | task 84132 | n_tokens = 40433, memory_seq_rm [40433, end)
slot update_slots: id  1 | task 84132 | prompt processing progress, n_tokens = 40795, batch.n_tokens = 362, progress = 0.998434
slot update_slots: id  1 | task 84132 | n_tokens = 40795, memory_seq_rm [40795, end)
slot update_slots: id  1 | task 84132 | prompt processing progress, n_tokens = 40859, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 84132 | prompt done, n_tokens = 40859, batch.n_tokens = 64
slot init_sampler: id  1 | task 84132 | init sampler, took 8.21 ms, tokens: text = 40859, total = 40859
slot update_slots: id  1 | task 84132 | erasing old context checkpoint (pos_min = 36085, pos_max = 37105, size = 23.942 MiB)
slot update_slots: id  1 | task 84132 | created context checkpoint 8 of 8 (pos_min = 39771, pos_max = 40794, size = 24.012 MiB)
slot print_timing: id  1 | task 84132 | 
prompt eval time =     946.24 ms /   426 tokens (    2.22 ms per token,   450.20 tokens per second)
       eval time =  271138.57 ms /  9319 tokens (   29.10 ms per token,    34.37 tokens per second)
      total time =  272084.81 ms /  9745 tokens
slot      release: id  1 | task 84132 | stop processing: n_tokens = 50177, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.815 (> 0.100 thold), f_keep = 0.814
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 93453 | processing task, is_child = 0
slot update_slots: id  1 | task 93453 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 50137
slot update_slots: id  1 | task 93453 | n_past = 40859, slot.prompt.tokens.size() = 50177, seq_id = 1, pos_min = 49153, n_swa = 128
slot update_slots: id  1 | task 93453 | restored context checkpoint (pos_min = 39771, pos_max = 40794, size = 24.012 MiB)
slot update_slots: id  1 | task 93453 | n_tokens = 40794, memory_seq_rm [40794, end)
slot update_slots: id  1 | task 93453 | prompt processing progress, n_tokens = 42842, batch.n_tokens = 2048, progress = 0.854499
slot update_slots: id  1 | task 93453 | n_tokens = 42842, memory_seq_rm [42842, end)
slot update_slots: id  1 | task 93453 | prompt processing progress, n_tokens = 44890, batch.n_tokens = 2048, progress = 0.895347
slot update_slots: id  1 | task 93453 | n_tokens = 44890, memory_seq_rm [44890, end)
slot update_slots: id  1 | task 93453 | prompt processing progress, n_tokens = 46938, batch.n_tokens = 2048, progress = 0.936195
slot update_slots: id  1 | task 93453 | n_tokens = 46938, memory_seq_rm [46938, end)
slot update_slots: id  1 | task 93453 | prompt processing progress, n_tokens = 48986, batch.n_tokens = 2048, progress = 0.977043
slot update_slots: id  1 | task 93453 | n_tokens = 48986, memory_seq_rm [48986, end)
slot update_slots: id  1 | task 93453 | prompt processing progress, n_tokens = 50073, batch.n_tokens = 1087, progress = 0.998724
slot update_slots: id  1 | task 93453 | n_tokens = 50073, memory_seq_rm [50073, end)
slot update_slots: id  1 | task 93453 | prompt processing progress, n_tokens = 50137, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 93453 | prompt done, n_tokens = 50137, batch.n_tokens = 64
slot init_sampler: id  1 | task 93453 | init sampler, took 7.05 ms, tokens: text = 50137, total = 50137
slot update_slots: id  1 | task 93453 | erasing old context checkpoint (pos_min = 36677, pos_max = 37176, size = 11.725 MiB)
slot update_slots: id  1 | task 93453 | created context checkpoint 8 of 8 (pos_min = 49049, pos_max = 50072, size = 24.012 MiB)
slot print_timing: id  1 | task 93453 | 
prompt eval time =   14469.49 ms /  9343 tokens (    1.55 ms per token,   645.70 tokens per second)
       eval time =   24853.45 ms /   837 tokens (   29.69 ms per token,    33.68 tokens per second)
      total time =   39322.93 ms / 10180 tokens
slot      release: id  1 | task 93453 | stop processing: n_tokens = 50973, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.723 (> 0.100 thold), f_keep = 0.677
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 94296 | processing task, is_child = 0
slot update_slots: id  1 | task 94296 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 47745
slot update_slots: id  1 | task 94296 | n_past = 34527, slot.prompt.tokens.size() = 50973, seq_id = 1, pos_min = 49949, n_swa = 128
slot update_slots: id  1 | task 94296 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  1 | task 94296 | erased invalidated context checkpoint (pos_min = 37114, pos_max = 37609, n_swa = 128, size = 11.631 MiB)
slot update_slots: id  1 | task 94296 | erased invalidated context checkpoint (pos_min = 37333, pos_max = 38229, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  1 | task 94296 | erased invalidated context checkpoint (pos_min = 37820, pos_max = 38843, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  1 | task 94296 | erased invalidated context checkpoint (pos_min = 38475, pos_max = 39244, n_swa = 128, size = 18.056 MiB)
slot update_slots: id  1 | task 94296 | erased invalidated context checkpoint (pos_min = 38908, pos_max = 39871, n_swa = 128, size = 22.605 MiB)
slot update_slots: id  1 | task 94296 | erased invalidated context checkpoint (pos_min = 39445, pos_max = 40368, n_swa = 128, size = 21.667 MiB)
slot update_slots: id  1 | task 94296 | erased invalidated context checkpoint (pos_min = 39771, pos_max = 40794, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  1 | task 94296 | erased invalidated context checkpoint (pos_min = 49049, pos_max = 50072, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  1 | task 94296 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 2048, batch.n_tokens = 2048, progress = 0.042895
slot update_slots: id  1 | task 94296 | n_tokens = 2048, memory_seq_rm [2048, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 4096, batch.n_tokens = 2048, progress = 0.085789
slot update_slots: id  1 | task 94296 | n_tokens = 4096, memory_seq_rm [4096, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 6144, batch.n_tokens = 2048, progress = 0.128684
slot update_slots: id  1 | task 94296 | n_tokens = 6144, memory_seq_rm [6144, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 8192, batch.n_tokens = 2048, progress = 0.171578
slot update_slots: id  1 | task 94296 | n_tokens = 8192, memory_seq_rm [8192, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 10240, batch.n_tokens = 2048, progress = 0.214473
slot update_slots: id  1 | task 94296 | n_tokens = 10240, memory_seq_rm [10240, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 12288, batch.n_tokens = 2048, progress = 0.257367
slot update_slots: id  1 | task 94296 | n_tokens = 12288, memory_seq_rm [12288, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 14336, batch.n_tokens = 2048, progress = 0.300262
slot update_slots: id  1 | task 94296 | n_tokens = 14336, memory_seq_rm [14336, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 16384, batch.n_tokens = 2048, progress = 0.343156
slot update_slots: id  1 | task 94296 | n_tokens = 16384, memory_seq_rm [16384, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 18432, batch.n_tokens = 2048, progress = 0.386051
slot update_slots: id  1 | task 94296 | n_tokens = 18432, memory_seq_rm [18432, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 20480, batch.n_tokens = 2048, progress = 0.428945
slot update_slots: id  1 | task 94296 | n_tokens = 20480, memory_seq_rm [20480, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 22528, batch.n_tokens = 2048, progress = 0.471840
slot update_slots: id  1 | task 94296 | n_tokens = 22528, memory_seq_rm [22528, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 24576, batch.n_tokens = 2048, progress = 0.514735
slot update_slots: id  1 | task 94296 | n_tokens = 24576, memory_seq_rm [24576, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 26624, batch.n_tokens = 2048, progress = 0.557629
slot update_slots: id  1 | task 94296 | n_tokens = 26624, memory_seq_rm [26624, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 28672, batch.n_tokens = 2048, progress = 0.600524
slot update_slots: id  1 | task 94296 | n_tokens = 28672, memory_seq_rm [28672, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 30720, batch.n_tokens = 2048, progress = 0.643418
slot update_slots: id  1 | task 94296 | n_tokens = 30720, memory_seq_rm [30720, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 32768, batch.n_tokens = 2048, progress = 0.686313
slot update_slots: id  1 | task 94296 | n_tokens = 32768, memory_seq_rm [32768, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 34816, batch.n_tokens = 2048, progress = 0.729207
slot update_slots: id  1 | task 94296 | n_tokens = 34816, memory_seq_rm [34816, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 36864, batch.n_tokens = 2048, progress = 0.772102
slot update_slots: id  1 | task 94296 | n_tokens = 36864, memory_seq_rm [36864, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 38912, batch.n_tokens = 2048, progress = 0.814996
slot update_slots: id  1 | task 94296 | n_tokens = 38912, memory_seq_rm [38912, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 40960, batch.n_tokens = 2048, progress = 0.857891
slot update_slots: id  1 | task 94296 | n_tokens = 40960, memory_seq_rm [40960, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 43008, batch.n_tokens = 2048, progress = 0.900785
slot update_slots: id  1 | task 94296 | n_tokens = 43008, memory_seq_rm [43008, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 45056, batch.n_tokens = 2048, progress = 0.943680
slot update_slots: id  1 | task 94296 | n_tokens = 45056, memory_seq_rm [45056, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 47104, batch.n_tokens = 2048, progress = 0.986575
slot update_slots: id  1 | task 94296 | n_tokens = 47104, memory_seq_rm [47104, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 47681, batch.n_tokens = 577, progress = 0.998660
slot update_slots: id  1 | task 94296 | n_tokens = 47681, memory_seq_rm [47681, end)
slot update_slots: id  1 | task 94296 | prompt processing progress, n_tokens = 47745, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 94296 | prompt done, n_tokens = 47745, batch.n_tokens = 64
slot init_sampler: id  1 | task 94296 | init sampler, took 9.67 ms, tokens: text = 47745, total = 47745
slot update_slots: id  1 | task 94296 | created context checkpoint 1 of 8 (pos_min = 46657, pos_max = 47680, size = 24.012 MiB)
slot print_timing: id  1 | task 94296 | 
prompt eval time =   60809.54 ms / 47745 tokens (    1.27 ms per token,   785.16 tokens per second)
       eval time =   45395.62 ms /  1560 tokens (   29.10 ms per token,    34.36 tokens per second)
      total time =  106205.16 ms / 49305 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  1 | task 94296 | stop processing: n_tokens = 49304, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.967 (> 0.100 thold), f_keep = 0.968
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 95881 | processing task, is_child = 0
slot update_slots: id  1 | task 95881 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 49351
slot update_slots: id  1 | task 95881 | n_past = 47745, slot.prompt.tokens.size() = 49304, seq_id = 1, pos_min = 48280, n_swa = 128
slot update_slots: id  1 | task 95881 | restored context checkpoint (pos_min = 46657, pos_max = 47680, size = 24.012 MiB)
slot update_slots: id  1 | task 95881 | n_tokens = 47680, memory_seq_rm [47680, end)
slot update_slots: id  1 | task 95881 | prompt processing progress, n_tokens = 49287, batch.n_tokens = 1607, progress = 0.998703
slot update_slots: id  1 | task 95881 | n_tokens = 49287, memory_seq_rm [49287, end)
slot update_slots: id  1 | task 95881 | prompt processing progress, n_tokens = 49351, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 95881 | prompt done, n_tokens = 49351, batch.n_tokens = 64
slot init_sampler: id  1 | task 95881 | init sampler, took 7.36 ms, tokens: text = 49351, total = 49351
slot update_slots: id  1 | task 95881 | created context checkpoint 2 of 8 (pos_min = 48263, pos_max = 49286, size = 24.012 MiB)
slot print_timing: id  1 | task 95881 | 
prompt eval time =    3245.68 ms /  1671 tokens (    1.94 ms per token,   514.84 tokens per second)
       eval time =    1136.82 ms /    39 tokens (   29.15 ms per token,    34.31 tokens per second)
      total time =    4382.50 ms /  1710 tokens
slot      release: id  1 | task 95881 | stop processing: n_tokens = 49389, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.999 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 95922 | processing task, is_child = 0
slot update_slots: id  1 | task 95922 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 49405
slot update_slots: id  1 | task 95922 | n_tokens = 49351, memory_seq_rm [49351, end)
slot update_slots: id  1 | task 95922 | prompt processing progress, n_tokens = 49405, batch.n_tokens = 54, progress = 1.000000
slot update_slots: id  1 | task 95922 | prompt done, n_tokens = 49405, batch.n_tokens = 54
slot init_sampler: id  1 | task 95922 | init sampler, took 10.70 ms, tokens: text = 49405, total = 49405
slot print_timing: id  1 | task 95922 | 
prompt eval time =     218.44 ms /    54 tokens (    4.05 ms per token,   247.21 tokens per second)
       eval time =    1164.14 ms /    40 tokens (   29.10 ms per token,    34.36 tokens per second)
      total time =    1382.59 ms /    94 tokens
slot      release: id  1 | task 95922 | stop processing: n_tokens = 49444, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 95963 | processing task, is_child = 0
slot update_slots: id  1 | task 95963 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 49487
slot update_slots: id  1 | task 95963 | n_tokens = 49405, memory_seq_rm [49405, end)
slot update_slots: id  1 | task 95963 | prompt processing progress, n_tokens = 49423, batch.n_tokens = 18, progress = 0.998707
slot update_slots: id  1 | task 95963 | n_tokens = 49423, memory_seq_rm [49423, end)
slot update_slots: id  1 | task 95963 | prompt processing progress, n_tokens = 49487, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 95963 | prompt done, n_tokens = 49487, batch.n_tokens = 64
slot init_sampler: id  1 | task 95963 | init sampler, took 9.70 ms, tokens: text = 49487, total = 49487
slot update_slots: id  1 | task 95963 | created context checkpoint 3 of 8 (pos_min = 48420, pos_max = 49422, size = 23.520 MiB)
slot print_timing: id  1 | task 95963 | 
prompt eval time =     448.88 ms /    82 tokens (    5.47 ms per token,   182.68 tokens per second)
       eval time =    5238.27 ms /   176 tokens (   29.76 ms per token,    33.60 tokens per second)
      total time =    5687.15 ms /   258 tokens
slot      release: id  1 | task 95963 | stop processing: n_tokens = 49662, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 96141 | processing task, is_child = 0
slot update_slots: id  1 | task 96141 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 49601
slot update_slots: id  1 | task 96141 | n_tokens = 49487, memory_seq_rm [49487, end)
slot update_slots: id  1 | task 96141 | prompt processing progress, n_tokens = 49537, batch.n_tokens = 50, progress = 0.998710
slot update_slots: id  1 | task 96141 | n_tokens = 49537, memory_seq_rm [49537, end)
slot update_slots: id  1 | task 96141 | prompt processing progress, n_tokens = 49601, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  1 | task 96141 | prompt done, n_tokens = 49601, batch.n_tokens = 64
slot init_sampler: id  1 | task 96141 | init sampler, took 6.84 ms, tokens: text = 49601, total = 49601
slot update_slots: id  1 | task 96141 | created context checkpoint 4 of 8 (pos_min = 48638, pos_max = 49536, size = 21.081 MiB)
slot print_timing: id  1 | task 96141 | 
prompt eval time =     550.05 ms /   114 tokens (    4.83 ms per token,   207.25 tokens per second)
       eval time =    3588.21 ms /   124 tokens (   28.94 ms per token,    34.56 tokens per second)
      total time =    4138.26 ms /   238 tokens
slot      release: id  1 | task 96141 | stop processing: n_tokens = 49724, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.931 (> 0.100 thold), f_keep = 0.012
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 49724, total state size = 1189.988 MiB
