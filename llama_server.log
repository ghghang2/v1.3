ggml_cuda_init: found 1 CUDA devices:
  Device 0: Tesla T4, compute capability 7.5, VMM: yes
common_download_file_single_online: no previous model file found /root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_preset.ini
common_download_file_single_online: HEAD invalid http status code received: 404
no remote preset found, skipping
common_download_file_single_online: no previous model file found /root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-F16.gguf
common_download_file_single_online: trying to download model from https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-F16.gguf to /root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-F16.gguf.downloadInProgress (etag:"78f73a4ef91c8f92d4df971f570ff3719007201f6d955b8695384a1b21b04a80")...
main: n_parallel is set to auto, using n_parallel = 4 and kv_unified = true
build: 7772 (287a33017) with GNU 11.4.0 for Linux x86_64
system info: n_threads = 1, n_threads_batch = 1, total_threads = 2

system_info: n_threads = 1 (n_threads_batch = 1) / 2 | CUDA : ARCHS = 750 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | 

Running without SSL
init: using 6 threads for HTTP server
start: binding port with default address family
main: loading model
srv    load_model: loading model '/root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-F16.gguf'
common_init_result: fitting params to device memory, for bugs during this step try to reproduce them with -fit off, or provide --verbose logs if the bug only occurs with -fit on
srv  log_server_r: request: GET /health 127.0.0.1 503
llama_params_fit_impl: projected to use 15546 MiB of device memory vs. 14992 MiB of free device memory
llama_params_fit_impl: cannot meet free memory target of 1024 MiB, need to reduce device memory by 1578 MiB
srv  log_server_r: request: GET /health 127.0.0.1 503
llama_params_fit_impl: context size reduced from 131072 to 64000 -> need 1580 MiB less memory in total
llama_params_fit_impl: entire model can be fit by reducing context
llama_params_fit: successfully fit params to free device memory
llama_params_fit: fitting params to free memory took 1.92 seconds
llama_model_load_from_file_impl: using device CUDA0 (Tesla T4) (0000:00:04.0) - 14992 MiB free
llama_model_loader: direct I/O is enabled, disabling mmap
llama_model_loader: loaded meta data with 37 key-value pairs and 459 tensors from /root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-F16.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = gpt-oss
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Gpt-Oss-20B
llama_model_loader: - kv   3:                           general.basename str              = Gpt-Oss-20B
llama_model_loader: - kv   4:                       general.quantized_by str              = Unsloth
llama_model_loader: - kv   5:                         general.size_label str              = 20B
llama_model_loader: - kv   6:                            general.license str              = apache-2.0
llama_model_loader: - kv   7:                           general.repo_url str              = https://huggingface.co/unsloth
llama_model_loader: - kv   8:                               general.tags arr[str,2]       = ["vllm", "text-generation"]
llama_model_loader: - kv   9:                        gpt-oss.block_count u32              = 24
llama_model_loader: - kv  10:                     gpt-oss.context_length u32              = 131072
llama_model_loader: - kv  11:                   gpt-oss.embedding_length u32              = 2880
llama_model_loader: - kv  12:                gpt-oss.feed_forward_length u32              = 2880
llama_model_loader: - kv  13:               gpt-oss.attention.head_count u32              = 64
llama_model_loader: - kv  14:            gpt-oss.attention.head_count_kv u32              = 8
llama_model_loader: - kv  15:                     gpt-oss.rope.freq_base f32              = 150000.000000
llama_model_loader: - kv  16:   gpt-oss.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  17:                       gpt-oss.expert_count u32              = 32
llama_model_loader: - kv  18:                  gpt-oss.expert_used_count u32              = 4
llama_model_loader: - kv  19:               gpt-oss.attention.key_length u32              = 64
llama_model_loader: - kv  20:             gpt-oss.attention.value_length u32              = 64
llama_model_loader: - kv  21:                          general.file_type u32              = 1
llama_model_loader: - kv  22:           gpt-oss.attention.sliding_window u32              = 128
llama_model_loader: - kv  23:         gpt-oss.expert_feed_forward_length u32              = 2880
llama_model_loader: - kv  24:                  gpt-oss.rope.scaling.type str              = yarn
llama_model_loader: - kv  25:                gpt-oss.rope.scaling.factor f32              = 32.000000
llama_model_loader: - kv  26: gpt-oss.rope.scaling.original_context_length u32              = 4096
llama_model_loader: - kv  27:               general.quantization_version u32              = 2
llama_model_loader: - kv  28:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  29:                         tokenizer.ggml.pre str              = gpt-4o
llama_model_loader: - kv  30:                      tokenizer.ggml.tokens arr[str,201088]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  31:                  tokenizer.ggml.token_type arr[i32,201088]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  32:                      tokenizer.ggml.merges arr[str,446189]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  33:                tokenizer.ggml.bos_token_id u32              = 199998
llama_model_loader: - kv  34:                tokenizer.ggml.eos_token_id u32              = 200002
llama_model_loader: - kv  35:            tokenizer.ggml.padding_token_id u32              = 200017
llama_model_loader: - kv  36:                    tokenizer.chat_template str              = {# Chat template fixes by Unsloth #}\n...
llama_model_loader: - type  f32:  289 tensors
llama_model_loader: - type  f16:   98 tensors
llama_model_loader: - type mxfp4:   72 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = F16
print_info: file size   = 12.83 GiB (5.27 BPW) 
load: 0 unused tokens
load: setting token '<|message|>' (200008) attribute to USER_DEFINED (16), old attributes: 8
load: setting token '<|start|>' (200006) attribute to USER_DEFINED (16), old attributes: 8
load: setting token '<|constrain|>' (200003) attribute to USER_DEFINED (16), old attributes: 8
load: setting token '<|channel|>' (200005) attribute to USER_DEFINED (16), old attributes: 8
load: printing all EOG tokens:
load:   - 199999 ('<|endoftext|>')
load:   - 200002 ('<|return|>')
load:   - 200007 ('<|end|>')
load:   - 200012 ('<|call|>')
load: special_eog_ids contains both '<|return|>' and '<|call|>', or '<|calls|>' and '<|flush|>' tokens, removing '<|end|>' token from EOG list
load: special tokens cache size = 21
load: token to piece cache size = 1.3332 MB
print_info: arch                  = gpt-oss
print_info: vocab_only            = 0
print_info: no_alloc              = 0
print_info: n_ctx_train           = 131072
print_info: n_embd                = 2880
print_info: n_embd_inp            = 2880
print_info: n_layer               = 24
print_info: n_head                = 64
print_info: n_head_kv             = 8
print_info: n_rot                 = 64
print_info: n_swa                 = 128
print_info: is_swa_any            = 1
print_info: n_embd_head_k         = 64
print_info: n_embd_head_v         = 64
print_info: n_gqa                 = 8
print_info: n_embd_k_gqa          = 512
print_info: n_embd_v_gqa          = 512
print_info: f_norm_eps            = 0.0e+00
print_info: f_norm_rms_eps        = 1.0e-05
print_info: f_clamp_kqv           = 0.0e+00
print_info: f_max_alibi_bias      = 0.0e+00
print_info: f_logit_scale         = 0.0e+00
print_info: f_attn_scale          = 0.0e+00
print_info: n_ff                  = 2880
print_info: n_expert              = 32
print_info: n_expert_used         = 4
print_info: n_expert_groups       = 0
print_info: n_group_used          = 0
print_info: causal attn           = 1
print_info: pooling type          = 0
print_info: rope type             = 2
print_info: rope scaling          = yarn
print_info: freq_base_train       = 150000.0
print_info: freq_scale_train      = 0.03125
print_info: freq_base_swa         = 150000.0
print_info: freq_scale_swa        = 0.03125
print_info: n_ctx_orig_yarn       = 4096
print_info: rope_yarn_log_mul     = 0.0000
print_info: rope_finetuned        = unknown
print_info: model type            = 20B
print_info: model params          = 20.91 B
print_info: general.name          = Gpt-Oss-20B
print_info: n_ff_exp              = 2880
print_info: vocab type            = BPE
print_info: n_vocab               = 201088
print_info: n_merges              = 446189
print_info: BOS token             = 199998 '<|startoftext|>'
print_info: EOS token             = 200002 '<|return|>'
print_info: EOT token             = 199999 '<|endoftext|>'
print_info: PAD token             = 200017 '<|reserved_200017|>'
print_info: LF token              = 198 'Ċ'
print_info: EOG token             = 199999 '<|endoftext|>'
print_info: EOG token             = 200002 '<|return|>'
print_info: EOG token             = 200012 '<|call|>'
print_info: max token length      = 256
load_tensors: loading model tensors, this can take a while... (mmap = false, direct_io = true)
srv  log_server_r: request: GET /health 127.0.0.1 503
load_tensors: offloading output layer to GPU
load_tensors: offloading 23 repeating layers to GPU
load_tensors: offloaded 25/25 layers to GPU
load_tensors:        CUDA0 model buffer size = 12036.68 MiB
load_tensors:    CUDA_Host model buffer size =  1104.61 MiB
.srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
srv  log_server_r: request: GET /health 127.0.0.1 503
srv  log_server_r: request: GET /health 127.0.0.1 503
srv  log_server_r: request: GET /health 127.0.0.1 503
srv  log_server_r: request: GET /health 127.0.0.1 503
.
common_init_result: added <|endoftext|> logit bias = -inf
common_init_result: added <|return|> logit bias = -inf
common_init_result: added <|call|> logit bias = -inf
llama_context: constructing llama_context
llama_context: n_seq_max     = 4
llama_context: n_ctx         = 64000
llama_context: n_ctx_seq     = 64000
llama_context: n_batch       = 2048
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = auto
llama_context: kv_unified    = true
llama_context: freq_base     = 150000.0
llama_context: freq_scale    = 0.03125
llama_context: n_ctx_seq (64000) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_context:  CUDA_Host  output buffer size =     3.07 MiB
llama_kv_cache_iswa: creating non-SWA KV cache, size = 64000 cells
llama_kv_cache:      CUDA0 KV buffer size =  1500.00 MiB
llama_kv_cache: size = 1500.00 MiB ( 64000 cells,  12 layers,  4/1 seqs), K (f16):  750.00 MiB, V (f16):  750.00 MiB
llama_kv_cache_iswa: creating     SWA KV cache, size = 1024 cells
llama_kv_cache:      CUDA0 KV buffer size =    24.00 MiB
llama_kv_cache: size =   24.00 MiB (  1024 cells,  12 layers,  4/1 seqs), K (f16):   12.00 MiB, V (f16):   12.00 MiB
sched_reserve: reserving ...
sched_reserve: Flash Attention was auto, set to enabled
sched_reserve:      CUDA0 compute buffer size =   398.38 MiB
sched_reserve:  CUDA_Host compute buffer size =   132.65 MiB
sched_reserve: graph nodes  = 1352
sched_reserve: graph splits = 2
sched_reserve: reserve took 64.82 ms, sched copies = 1
common_init_from_params: warming up the model with an empty run - please wait ... (--no-warmup to disable)
srv    load_model: initializing slots, n_slots = 4
slot   load_model: id  0 | task -1 | new slot, n_ctx = 64000
slot   load_model: id  1 | task -1 | new slot, n_ctx = 64000
slot   load_model: id  2 | task -1 | new slot, n_ctx = 64000
slot   load_model: id  3 | task -1 | new slot, n_ctx = 64000
srv    load_model: prompt cache is enabled, size limit: 8192 MiB
srv    load_model: use `--cache-ram 0` to disable the prompt cache
srv    load_model: for more info see https://github.com/ggml-org/llama.cpp/pull/16391
srv    load_model: thinking = 0
load_model: chat template, example_format: '<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2026-02-08

Reasoning: medium

# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions

You are a helpful assistant<|end|><|start|>user<|message|>Hello<|end|><|start|>assistant<|channel|>final<|message|>Hi there<|end|><|start|>user<|message|>How are you?<|end|><|start|>assistant'
main: model loaded
main: server is listening on http://127.0.0.1:8000
main: starting the main loop...
srv  update_slots: all slots are idle
srv  log_server_r: request: GET /health 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LRU, t_last = -1
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 0 | processing task, is_child = 0
slot update_slots: id  3 | task 0 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 477
slot update_slots: id  3 | task 0 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  3 | task 0 | prompt processing progress, n_tokens = 413, batch.n_tokens = 413, progress = 0.865828
slot update_slots: id  3 | task 0 | n_tokens = 413, memory_seq_rm [413, end)
slot update_slots: id  3 | task 0 | prompt processing progress, n_tokens = 477, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 0 | prompt done, n_tokens = 477, batch.n_tokens = 64
slot init_sampler: id  3 | task 0 | init sampler, took 0.08 ms, tokens: text = 477, total = 477
slot update_slots: id  3 | task 0 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 412, size = 9.685 MiB)
slot print_timing: id  3 | task 0 | 
prompt eval time =     863.02 ms /   477 tokens (    1.81 ms per token,   552.71 tokens per second)
       eval time =    1348.78 ms /    62 tokens (   21.75 ms per token,    45.97 tokens per second)
      total time =    2211.80 ms /   539 tokens
slot      release: id  3 | task 0 | stop processing: n_tokens = 538, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.507 (> 0.100 thold), f_keep = 0.887
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 64 | processing task, is_child = 0
slot update_slots: id  3 | task 64 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 940
slot update_slots: id  3 | task 64 | n_tokens = 477, memory_seq_rm [477, end)
slot update_slots: id  3 | task 64 | prompt processing progress, n_tokens = 876, batch.n_tokens = 399, progress = 0.931915
slot update_slots: id  3 | task 64 | n_tokens = 876, memory_seq_rm [876, end)
slot update_slots: id  3 | task 64 | prompt processing progress, n_tokens = 940, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 64 | prompt done, n_tokens = 940, batch.n_tokens = 64
slot init_sampler: id  3 | task 64 | init sampler, took 0.17 ms, tokens: text = 940, total = 940
slot update_slots: id  3 | task 64 | created context checkpoint 2 of 8 (pos_min = 0, pos_max = 875, size = 20.542 MiB)
slot print_timing: id  3 | task 64 | 
prompt eval time =     488.07 ms /   463 tokens (    1.05 ms per token,   948.63 tokens per second)
       eval time =    1335.12 ms /    59 tokens (   22.63 ms per token,    44.19 tokens per second)
      total time =    1823.19 ms /   522 tokens
slot      release: id  3 | task 64 | stop processing: n_tokens = 998, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.517 (> 0.100 thold), f_keep = 0.942
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 125 | processing task, is_child = 0
slot update_slots: id  3 | task 125 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1818
slot update_slots: id  3 | task 125 | n_tokens = 940, memory_seq_rm [940, end)
slot update_slots: id  3 | task 125 | prompt processing progress, n_tokens = 1754, batch.n_tokens = 814, progress = 0.964796
slot update_slots: id  3 | task 125 | n_tokens = 1754, memory_seq_rm [1754, end)
slot update_slots: id  3 | task 125 | prompt processing progress, n_tokens = 1818, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 125 | prompt done, n_tokens = 1818, batch.n_tokens = 64
slot init_sampler: id  3 | task 125 | init sampler, took 0.30 ms, tokens: text = 1818, total = 1818
slot update_slots: id  3 | task 125 | created context checkpoint 3 of 8 (pos_min = 730, pos_max = 1753, size = 24.012 MiB)
slot print_timing: id  3 | task 125 | 
prompt eval time =     924.11 ms /   878 tokens (    1.05 ms per token,   950.11 tokens per second)
       eval time =    1284.65 ms /    57 tokens (   22.54 ms per token,    44.37 tokens per second)
      total time =    2208.76 ms /   935 tokens
slot      release: id  3 | task 125 | stop processing: n_tokens = 1874, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.482 (> 0.100 thold), f_keep = 0.970
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 184 | processing task, is_child = 0
slot update_slots: id  3 | task 184 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3768
slot update_slots: id  3 | task 184 | n_tokens = 1818, memory_seq_rm [1818, end)
slot update_slots: id  3 | task 184 | prompt processing progress, n_tokens = 3704, batch.n_tokens = 1886, progress = 0.983015
slot update_slots: id  3 | task 184 | n_tokens = 3704, memory_seq_rm [3704, end)
slot update_slots: id  3 | task 184 | prompt processing progress, n_tokens = 3768, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 184 | prompt done, n_tokens = 3768, batch.n_tokens = 64
slot init_sampler: id  3 | task 184 | init sampler, took 0.99 ms, tokens: text = 3768, total = 3768
slot update_slots: id  3 | task 184 | created context checkpoint 4 of 8 (pos_min = 2680, pos_max = 3703, size = 24.012 MiB)
slot print_timing: id  3 | task 184 | 
prompt eval time =    1904.26 ms /  1950 tokens (    0.98 ms per token,  1024.02 tokens per second)
       eval time =    5623.24 ms /   245 tokens (   22.95 ms per token,    43.57 tokens per second)
      total time =    7527.50 ms /  2195 tokens
slot      release: id  3 | task 184 | stop processing: n_tokens = 4012, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.801 (> 0.100 thold), f_keep = 0.939
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 431 | processing task, is_child = 0
slot update_slots: id  3 | task 431 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4703
slot update_slots: id  3 | task 431 | n_tokens = 3768, memory_seq_rm [3768, end)
slot update_slots: id  3 | task 431 | prompt processing progress, n_tokens = 4639, batch.n_tokens = 871, progress = 0.986392
slot update_slots: id  3 | task 431 | n_tokens = 4639, memory_seq_rm [4639, end)
slot update_slots: id  3 | task 431 | prompt processing progress, n_tokens = 4703, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 431 | prompt done, n_tokens = 4703, batch.n_tokens = 64
slot init_sampler: id  3 | task 431 | init sampler, took 0.85 ms, tokens: text = 4703, total = 4703
slot update_slots: id  3 | task 431 | created context checkpoint 5 of 8 (pos_min = 3615, pos_max = 4638, size = 24.012 MiB)
slot print_timing: id  3 | task 431 | 
prompt eval time =    1036.04 ms /   935 tokens (    1.11 ms per token,   902.47 tokens per second)
       eval time =    4566.59 ms /   198 tokens (   23.06 ms per token,    43.36 tokens per second)
      total time =    5602.64 ms /  1133 tokens
slot      release: id  3 | task 431 | stop processing: n_tokens = 4900, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.887 (> 0.100 thold), f_keep = 0.960
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 631 | processing task, is_child = 0
slot update_slots: id  3 | task 631 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5305
slot update_slots: id  3 | task 631 | n_tokens = 4703, memory_seq_rm [4703, end)
slot update_slots: id  3 | task 631 | prompt processing progress, n_tokens = 5241, batch.n_tokens = 538, progress = 0.987936
slot update_slots: id  3 | task 631 | n_tokens = 5241, memory_seq_rm [5241, end)
slot update_slots: id  3 | task 631 | prompt processing progress, n_tokens = 5305, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 631 | prompt done, n_tokens = 5305, batch.n_tokens = 64
slot init_sampler: id  3 | task 631 | init sampler, took 1.15 ms, tokens: text = 5305, total = 5305
slot update_slots: id  3 | task 631 | created context checkpoint 6 of 8 (pos_min = 4217, pos_max = 5240, size = 24.012 MiB)
slot print_timing: id  3 | task 631 | 
prompt eval time =     744.67 ms /   602 tokens (    1.24 ms per token,   808.41 tokens per second)
       eval time =   17640.16 ms /   743 tokens (   23.74 ms per token,    42.12 tokens per second)
      total time =   18384.83 ms /  1345 tokens
slot      release: id  3 | task 631 | stop processing: n_tokens = 6047, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.877
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1376 | processing task, is_child = 0
slot update_slots: id  3 | task 1376 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5365
slot update_slots: id  3 | task 1376 | n_tokens = 5305, memory_seq_rm [5305, end)
slot update_slots: id  3 | task 1376 | prompt processing progress, n_tokens = 5365, batch.n_tokens = 60, progress = 1.000000
slot update_slots: id  3 | task 1376 | prompt done, n_tokens = 5365, batch.n_tokens = 60
slot init_sampler: id  3 | task 1376 | init sampler, took 0.83 ms, tokens: text = 5365, total = 5365
slot print_timing: id  3 | task 1376 | 
prompt eval time =     148.59 ms /    60 tokens (    2.48 ms per token,   403.81 tokens per second)
       eval time =   18635.54 ms /   767 tokens (   24.30 ms per token,    41.16 tokens per second)
      total time =   18784.13 ms /   827 tokens
slot      release: id  3 | task 1376 | stop processing: n_tokens = 6131, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.972 (> 0.100 thold), f_keep = 0.875
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 2144 | processing task, is_child = 0
slot update_slots: id  3 | task 2144 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5521
slot update_slots: id  3 | task 2144 | n_tokens = 5365, memory_seq_rm [5365, end)
slot update_slots: id  3 | task 2144 | prompt processing progress, n_tokens = 5457, batch.n_tokens = 92, progress = 0.988408
slot update_slots: id  3 | task 2144 | n_tokens = 5457, memory_seq_rm [5457, end)
slot update_slots: id  3 | task 2144 | prompt processing progress, n_tokens = 5521, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 2144 | prompt done, n_tokens = 5521, batch.n_tokens = 64
slot init_sampler: id  3 | task 2144 | init sampler, took 1.39 ms, tokens: text = 5521, total = 5521
slot update_slots: id  3 | task 2144 | created context checkpoint 7 of 8 (pos_min = 5107, pos_max = 5456, size = 8.207 MiB)
slot print_timing: id  3 | task 2144 | 
prompt eval time =     411.77 ms /   156 tokens (    2.64 ms per token,   378.85 tokens per second)
       eval time =   14368.36 ms /   576 tokens (   24.95 ms per token,    40.09 tokens per second)
      total time =   14780.13 ms /   732 tokens
slot      release: id  3 | task 2144 | stop processing: n_tokens = 6096, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.929 (> 0.100 thold), f_keep = 0.906
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 2722 | processing task, is_child = 0
slot update_slots: id  3 | task 2722 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5944
slot update_slots: id  3 | task 2722 | n_tokens = 5521, memory_seq_rm [5521, end)
slot update_slots: id  3 | task 2722 | prompt processing progress, n_tokens = 5880, batch.n_tokens = 359, progress = 0.989233
slot update_slots: id  3 | task 2722 | n_tokens = 5880, memory_seq_rm [5880, end)
slot update_slots: id  3 | task 2722 | prompt processing progress, n_tokens = 5944, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 2722 | prompt done, n_tokens = 5944, batch.n_tokens = 64
slot init_sampler: id  3 | task 2722 | init sampler, took 0.94 ms, tokens: text = 5944, total = 5944
slot update_slots: id  3 | task 2722 | created context checkpoint 8 of 8 (pos_min = 5107, pos_max = 5879, size = 18.126 MiB)
slot print_timing: id  3 | task 2722 | 
prompt eval time =     607.18 ms /   423 tokens (    1.44 ms per token,   696.66 tokens per second)
       eval time =    1340.94 ms /    50 tokens (   26.82 ms per token,    37.29 tokens per second)
      total time =    1948.12 ms /   473 tokens
slot      release: id  3 | task 2722 | stop processing: n_tokens = 5993, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.899 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 2774 | processing task, is_child = 0
slot update_slots: id  3 | task 2774 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6613
slot update_slots: id  3 | task 2774 | n_tokens = 5944, memory_seq_rm [5944, end)
slot update_slots: id  3 | task 2774 | prompt processing progress, n_tokens = 6549, batch.n_tokens = 605, progress = 0.990322
slot update_slots: id  3 | task 2774 | n_tokens = 6549, memory_seq_rm [6549, end)
slot update_slots: id  3 | task 2774 | prompt processing progress, n_tokens = 6613, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 2774 | prompt done, n_tokens = 6613, batch.n_tokens = 64
slot init_sampler: id  3 | task 2774 | init sampler, took 1.04 ms, tokens: text = 6613, total = 6613
slot update_slots: id  3 | task 2774 | erasing old context checkpoint (pos_min = 0, pos_max = 412, size = 9.685 MiB)
slot update_slots: id  3 | task 2774 | created context checkpoint 8 of 8 (pos_min = 5525, pos_max = 6548, size = 24.012 MiB)
slot print_timing: id  3 | task 2774 | 
prompt eval time =     995.27 ms /   669 tokens (    1.49 ms per token,   672.18 tokens per second)
       eval time =    6052.76 ms /   234 tokens (   25.87 ms per token,    38.66 tokens per second)
      total time =    7048.03 ms /   903 tokens
slot      release: id  3 | task 2774 | stop processing: n_tokens = 6846, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.981 (> 0.100 thold), f_keep = 0.966
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3010 | processing task, is_child = 0
slot update_slots: id  3 | task 3010 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6739
slot update_slots: id  3 | task 3010 | n_tokens = 6613, memory_seq_rm [6613, end)
slot update_slots: id  3 | task 3010 | prompt processing progress, n_tokens = 6675, batch.n_tokens = 62, progress = 0.990503
slot update_slots: id  3 | task 3010 | n_tokens = 6675, memory_seq_rm [6675, end)
slot update_slots: id  3 | task 3010 | prompt processing progress, n_tokens = 6739, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3010 | prompt done, n_tokens = 6739, batch.n_tokens = 64
slot init_sampler: id  3 | task 3010 | init sampler, took 1.01 ms, tokens: text = 6739, total = 6739
slot update_slots: id  3 | task 3010 | erasing old context checkpoint (pos_min = 0, pos_max = 875, size = 20.542 MiB)
slot update_slots: id  3 | task 3010 | created context checkpoint 8 of 8 (pos_min = 5822, pos_max = 6674, size = 20.002 MiB)
slot print_timing: id  3 | task 3010 | 
prompt eval time =     383.81 ms /   126 tokens (    3.05 ms per token,   328.29 tokens per second)
       eval time =   10641.06 ms /   405 tokens (   26.27 ms per token,    38.06 tokens per second)
      total time =   11024.87 ms /   531 tokens
slot      release: id  3 | task 3010 | stop processing: n_tokens = 7143, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.965 (> 0.100 thold), f_keep = 0.943
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3417 | processing task, is_child = 0
slot update_slots: id  3 | task 3417 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6981
slot update_slots: id  3 | task 3417 | n_tokens = 6739, memory_seq_rm [6739, end)
slot update_slots: id  3 | task 3417 | prompt processing progress, n_tokens = 6917, batch.n_tokens = 178, progress = 0.990832
slot update_slots: id  3 | task 3417 | n_tokens = 6917, memory_seq_rm [6917, end)
slot update_slots: id  3 | task 3417 | prompt processing progress, n_tokens = 6981, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3417 | prompt done, n_tokens = 6981, batch.n_tokens = 64
slot init_sampler: id  3 | task 3417 | init sampler, took 1.02 ms, tokens: text = 6981, total = 6981
slot update_slots: id  3 | task 3417 | erasing old context checkpoint (pos_min = 730, pos_max = 1753, size = 24.012 MiB)
slot update_slots: id  3 | task 3417 | created context checkpoint 8 of 8 (pos_min = 6119, pos_max = 6916, size = 18.713 MiB)
slot print_timing: id  3 | task 3417 | 
prompt eval time =     475.63 ms /   242 tokens (    1.97 ms per token,   508.80 tokens per second)
       eval time =    1400.01 ms /    54 tokens (   25.93 ms per token,    38.57 tokens per second)
      total time =    1875.64 ms /   296 tokens
slot      release: id  3 | task 3417 | stop processing: n_tokens = 7034, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3473 | processing task, is_child = 0
slot update_slots: id  3 | task 3473 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7055
slot update_slots: id  3 | task 3473 | n_tokens = 6981, memory_seq_rm [6981, end)
slot update_slots: id  3 | task 3473 | prompt processing progress, n_tokens = 6991, batch.n_tokens = 10, progress = 0.990928
slot update_slots: id  3 | task 3473 | n_tokens = 6991, memory_seq_rm [6991, end)
slot update_slots: id  3 | task 3473 | prompt processing progress, n_tokens = 7055, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3473 | prompt done, n_tokens = 7055, batch.n_tokens = 64
slot init_sampler: id  3 | task 3473 | init sampler, took 1.05 ms, tokens: text = 7055, total = 7055
slot update_slots: id  3 | task 3473 | erasing old context checkpoint (pos_min = 2680, pos_max = 3703, size = 24.012 MiB)
slot update_slots: id  3 | task 3473 | created context checkpoint 8 of 8 (pos_min = 6119, pos_max = 6990, size = 20.448 MiB)
slot print_timing: id  3 | task 3473 | 
prompt eval time =     266.29 ms /    74 tokens (    3.60 ms per token,   277.89 tokens per second)
       eval time =     770.10 ms /    29 tokens (   26.56 ms per token,    37.66 tokens per second)
      total time =    1036.39 ms /   103 tokens
slot      release: id  3 | task 3473 | stop processing: n_tokens = 7083, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3504 | processing task, is_child = 0
slot update_slots: id  3 | task 3504 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7121
slot update_slots: id  3 | task 3504 | n_tokens = 7055, memory_seq_rm [7055, end)
slot update_slots: id  3 | task 3504 | prompt processing progress, n_tokens = 7057, batch.n_tokens = 2, progress = 0.991013
slot update_slots: id  3 | task 3504 | n_tokens = 7057, memory_seq_rm [7057, end)
slot update_slots: id  3 | task 3504 | prompt processing progress, n_tokens = 7121, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3504 | prompt done, n_tokens = 7121, batch.n_tokens = 64
slot init_sampler: id  3 | task 3504 | init sampler, took 1.04 ms, tokens: text = 7121, total = 7121
slot update_slots: id  3 | task 3504 | erasing old context checkpoint (pos_min = 3615, pos_max = 4638, size = 24.012 MiB)
slot update_slots: id  3 | task 3504 | created context checkpoint 8 of 8 (pos_min = 6119, pos_max = 7056, size = 21.995 MiB)
slot print_timing: id  3 | task 3504 | 
prompt eval time =     313.62 ms /    66 tokens (    4.75 ms per token,   210.45 tokens per second)
       eval time =    1023.86 ms /    42 tokens (   24.38 ms per token,    41.02 tokens per second)
      total time =    1337.48 ms /   108 tokens
slot      release: id  3 | task 3504 | stop processing: n_tokens = 7162, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.252 (> 0.100 thold), f_keep = 0.064
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 7162, total state size = 191.954 MiB
srv          load:  - looking for better prompt, base f_keep = 0.064, sim = 0.252
srv        update:  - cache state: 1 prompts, 347.469 MiB (limits: 8192.000 MiB, 64000 tokens, 168852 est)
srv        update:    - prompt 0x55a5f0b7a5c0:    7162 tokens, checkpoints:  8,   347.469 MiB
srv  get_availabl: prompt cache update took 250.58 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3548 | processing task, is_child = 0
slot update_slots: id  3 | task 3548 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1818
slot update_slots: id  3 | task 3548 | n_past = 459, slot.prompt.tokens.size() = 7162, seq_id = 3, pos_min = 6138, n_swa = 128
slot update_slots: id  3 | task 3548 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  3 | task 3548 | erased invalidated context checkpoint (pos_min = 4217, pos_max = 5240, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 3548 | erased invalidated context checkpoint (pos_min = 5107, pos_max = 5456, n_swa = 128, size = 8.207 MiB)
slot update_slots: id  3 | task 3548 | erased invalidated context checkpoint (pos_min = 5107, pos_max = 5879, n_swa = 128, size = 18.126 MiB)
slot update_slots: id  3 | task 3548 | erased invalidated context checkpoint (pos_min = 5525, pos_max = 6548, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 3548 | erased invalidated context checkpoint (pos_min = 5822, pos_max = 6674, n_swa = 128, size = 20.002 MiB)
slot update_slots: id  3 | task 3548 | erased invalidated context checkpoint (pos_min = 6119, pos_max = 6916, n_swa = 128, size = 18.713 MiB)
slot update_slots: id  3 | task 3548 | erased invalidated context checkpoint (pos_min = 6119, pos_max = 6990, n_swa = 128, size = 20.448 MiB)
slot update_slots: id  3 | task 3548 | erased invalidated context checkpoint (pos_min = 6119, pos_max = 7056, n_swa = 128, size = 21.995 MiB)
slot update_slots: id  3 | task 3548 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  3 | task 3548 | prompt processing progress, n_tokens = 1754, batch.n_tokens = 1754, progress = 0.964796
slot update_slots: id  3 | task 3548 | n_tokens = 1754, memory_seq_rm [1754, end)
slot update_slots: id  3 | task 3548 | prompt processing progress, n_tokens = 1818, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3548 | prompt done, n_tokens = 1818, batch.n_tokens = 64
slot init_sampler: id  3 | task 3548 | init sampler, took 0.34 ms, tokens: text = 1818, total = 1818
slot update_slots: id  3 | task 3548 | created context checkpoint 1 of 8 (pos_min = 730, pos_max = 1753, size = 24.012 MiB)
slot print_timing: id  3 | task 3548 | 
prompt eval time =    1996.37 ms /  1818 tokens (    1.10 ms per token,   910.65 tokens per second)
       eval time =    1310.83 ms /    54 tokens (   24.27 ms per token,    41.20 tokens per second)
      total time =    3307.20 ms /  1872 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 3548 | stop processing: n_tokens = 1871, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.660 (> 0.100 thold), f_keep = 0.972
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3604 | processing task, is_child = 0
slot update_slots: id  3 | task 3604 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2753
slot update_slots: id  3 | task 3604 | n_tokens = 1818, memory_seq_rm [1818, end)
slot update_slots: id  3 | task 3604 | prompt processing progress, n_tokens = 2689, batch.n_tokens = 871, progress = 0.976753
slot update_slots: id  3 | task 3604 | n_tokens = 2689, memory_seq_rm [2689, end)
slot update_slots: id  3 | task 3604 | prompt processing progress, n_tokens = 2753, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3604 | prompt done, n_tokens = 2753, batch.n_tokens = 64
slot init_sampler: id  3 | task 3604 | init sampler, took 0.56 ms, tokens: text = 2753, total = 2753
slot update_slots: id  3 | task 3604 | created context checkpoint 2 of 8 (pos_min = 1665, pos_max = 2688, size = 24.012 MiB)
slot print_timing: id  3 | task 3604 | 
prompt eval time =    1108.92 ms /   935 tokens (    1.19 ms per token,   843.16 tokens per second)
       eval time =   11377.31 ms /   467 tokens (   24.36 ms per token,    41.05 tokens per second)
      total time =   12486.23 ms /  1402 tokens
slot      release: id  3 | task 3604 | stop processing: n_tokens = 3219, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.787 (> 0.100 thold), f_keep = 0.559
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4073 | processing task, is_child = 0
slot update_slots: id  3 | task 4073 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2285
slot update_slots: id  3 | task 4073 | n_past = 1799, slot.prompt.tokens.size() = 3219, seq_id = 3, pos_min = 2195, n_swa = 128
slot update_slots: id  3 | task 4073 | restored context checkpoint (pos_min = 1665, pos_max = 2688, size = 24.012 MiB)
slot update_slots: id  3 | task 4073 | n_tokens = 1799, memory_seq_rm [1799, end)
slot update_slots: id  3 | task 4073 | prompt processing progress, n_tokens = 2221, batch.n_tokens = 422, progress = 0.971991
slot update_slots: id  3 | task 4073 | n_tokens = 2221, memory_seq_rm [2221, end)
slot update_slots: id  3 | task 4073 | prompt processing progress, n_tokens = 2285, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4073 | prompt done, n_tokens = 2285, batch.n_tokens = 64
slot init_sampler: id  3 | task 4073 | init sampler, took 0.48 ms, tokens: text = 2285, total = 2285
slot print_timing: id  3 | task 4073 | 
prompt eval time =     640.55 ms /   486 tokens (    1.32 ms per token,   758.72 tokens per second)
       eval time =   12509.91 ms /   492 tokens (   25.43 ms per token,    39.33 tokens per second)
      total time =   13150.47 ms /   978 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 4073 | stop processing: n_tokens = 2776, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.830 (> 0.100 thold), f_keep = 0.817
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4567 | processing task, is_child = 0
slot update_slots: id  3 | task 4567 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2730
slot update_slots: id  3 | task 4567 | n_tokens = 2267, memory_seq_rm [2267, end)
slot update_slots: id  3 | task 4567 | prompt processing progress, n_tokens = 2666, batch.n_tokens = 399, progress = 0.976557
slot update_slots: id  3 | task 4567 | n_tokens = 2666, memory_seq_rm [2666, end)
slot update_slots: id  3 | task 4567 | prompt processing progress, n_tokens = 2730, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4567 | prompt done, n_tokens = 2730, batch.n_tokens = 64
slot init_sampler: id  3 | task 4567 | init sampler, took 0.51 ms, tokens: text = 2730, total = 2730
slot print_timing: id  3 | task 4567 | 
prompt eval time =     641.49 ms /   463 tokens (    1.39 ms per token,   721.76 tokens per second)
       eval time =    1089.03 ms /    45 tokens (   24.20 ms per token,    41.32 tokens per second)
      total time =    1730.51 ms /   508 tokens
slot      release: id  3 | task 4567 | stop processing: n_tokens = 2774, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.825 (> 0.100 thold), f_keep = 0.984
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4614 | processing task, is_child = 0
slot update_slots: id  3 | task 4614 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3311
slot update_slots: id  3 | task 4614 | n_tokens = 2730, memory_seq_rm [2730, end)
slot update_slots: id  3 | task 4614 | prompt processing progress, n_tokens = 3247, batch.n_tokens = 517, progress = 0.980671
slot update_slots: id  3 | task 4614 | n_tokens = 3247, memory_seq_rm [3247, end)
slot update_slots: id  3 | task 4614 | prompt processing progress, n_tokens = 3311, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4614 | prompt done, n_tokens = 3311, batch.n_tokens = 64
slot init_sampler: id  3 | task 4614 | init sampler, took 0.51 ms, tokens: text = 3311, total = 3311
slot update_slots: id  3 | task 4614 | created context checkpoint 3 of 8 (pos_min = 2223, pos_max = 3246, size = 24.012 MiB)
slot print_timing: id  3 | task 4614 | 
prompt eval time =     694.58 ms /   581 tokens (    1.20 ms per token,   836.48 tokens per second)
       eval time =   15612.34 ms /   618 tokens (   25.26 ms per token,    39.58 tokens per second)
      total time =   16306.91 ms /  1199 tokens
slot      release: id  3 | task 4614 | stop processing: n_tokens = 3928, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.906 (> 0.100 thold), f_keep = 0.843
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5234 | processing task, is_child = 0
slot update_slots: id  3 | task 5234 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3656
slot update_slots: id  3 | task 5234 | n_tokens = 3311, memory_seq_rm [3311, end)
slot update_slots: id  3 | task 5234 | prompt processing progress, n_tokens = 3592, batch.n_tokens = 281, progress = 0.982495
slot update_slots: id  3 | task 5234 | n_tokens = 3592, memory_seq_rm [3592, end)
slot update_slots: id  3 | task 5234 | prompt processing progress, n_tokens = 3656, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5234 | prompt done, n_tokens = 3656, batch.n_tokens = 64
slot init_sampler: id  3 | task 5234 | init sampler, took 0.58 ms, tokens: text = 3656, total = 3656
slot update_slots: id  3 | task 5234 | created context checkpoint 4 of 8 (pos_min = 3104, pos_max = 3591, size = 11.443 MiB)
slot print_timing: id  3 | task 5234 | 
prompt eval time =     515.90 ms /   345 tokens (    1.50 ms per token,   668.74 tokens per second)
       eval time =     635.06 ms /    25 tokens (   25.40 ms per token,    39.37 tokens per second)
      total time =    1150.95 ms /   370 tokens
slot      release: id  3 | task 5234 | stop processing: n_tokens = 3680, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.939 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5261 | processing task, is_child = 0
slot update_slots: id  3 | task 5261 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3894
slot update_slots: id  3 | task 5261 | n_tokens = 3656, memory_seq_rm [3656, end)
slot update_slots: id  3 | task 5261 | prompt processing progress, n_tokens = 3830, batch.n_tokens = 174, progress = 0.983564
slot update_slots: id  3 | task 5261 | n_tokens = 3830, memory_seq_rm [3830, end)
slot update_slots: id  3 | task 5261 | prompt processing progress, n_tokens = 3894, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5261 | prompt done, n_tokens = 3894, batch.n_tokens = 64
slot init_sampler: id  3 | task 5261 | init sampler, took 0.58 ms, tokens: text = 3894, total = 3894
slot update_slots: id  3 | task 5261 | created context checkpoint 5 of 8 (pos_min = 3311, pos_max = 3829, size = 12.170 MiB)
slot print_timing: id  3 | task 5261 | 
prompt eval time =     447.81 ms /   238 tokens (    1.88 ms per token,   531.47 tokens per second)
       eval time =    1434.26 ms /    55 tokens (   26.08 ms per token,    38.35 tokens per second)
      total time =    1882.08 ms /   293 tokens
slot      release: id  3 | task 5261 | stop processing: n_tokens = 3948, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.662 (> 0.100 thold), f_keep = 0.986
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5318 | processing task, is_child = 0
slot update_slots: id  3 | task 5318 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5878
slot update_slots: id  3 | task 5318 | n_tokens = 3894, memory_seq_rm [3894, end)
slot update_slots: id  3 | task 5318 | prompt processing progress, n_tokens = 5814, batch.n_tokens = 1920, progress = 0.989112
slot update_slots: id  3 | task 5318 | n_tokens = 5814, memory_seq_rm [5814, end)
slot update_slots: id  3 | task 5318 | prompt processing progress, n_tokens = 5878, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5318 | prompt done, n_tokens = 5878, batch.n_tokens = 64
slot init_sampler: id  3 | task 5318 | init sampler, took 1.12 ms, tokens: text = 5878, total = 5878
slot update_slots: id  3 | task 5318 | created context checkpoint 6 of 8 (pos_min = 4790, pos_max = 5813, size = 24.012 MiB)
slot print_timing: id  3 | task 5318 | 
prompt eval time =    2318.28 ms /  1984 tokens (    1.17 ms per token,   855.81 tokens per second)
       eval time =    2939.40 ms /   113 tokens (   26.01 ms per token,    38.44 tokens per second)
      total time =    5257.68 ms /  2097 tokens
slot      release: id  3 | task 5318 | stop processing: n_tokens = 5990, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.979 (> 0.100 thold), f_keep = 0.981
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5433 | processing task, is_child = 0
slot update_slots: id  3 | task 5433 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6003
slot update_slots: id  3 | task 5433 | n_tokens = 5878, memory_seq_rm [5878, end)
slot update_slots: id  3 | task 5433 | prompt processing progress, n_tokens = 5939, batch.n_tokens = 61, progress = 0.989339
slot update_slots: id  3 | task 5433 | n_tokens = 5939, memory_seq_rm [5939, end)
slot update_slots: id  3 | task 5433 | prompt processing progress, n_tokens = 6003, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5433 | prompt done, n_tokens = 6003, batch.n_tokens = 64
slot init_sampler: id  3 | task 5433 | init sampler, took 0.90 ms, tokens: text = 6003, total = 6003
slot update_slots: id  3 | task 5433 | created context checkpoint 7 of 8 (pos_min = 4966, pos_max = 5938, size = 22.816 MiB)
slot print_timing: id  3 | task 5433 | 
prompt eval time =     345.33 ms /   125 tokens (    2.76 ms per token,   361.98 tokens per second)
       eval time =     373.32 ms /    14 tokens (   26.67 ms per token,    37.50 tokens per second)
      total time =     718.64 ms /   139 tokens
slot      release: id  3 | task 5433 | stop processing: n_tokens = 6016, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.821 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5449 | processing task, is_child = 0
slot update_slots: id  3 | task 5449 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7315
slot update_slots: id  3 | task 5449 | n_tokens = 6003, memory_seq_rm [6003, end)
slot update_slots: id  3 | task 5449 | prompt processing progress, n_tokens = 7251, batch.n_tokens = 1248, progress = 0.991251
slot update_slots: id  3 | task 5449 | n_tokens = 7251, memory_seq_rm [7251, end)
slot update_slots: id  3 | task 5449 | prompt processing progress, n_tokens = 7315, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5449 | prompt done, n_tokens = 7315, batch.n_tokens = 64
slot init_sampler: id  3 | task 5449 | init sampler, took 1.11 ms, tokens: text = 7315, total = 7315
slot update_slots: id  3 | task 5449 | created context checkpoint 8 of 8 (pos_min = 6227, pos_max = 7250, size = 24.012 MiB)
slot print_timing: id  3 | task 5449 | 
prompt eval time =    1631.99 ms /  1312 tokens (    1.24 ms per token,   803.93 tokens per second)
       eval time =    6018.15 ms /   234 tokens (   25.72 ms per token,    38.88 tokens per second)
      total time =    7650.14 ms /  1546 tokens
slot      release: id  3 | task 5449 | stop processing: n_tokens = 7548, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.976 (> 0.100 thold), f_keep = 0.969
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5685 | processing task, is_child = 0
slot update_slots: id  3 | task 5685 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7497
slot update_slots: id  3 | task 5685 | n_tokens = 7315, memory_seq_rm [7315, end)
slot update_slots: id  3 | task 5685 | prompt processing progress, n_tokens = 7433, batch.n_tokens = 118, progress = 0.991463
slot update_slots: id  3 | task 5685 | n_tokens = 7433, memory_seq_rm [7433, end)
slot update_slots: id  3 | task 5685 | prompt processing progress, n_tokens = 7497, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5685 | prompt done, n_tokens = 7497, batch.n_tokens = 64
slot init_sampler: id  3 | task 5685 | init sampler, took 1.11 ms, tokens: text = 7497, total = 7497
slot update_slots: id  3 | task 5685 | erasing old context checkpoint (pos_min = 730, pos_max = 1753, size = 24.012 MiB)
slot update_slots: id  3 | task 5685 | created context checkpoint 8 of 8 (pos_min = 6524, pos_max = 7432, size = 21.315 MiB)
slot print_timing: id  3 | task 5685 | 
prompt eval time =     458.57 ms /   182 tokens (    2.52 ms per token,   396.88 tokens per second)
       eval time =     372.33 ms /    14 tokens (   26.59 ms per token,    37.60 tokens per second)
      total time =     830.90 ms /   196 tokens
slot      release: id  3 | task 5685 | stop processing: n_tokens = 7510, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5701 | processing task, is_child = 0
slot update_slots: id  3 | task 5701 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7568
slot update_slots: id  3 | task 5701 | n_tokens = 7497, memory_seq_rm [7497, end)
slot update_slots: id  3 | task 5701 | prompt processing progress, n_tokens = 7504, batch.n_tokens = 7, progress = 0.991543
slot update_slots: id  3 | task 5701 | n_tokens = 7504, memory_seq_rm [7504, end)
slot update_slots: id  3 | task 5701 | prompt processing progress, n_tokens = 7568, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5701 | prompt done, n_tokens = 7568, batch.n_tokens = 64
slot init_sampler: id  3 | task 5701 | init sampler, took 1.12 ms, tokens: text = 7568, total = 7568
slot update_slots: id  3 | task 5701 | erasing old context checkpoint (pos_min = 1665, pos_max = 2688, size = 24.012 MiB)
slot update_slots: id  3 | task 5701 | created context checkpoint 8 of 8 (pos_min = 6578, pos_max = 7503, size = 21.714 MiB)
slot print_timing: id  3 | task 5701 | 
prompt eval time =     319.23 ms /    71 tokens (    4.50 ms per token,   222.41 tokens per second)
       eval time =    1175.56 ms /    48 tokens (   24.49 ms per token,    40.83 tokens per second)
      total time =    1494.79 ms /   119 tokens
slot      release: id  3 | task 5701 | stop processing: n_tokens = 7615, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.761 (> 0.100 thold), f_keep = 0.355
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 7615, total state size = 200.419 MiB
srv          load:  - looking for better prompt, base f_keep = 0.355, sim = 0.761
srv        update:  - cache state: 2 prompts, 709.383 MiB (limits: 8192.000 MiB, 64000 tokens, 170645 est)
srv        update:    - prompt 0x55a5f0b7a5c0:    7162 tokens, checkpoints:  8,   347.469 MiB
srv        update:    - prompt 0x55a5f1d40020:    7615 tokens, checkpoints:  8,   361.914 MiB
srv  get_availabl: prompt cache update took 263.62 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5751 | processing task, is_child = 0
slot update_slots: id  3 | task 5751 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3548
slot update_slots: id  3 | task 5751 | n_past = 2700, slot.prompt.tokens.size() = 7615, seq_id = 3, pos_min = 6683, n_swa = 128
slot update_slots: id  3 | task 5751 | restored context checkpoint (pos_min = 2223, pos_max = 3246, size = 24.012 MiB)
slot update_slots: id  3 | task 5751 | erased invalidated context checkpoint (pos_min = 3104, pos_max = 3591, n_swa = 128, size = 11.443 MiB)
slot update_slots: id  3 | task 5751 | erased invalidated context checkpoint (pos_min = 3311, pos_max = 3829, n_swa = 128, size = 12.170 MiB)
slot update_slots: id  3 | task 5751 | erased invalidated context checkpoint (pos_min = 4790, pos_max = 5813, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 5751 | erased invalidated context checkpoint (pos_min = 4966, pos_max = 5938, n_swa = 128, size = 22.816 MiB)
slot update_slots: id  3 | task 5751 | erased invalidated context checkpoint (pos_min = 6227, pos_max = 7250, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 5751 | erased invalidated context checkpoint (pos_min = 6524, pos_max = 7432, n_swa = 128, size = 21.315 MiB)
slot update_slots: id  3 | task 5751 | erased invalidated context checkpoint (pos_min = 6578, pos_max = 7503, n_swa = 128, size = 21.714 MiB)
slot update_slots: id  3 | task 5751 | n_tokens = 2700, memory_seq_rm [2700, end)
slot update_slots: id  3 | task 5751 | prompt processing progress, n_tokens = 3484, batch.n_tokens = 784, progress = 0.981962
slot update_slots: id  3 | task 5751 | n_tokens = 3484, memory_seq_rm [3484, end)
slot update_slots: id  3 | task 5751 | prompt processing progress, n_tokens = 3548, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5751 | prompt done, n_tokens = 3548, batch.n_tokens = 64
slot init_sampler: id  3 | task 5751 | init sampler, took 0.54 ms, tokens: text = 3548, total = 3548
slot update_slots: id  3 | task 5751 | created context checkpoint 2 of 8 (pos_min = 2583, pos_max = 3483, size = 21.128 MiB)
slot print_timing: id  3 | task 5751 | 
prompt eval time =    1072.64 ms /   848 tokens (    1.26 ms per token,   790.57 tokens per second)
       eval time =    8307.36 ms /   339 tokens (   24.51 ms per token,    40.81 tokens per second)
      total time =    9380.01 ms /  1187 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 5751 | stop processing: n_tokens = 3886, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.925 (> 0.100 thold), f_keep = 0.909
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 6092 | processing task, is_child = 0
slot update_slots: id  3 | task 6092 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3819
slot update_slots: id  3 | task 6092 | n_tokens = 3533, memory_seq_rm [3533, end)
slot update_slots: id  3 | task 6092 | prompt processing progress, n_tokens = 3755, batch.n_tokens = 222, progress = 0.983242
slot update_slots: id  3 | task 6092 | n_tokens = 3755, memory_seq_rm [3755, end)
slot update_slots: id  3 | task 6092 | prompt processing progress, n_tokens = 3819, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 6092 | prompt done, n_tokens = 3819, batch.n_tokens = 64
slot init_sampler: id  3 | task 6092 | init sampler, took 0.65 ms, tokens: text = 3819, total = 3819
slot update_slots: id  3 | task 6092 | created context checkpoint 3 of 8 (pos_min = 2922, pos_max = 3754, size = 19.533 MiB)
slot print_timing: id  3 | task 6092 | 
prompt eval time =     549.84 ms /   286 tokens (    1.92 ms per token,   520.15 tokens per second)
       eval time =    1700.79 ms /    68 tokens (   25.01 ms per token,    39.98 tokens per second)
      total time =    2250.63 ms /   354 tokens
slot      release: id  3 | task 6092 | stop processing: n_tokens = 3886, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.983
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 6162 | processing task, is_child = 0
slot update_slots: id  3 | task 6162 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3879
slot update_slots: id  3 | task 6162 | n_tokens = 3819, memory_seq_rm [3819, end)
slot update_slots: id  3 | task 6162 | prompt processing progress, n_tokens = 3879, batch.n_tokens = 60, progress = 1.000000
slot update_slots: id  3 | task 6162 | prompt done, n_tokens = 3879, batch.n_tokens = 60
slot init_sampler: id  3 | task 6162 | init sampler, took 1.29 ms, tokens: text = 3879, total = 3879
slot print_timing: id  3 | task 6162 | 
prompt eval time =     155.84 ms /    60 tokens (    2.60 ms per token,   385.01 tokens per second)
       eval time =   11588.01 ms /   459 tokens (   25.25 ms per token,    39.61 tokens per second)
      total time =   11743.85 ms /   519 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 6162 | stop processing: n_tokens = 4337, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.909 (> 0.100 thold), f_keep = 0.878
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 6622 | processing task, is_child = 0
slot update_slots: id  3 | task 6622 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4190
slot update_slots: id  3 | task 6622 | n_tokens = 3807, memory_seq_rm [3807, end)
slot update_slots: id  3 | task 6622 | prompt processing progress, n_tokens = 4126, batch.n_tokens = 319, progress = 0.984726
slot update_slots: id  3 | task 6622 | n_tokens = 4126, memory_seq_rm [4126, end)
slot update_slots: id  3 | task 6622 | prompt processing progress, n_tokens = 4190, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 6622 | prompt done, n_tokens = 4190, batch.n_tokens = 64
slot init_sampler: id  3 | task 6622 | init sampler, took 0.76 ms, tokens: text = 4190, total = 4190
slot update_slots: id  3 | task 6622 | created context checkpoint 4 of 8 (pos_min = 3504, pos_max = 4125, size = 14.586 MiB)
slot print_timing: id  3 | task 6622 | 
prompt eval time =     583.57 ms /   383 tokens (    1.52 ms per token,   656.30 tokens per second)
       eval time =    6175.42 ms /   251 tokens (   24.60 ms per token,    40.65 tokens per second)
      total time =    6758.99 ms /   634 tokens
slot      release: id  3 | task 6622 | stop processing: n_tokens = 4440, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.747 (> 0.100 thold), f_keep = 0.944
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 6875 | processing task, is_child = 0
slot update_slots: id  3 | task 6875 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5608
slot update_slots: id  3 | task 6875 | n_tokens = 4190, memory_seq_rm [4190, end)
slot update_slots: id  3 | task 6875 | prompt processing progress, n_tokens = 5544, batch.n_tokens = 1354, progress = 0.988588
slot update_slots: id  3 | task 6875 | n_tokens = 5544, memory_seq_rm [5544, end)
slot update_slots: id  3 | task 6875 | prompt processing progress, n_tokens = 5608, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 6875 | prompt done, n_tokens = 5608, batch.n_tokens = 64
slot init_sampler: id  3 | task 6875 | init sampler, took 0.88 ms, tokens: text = 5608, total = 5608
slot update_slots: id  3 | task 6875 | created context checkpoint 5 of 8 (pos_min = 4520, pos_max = 5543, size = 24.012 MiB)
slot print_timing: id  3 | task 6875 | 
prompt eval time =    1560.67 ms /  1418 tokens (    1.10 ms per token,   908.58 tokens per second)
       eval time =   27759.13 ms /  1058 tokens (   26.24 ms per token,    38.11 tokens per second)
      total time =   29319.80 ms /  2476 tokens
slot      release: id  3 | task 6875 | stop processing: n_tokens = 6665, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.856 (> 0.100 thold), f_keep = 0.627
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 7935 | processing task, is_child = 0
slot update_slots: id  3 | task 7935 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4877
slot update_slots: id  3 | task 7935 | n_past = 4176, slot.prompt.tokens.size() = 6665, seq_id = 3, pos_min = 5641, n_swa = 128
slot update_slots: id  3 | task 7935 | restored context checkpoint (pos_min = 3504, pos_max = 4125, size = 14.586 MiB)
slot update_slots: id  3 | task 7935 | erased invalidated context checkpoint (pos_min = 4520, pos_max = 5543, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 7935 | n_tokens = 4125, memory_seq_rm [4125, end)
slot update_slots: id  3 | task 7935 | prompt processing progress, n_tokens = 4813, batch.n_tokens = 688, progress = 0.986877
slot update_slots: id  3 | task 7935 | n_tokens = 4813, memory_seq_rm [4813, end)
slot update_slots: id  3 | task 7935 | prompt processing progress, n_tokens = 4877, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 7935 | prompt done, n_tokens = 4877, batch.n_tokens = 64
slot init_sampler: id  3 | task 7935 | init sampler, took 0.76 ms, tokens: text = 4877, total = 4877
slot update_slots: id  3 | task 7935 | created context checkpoint 5 of 8 (pos_min = 3789, pos_max = 4812, size = 24.012 MiB)
slot print_timing: id  3 | task 7935 | 
prompt eval time =    1028.39 ms /   752 tokens (    1.37 ms per token,   731.24 tokens per second)
       eval time =    2635.39 ms /   109 tokens (   24.18 ms per token,    41.36 tokens per second)
      total time =    3663.78 ms /   861 tokens
slot      release: id  3 | task 7935 | stop processing: n_tokens = 4985, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.978
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8046 | processing task, is_child = 0
slot update_slots: id  3 | task 8046 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4926
slot update_slots: id  3 | task 8046 | n_tokens = 4877, memory_seq_rm [4877, end)
slot update_slots: id  3 | task 8046 | prompt processing progress, n_tokens = 4926, batch.n_tokens = 49, progress = 1.000000
slot update_slots: id  3 | task 8046 | prompt done, n_tokens = 4926, batch.n_tokens = 49
slot init_sampler: id  3 | task 8046 | init sampler, took 0.96 ms, tokens: text = 4926, total = 4926
slot print_timing: id  3 | task 8046 | 
prompt eval time =     243.60 ms /    49 tokens (    4.97 ms per token,   201.15 tokens per second)
       eval time =    1877.80 ms /    76 tokens (   24.71 ms per token,    40.47 tokens per second)
      total time =    2121.40 ms /   125 tokens
slot      release: id  3 | task 8046 | stop processing: n_tokens = 5001, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.870 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8123 | processing task, is_child = 0
slot update_slots: id  3 | task 8123 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5662
slot update_slots: id  3 | task 8123 | n_tokens = 4926, memory_seq_rm [4926, end)
slot update_slots: id  3 | task 8123 | prompt processing progress, n_tokens = 5598, batch.n_tokens = 672, progress = 0.988697
slot update_slots: id  3 | task 8123 | n_tokens = 5598, memory_seq_rm [5598, end)
slot update_slots: id  3 | task 8123 | prompt processing progress, n_tokens = 5662, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 8123 | prompt done, n_tokens = 5662, batch.n_tokens = 64
slot init_sampler: id  3 | task 8123 | init sampler, took 0.85 ms, tokens: text = 5662, total = 5662
slot update_slots: id  3 | task 8123 | created context checkpoint 6 of 8 (pos_min = 4574, pos_max = 5597, size = 24.012 MiB)
slot print_timing: id  3 | task 8123 | 
prompt eval time =     943.68 ms /   736 tokens (    1.28 ms per token,   779.93 tokens per second)
       eval time =   23370.75 ms /   914 tokens (   25.57 ms per token,    39.11 tokens per second)
      total time =   24314.43 ms /  1650 tokens
slot      release: id  3 | task 8123 | stop processing: n_tokens = 6575, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.847 (> 0.100 thold), f_keep = 0.738
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9039 | processing task, is_child = 0
slot update_slots: id  3 | task 9039 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5735
slot update_slots: id  3 | task 9039 | n_past = 4855, slot.prompt.tokens.size() = 6575, seq_id = 3, pos_min = 5551, n_swa = 128
slot update_slots: id  3 | task 9039 | restored context checkpoint (pos_min = 4574, pos_max = 5597, size = 24.012 MiB)
slot update_slots: id  3 | task 9039 | n_tokens = 4855, memory_seq_rm [4855, end)
slot update_slots: id  3 | task 9039 | prompt processing progress, n_tokens = 5671, batch.n_tokens = 816, progress = 0.988840
slot update_slots: id  3 | task 9039 | n_tokens = 5671, memory_seq_rm [5671, end)
slot update_slots: id  3 | task 9039 | prompt processing progress, n_tokens = 5735, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9039 | prompt done, n_tokens = 5735, batch.n_tokens = 64
slot init_sampler: id  3 | task 9039 | init sampler, took 0.86 ms, tokens: text = 5735, total = 5735
slot update_slots: id  3 | task 9039 | created context checkpoint 7 of 8 (pos_min = 4728, pos_max = 5670, size = 22.113 MiB)
slot print_timing: id  3 | task 9039 | 
prompt eval time =    1125.03 ms /   880 tokens (    1.28 ms per token,   782.20 tokens per second)
       eval time =    2158.98 ms /    88 tokens (   24.53 ms per token,    40.76 tokens per second)
      total time =    3284.01 ms /   968 tokens
slot      release: id  3 | task 9039 | stop processing: n_tokens = 5822, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.954 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9129 | processing task, is_child = 0
slot update_slots: id  3 | task 9129 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6010
slot update_slots: id  3 | task 9129 | n_tokens = 5735, memory_seq_rm [5735, end)
slot update_slots: id  3 | task 9129 | prompt processing progress, n_tokens = 5946, batch.n_tokens = 211, progress = 0.989351
slot update_slots: id  3 | task 9129 | n_tokens = 5946, memory_seq_rm [5946, end)
slot update_slots: id  3 | task 9129 | prompt processing progress, n_tokens = 6010, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9129 | prompt done, n_tokens = 6010, batch.n_tokens = 64
slot init_sampler: id  3 | task 9129 | init sampler, took 1.12 ms, tokens: text = 6010, total = 6010
slot update_slots: id  3 | task 9129 | created context checkpoint 8 of 8 (pos_min = 5026, pos_max = 5945, size = 21.573 MiB)
slot print_timing: id  3 | task 9129 | 
prompt eval time =     612.52 ms /   275 tokens (    2.23 ms per token,   448.97 tokens per second)
       eval time =    1804.63 ms /    72 tokens (   25.06 ms per token,    39.90 tokens per second)
      total time =    2417.15 ms /   347 tokens
slot      release: id  3 | task 9129 | stop processing: n_tokens = 6081, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.752 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9203 | processing task, is_child = 0
slot update_slots: id  3 | task 9203 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7994
slot update_slots: id  3 | task 9203 | n_tokens = 6010, memory_seq_rm [6010, end)
slot update_slots: id  3 | task 9203 | prompt processing progress, n_tokens = 7930, batch.n_tokens = 1920, progress = 0.991994
slot update_slots: id  3 | task 9203 | n_tokens = 7930, memory_seq_rm [7930, end)
slot update_slots: id  3 | task 9203 | prompt processing progress, n_tokens = 7994, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9203 | prompt done, n_tokens = 7994, batch.n_tokens = 64
slot init_sampler: id  3 | task 9203 | init sampler, took 1.19 ms, tokens: text = 7994, total = 7994
slot update_slots: id  3 | task 9203 | erasing old context checkpoint (pos_min = 2223, pos_max = 3246, size = 24.012 MiB)
slot update_slots: id  3 | task 9203 | created context checkpoint 8 of 8 (pos_min = 6906, pos_max = 7929, size = 24.012 MiB)
slot print_timing: id  3 | task 9203 | 
prompt eval time =    2288.05 ms /  1984 tokens (    1.15 ms per token,   867.11 tokens per second)
       eval time =   20775.41 ms /   794 tokens (   26.17 ms per token,    38.22 tokens per second)
      total time =   23063.46 ms /  2778 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 9203 | stop processing: n_tokens = 8787, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.919 (> 0.100 thold), f_keep = 0.910
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9999 | processing task, is_child = 0
slot update_slots: id  3 | task 9999 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8700
slot update_slots: id  3 | task 9999 | n_tokens = 7994, memory_seq_rm [7994, end)
slot update_slots: id  3 | task 9999 | prompt processing progress, n_tokens = 8636, batch.n_tokens = 642, progress = 0.992644
slot update_slots: id  3 | task 9999 | n_tokens = 8636, memory_seq_rm [8636, end)
slot update_slots: id  3 | task 9999 | prompt processing progress, n_tokens = 8700, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9999 | prompt done, n_tokens = 8700, batch.n_tokens = 64
slot init_sampler: id  3 | task 9999 | init sampler, took 1.64 ms, tokens: text = 8700, total = 8700
slot update_slots: id  3 | task 9999 | erasing old context checkpoint (pos_min = 2583, pos_max = 3483, size = 21.128 MiB)
slot update_slots: id  3 | task 9999 | created context checkpoint 8 of 8 (pos_min = 7763, pos_max = 8635, size = 20.471 MiB)
slot print_timing: id  3 | task 9999 | 
prompt eval time =    1024.66 ms /   706 tokens (    1.45 ms per token,   689.01 tokens per second)
       eval time =    1376.76 ms /    52 tokens (   26.48 ms per token,    37.77 tokens per second)
      total time =    2401.42 ms /   758 tokens
slot      release: id  3 | task 9999 | stop processing: n_tokens = 8751, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.948 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10053 | processing task, is_child = 0
slot update_slots: id  3 | task 10053 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 9179
slot update_slots: id  3 | task 10053 | n_tokens = 8700, memory_seq_rm [8700, end)
slot update_slots: id  3 | task 10053 | prompt processing progress, n_tokens = 9115, batch.n_tokens = 415, progress = 0.993028
slot update_slots: id  3 | task 10053 | n_tokens = 9115, memory_seq_rm [9115, end)
slot update_slots: id  3 | task 10053 | prompt processing progress, n_tokens = 9179, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 10053 | prompt done, n_tokens = 9179, batch.n_tokens = 64
slot init_sampler: id  3 | task 10053 | init sampler, took 1.36 ms, tokens: text = 9179, total = 9179
slot update_slots: id  3 | task 10053 | erasing old context checkpoint (pos_min = 2922, pos_max = 3754, size = 19.533 MiB)
slot update_slots: id  3 | task 10053 | created context checkpoint 8 of 8 (pos_min = 8091, pos_max = 9114, size = 24.012 MiB)
slot print_timing: id  3 | task 10053 | 
prompt eval time =     647.19 ms /   479 tokens (    1.35 ms per token,   740.12 tokens per second)
       eval time =   17906.38 ms /   681 tokens (   26.29 ms per token,    38.03 tokens per second)
      total time =   18553.57 ms /  1160 tokens
slot      release: id  3 | task 10053 | stop processing: n_tokens = 9859, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.929 (> 0.100 thold), f_keep = 0.931
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10736 | processing task, is_child = 0
slot update_slots: id  3 | task 10736 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 9885
slot update_slots: id  3 | task 10736 | n_tokens = 9179, memory_seq_rm [9179, end)
slot update_slots: id  3 | task 10736 | prompt processing progress, n_tokens = 9821, batch.n_tokens = 642, progress = 0.993526
slot update_slots: id  3 | task 10736 | n_tokens = 9821, memory_seq_rm [9821, end)
slot update_slots: id  3 | task 10736 | prompt processing progress, n_tokens = 9885, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 10736 | prompt done, n_tokens = 9885, batch.n_tokens = 64
slot init_sampler: id  3 | task 10736 | init sampler, took 2.19 ms, tokens: text = 9885, total = 9885
slot update_slots: id  3 | task 10736 | erasing old context checkpoint (pos_min = 3504, pos_max = 4125, size = 14.586 MiB)
slot update_slots: id  3 | task 10736 | created context checkpoint 8 of 8 (pos_min = 9052, pos_max = 9820, size = 18.033 MiB)
slot print_timing: id  3 | task 10736 | 
prompt eval time =     986.65 ms /   706 tokens (    1.40 ms per token,   715.55 tokens per second)
       eval time =    1306.45 ms /    52 tokens (   25.12 ms per token,    39.80 tokens per second)
      total time =    2293.10 ms /   758 tokens
slot      release: id  3 | task 10736 | stop processing: n_tokens = 9936, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.958 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10790 | processing task, is_child = 0
slot update_slots: id  3 | task 10790 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 10315
slot update_slots: id  3 | task 10790 | n_tokens = 9885, memory_seq_rm [9885, end)
slot update_slots: id  3 | task 10790 | prompt processing progress, n_tokens = 10251, batch.n_tokens = 366, progress = 0.993795
slot update_slots: id  3 | task 10790 | n_tokens = 10251, memory_seq_rm [10251, end)
slot update_slots: id  3 | task 10790 | prompt processing progress, n_tokens = 10315, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 10790 | prompt done, n_tokens = 10315, batch.n_tokens = 64
slot init_sampler: id  3 | task 10790 | init sampler, took 1.47 ms, tokens: text = 10315, total = 10315
slot update_slots: id  3 | task 10790 | erasing old context checkpoint (pos_min = 3789, pos_max = 4812, size = 24.012 MiB)
slot update_slots: id  3 | task 10790 | created context checkpoint 8 of 8 (pos_min = 9354, pos_max = 10250, size = 21.034 MiB)
slot print_timing: id  3 | task 10790 | 
prompt eval time =     632.92 ms /   430 tokens (    1.47 ms per token,   679.39 tokens per second)
       eval time =    1397.59 ms /    53 tokens (   26.37 ms per token,    37.92 tokens per second)
      total time =    2030.51 ms /   483 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 10790 | stop processing: n_tokens = 10367, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.868 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 10845 | processing task, is_child = 0
slot update_slots: id  3 | task 10845 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 11882
slot update_slots: id  3 | task 10845 | n_tokens = 10315, memory_seq_rm [10315, end)
slot update_slots: id  3 | task 10845 | prompt processing progress, n_tokens = 11818, batch.n_tokens = 1503, progress = 0.994614
slot update_slots: id  3 | task 10845 | n_tokens = 11818, memory_seq_rm [11818, end)
slot update_slots: id  3 | task 10845 | prompt processing progress, n_tokens = 11882, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 10845 | prompt done, n_tokens = 11882, batch.n_tokens = 64
slot init_sampler: id  3 | task 10845 | init sampler, took 2.31 ms, tokens: text = 11882, total = 11882
slot update_slots: id  3 | task 10845 | erasing old context checkpoint (pos_min = 4574, pos_max = 5597, size = 24.012 MiB)
slot update_slots: id  3 | task 10845 | created context checkpoint 8 of 8 (pos_min = 10794, pos_max = 11817, size = 24.012 MiB)
slot print_timing: id  3 | task 10845 | 
prompt eval time =    1861.97 ms /  1567 tokens (    1.19 ms per token,   841.58 tokens per second)
       eval time =    5975.30 ms /   233 tokens (   25.65 ms per token,    38.99 tokens per second)
      total time =    7837.27 ms /  1800 tokens
slot      release: id  3 | task 10845 | stop processing: n_tokens = 12114, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.979 (> 0.100 thold), f_keep = 0.981
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11080 | processing task, is_child = 0
slot update_slots: id  3 | task 11080 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 12141
slot update_slots: id  3 | task 11080 | n_tokens = 11882, memory_seq_rm [11882, end)
slot update_slots: id  3 | task 11080 | prompt processing progress, n_tokens = 12077, batch.n_tokens = 195, progress = 0.994729
slot update_slots: id  3 | task 11080 | n_tokens = 12077, memory_seq_rm [12077, end)
slot update_slots: id  3 | task 11080 | prompt processing progress, n_tokens = 12141, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11080 | prompt done, n_tokens = 12141, batch.n_tokens = 64
slot init_sampler: id  3 | task 11080 | init sampler, took 1.79 ms, tokens: text = 12141, total = 12141
slot update_slots: id  3 | task 11080 | erasing old context checkpoint (pos_min = 4728, pos_max = 5670, size = 22.113 MiB)
slot update_slots: id  3 | task 11080 | created context checkpoint 8 of 8 (pos_min = 11090, pos_max = 12076, size = 23.144 MiB)
slot print_timing: id  3 | task 11080 | 
prompt eval time =     500.76 ms /   259 tokens (    1.93 ms per token,   517.21 tokens per second)
       eval time =    1284.62 ms /    50 tokens (   25.69 ms per token,    38.92 tokens per second)
      total time =    1785.38 ms /   309 tokens
slot      release: id  3 | task 11080 | stop processing: n_tokens = 12190, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.971 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11132 | processing task, is_child = 0
slot update_slots: id  3 | task 11132 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 12503
slot update_slots: id  3 | task 11132 | n_tokens = 12141, memory_seq_rm [12141, end)
slot update_slots: id  3 | task 11132 | prompt processing progress, n_tokens = 12439, batch.n_tokens = 298, progress = 0.994881
slot update_slots: id  3 | task 11132 | n_tokens = 12439, memory_seq_rm [12439, end)
slot update_slots: id  3 | task 11132 | prompt processing progress, n_tokens = 12503, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11132 | prompt done, n_tokens = 12503, batch.n_tokens = 64
slot init_sampler: id  3 | task 11132 | init sampler, took 1.77 ms, tokens: text = 12503, total = 12503
slot update_slots: id  3 | task 11132 | erasing old context checkpoint (pos_min = 5026, pos_max = 5945, size = 21.573 MiB)
slot update_slots: id  3 | task 11132 | created context checkpoint 8 of 8 (pos_min = 11415, pos_max = 12438, size = 24.012 MiB)
slot print_timing: id  3 | task 11132 | 
prompt eval time =     575.56 ms /   362 tokens (    1.59 ms per token,   628.95 tokens per second)
       eval time =    1470.82 ms /    56 tokens (   26.26 ms per token,    38.07 tokens per second)
      total time =    2046.38 ms /   418 tokens
slot      release: id  3 | task 11132 | stop processing: n_tokens = 12558, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.946 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11190 | processing task, is_child = 0
slot update_slots: id  3 | task 11190 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13221
slot update_slots: id  3 | task 11190 | n_tokens = 12503, memory_seq_rm [12503, end)
slot update_slots: id  3 | task 11190 | prompt processing progress, n_tokens = 13157, batch.n_tokens = 654, progress = 0.995159
slot update_slots: id  3 | task 11190 | n_tokens = 13157, memory_seq_rm [13157, end)
slot update_slots: id  3 | task 11190 | prompt processing progress, n_tokens = 13221, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 11190 | prompt done, n_tokens = 13221, batch.n_tokens = 64
slot init_sampler: id  3 | task 11190 | init sampler, took 2.85 ms, tokens: text = 13221, total = 13221
slot update_slots: id  3 | task 11190 | erasing old context checkpoint (pos_min = 6906, pos_max = 7929, size = 24.012 MiB)
slot update_slots: id  3 | task 11190 | created context checkpoint 8 of 8 (pos_min = 12133, pos_max = 13156, size = 24.012 MiB)
slot print_timing: id  3 | task 11190 | 
prompt eval time =    1018.10 ms /   718 tokens (    1.42 ms per token,   705.23 tokens per second)
       eval time =   22028.15 ms /   852 tokens (   25.85 ms per token,    38.68 tokens per second)
      total time =   23046.25 ms /  1570 tokens
slot      release: id  3 | task 11190 | stop processing: n_tokens = 14072, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.949 (> 0.100 thold), f_keep = 0.940
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12044 | processing task, is_child = 0
slot update_slots: id  3 | task 12044 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13927
slot update_slots: id  3 | task 12044 | n_tokens = 13221, memory_seq_rm [13221, end)
slot update_slots: id  3 | task 12044 | prompt processing progress, n_tokens = 13863, batch.n_tokens = 642, progress = 0.995405
slot update_slots: id  3 | task 12044 | n_tokens = 13863, memory_seq_rm [13863, end)
slot update_slots: id  3 | task 12044 | prompt processing progress, n_tokens = 13927, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12044 | prompt done, n_tokens = 13927, batch.n_tokens = 64
slot init_sampler: id  3 | task 12044 | init sampler, took 2.00 ms, tokens: text = 13927, total = 13927
slot update_slots: id  3 | task 12044 | erasing old context checkpoint (pos_min = 7763, pos_max = 8635, size = 20.471 MiB)
slot update_slots: id  3 | task 12044 | created context checkpoint 8 of 8 (pos_min = 13048, pos_max = 13862, size = 19.111 MiB)
slot print_timing: id  3 | task 12044 | 
prompt eval time =    1049.62 ms /   706 tokens (    1.49 ms per token,   672.63 tokens per second)
       eval time =    1344.23 ms /    52 tokens (   25.85 ms per token,    38.68 tokens per second)
      total time =    2393.85 ms /   758 tokens
slot      release: id  3 | task 12044 | stop processing: n_tokens = 13978, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.951 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12098 | processing task, is_child = 0
slot update_slots: id  3 | task 12098 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 14645
slot update_slots: id  3 | task 12098 | n_tokens = 13927, memory_seq_rm [13927, end)
slot update_slots: id  3 | task 12098 | prompt processing progress, n_tokens = 14581, batch.n_tokens = 654, progress = 0.995630
slot update_slots: id  3 | task 12098 | n_tokens = 14581, memory_seq_rm [14581, end)
slot update_slots: id  3 | task 12098 | prompt processing progress, n_tokens = 14645, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12098 | prompt done, n_tokens = 14645, batch.n_tokens = 64
slot init_sampler: id  3 | task 12098 | init sampler, took 2.78 ms, tokens: text = 14645, total = 14645
slot update_slots: id  3 | task 12098 | erasing old context checkpoint (pos_min = 8091, pos_max = 9114, size = 24.012 MiB)
slot update_slots: id  3 | task 12098 | created context checkpoint 8 of 8 (pos_min = 13557, pos_max = 14580, size = 24.012 MiB)
slot print_timing: id  3 | task 12098 | 
prompt eval time =    1057.03 ms /   718 tokens (    1.47 ms per token,   679.26 tokens per second)
       eval time =    1473.80 ms /    56 tokens (   26.32 ms per token,    38.00 tokens per second)
      total time =    2530.83 ms /   774 tokens
slot      release: id  3 | task 12098 | stop processing: n_tokens = 14700, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.881 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12156 | processing task, is_child = 0
slot update_slots: id  3 | task 12156 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16629
slot update_slots: id  3 | task 12156 | n_tokens = 14645, memory_seq_rm [14645, end)
slot update_slots: id  3 | task 12156 | prompt processing progress, n_tokens = 16565, batch.n_tokens = 1920, progress = 0.996151
slot update_slots: id  3 | task 12156 | n_tokens = 16565, memory_seq_rm [16565, end)
slot update_slots: id  3 | task 12156 | prompt processing progress, n_tokens = 16629, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12156 | prompt done, n_tokens = 16629, batch.n_tokens = 64
slot init_sampler: id  3 | task 12156 | init sampler, took 2.46 ms, tokens: text = 16629, total = 16629
slot update_slots: id  3 | task 12156 | erasing old context checkpoint (pos_min = 9052, pos_max = 9820, size = 18.033 MiB)
slot update_slots: id  3 | task 12156 | created context checkpoint 8 of 8 (pos_min = 15541, pos_max = 16564, size = 24.012 MiB)
slot print_timing: id  3 | task 12156 | 
prompt eval time =    2559.53 ms /  1984 tokens (    1.29 ms per token,   775.14 tokens per second)
       eval time =   22504.20 ms /   837 tokens (   26.89 ms per token,    37.19 tokens per second)
      total time =   25063.73 ms /  2821 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 12156 | stop processing: n_tokens = 17465, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.959 (> 0.100 thold), f_keep = 0.952
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12995 | processing task, is_child = 0
slot update_slots: id  3 | task 12995 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 17335
slot update_slots: id  3 | task 12995 | n_tokens = 16629, memory_seq_rm [16629, end)
slot update_slots: id  3 | task 12995 | prompt processing progress, n_tokens = 17271, batch.n_tokens = 642, progress = 0.996308
slot update_slots: id  3 | task 12995 | n_tokens = 17271, memory_seq_rm [17271, end)
slot update_slots: id  3 | task 12995 | prompt processing progress, n_tokens = 17335, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12995 | prompt done, n_tokens = 17335, batch.n_tokens = 64
slot init_sampler: id  3 | task 12995 | init sampler, took 2.46 ms, tokens: text = 17335, total = 17335
slot update_slots: id  3 | task 12995 | erasing old context checkpoint (pos_min = 9354, pos_max = 10250, size = 21.034 MiB)
slot update_slots: id  3 | task 12995 | created context checkpoint 8 of 8 (pos_min = 16502, pos_max = 17270, size = 18.033 MiB)
slot print_timing: id  3 | task 12995 | 
prompt eval time =    1097.85 ms /   706 tokens (    1.56 ms per token,   643.07 tokens per second)
       eval time =    1236.88 ms /    47 tokens (   26.32 ms per token,    38.00 tokens per second)
      total time =    2334.73 ms /   753 tokens
slot      release: id  3 | task 12995 | stop processing: n_tokens = 17381, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 13044 | processing task, is_child = 0
slot update_slots: id  3 | task 13044 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 17417
slot update_slots: id  3 | task 13044 | n_tokens = 17335, memory_seq_rm [17335, end)
slot update_slots: id  3 | task 13044 | prompt processing progress, n_tokens = 17353, batch.n_tokens = 18, progress = 0.996325
slot update_slots: id  3 | task 13044 | n_tokens = 17353, memory_seq_rm [17353, end)
slot update_slots: id  3 | task 13044 | prompt processing progress, n_tokens = 17417, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 13044 | prompt done, n_tokens = 17417, batch.n_tokens = 64
slot init_sampler: id  3 | task 13044 | init sampler, took 2.48 ms, tokens: text = 17417, total = 17417
slot update_slots: id  3 | task 13044 | erasing old context checkpoint (pos_min = 10794, pos_max = 11817, size = 24.012 MiB)
slot update_slots: id  3 | task 13044 | created context checkpoint 8 of 8 (pos_min = 16502, pos_max = 17352, size = 19.955 MiB)
slot print_timing: id  3 | task 13044 | 
prompt eval time =     288.59 ms /    82 tokens (    3.52 ms per token,   284.14 tokens per second)
       eval time =    1433.06 ms /    54 tokens (   26.54 ms per token,    37.68 tokens per second)
      total time =    1721.65 ms /   136 tokens
slot      release: id  3 | task 13044 | stop processing: n_tokens = 17470, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 13100 | processing task, is_child = 0
slot update_slots: id  3 | task 13100 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 17671
slot update_slots: id  3 | task 13100 | n_tokens = 17417, memory_seq_rm [17417, end)
slot update_slots: id  3 | task 13100 | prompt processing progress, n_tokens = 17607, batch.n_tokens = 190, progress = 0.996378
slot update_slots: id  3 | task 13100 | n_tokens = 17607, memory_seq_rm [17607, end)
slot update_slots: id  3 | task 13100 | prompt processing progress, n_tokens = 17671, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 13100 | prompt done, n_tokens = 17671, batch.n_tokens = 64
slot init_sampler: id  3 | task 13100 | init sampler, took 2.52 ms, tokens: text = 17671, total = 17671
slot update_slots: id  3 | task 13100 | erasing old context checkpoint (pos_min = 11090, pos_max = 12076, size = 23.144 MiB)
slot update_slots: id  3 | task 13100 | created context checkpoint 8 of 8 (pos_min = 16710, pos_max = 17606, size = 21.034 MiB)
slot print_timing: id  3 | task 13100 | 
prompt eval time =     508.60 ms /   254 tokens (    2.00 ms per token,   499.41 tokens per second)
       eval time =    6011.63 ms /   225 tokens (   26.72 ms per token,    37.43 tokens per second)
      total time =    6520.24 ms /   479 tokens
slot      release: id  3 | task 13100 | stop processing: n_tokens = 17895, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 13327 | processing task, is_child = 0
slot update_slots: id  3 | task 13327 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 17930
slot update_slots: id  3 | task 13327 | n_tokens = 17671, memory_seq_rm [17671, end)
slot update_slots: id  3 | task 13327 | prompt processing progress, n_tokens = 17866, batch.n_tokens = 195, progress = 0.996431
slot update_slots: id  3 | task 13327 | n_tokens = 17866, memory_seq_rm [17866, end)
slot update_slots: id  3 | task 13327 | prompt processing progress, n_tokens = 17930, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 13327 | prompt done, n_tokens = 17930, batch.n_tokens = 64
slot init_sampler: id  3 | task 13327 | init sampler, took 3.43 ms, tokens: text = 17930, total = 17930
slot update_slots: id  3 | task 13327 | erasing old context checkpoint (pos_min = 11415, pos_max = 12438, size = 24.012 MiB)
slot update_slots: id  3 | task 13327 | created context checkpoint 8 of 8 (pos_min = 16911, pos_max = 17865, size = 22.394 MiB)
slot print_timing: id  3 | task 13327 | 
prompt eval time =     532.78 ms /   259 tokens (    2.06 ms per token,   486.12 tokens per second)
       eval time =    1497.63 ms /    56 tokens (   26.74 ms per token,    37.39 tokens per second)
      total time =    2030.42 ms /   315 tokens
slot      release: id  3 | task 13327 | stop processing: n_tokens = 17985, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.974 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 13385 | processing task, is_child = 0
slot update_slots: id  3 | task 13385 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 18417
slot update_slots: id  3 | task 13385 | n_tokens = 17930, memory_seq_rm [17930, end)
slot update_slots: id  3 | task 13385 | prompt processing progress, n_tokens = 18353, batch.n_tokens = 423, progress = 0.996525
slot update_slots: id  3 | task 13385 | n_tokens = 18353, memory_seq_rm [18353, end)
slot update_slots: id  3 | task 13385 | prompt processing progress, n_tokens = 18417, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 13385 | prompt done, n_tokens = 18417, batch.n_tokens = 64
slot init_sampler: id  3 | task 13385 | init sampler, took 2.61 ms, tokens: text = 18417, total = 18417
slot update_slots: id  3 | task 13385 | erasing old context checkpoint (pos_min = 12133, pos_max = 13156, size = 24.012 MiB)
slot update_slots: id  3 | task 13385 | created context checkpoint 8 of 8 (pos_min = 17329, pos_max = 18352, size = 24.012 MiB)
slot print_timing: id  3 | task 13385 | 
prompt eval time =     728.59 ms /   487 tokens (    1.50 ms per token,   668.41 tokens per second)
       eval time =    5949.60 ms /   222 tokens (   26.80 ms per token,    37.31 tokens per second)
      total time =    6678.19 ms /   709 tokens
slot      release: id  3 | task 13385 | stop processing: n_tokens = 18638, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 13609 | processing task, is_child = 0
slot update_slots: id  3 | task 13609 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 18676
slot update_slots: id  3 | task 13609 | n_tokens = 18417, memory_seq_rm [18417, end)
slot update_slots: id  3 | task 13609 | prompt processing progress, n_tokens = 18612, batch.n_tokens = 195, progress = 0.996573
slot update_slots: id  3 | task 13609 | n_tokens = 18612, memory_seq_rm [18612, end)
slot update_slots: id  3 | task 13609 | prompt processing progress, n_tokens = 18676, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 13609 | prompt done, n_tokens = 18676, batch.n_tokens = 64
slot init_sampler: id  3 | task 13609 | init sampler, took 2.65 ms, tokens: text = 18676, total = 18676
slot update_slots: id  3 | task 13609 | erasing old context checkpoint (pos_min = 13048, pos_max = 13862, size = 19.111 MiB)
slot update_slots: id  3 | task 13609 | created context checkpoint 8 of 8 (pos_min = 17721, pos_max = 18611, size = 20.893 MiB)
slot print_timing: id  3 | task 13609 | 
prompt eval time =     530.74 ms /   259 tokens (    2.05 ms per token,   488.00 tokens per second)
       eval time =    1732.57 ms /    64 tokens (   27.07 ms per token,    36.94 tokens per second)
      total time =    2263.31 ms /   323 tokens
slot      release: id  3 | task 13609 | stop processing: n_tokens = 18739, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.966 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 13675 | processing task, is_child = 0
slot update_slots: id  3 | task 13675 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 19331
slot update_slots: id  3 | task 13675 | n_tokens = 18676, memory_seq_rm [18676, end)
slot update_slots: id  3 | task 13675 | prompt processing progress, n_tokens = 19267, batch.n_tokens = 591, progress = 0.996689
slot update_slots: id  3 | task 13675 | n_tokens = 19267, memory_seq_rm [19267, end)
slot update_slots: id  3 | task 13675 | prompt processing progress, n_tokens = 19331, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 13675 | prompt done, n_tokens = 19331, batch.n_tokens = 64
slot init_sampler: id  3 | task 13675 | init sampler, took 3.58 ms, tokens: text = 19331, total = 19331
slot update_slots: id  3 | task 13675 | erasing old context checkpoint (pos_min = 13557, pos_max = 14580, size = 24.012 MiB)
slot update_slots: id  3 | task 13675 | created context checkpoint 8 of 8 (pos_min = 18376, pos_max = 19266, size = 20.893 MiB)
slot print_timing: id  3 | task 13675 | 
prompt eval time =    1059.26 ms /   655 tokens (    1.62 ms per token,   618.36 tokens per second)
       eval time =    6370.01 ms /   240 tokens (   26.54 ms per token,    37.68 tokens per second)
      total time =    7429.27 ms /   895 tokens
slot      release: id  3 | task 13675 | stop processing: n_tokens = 19570, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 13917 | processing task, is_child = 0
slot update_slots: id  3 | task 13917 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 19590
slot update_slots: id  3 | task 13917 | n_tokens = 19331, memory_seq_rm [19331, end)
slot update_slots: id  3 | task 13917 | prompt processing progress, n_tokens = 19526, batch.n_tokens = 195, progress = 0.996733
slot update_slots: id  3 | task 13917 | n_tokens = 19526, memory_seq_rm [19526, end)
slot update_slots: id  3 | task 13917 | prompt processing progress, n_tokens = 19590, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 13917 | prompt done, n_tokens = 19590, batch.n_tokens = 64
slot init_sampler: id  3 | task 13917 | init sampler, took 2.78 ms, tokens: text = 19590, total = 19590
slot update_slots: id  3 | task 13917 | erasing old context checkpoint (pos_min = 15541, pos_max = 16564, size = 24.012 MiB)
slot update_slots: id  3 | task 13917 | created context checkpoint 8 of 8 (pos_min = 18612, pos_max = 19525, size = 21.433 MiB)
slot print_timing: id  3 | task 13917 | 
prompt eval time =     532.91 ms /   259 tokens (    2.06 ms per token,   486.01 tokens per second)
       eval time =    2151.78 ms /    81 tokens (   26.57 ms per token,    37.64 tokens per second)
      total time =    2684.70 ms /   340 tokens
slot      release: id  3 | task 13917 | stop processing: n_tokens = 19670, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 14000 | processing task, is_child = 0
slot update_slots: id  3 | task 14000 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 19658
slot update_slots: id  3 | task 14000 | n_tokens = 19590, memory_seq_rm [19590, end)
slot update_slots: id  3 | task 14000 | prompt processing progress, n_tokens = 19594, batch.n_tokens = 4, progress = 0.996744
slot update_slots: id  3 | task 14000 | n_tokens = 19594, memory_seq_rm [19594, end)
slot update_slots: id  3 | task 14000 | prompt processing progress, n_tokens = 19658, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 14000 | prompt done, n_tokens = 19658, batch.n_tokens = 64
slot init_sampler: id  3 | task 14000 | init sampler, took 2.77 ms, tokens: text = 19658, total = 19658
slot update_slots: id  3 | task 14000 | erasing old context checkpoint (pos_min = 16502, pos_max = 17270, size = 18.033 MiB)
slot update_slots: id  3 | task 14000 | created context checkpoint 8 of 8 (pos_min = 18756, pos_max = 19593, size = 19.651 MiB)
slot print_timing: id  3 | task 14000 | 
prompt eval time =     250.01 ms /    68 tokens (    3.68 ms per token,   271.98 tokens per second)
       eval time =   54867.35 ms /  2029 tokens (   27.04 ms per token,    36.98 tokens per second)
      total time =   55117.36 ms /  2097 tokens
slot      release: id  3 | task 14000 | stop processing: n_tokens = 21686, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.906 (> 0.100 thold), f_keep = 0.906
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16031 | processing task, is_child = 0
slot update_slots: id  3 | task 16031 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 21700
slot update_slots: id  3 | task 16031 | n_past = 19658, slot.prompt.tokens.size() = 21686, seq_id = 3, pos_min = 20662, n_swa = 128
slot update_slots: id  3 | task 16031 | restored context checkpoint (pos_min = 18756, pos_max = 19593, size = 19.651 MiB)
slot update_slots: id  3 | task 16031 | n_tokens = 19593, memory_seq_rm [19593, end)
slot update_slots: id  3 | task 16031 | prompt processing progress, n_tokens = 21636, batch.n_tokens = 2043, progress = 0.997051
slot update_slots: id  3 | task 16031 | n_tokens = 21636, memory_seq_rm [21636, end)
slot update_slots: id  3 | task 16031 | prompt processing progress, n_tokens = 21700, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 16031 | prompt done, n_tokens = 21700, batch.n_tokens = 64
slot init_sampler: id  3 | task 16031 | init sampler, took 3.07 ms, tokens: text = 21700, total = 21700
slot update_slots: id  3 | task 16031 | erasing old context checkpoint (pos_min = 16502, pos_max = 17352, size = 19.955 MiB)
slot update_slots: id  3 | task 16031 | created context checkpoint 8 of 8 (pos_min = 20612, pos_max = 21635, size = 24.012 MiB)
slot print_timing: id  3 | task 16031 | 
prompt eval time =    2886.97 ms /  2107 tokens (    1.37 ms per token,   729.83 tokens per second)
       eval time =     652.99 ms /    24 tokens (   27.21 ms per token,    36.75 tokens per second)
      total time =    3539.97 ms /  2131 tokens
slot      release: id  3 | task 16031 | stop processing: n_tokens = 21723, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16057 | processing task, is_child = 0
slot update_slots: id  3 | task 16057 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 21766
slot update_slots: id  3 | task 16057 | n_tokens = 21700, memory_seq_rm [21700, end)
slot update_slots: id  3 | task 16057 | prompt processing progress, n_tokens = 21702, batch.n_tokens = 2, progress = 0.997060
slot update_slots: id  3 | task 16057 | n_tokens = 21702, memory_seq_rm [21702, end)
slot update_slots: id  3 | task 16057 | prompt processing progress, n_tokens = 21766, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 16057 | prompt done, n_tokens = 21766, batch.n_tokens = 64
slot init_sampler: id  3 | task 16057 | init sampler, took 4.16 ms, tokens: text = 21766, total = 21766
slot update_slots: id  3 | task 16057 | erasing old context checkpoint (pos_min = 16710, pos_max = 17606, size = 21.034 MiB)
slot update_slots: id  3 | task 16057 | created context checkpoint 8 of 8 (pos_min = 20699, pos_max = 21701, size = 23.520 MiB)
slot print_timing: id  3 | task 16057 | 
prompt eval time =     299.47 ms /    66 tokens (    4.54 ms per token,   220.39 tokens per second)
       eval time =    1266.15 ms /    48 tokens (   26.38 ms per token,    37.91 tokens per second)
      total time =    1565.62 ms /   114 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 16057 | stop processing: n_tokens = 21813, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.948 (> 0.100 thold), f_keep = 0.021
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 21813, total state size = 535.504 MiB
srv          load:  - looking for better prompt, base f_keep = 0.021, sim = 0.948
srv        update:  - cache state: 3 prompts, 1421.695 MiB (limits: 8192.000 MiB, 64000 tokens, 210836 est)
srv        update:    - prompt 0x55a5f0b7a5c0:    7162 tokens, checkpoints:  8,   347.469 MiB
srv        update:    - prompt 0x55a5f1d40020:    7615 tokens, checkpoints:  8,   361.914 MiB
srv        update:    - prompt 0x55a5f08766f0:   21813 tokens, checkpoints:  8,   712.311 MiB
srv  get_availabl: prompt cache update took 666.74 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16107 | processing task, is_child = 0
slot update_slots: id  3 | task 16107 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 484
slot update_slots: id  3 | task 16107 | n_past = 459, slot.prompt.tokens.size() = 21813, seq_id = 3, pos_min = 20789, n_swa = 128
slot update_slots: id  3 | task 16107 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  3 | task 16107 | erased invalidated context checkpoint (pos_min = 16911, pos_max = 17865, n_swa = 128, size = 22.394 MiB)
slot update_slots: id  3 | task 16107 | erased invalidated context checkpoint (pos_min = 17329, pos_max = 18352, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 16107 | erased invalidated context checkpoint (pos_min = 17721, pos_max = 18611, n_swa = 128, size = 20.893 MiB)
slot update_slots: id  3 | task 16107 | erased invalidated context checkpoint (pos_min = 18376, pos_max = 19266, n_swa = 128, size = 20.893 MiB)
slot update_slots: id  3 | task 16107 | erased invalidated context checkpoint (pos_min = 18612, pos_max = 19525, n_swa = 128, size = 21.433 MiB)
slot update_slots: id  3 | task 16107 | erased invalidated context checkpoint (pos_min = 18756, pos_max = 19593, n_swa = 128, size = 19.651 MiB)
slot update_slots: id  3 | task 16107 | erased invalidated context checkpoint (pos_min = 20612, pos_max = 21635, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 16107 | erased invalidated context checkpoint (pos_min = 20699, pos_max = 21701, n_swa = 128, size = 23.520 MiB)
slot update_slots: id  3 | task 16107 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  3 | task 16107 | prompt processing progress, n_tokens = 420, batch.n_tokens = 420, progress = 0.867769
slot update_slots: id  3 | task 16107 | n_tokens = 420, memory_seq_rm [420, end)
slot update_slots: id  3 | task 16107 | prompt processing progress, n_tokens = 484, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 16107 | prompt done, n_tokens = 484, batch.n_tokens = 64
slot init_sampler: id  3 | task 16107 | init sampler, took 0.10 ms, tokens: text = 484, total = 484
slot update_slots: id  3 | task 16107 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 419, size = 9.849 MiB)
slot print_timing: id  3 | task 16107 | 
prompt eval time =     610.81 ms /   484 tokens (    1.26 ms per token,   792.39 tokens per second)
       eval time =    2708.89 ms /   122 tokens (   22.20 ms per token,    45.04 tokens per second)
      total time =    3319.71 ms /   606 tokens
slot      release: id  3 | task 16107 | stop processing: n_tokens = 605, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.913 (> 0.100 thold), f_keep = 0.762
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16231 | processing task, is_child = 0
slot update_slots: id  3 | task 16231 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 505
slot update_slots: id  3 | task 16231 | n_tokens = 461, memory_seq_rm [461, end)
slot update_slots: id  3 | task 16231 | prompt processing progress, n_tokens = 505, batch.n_tokens = 44, progress = 1.000000
slot update_slots: id  3 | task 16231 | prompt done, n_tokens = 505, batch.n_tokens = 44
slot init_sampler: id  3 | task 16231 | init sampler, took 0.09 ms, tokens: text = 505, total = 505
slot print_timing: id  3 | task 16231 | 
prompt eval time =     207.56 ms /    44 tokens (    4.72 ms per token,   211.98 tokens per second)
       eval time =    1915.26 ms /    86 tokens (   22.27 ms per token,    44.90 tokens per second)
      total time =    2122.82 ms /   130 tokens
slot      release: id  3 | task 16231 | stop processing: n_tokens = 590, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.445 (> 0.100 thold), f_keep = 0.856
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16318 | processing task, is_child = 0
slot update_slots: id  3 | task 16318 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1136
slot update_slots: id  3 | task 16318 | n_tokens = 505, memory_seq_rm [505, end)
slot update_slots: id  3 | task 16318 | prompt processing progress, n_tokens = 1072, batch.n_tokens = 567, progress = 0.943662
slot update_slots: id  3 | task 16318 | n_tokens = 1072, memory_seq_rm [1072, end)
slot update_slots: id  3 | task 16318 | prompt processing progress, n_tokens = 1136, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 16318 | prompt done, n_tokens = 1136, batch.n_tokens = 64
slot init_sampler: id  3 | task 16318 | init sampler, took 0.21 ms, tokens: text = 1136, total = 1136
slot update_slots: id  3 | task 16318 | created context checkpoint 2 of 8 (pos_min = 48, pos_max = 1071, size = 24.012 MiB)
slot print_timing: id  3 | task 16318 | 
prompt eval time =     685.00 ms /   631 tokens (    1.09 ms per token,   921.17 tokens per second)
       eval time =    2198.97 ms /   100 tokens (   21.99 ms per token,    45.48 tokens per second)
      total time =    2883.97 ms /   731 tokens
slot      release: id  3 | task 16318 | stop processing: n_tokens = 1235, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.365 (> 0.100 thold), f_keep = 0.920
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16420 | processing task, is_child = 0
slot update_slots: id  3 | task 16420 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3109
slot update_slots: id  3 | task 16420 | n_tokens = 1136, memory_seq_rm [1136, end)
slot update_slots: id  3 | task 16420 | prompt processing progress, n_tokens = 3045, batch.n_tokens = 1909, progress = 0.979415
slot update_slots: id  3 | task 16420 | n_tokens = 3045, memory_seq_rm [3045, end)
slot update_slots: id  3 | task 16420 | prompt processing progress, n_tokens = 3109, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 16420 | prompt done, n_tokens = 3109, batch.n_tokens = 64
slot init_sampler: id  3 | task 16420 | init sampler, took 0.57 ms, tokens: text = 3109, total = 3109
slot update_slots: id  3 | task 16420 | created context checkpoint 3 of 8 (pos_min = 2021, pos_max = 3044, size = 24.012 MiB)
slot print_timing: id  3 | task 16420 | 
prompt eval time =    1847.60 ms /  1973 tokens (    0.94 ms per token,  1067.87 tokens per second)
       eval time =    1401.30 ms /    63 tokens (   22.24 ms per token,    44.96 tokens per second)
      total time =    3248.90 ms /  2036 tokens
slot      release: id  3 | task 16420 | stop processing: n_tokens = 3171, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.779 (> 0.100 thold), f_keep = 0.980
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16485 | processing task, is_child = 0
slot update_slots: id  3 | task 16485 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3991
slot update_slots: id  3 | task 16485 | n_tokens = 3109, memory_seq_rm [3109, end)
slot update_slots: id  3 | task 16485 | prompt processing progress, n_tokens = 3927, batch.n_tokens = 818, progress = 0.983964
slot update_slots: id  3 | task 16485 | n_tokens = 3927, memory_seq_rm [3927, end)
slot update_slots: id  3 | task 16485 | prompt processing progress, n_tokens = 3991, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 16485 | prompt done, n_tokens = 3991, batch.n_tokens = 64
slot init_sampler: id  3 | task 16485 | init sampler, took 0.62 ms, tokens: text = 3991, total = 3991
slot update_slots: id  3 | task 16485 | created context checkpoint 4 of 8 (pos_min = 2903, pos_max = 3926, size = 24.012 MiB)
slot print_timing: id  3 | task 16485 | 
prompt eval time =     954.30 ms /   882 tokens (    1.08 ms per token,   924.24 tokens per second)
       eval time =    5756.38 ms /   249 tokens (   23.12 ms per token,    43.26 tokens per second)
      total time =    6710.67 ms /  1131 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 16485 | stop processing: n_tokens = 4239, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.972 (> 0.100 thold), f_keep = 0.941
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16736 | processing task, is_child = 0
slot update_slots: id  3 | task 16736 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4108
slot update_slots: id  3 | task 16736 | n_tokens = 3991, memory_seq_rm [3991, end)
slot update_slots: id  3 | task 16736 | prompt processing progress, n_tokens = 4044, batch.n_tokens = 53, progress = 0.984421
slot update_slots: id  3 | task 16736 | n_tokens = 4044, memory_seq_rm [4044, end)
slot update_slots: id  3 | task 16736 | prompt processing progress, n_tokens = 4108, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 16736 | prompt done, n_tokens = 4108, batch.n_tokens = 64
slot init_sampler: id  3 | task 16736 | init sampler, took 0.77 ms, tokens: text = 4108, total = 4108
slot update_slots: id  3 | task 16736 | created context checkpoint 5 of 8 (pos_min = 3215, pos_max = 4043, size = 19.439 MiB)
slot print_timing: id  3 | task 16736 | 
prompt eval time =     295.55 ms /   117 tokens (    2.53 ms per token,   395.87 tokens per second)
       eval time =    3824.89 ms /   170 tokens (   22.50 ms per token,    44.45 tokens per second)
      total time =    4120.45 ms /   287 tokens
slot      release: id  3 | task 16736 | stop processing: n_tokens = 4277, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.976 (> 0.100 thold), f_keep = 0.960
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16908 | processing task, is_child = 0
slot update_slots: id  3 | task 16908 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4209
slot update_slots: id  3 | task 16908 | n_tokens = 4108, memory_seq_rm [4108, end)
slot update_slots: id  3 | task 16908 | prompt processing progress, n_tokens = 4145, batch.n_tokens = 37, progress = 0.984794
slot update_slots: id  3 | task 16908 | n_tokens = 4145, memory_seq_rm [4145, end)
slot update_slots: id  3 | task 16908 | prompt processing progress, n_tokens = 4209, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 16908 | prompt done, n_tokens = 4209, batch.n_tokens = 64
slot init_sampler: id  3 | task 16908 | init sampler, took 0.68 ms, tokens: text = 4209, total = 4209
slot update_slots: id  3 | task 16908 | created context checkpoint 6 of 8 (pos_min = 3358, pos_max = 4144, size = 18.455 MiB)
slot print_timing: id  3 | task 16908 | 
prompt eval time =     272.70 ms /   101 tokens (    2.70 ms per token,   370.37 tokens per second)
       eval time =     724.71 ms /    31 tokens (   23.38 ms per token,    42.78 tokens per second)
      total time =     997.41 ms /   132 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 16908 | stop processing: n_tokens = 4239, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 16941 | processing task, is_child = 0
slot update_slots: id  3 | task 16941 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4275
slot update_slots: id  3 | task 16941 | n_tokens = 4209, memory_seq_rm [4209, end)
slot update_slots: id  3 | task 16941 | prompt processing progress, n_tokens = 4211, batch.n_tokens = 2, progress = 0.985029
slot update_slots: id  3 | task 16941 | n_tokens = 4211, memory_seq_rm [4211, end)
slot update_slots: id  3 | task 16941 | prompt processing progress, n_tokens = 4275, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 16941 | prompt done, n_tokens = 4275, batch.n_tokens = 64
slot init_sampler: id  3 | task 16941 | init sampler, took 0.63 ms, tokens: text = 4275, total = 4275
slot update_slots: id  3 | task 16941 | created context checkpoint 7 of 8 (pos_min = 3358, pos_max = 4210, size = 20.002 MiB)
slot print_timing: id  3 | task 16941 | 
prompt eval time =     262.22 ms /    66 tokens (    3.97 ms per token,   251.69 tokens per second)
       eval time =    6666.72 ms /   295 tokens (   22.60 ms per token,    44.25 tokens per second)
      total time =    6928.94 ms /   361 tokens
slot      release: id  3 | task 16941 | stop processing: n_tokens = 4569, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.781 (> 0.100 thold), f_keep = 0.936
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 17238 | processing task, is_child = 0
slot update_slots: id  3 | task 17238 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5476
slot update_slots: id  3 | task 17238 | n_tokens = 4275, memory_seq_rm [4275, end)
slot update_slots: id  3 | task 17238 | prompt processing progress, n_tokens = 5412, batch.n_tokens = 1137, progress = 0.988313
slot update_slots: id  3 | task 17238 | n_tokens = 5412, memory_seq_rm [5412, end)
slot update_slots: id  3 | task 17238 | prompt processing progress, n_tokens = 5476, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 17238 | prompt done, n_tokens = 5476, batch.n_tokens = 64
slot init_sampler: id  3 | task 17238 | init sampler, took 0.99 ms, tokens: text = 5476, total = 5476
slot update_slots: id  3 | task 17238 | created context checkpoint 8 of 8 (pos_min = 4388, pos_max = 5411, size = 24.012 MiB)
slot print_timing: id  3 | task 17238 | 
prompt eval time =    1338.14 ms /  1201 tokens (    1.11 ms per token,   897.52 tokens per second)
       eval time =    2869.87 ms /   120 tokens (   23.92 ms per token,    41.81 tokens per second)
      total time =    4208.00 ms /  1321 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 17238 | stop processing: n_tokens = 5595, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.854 (> 0.100 thold), f_keep = 0.979
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 17360 | processing task, is_child = 0
slot update_slots: id  3 | task 17360 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6415
slot update_slots: id  3 | task 17360 | n_tokens = 5476, memory_seq_rm [5476, end)
slot update_slots: id  3 | task 17360 | prompt processing progress, n_tokens = 6351, batch.n_tokens = 875, progress = 0.990023
slot update_slots: id  3 | task 17360 | n_tokens = 6351, memory_seq_rm [6351, end)
slot update_slots: id  3 | task 17360 | prompt processing progress, n_tokens = 6415, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 17360 | prompt done, n_tokens = 6415, batch.n_tokens = 64
slot init_sampler: id  3 | task 17360 | init sampler, took 0.96 ms, tokens: text = 6415, total = 6415
slot update_slots: id  3 | task 17360 | erasing old context checkpoint (pos_min = 0, pos_max = 419, size = 9.849 MiB)
slot update_slots: id  3 | task 17360 | created context checkpoint 8 of 8 (pos_min = 5327, pos_max = 6350, size = 24.012 MiB)
slot print_timing: id  3 | task 17360 | 
prompt eval time =    1068.45 ms /   939 tokens (    1.14 ms per token,   878.84 tokens per second)
       eval time =    1726.17 ms /    74 tokens (   23.33 ms per token,    42.87 tokens per second)
      total time =    2794.63 ms /  1013 tokens
slot      release: id  3 | task 17360 | stop processing: n_tokens = 6488, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.989
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 17436 | processing task, is_child = 0
slot update_slots: id  3 | task 17436 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6481
slot update_slots: id  3 | task 17436 | n_tokens = 6415, memory_seq_rm [6415, end)
slot update_slots: id  3 | task 17436 | prompt processing progress, n_tokens = 6417, batch.n_tokens = 2, progress = 0.990125
slot update_slots: id  3 | task 17436 | n_tokens = 6417, memory_seq_rm [6417, end)
slot update_slots: id  3 | task 17436 | prompt processing progress, n_tokens = 6481, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 17436 | prompt done, n_tokens = 6481, batch.n_tokens = 64
slot init_sampler: id  3 | task 17436 | init sampler, took 1.27 ms, tokens: text = 6481, total = 6481
slot update_slots: id  3 | task 17436 | erasing old context checkpoint (pos_min = 48, pos_max = 1071, size = 24.012 MiB)
slot update_slots: id  3 | task 17436 | created context checkpoint 8 of 8 (pos_min = 5464, pos_max = 6416, size = 22.347 MiB)
slot print_timing: id  3 | task 17436 | 
prompt eval time =     301.57 ms /    66 tokens (    4.57 ms per token,   218.86 tokens per second)
       eval time =   15563.87 ms /   671 tokens (   23.20 ms per token,    43.11 tokens per second)
      total time =   15865.44 ms /   737 tokens
slot      release: id  3 | task 17436 | stop processing: n_tokens = 7151, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.966 (> 0.100 thold), f_keep = 0.906
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 18109 | processing task, is_child = 0
slot update_slots: id  3 | task 18109 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6707
slot update_slots: id  3 | task 18109 | n_tokens = 6481, memory_seq_rm [6481, end)
slot update_slots: id  3 | task 18109 | prompt processing progress, n_tokens = 6643, batch.n_tokens = 162, progress = 0.990458
slot update_slots: id  3 | task 18109 | n_tokens = 6643, memory_seq_rm [6643, end)
slot update_slots: id  3 | task 18109 | prompt processing progress, n_tokens = 6707, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 18109 | prompt done, n_tokens = 6707, batch.n_tokens = 64
slot init_sampler: id  3 | task 18109 | init sampler, took 1.17 ms, tokens: text = 6707, total = 6707
slot update_slots: id  3 | task 18109 | erasing old context checkpoint (pos_min = 2021, pos_max = 3044, size = 24.012 MiB)
slot update_slots: id  3 | task 18109 | created context checkpoint 8 of 8 (pos_min = 6201, pos_max = 6642, size = 10.365 MiB)
slot print_timing: id  3 | task 18109 | 
prompt eval time =     420.41 ms /   226 tokens (    1.86 ms per token,   537.57 tokens per second)
       eval time =    8538.63 ms /   370 tokens (   23.08 ms per token,    43.33 tokens per second)
      total time =    8959.04 ms /   596 tokens
slot      release: id  3 | task 18109 | stop processing: n_tokens = 7076, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.952 (> 0.100 thold), f_keep = 0.948
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 18481 | processing task, is_child = 0
slot update_slots: id  3 | task 18481 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7046
slot update_slots: id  3 | task 18481 | n_tokens = 6707, memory_seq_rm [6707, end)
slot update_slots: id  3 | task 18481 | prompt processing progress, n_tokens = 6982, batch.n_tokens = 275, progress = 0.990917
slot update_slots: id  3 | task 18481 | n_tokens = 6982, memory_seq_rm [6982, end)
slot update_slots: id  3 | task 18481 | prompt processing progress, n_tokens = 7046, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 18481 | prompt done, n_tokens = 7046, batch.n_tokens = 64
slot init_sampler: id  3 | task 18481 | init sampler, took 1.05 ms, tokens: text = 7046, total = 7046
slot update_slots: id  3 | task 18481 | erasing old context checkpoint (pos_min = 2903, pos_max = 3926, size = 24.012 MiB)
slot update_slots: id  3 | task 18481 | created context checkpoint 8 of 8 (pos_min = 6481, pos_max = 6981, size = 11.748 MiB)
slot print_timing: id  3 | task 18481 | 
prompt eval time =     476.22 ms /   339 tokens (    1.40 ms per token,   711.85 tokens per second)
       eval time =   17136.38 ms /   718 tokens (   23.87 ms per token,    41.90 tokens per second)
      total time =   17612.60 ms /  1057 tokens
slot      release: id  3 | task 18481 | stop processing: n_tokens = 7763, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.908
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 19201 | processing task, is_child = 0
slot update_slots: id  3 | task 19201 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7112
slot update_slots: id  3 | task 19201 | n_tokens = 7046, memory_seq_rm [7046, end)
slot update_slots: id  3 | task 19201 | prompt processing progress, n_tokens = 7048, batch.n_tokens = 2, progress = 0.991001
slot update_slots: id  3 | task 19201 | n_tokens = 7048, memory_seq_rm [7048, end)
slot update_slots: id  3 | task 19201 | prompt processing progress, n_tokens = 7112, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 19201 | prompt done, n_tokens = 7112, batch.n_tokens = 64
slot init_sampler: id  3 | task 19201 | init sampler, took 1.02 ms, tokens: text = 7112, total = 7112
slot update_slots: id  3 | task 19201 | erasing old context checkpoint (pos_min = 3215, pos_max = 4043, size = 19.439 MiB)
slot update_slots: id  3 | task 19201 | created context checkpoint 8 of 8 (pos_min = 6739, pos_max = 7047, size = 7.246 MiB)
slot print_timing: id  3 | task 19201 | 
prompt eval time =     283.86 ms /    66 tokens (    4.30 ms per token,   232.51 tokens per second)
       eval time =   12150.49 ms /   509 tokens (   23.87 ms per token,    41.89 tokens per second)
      total time =   12434.35 ms /   575 tokens
slot      release: id  3 | task 19201 | stop processing: n_tokens = 7620, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.469 (> 0.100 thold), f_keep = 0.035
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 7620, total state size = 192.141 MiB
srv          load:  - looking for better prompt, base f_keep = 0.035, sim = 0.469
srv        update:  - cache state: 4 prompts, 1752.023 MiB (limits: 8192.000 MiB, 64000 tokens, 206714 est)
srv        update:    - prompt 0x55a5f0b7a5c0:    7162 tokens, checkpoints:  8,   347.469 MiB
srv        update:    - prompt 0x55a5f1d40020:    7615 tokens, checkpoints:  8,   361.914 MiB
srv        update:    - prompt 0x55a5f08766f0:   21813 tokens, checkpoints:  8,   712.311 MiB
srv        update:    - prompt 0x55a5e9d8fee0:    7620 tokens, checkpoints:  8,   330.328 MiB
srv  get_availabl: prompt cache update took 211.67 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 19712 | processing task, is_child = 0
slot update_slots: id  3 | task 19712 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 571
slot update_slots: id  3 | task 19712 | n_past = 268, slot.prompt.tokens.size() = 7620, seq_id = 3, pos_min = 7046, n_swa = 128
slot update_slots: id  3 | task 19712 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  3 | task 19712 | erased invalidated context checkpoint (pos_min = 3358, pos_max = 4144, n_swa = 128, size = 18.455 MiB)
slot update_slots: id  3 | task 19712 | erased invalidated context checkpoint (pos_min = 3358, pos_max = 4210, n_swa = 128, size = 20.002 MiB)
slot update_slots: id  3 | task 19712 | erased invalidated context checkpoint (pos_min = 4388, pos_max = 5411, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 19712 | erased invalidated context checkpoint (pos_min = 5327, pos_max = 6350, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 19712 | erased invalidated context checkpoint (pos_min = 5464, pos_max = 6416, n_swa = 128, size = 22.347 MiB)
slot update_slots: id  3 | task 19712 | erased invalidated context checkpoint (pos_min = 6201, pos_max = 6642, n_swa = 128, size = 10.365 MiB)
slot update_slots: id  3 | task 19712 | erased invalidated context checkpoint (pos_min = 6481, pos_max = 6981, n_swa = 128, size = 11.748 MiB)
slot update_slots: id  3 | task 19712 | erased invalidated context checkpoint (pos_min = 6739, pos_max = 7047, n_swa = 128, size = 7.246 MiB)
slot update_slots: id  3 | task 19712 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  3 | task 19712 | prompt processing progress, n_tokens = 507, batch.n_tokens = 507, progress = 0.887916
slot update_slots: id  3 | task 19712 | n_tokens = 507, memory_seq_rm [507, end)
slot update_slots: id  3 | task 19712 | prompt processing progress, n_tokens = 571, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 19712 | prompt done, n_tokens = 571, batch.n_tokens = 64
slot init_sampler: id  3 | task 19712 | init sampler, took 0.10 ms, tokens: text = 571, total = 571
slot update_slots: id  3 | task 19712 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 506, size = 11.889 MiB)
slot print_timing: id  3 | task 19712 | 
prompt eval time =     648.99 ms /   571 tokens (    1.14 ms per token,   879.83 tokens per second)
       eval time =   24193.67 ms /  1075 tokens (   22.51 ms per token,    44.43 tokens per second)
      total time =   24842.66 ms /  1646 tokens
slot      release: id  3 | task 19712 | stop processing: n_tokens = 1645, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.911 (> 0.100 thold), f_keep = 0.347
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 1645, total state size = 62.586 MiB
srv          load:  - looking for better prompt, base f_keep = 0.347, sim = 0.911
srv        update:  - cache state: 5 prompts, 1826.498 MiB (limits: 8192.000 MiB, 64000 tokens, 205663 est)
srv        update:    - prompt 0x55a5f0b7a5c0:    7162 tokens, checkpoints:  8,   347.469 MiB
srv        update:    - prompt 0x55a5f1d40020:    7615 tokens, checkpoints:  8,   361.914 MiB
srv        update:    - prompt 0x55a5f08766f0:   21813 tokens, checkpoints:  8,   712.311 MiB
srv        update:    - prompt 0x55a5e9d8fee0:    7620 tokens, checkpoints:  8,   330.328 MiB
srv        update:    - prompt 0x55a5f253e010:    1645 tokens, checkpoints:  1,    74.475 MiB
srv  get_availabl: prompt cache update took 35.76 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 20789 | processing task, is_child = 0
slot update_slots: id  3 | task 20789 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 627
slot update_slots: id  3 | task 20789 | n_past = 571, slot.prompt.tokens.size() = 1645, seq_id = 3, pos_min = 621, n_swa = 128
slot update_slots: id  3 | task 20789 | restored context checkpoint (pos_min = 0, pos_max = 506, size = 11.889 MiB)
slot update_slots: id  3 | task 20789 | n_tokens = 506, memory_seq_rm [506, end)
slot update_slots: id  3 | task 20789 | prompt processing progress, n_tokens = 563, batch.n_tokens = 57, progress = 0.897927
slot update_slots: id  3 | task 20789 | n_tokens = 563, memory_seq_rm [563, end)
slot update_slots: id  3 | task 20789 | prompt processing progress, n_tokens = 627, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 20789 | prompt done, n_tokens = 627, batch.n_tokens = 64
slot init_sampler: id  3 | task 20789 | init sampler, took 0.11 ms, tokens: text = 627, total = 627
slot print_timing: id  3 | task 20789 | 
prompt eval time =     304.61 ms /   121 tokens (    2.52 ms per token,   397.24 tokens per second)
       eval time =     763.27 ms /    34 tokens (   22.45 ms per token,    44.54 tokens per second)
      total time =    1067.88 ms /   155 tokens
slot      release: id  3 | task 20789 | stop processing: n_tokens = 660, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.929 (> 0.100 thold), f_keep = 0.950
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 20825 | processing task, is_child = 0
slot update_slots: id  3 | task 20825 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 675
slot update_slots: id  3 | task 20825 | n_tokens = 627, memory_seq_rm [627, end)
slot update_slots: id  3 | task 20825 | prompt processing progress, n_tokens = 675, batch.n_tokens = 48, progress = 1.000000
slot update_slots: id  3 | task 20825 | prompt done, n_tokens = 675, batch.n_tokens = 48
slot init_sampler: id  3 | task 20825 | init sampler, took 0.13 ms, tokens: text = 675, total = 675
slot update_slots: id  3 | task 20825 | created context checkpoint 2 of 8 (pos_min = 0, pos_max = 626, size = 14.703 MiB)
slot print_timing: id  3 | task 20825 | 
prompt eval time =     218.61 ms /    48 tokens (    4.55 ms per token,   219.57 tokens per second)
       eval time =   16472.02 ms /   719 tokens (   22.91 ms per token,    43.65 tokens per second)
      total time =   16690.63 ms /   767 tokens
slot      release: id  3 | task 20825 | stop processing: n_tokens = 1393, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.774 (> 0.100 thold), f_keep = 0.485
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 1393, total state size = 56.677 MiB
srv          load:  - looking for better prompt, base f_keep = 0.485, sim = 0.774
srv        update:  - cache state: 6 prompts, 1909.766 MiB (limits: 8192.000 MiB, 64000 tokens, 202671 est)
srv        update:    - prompt 0x55a5f0b7a5c0:    7162 tokens, checkpoints:  8,   347.469 MiB
srv        update:    - prompt 0x55a5f1d40020:    7615 tokens, checkpoints:  8,   361.914 MiB
srv        update:    - prompt 0x55a5f08766f0:   21813 tokens, checkpoints:  8,   712.311 MiB
srv        update:    - prompt 0x55a5e9d8fee0:    7620 tokens, checkpoints:  8,   330.328 MiB
srv        update:    - prompt 0x55a5f253e010:    1645 tokens, checkpoints:  1,    74.475 MiB
srv        update:    - prompt 0x55a5f0eef780:    1393 tokens, checkpoints:  2,    83.268 MiB
srv  get_availabl: prompt cache update took 54.97 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 21545 | processing task, is_child = 0
slot update_slots: id  3 | task 21545 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 872
slot update_slots: id  3 | task 21545 | n_tokens = 675, memory_seq_rm [675, end)
slot update_slots: id  3 | task 21545 | prompt processing progress, n_tokens = 808, batch.n_tokens = 133, progress = 0.926606
slot update_slots: id  3 | task 21545 | n_tokens = 808, memory_seq_rm [808, end)
slot update_slots: id  3 | task 21545 | prompt processing progress, n_tokens = 872, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 21545 | prompt done, n_tokens = 872, batch.n_tokens = 64
slot init_sampler: id  3 | task 21545 | init sampler, took 0.17 ms, tokens: text = 872, total = 872
slot update_slots: id  3 | task 21545 | created context checkpoint 3 of 8 (pos_min = 369, pos_max = 807, size = 10.294 MiB)
slot print_timing: id  3 | task 21545 | 
prompt eval time =     352.12 ms /   197 tokens (    1.79 ms per token,   559.47 tokens per second)
       eval time =   15323.53 ms /   668 tokens (   22.94 ms per token,    43.59 tokens per second)
      total time =   15675.66 ms /   865 tokens
slot      release: id  3 | task 21545 | stop processing: n_tokens = 1539, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.765 (> 0.100 thold), f_keep = 0.567
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 22215 | processing task, is_child = 0
slot update_slots: id  3 | task 22215 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1140
slot update_slots: id  3 | task 22215 | n_tokens = 872, memory_seq_rm [872, end)
slot update_slots: id  3 | task 22215 | prompt processing progress, n_tokens = 1076, batch.n_tokens = 204, progress = 0.943860
slot update_slots: id  3 | task 22215 | n_tokens = 1076, memory_seq_rm [1076, end)
slot update_slots: id  3 | task 22215 | prompt processing progress, n_tokens = 1140, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 22215 | prompt done, n_tokens = 1140, batch.n_tokens = 64
slot init_sampler: id  3 | task 22215 | init sampler, took 0.21 ms, tokens: text = 1140, total = 1140
slot update_slots: id  3 | task 22215 | created context checkpoint 4 of 8 (pos_min = 675, pos_max = 1075, size = 9.403 MiB)
slot print_timing: id  3 | task 22215 | 
prompt eval time =     438.32 ms /   268 tokens (    1.64 ms per token,   611.42 tokens per second)
       eval time =    8686.29 ms /   375 tokens (   23.16 ms per token,    43.17 tokens per second)
      total time =    9124.61 ms /   643 tokens
slot      release: id  3 | task 22215 | stop processing: n_tokens = 1514, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.816 (> 0.100 thold), f_keep = 0.753
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 22592 | processing task, is_child = 0
slot update_slots: id  3 | task 22592 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1397
slot update_slots: id  3 | task 22592 | n_tokens = 1140, memory_seq_rm [1140, end)
slot update_slots: id  3 | task 22592 | prompt processing progress, n_tokens = 1333, batch.n_tokens = 193, progress = 0.954188
slot update_slots: id  3 | task 22592 | n_tokens = 1333, memory_seq_rm [1333, end)
slot update_slots: id  3 | task 22592 | prompt processing progress, n_tokens = 1397, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 22592 | prompt done, n_tokens = 1397, batch.n_tokens = 64
slot init_sampler: id  3 | task 22592 | init sampler, took 0.25 ms, tokens: text = 1397, total = 1397
slot update_slots: id  3 | task 22592 | created context checkpoint 5 of 8 (pos_min = 675, pos_max = 1332, size = 15.430 MiB)
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv          stop: cancel task, id_task = 22592
slot      release: id  3 | task 22592 | stop processing: n_tokens = 1819, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.968 (> 0.100 thold), f_keep = 0.301
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 1819, total state size = 66.666 MiB
srv          load:  - looking for better prompt, base f_keep = 0.301, sim = 0.968
srv        update:  - cache state: 7 prompts, 2038.151 MiB (limits: 8192.000 MiB, 64000 tokens, 197216 est)
srv        update:    - prompt 0x55a5f0b7a5c0:    7162 tokens, checkpoints:  8,   347.469 MiB
srv        update:    - prompt 0x55a5f1d40020:    7615 tokens, checkpoints:  8,   361.914 MiB
srv        update:    - prompt 0x55a5f08766f0:   21813 tokens, checkpoints:  8,   712.311 MiB
srv        update:    - prompt 0x55a5e9d8fee0:    7620 tokens, checkpoints:  8,   330.328 MiB
srv        update:    - prompt 0x55a5f253e010:    1645 tokens, checkpoints:  1,    74.475 MiB
srv        update:    - prompt 0x55a5f0eef780:    1393 tokens, checkpoints:  2,    83.268 MiB
srv        update:    - prompt 0x55a606fb61a0:    1819 tokens, checkpoints:  5,   128.385 MiB
srv  get_availabl: prompt cache update took 92.81 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 23018 | processing task, is_child = 0
slot update_slots: id  3 | task 23018 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 566
slot update_slots: id  3 | task 23018 | n_past = 548, slot.prompt.tokens.size() = 1819, seq_id = 3, pos_min = 795, n_swa = 128
slot update_slots: id  3 | task 23018 | restored context checkpoint (pos_min = 369, pos_max = 807, size = 10.294 MiB)
slot update_slots: id  3 | task 23018 | erased invalidated context checkpoint (pos_min = 675, pos_max = 1075, n_swa = 128, size = 9.403 MiB)
slot update_slots: id  3 | task 23018 | erased invalidated context checkpoint (pos_min = 675, pos_max = 1332, n_swa = 128, size = 15.430 MiB)
slot update_slots: id  3 | task 23018 | n_tokens = 548, memory_seq_rm [548, end)
slot update_slots: id  3 | task 23018 | prompt processing progress, n_tokens = 566, batch.n_tokens = 18, progress = 1.000000
slot update_slots: id  3 | task 23018 | prompt done, n_tokens = 566, batch.n_tokens = 18
slot init_sampler: id  3 | task 23018 | init sampler, took 0.11 ms, tokens: text = 566, total = 566
slot print_timing: id  3 | task 23018 | 
prompt eval time =     149.68 ms /    18 tokens (    8.32 ms per token,   120.26 tokens per second)
       eval time =    1086.26 ms /    48 tokens (   22.63 ms per token,    44.19 tokens per second)
      total time =    1235.94 ms /    66 tokens
slot      release: id  3 | task 23018 | stop processing: n_tokens = 613, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.473 (> 0.100 thold), f_keep = 0.923
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 23067 | processing task, is_child = 0
slot update_slots: id  3 | task 23067 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1196
slot update_slots: id  3 | task 23067 | n_tokens = 566, memory_seq_rm [566, end)
slot update_slots: id  3 | task 23067 | prompt processing progress, n_tokens = 1132, batch.n_tokens = 566, progress = 0.946488
slot update_slots: id  3 | task 23067 | n_tokens = 1132, memory_seq_rm [1132, end)
slot update_slots: id  3 | task 23067 | prompt processing progress, n_tokens = 1196, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 23067 | prompt done, n_tokens = 1196, batch.n_tokens = 64
slot init_sampler: id  3 | task 23067 | init sampler, took 0.23 ms, tokens: text = 1196, total = 1196
slot update_slots: id  3 | task 23067 | created context checkpoint 4 of 8 (pos_min = 439, pos_max = 1131, size = 16.250 MiB)
slot print_timing: id  3 | task 23067 | 
prompt eval time =     717.75 ms /   630 tokens (    1.14 ms per token,   877.75 tokens per second)
       eval time =    1279.97 ms /    55 tokens (   23.27 ms per token,    42.97 tokens per second)
      total time =    1997.72 ms /   685 tokens
slot      release: id  3 | task 23067 | stop processing: n_tokens = 1250, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.377 (> 0.100 thold), f_keep = 0.957
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 23124 | processing task, is_child = 0
slot update_slots: id  3 | task 23124 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3169
slot update_slots: id  3 | task 23124 | n_tokens = 1196, memory_seq_rm [1196, end)
slot update_slots: id  3 | task 23124 | prompt processing progress, n_tokens = 3105, batch.n_tokens = 1909, progress = 0.979804
slot update_slots: id  3 | task 23124 | n_tokens = 3105, memory_seq_rm [3105, end)
slot update_slots: id  3 | task 23124 | prompt processing progress, n_tokens = 3169, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 23124 | prompt done, n_tokens = 3169, batch.n_tokens = 64
slot init_sampler: id  3 | task 23124 | init sampler, took 0.61 ms, tokens: text = 3169, total = 3169
slot update_slots: id  3 | task 23124 | created context checkpoint 5 of 8 (pos_min = 2081, pos_max = 3104, size = 24.012 MiB)
slot print_timing: id  3 | task 23124 | 
prompt eval time =    1924.30 ms /  1973 tokens (    0.98 ms per token,  1025.31 tokens per second)
       eval time =     971.06 ms /    43 tokens (   22.58 ms per token,    44.28 tokens per second)
      total time =    2895.35 ms /  2016 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 23124 | stop processing: n_tokens = 3211, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.953 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 23169 | processing task, is_child = 0
slot update_slots: id  3 | task 23169 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3324
slot update_slots: id  3 | task 23169 | n_tokens = 3169, memory_seq_rm [3169, end)
slot update_slots: id  3 | task 23169 | prompt processing progress, n_tokens = 3260, batch.n_tokens = 91, progress = 0.980746
slot update_slots: id  3 | task 23169 | n_tokens = 3260, memory_seq_rm [3260, end)
slot update_slots: id  3 | task 23169 | prompt processing progress, n_tokens = 3324, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 23169 | prompt done, n_tokens = 3324, batch.n_tokens = 64
slot init_sampler: id  3 | task 23169 | init sampler, took 0.52 ms, tokens: text = 3324, total = 3324
slot update_slots: id  3 | task 23169 | created context checkpoint 6 of 8 (pos_min = 2236, pos_max = 3259, size = 24.012 MiB)
slot print_timing: id  3 | task 23169 | 
prompt eval time =     344.65 ms /   155 tokens (    2.22 ms per token,   449.73 tokens per second)
       eval time =   13192.42 ms /   570 tokens (   23.14 ms per token,    43.21 tokens per second)
      total time =   13537.07 ms /   725 tokens
slot      release: id  3 | task 23169 | stop processing: n_tokens = 3893, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.473 (> 0.100 thold), f_keep = 0.140
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 3893, total state size = 115.299 MiB
srv          load:  - looking for better prompt, base f_keep = 0.140, sim = 0.473
srv        update:  - cache state: 8 prompts, 2254.611 MiB (limits: 8192.000 MiB, 64000 tokens, 192427 est)
srv        update:    - prompt 0x55a5f0b7a5c0:    7162 tokens, checkpoints:  8,   347.469 MiB
srv        update:    - prompt 0x55a5f1d40020:    7615 tokens, checkpoints:  8,   361.914 MiB
srv        update:    - prompt 0x55a5f08766f0:   21813 tokens, checkpoints:  8,   712.311 MiB
srv        update:    - prompt 0x55a5e9d8fee0:    7620 tokens, checkpoints:  8,   330.328 MiB
srv        update:    - prompt 0x55a5f253e010:    1645 tokens, checkpoints:  1,    74.475 MiB
srv        update:    - prompt 0x55a5f0eef780:    1393 tokens, checkpoints:  2,    83.268 MiB
srv        update:    - prompt 0x55a606fb61a0:    1819 tokens, checkpoints:  5,   128.385 MiB
srv        update:    - prompt 0x55a5ef774150:    3893 tokens, checkpoints:  6,   216.460 MiB
srv  get_availabl: prompt cache update took 150.14 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 23741 | processing task, is_child = 0
slot update_slots: id  3 | task 23741 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1154
slot update_slots: id  3 | task 23741 | n_past = 546, slot.prompt.tokens.size() = 3893, seq_id = 3, pos_min = 2869, n_swa = 128
slot update_slots: id  3 | task 23741 | restored context checkpoint (pos_min = 369, pos_max = 807, size = 10.294 MiB)
slot update_slots: id  3 | task 23741 | erased invalidated context checkpoint (pos_min = 439, pos_max = 1131, n_swa = 128, size = 16.250 MiB)
slot update_slots: id  3 | task 23741 | erased invalidated context checkpoint (pos_min = 2081, pos_max = 3104, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 23741 | erased invalidated context checkpoint (pos_min = 2236, pos_max = 3259, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 23741 | n_tokens = 546, memory_seq_rm [546, end)
slot update_slots: id  3 | task 23741 | prompt processing progress, n_tokens = 1090, batch.n_tokens = 544, progress = 0.944541
slot update_slots: id  3 | task 23741 | n_tokens = 1090, memory_seq_rm [1090, end)
slot update_slots: id  3 | task 23741 | prompt processing progress, n_tokens = 1154, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 23741 | prompt done, n_tokens = 1154, batch.n_tokens = 64
slot init_sampler: id  3 | task 23741 | init sampler, took 0.20 ms, tokens: text = 1154, total = 1154
slot update_slots: id  3 | task 23741 | created context checkpoint 4 of 8 (pos_min = 419, pos_max = 1089, size = 15.735 MiB)
slot print_timing: id  3 | task 23741 | 
prompt eval time =     802.71 ms /   608 tokens (    1.32 ms per token,   757.43 tokens per second)
       eval time =    2421.43 ms /   109 tokens (   22.21 ms per token,    45.01 tokens per second)
      total time =    3224.14 ms /   717 tokens
slot      release: id  3 | task 23741 | stop processing: n_tokens = 1262, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.369 (> 0.100 thold), f_keep = 0.914
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 23852 | processing task, is_child = 0
slot update_slots: id  3 | task 23852 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3127
slot update_slots: id  3 | task 23852 | n_tokens = 1154, memory_seq_rm [1154, end)
slot update_slots: id  3 | task 23852 | prompt processing progress, n_tokens = 3063, batch.n_tokens = 1909, progress = 0.979533
slot update_slots: id  3 | task 23852 | n_tokens = 3063, memory_seq_rm [3063, end)
slot update_slots: id  3 | task 23852 | prompt processing progress, n_tokens = 3127, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 23852 | prompt done, n_tokens = 3127, batch.n_tokens = 64
slot init_sampler: id  3 | task 23852 | init sampler, took 0.54 ms, tokens: text = 3127, total = 3127
slot update_slots: id  3 | task 23852 | created context checkpoint 5 of 8 (pos_min = 2039, pos_max = 3062, size = 24.012 MiB)
slot print_timing: id  3 | task 23852 | 
prompt eval time =    1937.12 ms /  1973 tokens (    0.98 ms per token,  1018.52 tokens per second)
       eval time =    7005.14 ms /   307 tokens (   22.82 ms per token,    43.82 tokens per second)
      total time =    8942.25 ms /  2280 tokens
slot      release: id  3 | task 23852 | stop processing: n_tokens = 3433, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.906 (> 0.100 thold), f_keep = 0.911
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 24161 | processing task, is_child = 0
slot update_slots: id  3 | task 24161 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3451
slot update_slots: id  3 | task 24161 | n_tokens = 3127, memory_seq_rm [3127, end)
slot update_slots: id  3 | task 24161 | prompt processing progress, n_tokens = 3387, batch.n_tokens = 260, progress = 0.981455
slot update_slots: id  3 | task 24161 | n_tokens = 3387, memory_seq_rm [3387, end)
slot update_slots: id  3 | task 24161 | prompt processing progress, n_tokens = 3451, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 24161 | prompt done, n_tokens = 3451, batch.n_tokens = 64
slot init_sampler: id  3 | task 24161 | init sampler, took 0.67 ms, tokens: text = 3451, total = 3451
slot update_slots: id  3 | task 24161 | created context checkpoint 6 of 8 (pos_min = 2409, pos_max = 3386, size = 22.933 MiB)
slot print_timing: id  3 | task 24161 | 
prompt eval time =     459.48 ms /   324 tokens (    1.42 ms per token,   705.15 tokens per second)
       eval time =    1170.11 ms /    51 tokens (   22.94 ms per token,    43.59 tokens per second)
      total time =    1629.58 ms /   375 tokens
slot      release: id  3 | task 24161 | stop processing: n_tokens = 3501, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.828 (> 0.100 thold), f_keep = 0.986
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 24214 | processing task, is_child = 0
slot update_slots: id  3 | task 24214 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4170
slot update_slots: id  3 | task 24214 | n_tokens = 3451, memory_seq_rm [3451, end)
slot update_slots: id  3 | task 24214 | prompt processing progress, n_tokens = 4106, batch.n_tokens = 655, progress = 0.984652
slot update_slots: id  3 | task 24214 | n_tokens = 4106, memory_seq_rm [4106, end)
slot update_slots: id  3 | task 24214 | prompt processing progress, n_tokens = 4170, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 24214 | prompt done, n_tokens = 4170, batch.n_tokens = 64
slot init_sampler: id  3 | task 24214 | init sampler, took 0.63 ms, tokens: text = 4170, total = 4170
slot update_slots: id  3 | task 24214 | created context checkpoint 7 of 8 (pos_min = 3122, pos_max = 4105, size = 23.074 MiB)
slot print_timing: id  3 | task 24214 | 
prompt eval time =     831.69 ms /   719 tokens (    1.16 ms per token,   864.51 tokens per second)
       eval time =    4839.27 ms /   213 tokens (   22.72 ms per token,    44.01 tokens per second)
      total time =    5670.96 ms /   932 tokens
slot      release: id  3 | task 24214 | stop processing: n_tokens = 4382, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.948 (> 0.100 thold), f_keep = 0.952
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 24429 | processing task, is_child = 0
slot update_slots: id  3 | task 24429 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4398
slot update_slots: id  3 | task 24429 | n_tokens = 4170, memory_seq_rm [4170, end)
slot update_slots: id  3 | task 24429 | prompt processing progress, n_tokens = 4334, batch.n_tokens = 164, progress = 0.985448
slot update_slots: id  3 | task 24429 | n_tokens = 4334, memory_seq_rm [4334, end)
slot update_slots: id  3 | task 24429 | prompt processing progress, n_tokens = 4398, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 24429 | prompt done, n_tokens = 4398, batch.n_tokens = 64
slot init_sampler: id  3 | task 24429 | init sampler, took 0.67 ms, tokens: text = 4398, total = 4398
slot update_slots: id  3 | task 24429 | created context checkpoint 8 of 8 (pos_min = 3398, pos_max = 4333, size = 21.949 MiB)
slot print_timing: id  3 | task 24429 | 
prompt eval time =     411.11 ms /   228 tokens (    1.80 ms per token,   554.60 tokens per second)
       eval time =    4332.91 ms /   186 tokens (   23.30 ms per token,    42.93 tokens per second)
      total time =    4744.02 ms /   414 tokens
slot      release: id  3 | task 24429 | stop processing: n_tokens = 4583, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.957 (> 0.100 thold), f_keep = 0.960
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 24617 | processing task, is_child = 0
slot update_slots: id  3 | task 24617 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4596
slot update_slots: id  3 | task 24617 | n_tokens = 4398, memory_seq_rm [4398, end)
slot update_slots: id  3 | task 24617 | prompt processing progress, n_tokens = 4532, batch.n_tokens = 134, progress = 0.986075
slot update_slots: id  3 | task 24617 | n_tokens = 4532, memory_seq_rm [4532, end)
slot update_slots: id  3 | task 24617 | prompt processing progress, n_tokens = 4596, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 24617 | prompt done, n_tokens = 4596, batch.n_tokens = 64
slot init_sampler: id  3 | task 24617 | init sampler, took 0.84 ms, tokens: text = 4596, total = 4596
slot update_slots: id  3 | task 24617 | erasing old context checkpoint (pos_min = 0, pos_max = 506, size = 11.889 MiB)
slot update_slots: id  3 | task 24617 | created context checkpoint 8 of 8 (pos_min = 3585, pos_max = 4531, size = 22.206 MiB)
slot print_timing: id  3 | task 24617 | 
prompt eval time =     368.97 ms /   198 tokens (    1.86 ms per token,   536.63 tokens per second)
       eval time =     775.30 ms /    34 tokens (   22.80 ms per token,    43.85 tokens per second)
      total time =    1144.27 ms /   232 tokens
slot      release: id  3 | task 24617 | stop processing: n_tokens = 4629, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.162 (> 0.100 thold), f_keep = 0.068
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 4629, total state size = 130.752 MiB
srv          load:  - looking for better prompt, base f_keep = 0.068, sim = 0.162
srv        update:  - cache state: 9 prompts, 2540.268 MiB (limits: 8192.000 MiB, 64000 tokens, 185716 est)
srv        update:    - prompt 0x55a5f0b7a5c0:    7162 tokens, checkpoints:  8,   347.469 MiB
srv        update:    - prompt 0x55a5f1d40020:    7615 tokens, checkpoints:  8,   361.914 MiB
srv        update:    - prompt 0x55a5f08766f0:   21813 tokens, checkpoints:  8,   712.311 MiB
srv        update:    - prompt 0x55a5e9d8fee0:    7620 tokens, checkpoints:  8,   330.328 MiB
srv        update:    - prompt 0x55a5f253e010:    1645 tokens, checkpoints:  1,    74.475 MiB
srv        update:    - prompt 0x55a5f0eef780:    1393 tokens, checkpoints:  2,    83.268 MiB
srv        update:    - prompt 0x55a606fb61a0:    1819 tokens, checkpoints:  5,   128.385 MiB
srv        update:    - prompt 0x55a5ef774150:    3893 tokens, checkpoints:  6,   216.460 MiB
srv        update:    - prompt 0x55a5ef97d560:    4629 tokens, checkpoints:  8,   285.658 MiB
srv  get_availabl: prompt cache update took 224.59 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 24653 | processing task, is_child = 0
slot update_slots: id  3 | task 24653 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1943
slot update_slots: id  3 | task 24653 | n_past = 315, slot.prompt.tokens.size() = 4629, seq_id = 3, pos_min = 3682, n_swa = 128
slot update_slots: id  3 | task 24653 | restored context checkpoint (pos_min = 0, pos_max = 626, size = 14.703 MiB)
slot update_slots: id  3 | task 24653 | erased invalidated context checkpoint (pos_min = 369, pos_max = 807, n_swa = 128, size = 10.294 MiB)
slot update_slots: id  3 | task 24653 | erased invalidated context checkpoint (pos_min = 419, pos_max = 1089, n_swa = 128, size = 15.735 MiB)
slot update_slots: id  3 | task 24653 | erased invalidated context checkpoint (pos_min = 2039, pos_max = 3062, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 24653 | erased invalidated context checkpoint (pos_min = 2409, pos_max = 3386, n_swa = 128, size = 22.933 MiB)
slot update_slots: id  3 | task 24653 | erased invalidated context checkpoint (pos_min = 3122, pos_max = 4105, n_swa = 128, size = 23.074 MiB)
slot update_slots: id  3 | task 24653 | erased invalidated context checkpoint (pos_min = 3398, pos_max = 4333, n_swa = 128, size = 21.949 MiB)
slot update_slots: id  3 | task 24653 | erased invalidated context checkpoint (pos_min = 3585, pos_max = 4531, n_swa = 128, size = 22.206 MiB)
slot update_slots: id  3 | task 24653 | n_tokens = 315, memory_seq_rm [315, end)
slot update_slots: id  3 | task 24653 | prompt processing progress, n_tokens = 1879, batch.n_tokens = 1564, progress = 0.967061
slot update_slots: id  3 | task 24653 | n_tokens = 1879, memory_seq_rm [1879, end)
slot update_slots: id  3 | task 24653 | prompt processing progress, n_tokens = 1943, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 24653 | prompt done, n_tokens = 1943, batch.n_tokens = 64
slot init_sampler: id  3 | task 24653 | init sampler, took 0.36 ms, tokens: text = 1943, total = 1943
slot update_slots: id  3 | task 24653 | created context checkpoint 2 of 8 (pos_min = 855, pos_max = 1878, size = 24.012 MiB)
slot print_timing: id  3 | task 24653 | 
prompt eval time =    1703.32 ms /  1628 tokens (    1.05 ms per token,   955.78 tokens per second)
       eval time =     675.01 ms /    26 tokens (   25.96 ms per token,    38.52 tokens per second)
      total time =    2378.32 ms /  1654 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 24653 | stop processing: n_tokens = 1968, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.967 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 24681 | processing task, is_child = 0
slot update_slots: id  3 | task 24681 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2009
slot update_slots: id  3 | task 24681 | n_tokens = 1943, memory_seq_rm [1943, end)
slot update_slots: id  3 | task 24681 | prompt processing progress, n_tokens = 1945, batch.n_tokens = 2, progress = 0.968143
slot update_slots: id  3 | task 24681 | n_tokens = 1945, memory_seq_rm [1945, end)
slot update_slots: id  3 | task 24681 | prompt processing progress, n_tokens = 2009, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 24681 | prompt done, n_tokens = 2009, batch.n_tokens = 64
slot init_sampler: id  3 | task 24681 | init sampler, took 0.33 ms, tokens: text = 2009, total = 2009
slot update_slots: id  3 | task 24681 | created context checkpoint 3 of 8 (pos_min = 944, pos_max = 1944, size = 23.473 MiB)
slot print_timing: id  3 | task 24681 | 
prompt eval time =     257.87 ms /    66 tokens (    3.91 ms per token,   255.94 tokens per second)
       eval time =     271.96 ms /    13 tokens (   20.92 ms per token,    47.80 tokens per second)
      total time =     529.83 ms /    79 tokens
slot      release: id  3 | task 24681 | stop processing: n_tokens = 2021, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.963 (> 0.100 thold), f_keep = 0.953
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 24696 | processing task, is_child = 0
slot update_slots: id  3 | task 24696 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2002
slot update_slots: id  3 | task 24696 | n_tokens = 1927, memory_seq_rm [1927, end)
slot update_slots: id  3 | task 24696 | prompt processing progress, n_tokens = 1938, batch.n_tokens = 11, progress = 0.968032
slot update_slots: id  3 | task 24696 | n_tokens = 1938, memory_seq_rm [1938, end)
slot update_slots: id  3 | task 24696 | prompt processing progress, n_tokens = 2002, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 24696 | prompt done, n_tokens = 2002, batch.n_tokens = 64
slot init_sampler: id  3 | task 24696 | init sampler, took 0.32 ms, tokens: text = 2002, total = 2002
slot print_timing: id  3 | task 24696 | 
prompt eval time =     324.74 ms /    75 tokens (    4.33 ms per token,   230.95 tokens per second)
       eval time =    8430.87 ms /   366 tokens (   23.04 ms per token,    43.41 tokens per second)
      total time =    8755.61 ms /   441 tokens
slot      release: id  3 | task 24696 | stop processing: n_tokens = 2367, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.858 (> 0.100 thold), f_keep = 0.846
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 25064 | processing task, is_child = 0
slot update_slots: id  3 | task 25064 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2334
slot update_slots: id  3 | task 25064 | n_tokens = 2002, memory_seq_rm [2002, end)
slot update_slots: id  3 | task 25064 | prompt processing progress, n_tokens = 2270, batch.n_tokens = 268, progress = 0.972579
slot update_slots: id  3 | task 25064 | n_tokens = 2270, memory_seq_rm [2270, end)
slot update_slots: id  3 | task 25064 | prompt processing progress, n_tokens = 2334, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 25064 | prompt done, n_tokens = 2334, batch.n_tokens = 64
slot init_sampler: id  3 | task 25064 | init sampler, took 0.45 ms, tokens: text = 2334, total = 2334
slot update_slots: id  3 | task 25064 | created context checkpoint 4 of 8 (pos_min = 1343, pos_max = 2269, size = 21.737 MiB)
slot print_timing: id  3 | task 25064 | 
prompt eval time =     456.40 ms /   332 tokens (    1.37 ms per token,   727.43 tokens per second)
       eval time =    6269.06 ms /   276 tokens (   22.71 ms per token,    44.03 tokens per second)
      total time =    6725.46 ms /   608 tokens
slot      release: id  3 | task 25064 | stop processing: n_tokens = 2609, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.964 (> 0.100 thold), f_keep = 0.895
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 25342 | processing task, is_child = 0
slot update_slots: id  3 | task 25342 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2421
slot update_slots: id  3 | task 25342 | n_tokens = 2334, memory_seq_rm [2334, end)
slot update_slots: id  3 | task 25342 | prompt processing progress, n_tokens = 2357, batch.n_tokens = 23, progress = 0.973565
slot update_slots: id  3 | task 25342 | n_tokens = 2357, memory_seq_rm [2357, end)
slot update_slots: id  3 | task 25342 | prompt processing progress, n_tokens = 2421, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 25342 | prompt done, n_tokens = 2421, batch.n_tokens = 64
slot init_sampler: id  3 | task 25342 | init sampler, took 0.38 ms, tokens: text = 2421, total = 2421
slot update_slots: id  3 | task 25342 | created context checkpoint 5 of 8 (pos_min = 1631, pos_max = 2356, size = 17.024 MiB)
slot print_timing: id  3 | task 25342 | 
prompt eval time =     236.96 ms /    87 tokens (    2.72 ms per token,   367.16 tokens per second)
       eval time =    7031.40 ms /   312 tokens (   22.54 ms per token,    44.37 tokens per second)
      total time =    7268.36 ms /   399 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 25342 | stop processing: n_tokens = 2732, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.961 (> 0.100 thold), f_keep = 0.886
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 25656 | processing task, is_child = 0
slot update_slots: id  3 | task 25656 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2518
slot update_slots: id  3 | task 25656 | n_tokens = 2421, memory_seq_rm [2421, end)
slot update_slots: id  3 | task 25656 | prompt processing progress, n_tokens = 2454, batch.n_tokens = 33, progress = 0.974583
slot update_slots: id  3 | task 25656 | n_tokens = 2454, memory_seq_rm [2454, end)
slot update_slots: id  3 | task 25656 | prompt processing progress, n_tokens = 2518, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 25656 | prompt done, n_tokens = 2518, batch.n_tokens = 64
slot init_sampler: id  3 | task 25656 | init sampler, took 0.46 ms, tokens: text = 2518, total = 2518
slot update_slots: id  3 | task 25656 | created context checkpoint 6 of 8 (pos_min = 1754, pos_max = 2453, size = 16.415 MiB)
slot print_timing: id  3 | task 25656 | 
prompt eval time =     379.45 ms /    97 tokens (    3.91 ms per token,   255.63 tokens per second)
       eval time =    4837.77 ms /   215 tokens (   22.50 ms per token,    44.44 tokens per second)
      total time =    5217.22 ms /   312 tokens
slot      release: id  3 | task 25656 | stop processing: n_tokens = 2732, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.959 (> 0.100 thold), f_keep = 0.922
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 25873 | processing task, is_child = 0
slot update_slots: id  3 | task 25873 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2625
slot update_slots: id  3 | task 25873 | n_tokens = 2518, memory_seq_rm [2518, end)
slot update_slots: id  3 | task 25873 | prompt processing progress, n_tokens = 2561, batch.n_tokens = 43, progress = 0.975619
slot update_slots: id  3 | task 25873 | n_tokens = 2561, memory_seq_rm [2561, end)
slot update_slots: id  3 | task 25873 | prompt processing progress, n_tokens = 2625, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 25873 | prompt done, n_tokens = 2625, batch.n_tokens = 64
slot init_sampler: id  3 | task 25873 | init sampler, took 0.39 ms, tokens: text = 2625, total = 2625
slot update_slots: id  3 | task 25873 | created context checkpoint 7 of 8 (pos_min = 1754, pos_max = 2560, size = 18.924 MiB)
slot print_timing: id  3 | task 25873 | 
prompt eval time =     279.25 ms /   107 tokens (    2.61 ms per token,   383.18 tokens per second)
       eval time =    2241.77 ms /    99 tokens (   22.64 ms per token,    44.16 tokens per second)
      total time =    2521.01 ms /   206 tokens
slot      release: id  3 | task 25873 | stop processing: n_tokens = 2723, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.565 (> 0.100 thold), f_keep = 0.964
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 25974 | processing task, is_child = 0
slot update_slots: id  3 | task 25974 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4642
slot update_slots: id  3 | task 25974 | n_tokens = 2625, memory_seq_rm [2625, end)
slot update_slots: id  3 | task 25974 | prompt processing progress, n_tokens = 4578, batch.n_tokens = 1953, progress = 0.986213
slot update_slots: id  3 | task 25974 | n_tokens = 4578, memory_seq_rm [4578, end)
slot update_slots: id  3 | task 25974 | prompt processing progress, n_tokens = 4642, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 25974 | prompt done, n_tokens = 4642, batch.n_tokens = 64
slot init_sampler: id  3 | task 25974 | init sampler, took 0.88 ms, tokens: text = 4642, total = 4642
slot update_slots: id  3 | task 25974 | created context checkpoint 8 of 8 (pos_min = 3554, pos_max = 4577, size = 24.012 MiB)
slot print_timing: id  3 | task 25974 | 
prompt eval time =    2011.51 ms /  2017 tokens (    1.00 ms per token,  1002.73 tokens per second)
       eval time =    4102.51 ms /   175 tokens (   23.44 ms per token,    42.66 tokens per second)
      total time =    6114.02 ms /  2192 tokens
slot      release: id  3 | task 25974 | stop processing: n_tokens = 4816, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.965 (> 0.100 thold), f_keep = 0.964
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 26151 | processing task, is_child = 0
slot update_slots: id  3 | task 26151 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4812
slot update_slots: id  3 | task 26151 | n_tokens = 4642, memory_seq_rm [4642, end)
slot update_slots: id  3 | task 26151 | prompt processing progress, n_tokens = 4748, batch.n_tokens = 106, progress = 0.986700
slot update_slots: id  3 | task 26151 | n_tokens = 4748, memory_seq_rm [4748, end)
slot update_slots: id  3 | task 26151 | prompt processing progress, n_tokens = 4812, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 26151 | prompt done, n_tokens = 4812, batch.n_tokens = 64
slot init_sampler: id  3 | task 26151 | init sampler, took 0.73 ms, tokens: text = 4812, total = 4812
slot update_slots: id  3 | task 26151 | erasing old context checkpoint (pos_min = 0, pos_max = 626, size = 14.703 MiB)
slot update_slots: id  3 | task 26151 | created context checkpoint 8 of 8 (pos_min = 3792, pos_max = 4747, size = 22.417 MiB)
slot print_timing: id  3 | task 26151 | 
prompt eval time =     370.62 ms /   170 tokens (    2.18 ms per token,   458.70 tokens per second)
       eval time =    7152.11 ms /   309 tokens (   23.15 ms per token,    43.20 tokens per second)
      total time =    7522.72 ms /   479 tokens
slot      release: id  3 | task 26151 | stop processing: n_tokens = 5120, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.983 (> 0.100 thold), f_keep = 0.940
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 26462 | processing task, is_child = 0
slot update_slots: id  3 | task 26462 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4896
slot update_slots: id  3 | task 26462 | n_tokens = 4812, memory_seq_rm [4812, end)
slot update_slots: id  3 | task 26462 | prompt processing progress, n_tokens = 4832, batch.n_tokens = 20, progress = 0.986928
slot update_slots: id  3 | task 26462 | n_tokens = 4832, memory_seq_rm [4832, end)
slot update_slots: id  3 | task 26462 | prompt processing progress, n_tokens = 4896, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 26462 | prompt done, n_tokens = 4896, batch.n_tokens = 64
slot init_sampler: id  3 | task 26462 | init sampler, took 0.91 ms, tokens: text = 4896, total = 4896
slot update_slots: id  3 | task 26462 | erasing old context checkpoint (pos_min = 855, pos_max = 1878, size = 24.012 MiB)
slot update_slots: id  3 | task 26462 | created context checkpoint 8 of 8 (pos_min = 4096, pos_max = 4831, size = 17.259 MiB)
slot print_timing: id  3 | task 26462 | 
prompt eval time =     345.39 ms /    84 tokens (    4.11 ms per token,   243.20 tokens per second)
       eval time =    2549.08 ms /   107 tokens (   23.82 ms per token,    41.98 tokens per second)
      total time =    2894.48 ms /   191 tokens
slot      release: id  3 | task 26462 | stop processing: n_tokens = 5002, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.967 (> 0.100 thold), f_keep = 0.979
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 26571 | processing task, is_child = 0
slot update_slots: id  3 | task 26571 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5063
slot update_slots: id  3 | task 26571 | n_tokens = 4896, memory_seq_rm [4896, end)
slot update_slots: id  3 | task 26571 | prompt processing progress, n_tokens = 4999, batch.n_tokens = 103, progress = 0.987359
slot update_slots: id  3 | task 26571 | n_tokens = 4999, memory_seq_rm [4999, end)
slot update_slots: id  3 | task 26571 | prompt processing progress, n_tokens = 5063, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 26571 | prompt done, n_tokens = 5063, batch.n_tokens = 64
slot init_sampler: id  3 | task 26571 | init sampler, took 0.77 ms, tokens: text = 5063, total = 5063
slot update_slots: id  3 | task 26571 | erasing old context checkpoint (pos_min = 944, pos_max = 1944, size = 23.473 MiB)
slot update_slots: id  3 | task 26571 | created context checkpoint 8 of 8 (pos_min = 4240, pos_max = 4998, size = 17.798 MiB)
slot print_timing: id  3 | task 26571 | 
prompt eval time =     383.56 ms /   167 tokens (    2.30 ms per token,   435.39 tokens per second)
       eval time =    3507.08 ms /   151 tokens (   23.23 ms per token,    43.06 tokens per second)
      total time =    3890.64 ms /   318 tokens
slot      release: id  3 | task 26571 | stop processing: n_tokens = 5213, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.980 (> 0.100 thold), f_keep = 0.971
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 26724 | processing task, is_child = 0
slot update_slots: id  3 | task 26724 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5168
slot update_slots: id  3 | task 26724 | n_tokens = 5063, memory_seq_rm [5063, end)
slot update_slots: id  3 | task 26724 | prompt processing progress, n_tokens = 5104, batch.n_tokens = 41, progress = 0.987616
slot update_slots: id  3 | task 26724 | n_tokens = 5104, memory_seq_rm [5104, end)
slot update_slots: id  3 | task 26724 | prompt processing progress, n_tokens = 5168, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 26724 | prompt done, n_tokens = 5168, batch.n_tokens = 64
slot init_sampler: id  3 | task 26724 | init sampler, took 1.47 ms, tokens: text = 5168, total = 5168
slot update_slots: id  3 | task 26724 | erasing old context checkpoint (pos_min = 1343, pos_max = 2269, size = 21.737 MiB)
slot update_slots: id  3 | task 26724 | created context checkpoint 8 of 8 (pos_min = 4451, pos_max = 5103, size = 15.312 MiB)
slot print_timing: id  3 | task 26724 | 
prompt eval time =     400.71 ms /   105 tokens (    3.82 ms per token,   262.04 tokens per second)
       eval time =    6889.18 ms /   294 tokens (   23.43 ms per token,    42.68 tokens per second)
      total time =    7289.89 ms /   399 tokens
slot      release: id  3 | task 26724 | stop processing: n_tokens = 5461, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.678 (> 0.100 thold), f_keep = 0.360
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 5461, total state size = 145.923 MiB
srv          load:  - looking for better prompt, base f_keep = 0.360, sim = 0.678
srv        update:  - cache state: 10 prompts, 2835.353 MiB (limits: 8192.000 MiB, 64000 tokens, 182166 est)
srv        update:    - prompt 0x55a5f0b7a5c0:    7162 tokens, checkpoints:  8,   347.469 MiB
srv        update:    - prompt 0x55a5f1d40020:    7615 tokens, checkpoints:  8,   361.914 MiB
srv        update:    - prompt 0x55a5f08766f0:   21813 tokens, checkpoints:  8,   712.311 MiB
srv        update:    - prompt 0x55a5e9d8fee0:    7620 tokens, checkpoints:  8,   330.328 MiB
srv        update:    - prompt 0x55a5f253e010:    1645 tokens, checkpoints:  1,    74.475 MiB
srv        update:    - prompt 0x55a5f0eef780:    1393 tokens, checkpoints:  2,    83.268 MiB
srv        update:    - prompt 0x55a606fb61a0:    1819 tokens, checkpoints:  5,   128.385 MiB
srv        update:    - prompt 0x55a5ef774150:    3893 tokens, checkpoints:  6,   216.460 MiB
srv        update:    - prompt 0x55a5ef97d560:    4629 tokens, checkpoints:  8,   285.658 MiB
srv        update:    - prompt 0x55a5f1e7ee30:    5461 tokens, checkpoints:  8,   295.084 MiB
srv  get_availabl: prompt cache update took 204.07 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 27020 | processing task, is_child = 0
slot update_slots: id  3 | task 27020 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2901
slot update_slots: id  3 | task 27020 | n_past = 1968, slot.prompt.tokens.size() = 5461, seq_id = 3, pos_min = 4699, n_swa = 128
slot update_slots: id  3 | task 27020 | restored context checkpoint (pos_min = 1754, pos_max = 2560, size = 18.924 MiB)
slot update_slots: id  3 | task 27020 | erased invalidated context checkpoint (pos_min = 3554, pos_max = 4577, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 27020 | erased invalidated context checkpoint (pos_min = 3792, pos_max = 4747, n_swa = 128, size = 22.417 MiB)
slot update_slots: id  3 | task 27020 | erased invalidated context checkpoint (pos_min = 4096, pos_max = 4831, n_swa = 128, size = 17.259 MiB)
slot update_slots: id  3 | task 27020 | erased invalidated context checkpoint (pos_min = 4240, pos_max = 4998, n_swa = 128, size = 17.798 MiB)
slot update_slots: id  3 | task 27020 | erased invalidated context checkpoint (pos_min = 4451, pos_max = 5103, n_swa = 128, size = 15.312 MiB)
slot update_slots: id  3 | task 27020 | n_tokens = 1968, memory_seq_rm [1968, end)
slot update_slots: id  3 | task 27020 | prompt processing progress, n_tokens = 2837, batch.n_tokens = 869, progress = 0.977939
slot update_slots: id  3 | task 27020 | n_tokens = 2837, memory_seq_rm [2837, end)
slot update_slots: id  3 | task 27020 | prompt processing progress, n_tokens = 2901, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 27020 | prompt done, n_tokens = 2901, batch.n_tokens = 64
slot init_sampler: id  3 | task 27020 | init sampler, took 0.46 ms, tokens: text = 2901, total = 2901
slot update_slots: id  3 | task 27020 | created context checkpoint 4 of 8 (pos_min = 1968, pos_max = 2836, size = 20.377 MiB)
slot print_timing: id  3 | task 27020 | 
prompt eval time =    1062.64 ms /   933 tokens (    1.14 ms per token,   878.00 tokens per second)
       eval time =   21896.35 ms /   960 tokens (   22.81 ms per token,    43.84 tokens per second)
      total time =   22958.99 ms /  1893 tokens
slot      release: id  3 | task 27020 | stop processing: n_tokens = 3860, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.877 (> 0.100 thold), f_keep = 0.742
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 27982 | processing task, is_child = 0
slot update_slots: id  3 | task 27982 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3265
slot update_slots: id  3 | task 27982 | n_past = 2863, slot.prompt.tokens.size() = 3860, seq_id = 3, pos_min = 2836, n_swa = 128
slot update_slots: id  3 | task 27982 | restored context checkpoint (pos_min = 1968, pos_max = 2836, size = 20.377 MiB)
slot update_slots: id  3 | task 27982 | n_tokens = 2836, memory_seq_rm [2836, end)
slot update_slots: id  3 | task 27982 | prompt processing progress, n_tokens = 3201, batch.n_tokens = 365, progress = 0.980398
slot update_slots: id  3 | task 27982 | n_tokens = 3201, memory_seq_rm [3201, end)
slot update_slots: id  3 | task 27982 | prompt processing progress, n_tokens = 3265, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 27982 | prompt done, n_tokens = 3265, batch.n_tokens = 64
slot init_sampler: id  3 | task 27982 | init sampler, took 0.51 ms, tokens: text = 3265, total = 3265
slot update_slots: id  3 | task 27982 | created context checkpoint 5 of 8 (pos_min = 2177, pos_max = 3200, size = 24.012 MiB)
slot print_timing: id  3 | task 27982 | 
prompt eval time =     668.82 ms /   429 tokens (    1.56 ms per token,   641.43 tokens per second)
       eval time =    8974.67 ms /   402 tokens (   22.33 ms per token,    44.79 tokens per second)
      total time =    9643.49 ms /   831 tokens
slot      release: id  3 | task 27982 | stop processing: n_tokens = 3666, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.901 (> 0.100 thold), f_keep = 0.891
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 28386 | processing task, is_child = 0
slot update_slots: id  3 | task 28386 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3622
slot update_slots: id  3 | task 28386 | n_tokens = 3265, memory_seq_rm [3265, end)
slot update_slots: id  3 | task 28386 | prompt processing progress, n_tokens = 3558, batch.n_tokens = 293, progress = 0.982330
slot update_slots: id  3 | task 28386 | n_tokens = 3558, memory_seq_rm [3558, end)
slot update_slots: id  3 | task 28386 | prompt processing progress, n_tokens = 3622, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 28386 | prompt done, n_tokens = 3622, batch.n_tokens = 64
slot init_sampler: id  3 | task 28386 | init sampler, took 0.71 ms, tokens: text = 3622, total = 3622
slot update_slots: id  3 | task 28386 | created context checkpoint 6 of 8 (pos_min = 2642, pos_max = 3557, size = 21.480 MiB)
slot print_timing: id  3 | task 28386 | 
prompt eval time =     489.88 ms /   357 tokens (    1.37 ms per token,   728.74 tokens per second)
       eval time =    5384.58 ms /   240 tokens (   22.44 ms per token,    44.57 tokens per second)
      total time =    5874.46 ms /   597 tokens
slot      release: id  3 | task 28386 | stop processing: n_tokens = 3861, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.963 (> 0.100 thold), f_keep = 0.938
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 28628 | processing task, is_child = 0
slot update_slots: id  3 | task 28628 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3760
slot update_slots: id  3 | task 28628 | n_tokens = 3622, memory_seq_rm [3622, end)
slot update_slots: id  3 | task 28628 | prompt processing progress, n_tokens = 3696, batch.n_tokens = 74, progress = 0.982979
slot update_slots: id  3 | task 28628 | n_tokens = 3696, memory_seq_rm [3696, end)
slot update_slots: id  3 | task 28628 | prompt processing progress, n_tokens = 3760, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 28628 | prompt done, n_tokens = 3760, batch.n_tokens = 64
slot init_sampler: id  3 | task 28628 | init sampler, took 0.57 ms, tokens: text = 3760, total = 3760
slot update_slots: id  3 | task 28628 | created context checkpoint 7 of 8 (pos_min = 2837, pos_max = 3695, size = 20.143 MiB)
slot print_timing: id  3 | task 28628 | 
prompt eval time =     328.70 ms /   138 tokens (    2.38 ms per token,   419.84 tokens per second)
       eval time =    1375.87 ms /    61 tokens (   22.56 ms per token,    44.34 tokens per second)
      total time =    1704.57 ms /   199 tokens
slot      release: id  3 | task 28628 | stop processing: n_tokens = 3820, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.651 (> 0.100 thold), f_keep = 0.984
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 28691 | processing task, is_child = 0
slot update_slots: id  3 | task 28691 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5777
slot update_slots: id  3 | task 28691 | n_tokens = 3760, memory_seq_rm [3760, end)
slot update_slots: id  3 | task 28691 | prompt processing progress, n_tokens = 5713, batch.n_tokens = 1953, progress = 0.988922
slot update_slots: id  3 | task 28691 | n_tokens = 5713, memory_seq_rm [5713, end)
slot update_slots: id  3 | task 28691 | prompt processing progress, n_tokens = 5777, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 28691 | prompt done, n_tokens = 5777, batch.n_tokens = 64
slot init_sampler: id  3 | task 28691 | init sampler, took 1.07 ms, tokens: text = 5777, total = 5777
slot update_slots: id  3 | task 28691 | created context checkpoint 8 of 8 (pos_min = 4689, pos_max = 5712, size = 24.012 MiB)
slot print_timing: id  3 | task 28691 | 
prompt eval time =    2014.05 ms /  2017 tokens (    1.00 ms per token,  1001.47 tokens per second)
       eval time =   12028.46 ms /   520 tokens (   23.13 ms per token,    43.23 tokens per second)
      total time =   14042.51 ms /  2537 tokens
slot      release: id  3 | task 28691 | stop processing: n_tokens = 6296, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.981 (> 0.100 thold), f_keep = 0.918
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 29213 | processing task, is_child = 0
slot update_slots: id  3 | task 29213 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5886
slot update_slots: id  3 | task 29213 | n_tokens = 5777, memory_seq_rm [5777, end)
slot update_slots: id  3 | task 29213 | prompt processing progress, n_tokens = 5822, batch.n_tokens = 45, progress = 0.989127
slot update_slots: id  3 | task 29213 | n_tokens = 5822, memory_seq_rm [5822, end)
slot update_slots: id  3 | task 29213 | prompt processing progress, n_tokens = 5886, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 29213 | prompt done, n_tokens = 5886, batch.n_tokens = 64
slot init_sampler: id  3 | task 29213 | init sampler, took 2.58 ms, tokens: text = 5886, total = 5886
slot update_slots: id  3 | task 29213 | erasing old context checkpoint (pos_min = 1631, pos_max = 2356, size = 17.024 MiB)
slot update_slots: id  3 | task 29213 | created context checkpoint 8 of 8 (pos_min = 5272, pos_max = 5821, size = 12.897 MiB)
slot print_timing: id  3 | task 29213 | 
prompt eval time =     380.30 ms /   109 tokens (    3.49 ms per token,   286.62 tokens per second)
       eval time =    6722.94 ms /   286 tokens (   23.51 ms per token,    42.54 tokens per second)
      total time =    7103.24 ms /   395 tokens
slot      release: id  3 | task 29213 | stop processing: n_tokens = 6171, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.877 (> 0.100 thold), f_keep = 0.954
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 29501 | processing task, is_child = 0
slot update_slots: id  3 | task 29501 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6713
slot update_slots: id  3 | task 29501 | n_tokens = 5886, memory_seq_rm [5886, end)
slot update_slots: id  3 | task 29501 | prompt processing progress, n_tokens = 6649, batch.n_tokens = 763, progress = 0.990466
slot update_slots: id  3 | task 29501 | n_tokens = 6649, memory_seq_rm [6649, end)
slot update_slots: id  3 | task 29501 | prompt processing progress, n_tokens = 6713, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 29501 | prompt done, n_tokens = 6713, batch.n_tokens = 64
slot init_sampler: id  3 | task 29501 | init sampler, took 1.51 ms, tokens: text = 6713, total = 6713
slot update_slots: id  3 | task 29501 | erasing old context checkpoint (pos_min = 1754, pos_max = 2453, size = 16.415 MiB)
slot update_slots: id  3 | task 29501 | created context checkpoint 8 of 8 (pos_min = 5777, pos_max = 6648, size = 20.448 MiB)
slot print_timing: id  3 | task 29501 | 
prompt eval time =    1063.86 ms /   827 tokens (    1.29 ms per token,   777.36 tokens per second)
       eval time =   28674.78 ms /  1226 tokens (   23.39 ms per token,    42.76 tokens per second)
      total time =   29738.64 ms /  2053 tokens
slot      release: id  3 | task 29501 | stop processing: n_tokens = 7938, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.900 (> 0.100 thold), f_keep = 0.846
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 30729 | processing task, is_child = 0
slot update_slots: id  3 | task 30729 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7459
slot update_slots: id  3 | task 30729 | n_past = 6713, slot.prompt.tokens.size() = 7938, seq_id = 3, pos_min = 6914, n_swa = 128
slot update_slots: id  3 | task 30729 | restored context checkpoint (pos_min = 5777, pos_max = 6648, size = 20.448 MiB)
slot update_slots: id  3 | task 30729 | n_tokens = 6648, memory_seq_rm [6648, end)
slot update_slots: id  3 | task 30729 | prompt processing progress, n_tokens = 7395, batch.n_tokens = 747, progress = 0.991420
slot update_slots: id  3 | task 30729 | n_tokens = 7395, memory_seq_rm [7395, end)
slot update_slots: id  3 | task 30729 | prompt processing progress, n_tokens = 7459, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 30729 | prompt done, n_tokens = 7459, batch.n_tokens = 64
slot init_sampler: id  3 | task 30729 | init sampler, took 1.66 ms, tokens: text = 7459, total = 7459
slot update_slots: id  3 | task 30729 | erasing old context checkpoint (pos_min = 1754, pos_max = 2560, size = 18.924 MiB)
slot update_slots: id  3 | task 30729 | created context checkpoint 8 of 8 (pos_min = 6371, pos_max = 7394, size = 24.012 MiB)
slot print_timing: id  3 | task 30729 | 
prompt eval time =    1052.06 ms /   811 tokens (    1.30 ms per token,   770.87 tokens per second)
       eval time =     667.39 ms /    27 tokens (   24.72 ms per token,    40.46 tokens per second)
      total time =    1719.45 ms /   838 tokens
slot      release: id  3 | task 30729 | stop processing: n_tokens = 7485, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 30758 | processing task, is_child = 0
slot update_slots: id  3 | task 30758 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7525
slot update_slots: id  3 | task 30758 | n_tokens = 7459, memory_seq_rm [7459, end)
slot update_slots: id  3 | task 30758 | prompt processing progress, n_tokens = 7461, batch.n_tokens = 2, progress = 0.991495
slot update_slots: id  3 | task 30758 | n_tokens = 7461, memory_seq_rm [7461, end)
slot update_slots: id  3 | task 30758 | prompt processing progress, n_tokens = 7525, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 30758 | prompt done, n_tokens = 7525, batch.n_tokens = 64
slot init_sampler: id  3 | task 30758 | init sampler, took 1.10 ms, tokens: text = 7525, total = 7525
slot update_slots: id  3 | task 30758 | erasing old context checkpoint (pos_min = 1968, pos_max = 2836, size = 20.377 MiB)
slot update_slots: id  3 | task 30758 | created context checkpoint 8 of 8 (pos_min = 6461, pos_max = 7460, size = 23.449 MiB)
slot print_timing: id  3 | task 30758 | 
prompt eval time =     265.92 ms /    66 tokens (    4.03 ms per token,   248.20 tokens per second)
       eval time =    1605.46 ms /    70 tokens (   22.94 ms per token,    43.60 tokens per second)
      total time =    1871.38 ms /   136 tokens
slot      release: id  3 | task 30758 | stop processing: n_tokens = 7594, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.672 (> 0.100 thold), f_keep = 0.426
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 7594, total state size = 202.084 MiB
srv          load:  - looking for better prompt, base f_keep = 0.426, sim = 0.672
srv        update:  - cache state: 11 prompts, 3207.889 MiB (limits: 8192.000 MiB, 64000 tokens, 180403 est)
srv        update:    - prompt 0x55a5f0b7a5c0:    7162 tokens, checkpoints:  8,   347.469 MiB
srv        update:    - prompt 0x55a5f1d40020:    7615 tokens, checkpoints:  8,   361.914 MiB
srv        update:    - prompt 0x55a5f08766f0:   21813 tokens, checkpoints:  8,   712.311 MiB
srv        update:    - prompt 0x55a5e9d8fee0:    7620 tokens, checkpoints:  8,   330.328 MiB
srv        update:    - prompt 0x55a5f253e010:    1645 tokens, checkpoints:  1,    74.475 MiB
srv        update:    - prompt 0x55a5f0eef780:    1393 tokens, checkpoints:  2,    83.268 MiB
srv        update:    - prompt 0x55a606fb61a0:    1819 tokens, checkpoints:  5,   128.385 MiB
srv        update:    - prompt 0x55a5ef774150:    3893 tokens, checkpoints:  6,   216.460 MiB
srv        update:    - prompt 0x55a5ef97d560:    4629 tokens, checkpoints:  8,   285.658 MiB
srv        update:    - prompt 0x55a5f1e7ee30:    5461 tokens, checkpoints:  8,   295.084 MiB
srv        update:    - prompt 0x55a62d43ef60:    7594 tokens, checkpoints:  8,   372.536 MiB
srv  get_availabl: prompt cache update took 322.63 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 30830 | processing task, is_child = 0
slot update_slots: id  3 | task 30830 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4821
slot update_slots: id  3 | task 30830 | n_past = 3238, slot.prompt.tokens.size() = 7594, seq_id = 3, pos_min = 6570, n_swa = 128
slot update_slots: id  3 | task 30830 | restored context checkpoint (pos_min = 2837, pos_max = 3695, size = 20.143 MiB)
slot update_slots: id  3 | task 30830 | erased invalidated context checkpoint (pos_min = 4689, pos_max = 5712, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 30830 | erased invalidated context checkpoint (pos_min = 5272, pos_max = 5821, n_swa = 128, size = 12.897 MiB)
slot update_slots: id  3 | task 30830 | erased invalidated context checkpoint (pos_min = 5777, pos_max = 6648, n_swa = 128, size = 20.448 MiB)
slot update_slots: id  3 | task 30830 | erased invalidated context checkpoint (pos_min = 6371, pos_max = 7394, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 30830 | erased invalidated context checkpoint (pos_min = 6461, pos_max = 7460, n_swa = 128, size = 23.449 MiB)
slot update_slots: id  3 | task 30830 | n_tokens = 3238, memory_seq_rm [3238, end)
slot update_slots: id  3 | task 30830 | prompt processing progress, n_tokens = 4757, batch.n_tokens = 1519, progress = 0.986725
slot update_slots: id  3 | task 30830 | n_tokens = 4757, memory_seq_rm [4757, end)
slot update_slots: id  3 | task 30830 | prompt processing progress, n_tokens = 4821, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 30830 | prompt done, n_tokens = 4821, batch.n_tokens = 64
slot init_sampler: id  3 | task 30830 | init sampler, took 0.91 ms, tokens: text = 4821, total = 4821
slot update_slots: id  3 | task 30830 | created context checkpoint 4 of 8 (pos_min = 3733, pos_max = 4756, size = 24.012 MiB)
slot print_timing: id  3 | task 30830 | 
prompt eval time =    1677.47 ms /  1583 tokens (    1.06 ms per token,   943.68 tokens per second)
       eval time =    1400.69 ms /    62 tokens (   22.59 ms per token,    44.26 tokens per second)
      total time =    3078.15 ms /  1645 tokens
slot      release: id  3 | task 30830 | stop processing: n_tokens = 4882, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.978 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 30894 | processing task, is_child = 0
slot update_slots: id  3 | task 30894 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4930
slot update_slots: id  3 | task 30894 | n_tokens = 4821, memory_seq_rm [4821, end)
slot update_slots: id  3 | task 30894 | prompt processing progress, n_tokens = 4866, batch.n_tokens = 45, progress = 0.987018
slot update_slots: id  3 | task 30894 | n_tokens = 4866, memory_seq_rm [4866, end)
slot update_slots: id  3 | task 30894 | prompt processing progress, n_tokens = 4930, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 30894 | prompt done, n_tokens = 4930, batch.n_tokens = 64
slot init_sampler: id  3 | task 30894 | init sampler, took 0.75 ms, tokens: text = 4930, total = 4930
slot update_slots: id  3 | task 30894 | created context checkpoint 5 of 8 (pos_min = 3858, pos_max = 4865, size = 23.637 MiB)
slot print_timing: id  3 | task 30894 | 
prompt eval time =     271.67 ms /   109 tokens (    2.49 ms per token,   401.23 tokens per second)
       eval time =     935.37 ms /    41 tokens (   22.81 ms per token,    43.83 tokens per second)
      total time =    1207.04 ms /   150 tokens
slot      release: id  3 | task 30894 | stop processing: n_tokens = 4970, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.121 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 30937 | processing task, is_child = 0
slot update_slots: id  3 | task 30937 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 40802
slot update_slots: id  3 | task 30937 | n_tokens = 4930, memory_seq_rm [4930, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 6978, batch.n_tokens = 2048, progress = 0.171021
slot update_slots: id  3 | task 30937 | n_tokens = 6978, memory_seq_rm [6978, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 9026, batch.n_tokens = 2048, progress = 0.221215
slot update_slots: id  3 | task 30937 | n_tokens = 9026, memory_seq_rm [9026, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 11074, batch.n_tokens = 2048, progress = 0.271408
slot update_slots: id  3 | task 30937 | n_tokens = 11074, memory_seq_rm [11074, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 13122, batch.n_tokens = 2048, progress = 0.321602
slot update_slots: id  3 | task 30937 | n_tokens = 13122, memory_seq_rm [13122, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 15170, batch.n_tokens = 2048, progress = 0.371796
slot update_slots: id  3 | task 30937 | n_tokens = 15170, memory_seq_rm [15170, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 17218, batch.n_tokens = 2048, progress = 0.421989
slot update_slots: id  3 | task 30937 | n_tokens = 17218, memory_seq_rm [17218, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 19266, batch.n_tokens = 2048, progress = 0.472183
slot update_slots: id  3 | task 30937 | n_tokens = 19266, memory_seq_rm [19266, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 21314, batch.n_tokens = 2048, progress = 0.522376
slot update_slots: id  3 | task 30937 | n_tokens = 21314, memory_seq_rm [21314, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 23362, batch.n_tokens = 2048, progress = 0.572570
slot update_slots: id  3 | task 30937 | n_tokens = 23362, memory_seq_rm [23362, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 25410, batch.n_tokens = 2048, progress = 0.622764
slot update_slots: id  3 | task 30937 | n_tokens = 25410, memory_seq_rm [25410, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 27458, batch.n_tokens = 2048, progress = 0.672957
slot update_slots: id  3 | task 30937 | n_tokens = 27458, memory_seq_rm [27458, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 29506, batch.n_tokens = 2048, progress = 0.723151
slot update_slots: id  3 | task 30937 | n_tokens = 29506, memory_seq_rm [29506, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 31554, batch.n_tokens = 2048, progress = 0.773344
slot update_slots: id  3 | task 30937 | n_tokens = 31554, memory_seq_rm [31554, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 33602, batch.n_tokens = 2048, progress = 0.823538
slot update_slots: id  3 | task 30937 | n_tokens = 33602, memory_seq_rm [33602, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 35650, batch.n_tokens = 2048, progress = 0.873732
slot update_slots: id  3 | task 30937 | n_tokens = 35650, memory_seq_rm [35650, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 37698, batch.n_tokens = 2048, progress = 0.923925
slot update_slots: id  3 | task 30937 | n_tokens = 37698, memory_seq_rm [37698, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 39746, batch.n_tokens = 2048, progress = 0.974119
slot update_slots: id  3 | task 30937 | n_tokens = 39746, memory_seq_rm [39746, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 40738, batch.n_tokens = 992, progress = 0.998431
slot update_slots: id  3 | task 30937 | n_tokens = 40738, memory_seq_rm [40738, end)
slot update_slots: id  3 | task 30937 | prompt processing progress, n_tokens = 40802, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 30937 | prompt done, n_tokens = 40802, batch.n_tokens = 64
slot init_sampler: id  3 | task 30937 | init sampler, took 5.80 ms, tokens: text = 40802, total = 40802
slot update_slots: id  3 | task 30937 | created context checkpoint 6 of 8 (pos_min = 39714, pos_max = 40737, size = 24.012 MiB)
slot print_timing: id  3 | task 30937 | 
prompt eval time =   42010.96 ms / 35872 tokens (    1.17 ms per token,   853.87 tokens per second)
       eval time =    6927.17 ms /   255 tokens (   27.17 ms per token,    36.81 tokens per second)
      total time =   48938.12 ms / 36127 tokens
slot      release: id  3 | task 30937 | stop processing: n_tokens = 41056, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.920 (> 0.100 thold), f_keep = 0.117
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 41056, total state size = 986.732 MiB
srv          load:  - looking for better prompt, base f_keep = 0.117, sim = 0.920
srv        update:  - cache state: 12 prompts, 4331.917 MiB (limits: 8192.000 MiB, 64000 tokens, 211233 est)
srv        update:    - prompt 0x55a5f0b7a5c0:    7162 tokens, checkpoints:  8,   347.469 MiB
srv        update:    - prompt 0x55a5f1d40020:    7615 tokens, checkpoints:  8,   361.914 MiB
srv        update:    - prompt 0x55a5f08766f0:   21813 tokens, checkpoints:  8,   712.311 MiB
srv        update:    - prompt 0x55a5e9d8fee0:    7620 tokens, checkpoints:  8,   330.328 MiB
srv        update:    - prompt 0x55a5f253e010:    1645 tokens, checkpoints:  1,    74.475 MiB
srv        update:    - prompt 0x55a5f0eef780:    1393 tokens, checkpoints:  2,    83.268 MiB
srv        update:    - prompt 0x55a606fb61a0:    1819 tokens, checkpoints:  5,   128.385 MiB
srv        update:    - prompt 0x55a5ef774150:    3893 tokens, checkpoints:  6,   216.460 MiB
srv        update:    - prompt 0x55a5ef97d560:    4629 tokens, checkpoints:  8,   285.658 MiB
srv        update:    - prompt 0x55a5f1e7ee30:    5461 tokens, checkpoints:  8,   295.084 MiB
srv        update:    - prompt 0x55a62d43ef60:    7594 tokens, checkpoints:  8,   372.536 MiB
srv        update:    - prompt 0x55a5f0e5e010:   41056 tokens, checkpoints:  6,  1124.027 MiB
srv  get_availabl: prompt cache update took 876.06 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 31211 | processing task, is_child = 0
slot update_slots: id  3 | task 31211 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5223
slot update_slots: id  3 | task 31211 | n_past = 4805, slot.prompt.tokens.size() = 41056, seq_id = 3, pos_min = 40032, n_swa = 128
slot update_slots: id  3 | task 31211 | restored context checkpoint (pos_min = 3858, pos_max = 4865, size = 23.637 MiB)
slot update_slots: id  3 | task 31211 | erased invalidated context checkpoint (pos_min = 39714, pos_max = 40737, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 31211 | n_tokens = 4805, memory_seq_rm [4805, end)
slot update_slots: id  3 | task 31211 | prompt processing progress, n_tokens = 5159, batch.n_tokens = 354, progress = 0.987746
slot update_slots: id  3 | task 31211 | n_tokens = 5159, memory_seq_rm [5159, end)
slot update_slots: id  3 | task 31211 | prompt processing progress, n_tokens = 5223, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 31211 | prompt done, n_tokens = 5223, batch.n_tokens = 64
slot init_sampler: id  3 | task 31211 | init sampler, took 0.78 ms, tokens: text = 5223, total = 5223
slot update_slots: id  3 | task 31211 | created context checkpoint 6 of 8 (pos_min = 4135, pos_max = 5158, size = 24.012 MiB)
slot print_timing: id  3 | task 31211 | 
prompt eval time =     643.93 ms /   418 tokens (    1.54 ms per token,   649.14 tokens per second)
       eval time =     908.86 ms /    42 tokens (   21.64 ms per token,    46.21 tokens per second)
      total time =    1552.79 ms /   460 tokens
slot      release: id  3 | task 31211 | stop processing: n_tokens = 5264, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.127 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 31255 | processing task, is_child = 0
slot update_slots: id  3 | task 31255 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 41098
slot update_slots: id  3 | task 31255 | n_tokens = 5223, memory_seq_rm [5223, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 7271, batch.n_tokens = 2048, progress = 0.176919
slot update_slots: id  3 | task 31255 | n_tokens = 7271, memory_seq_rm [7271, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 9319, batch.n_tokens = 2048, progress = 0.226751
slot update_slots: id  3 | task 31255 | n_tokens = 9319, memory_seq_rm [9319, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 11367, batch.n_tokens = 2048, progress = 0.276583
slot update_slots: id  3 | task 31255 | n_tokens = 11367, memory_seq_rm [11367, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 13415, batch.n_tokens = 2048, progress = 0.326415
slot update_slots: id  3 | task 31255 | n_tokens = 13415, memory_seq_rm [13415, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 15463, batch.n_tokens = 2048, progress = 0.376247
slot update_slots: id  3 | task 31255 | n_tokens = 15463, memory_seq_rm [15463, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 17511, batch.n_tokens = 2048, progress = 0.426079
slot update_slots: id  3 | task 31255 | n_tokens = 17511, memory_seq_rm [17511, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 19559, batch.n_tokens = 2048, progress = 0.475911
slot update_slots: id  3 | task 31255 | n_tokens = 19559, memory_seq_rm [19559, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 21607, batch.n_tokens = 2048, progress = 0.525743
slot update_slots: id  3 | task 31255 | n_tokens = 21607, memory_seq_rm [21607, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 23655, batch.n_tokens = 2048, progress = 0.575575
slot update_slots: id  3 | task 31255 | n_tokens = 23655, memory_seq_rm [23655, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 25703, batch.n_tokens = 2048, progress = 0.625408
slot update_slots: id  3 | task 31255 | n_tokens = 25703, memory_seq_rm [25703, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 27751, batch.n_tokens = 2048, progress = 0.675240
slot update_slots: id  3 | task 31255 | n_tokens = 27751, memory_seq_rm [27751, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 29799, batch.n_tokens = 2048, progress = 0.725072
slot update_slots: id  3 | task 31255 | n_tokens = 29799, memory_seq_rm [29799, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 31847, batch.n_tokens = 2048, progress = 0.774904
slot update_slots: id  3 | task 31255 | n_tokens = 31847, memory_seq_rm [31847, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 33895, batch.n_tokens = 2048, progress = 0.824736
slot update_slots: id  3 | task 31255 | n_tokens = 33895, memory_seq_rm [33895, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 35943, batch.n_tokens = 2048, progress = 0.874568
slot update_slots: id  3 | task 31255 | n_tokens = 35943, memory_seq_rm [35943, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 37991, batch.n_tokens = 2048, progress = 0.924400
slot update_slots: id  3 | task 31255 | n_tokens = 37991, memory_seq_rm [37991, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 40039, batch.n_tokens = 2048, progress = 0.974232
slot update_slots: id  3 | task 31255 | n_tokens = 40039, memory_seq_rm [40039, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 41034, batch.n_tokens = 995, progress = 0.998443
slot update_slots: id  3 | task 31255 | n_tokens = 41034, memory_seq_rm [41034, end)
slot update_slots: id  3 | task 31255 | prompt processing progress, n_tokens = 41098, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 31255 | prompt done, n_tokens = 41098, batch.n_tokens = 64
slot init_sampler: id  3 | task 31255 | init sampler, took 7.84 ms, tokens: text = 41098, total = 41098
slot update_slots: id  3 | task 31255 | created context checkpoint 7 of 8 (pos_min = 40010, pos_max = 41033, size = 24.012 MiB)
slot print_timing: id  3 | task 31255 | 
prompt eval time =   41533.76 ms / 35875 tokens (    1.16 ms per token,   863.76 tokens per second)
       eval time =    5828.47 ms /   215 tokens (   27.11 ms per token,    36.89 tokens per second)
      total time =   47362.22 ms / 36090 tokens
slot      release: id  3 | task 31255 | stop processing: n_tokens = 41312, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 31489 | processing task, is_child = 0
slot update_slots: id  3 | task 31489 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 41477
slot update_slots: id  3 | task 31489 | n_tokens = 41098, memory_seq_rm [41098, end)
slot update_slots: id  3 | task 31489 | prompt processing progress, n_tokens = 41413, batch.n_tokens = 315, progress = 0.998457
slot update_slots: id  3 | task 31489 | n_tokens = 41413, memory_seq_rm [41413, end)
slot update_slots: id  3 | task 31489 | prompt processing progress, n_tokens = 41477, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 31489 | prompt done, n_tokens = 41477, batch.n_tokens = 64
slot init_sampler: id  3 | task 31489 | init sampler, took 5.88 ms, tokens: text = 41477, total = 41477
slot update_slots: id  3 | task 31489 | created context checkpoint 8 of 8 (pos_min = 40389, pos_max = 41412, size = 24.012 MiB)
slot print_timing: id  3 | task 31489 | 
prompt eval time =     743.34 ms /   379 tokens (    1.96 ms per token,   509.86 tokens per second)
       eval time =    1497.49 ms /    56 tokens (   26.74 ms per token,    37.40 tokens per second)
      total time =    2240.83 ms /   435 tokens
slot      release: id  3 | task 31489 | stop processing: n_tokens = 41532, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 31547 | processing task, is_child = 0
slot update_slots: id  3 | task 31547 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 41560
slot update_slots: id  3 | task 31547 | n_tokens = 41477, memory_seq_rm [41477, end)
slot update_slots: id  3 | task 31547 | prompt processing progress, n_tokens = 41496, batch.n_tokens = 19, progress = 0.998460
slot update_slots: id  3 | task 31547 | n_tokens = 41496, memory_seq_rm [41496, end)
slot update_slots: id  3 | task 31547 | prompt processing progress, n_tokens = 41560, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 31547 | prompt done, n_tokens = 41560, batch.n_tokens = 64
slot init_sampler: id  3 | task 31547 | init sampler, took 6.96 ms, tokens: text = 41560, total = 41560
slot update_slots: id  3 | task 31547 | erasing old context checkpoint (pos_min = 2177, pos_max = 3200, size = 24.012 MiB)
slot update_slots: id  3 | task 31547 | created context checkpoint 8 of 8 (pos_min = 40508, pos_max = 41495, size = 23.168 MiB)
slot print_timing: id  3 | task 31547 | 
prompt eval time =     332.82 ms /    83 tokens (    4.01 ms per token,   249.39 tokens per second)
       eval time =    1678.37 ms /    60 tokens (   27.97 ms per token,    35.75 tokens per second)
      total time =    2011.19 ms /   143 tokens
slot      release: id  3 | task 31547 | stop processing: n_tokens = 41619, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 31609 | processing task, is_child = 0
slot update_slots: id  3 | task 31609 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 41638
slot update_slots: id  3 | task 31609 | n_tokens = 41560, memory_seq_rm [41560, end)
slot update_slots: id  3 | task 31609 | prompt processing progress, n_tokens = 41574, batch.n_tokens = 14, progress = 0.998463
slot update_slots: id  3 | task 31609 | n_tokens = 41574, memory_seq_rm [41574, end)
slot update_slots: id  3 | task 31609 | prompt processing progress, n_tokens = 41638, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 31609 | prompt done, n_tokens = 41638, batch.n_tokens = 64
slot init_sampler: id  3 | task 31609 | init sampler, took 8.56 ms, tokens: text = 41638, total = 41638
slot update_slots: id  3 | task 31609 | erasing old context checkpoint (pos_min = 2642, pos_max = 3557, size = 21.480 MiB)
slot update_slots: id  3 | task 31609 | created context checkpoint 8 of 8 (pos_min = 40595, pos_max = 41573, size = 22.957 MiB)
slot print_timing: id  3 | task 31609 | 
prompt eval time =     322.54 ms /    78 tokens (    4.14 ms per token,   241.83 tokens per second)
       eval time =    1729.89 ms /    62 tokens (   27.90 ms per token,    35.84 tokens per second)
      total time =    2052.43 ms /   140 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 31609 | stop processing: n_tokens = 41699, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 31673 | processing task, is_child = 0
slot update_slots: id  3 | task 31673 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 41718
slot update_slots: id  3 | task 31673 | n_tokens = 41638, memory_seq_rm [41638, end)
slot update_slots: id  3 | task 31673 | prompt processing progress, n_tokens = 41654, batch.n_tokens = 16, progress = 0.998466
slot update_slots: id  3 | task 31673 | n_tokens = 41654, memory_seq_rm [41654, end)
slot update_slots: id  3 | task 31673 | prompt processing progress, n_tokens = 41718, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 31673 | prompt done, n_tokens = 41718, batch.n_tokens = 64
slot init_sampler: id  3 | task 31673 | init sampler, took 5.76 ms, tokens: text = 41718, total = 41718
slot update_slots: id  3 | task 31673 | erasing old context checkpoint (pos_min = 2837, pos_max = 3695, size = 20.143 MiB)
slot update_slots: id  3 | task 31673 | created context checkpoint 8 of 8 (pos_min = 40675, pos_max = 41653, size = 22.957 MiB)
slot print_timing: id  3 | task 31673 | 
prompt eval time =     330.25 ms /    80 tokens (    4.13 ms per token,   242.24 tokens per second)
       eval time =    1626.58 ms /    60 tokens (   27.11 ms per token,    36.89 tokens per second)
      total time =    1956.83 ms /   140 tokens
slot      release: id  3 | task 31673 | stop processing: n_tokens = 41777, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 31735 | processing task, is_child = 0
slot update_slots: id  3 | task 31735 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 42125
slot update_slots: id  3 | task 31735 | n_tokens = 41718, memory_seq_rm [41718, end)
slot update_slots: id  3 | task 31735 | prompt processing progress, n_tokens = 42061, batch.n_tokens = 343, progress = 0.998481
slot update_slots: id  3 | task 31735 | n_tokens = 42061, memory_seq_rm [42061, end)
slot update_slots: id  3 | task 31735 | prompt processing progress, n_tokens = 42125, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 31735 | prompt done, n_tokens = 42125, batch.n_tokens = 64
slot init_sampler: id  3 | task 31735 | init sampler, took 5.94 ms, tokens: text = 42125, total = 42125
slot update_slots: id  3 | task 31735 | erasing old context checkpoint (pos_min = 3733, pos_max = 4756, size = 24.012 MiB)
slot update_slots: id  3 | task 31735 | created context checkpoint 8 of 8 (pos_min = 41037, pos_max = 42060, size = 24.012 MiB)
slot print_timing: id  3 | task 31735 | 
prompt eval time =     825.34 ms /   407 tokens (    2.03 ms per token,   493.13 tokens per second)
       eval time =    2015.45 ms /    74 tokens (   27.24 ms per token,    36.72 tokens per second)
      total time =    2840.79 ms /   481 tokens
slot      release: id  3 | task 31735 | stop processing: n_tokens = 42198, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 31811 | processing task, is_child = 0
slot update_slots: id  3 | task 31811 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 42208
slot update_slots: id  3 | task 31811 | n_tokens = 42125, memory_seq_rm [42125, end)
slot update_slots: id  3 | task 31811 | prompt processing progress, n_tokens = 42144, batch.n_tokens = 19, progress = 0.998484
slot update_slots: id  3 | task 31811 | n_tokens = 42144, memory_seq_rm [42144, end)
slot update_slots: id  3 | task 31811 | prompt processing progress, n_tokens = 42208, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 31811 | prompt done, n_tokens = 42208, batch.n_tokens = 64
slot init_sampler: id  3 | task 31811 | init sampler, took 5.88 ms, tokens: text = 42208, total = 42208
slot update_slots: id  3 | task 31811 | erasing old context checkpoint (pos_min = 3858, pos_max = 4865, size = 23.637 MiB)
slot update_slots: id  3 | task 31811 | created context checkpoint 8 of 8 (pos_min = 41174, pos_max = 42143, size = 22.746 MiB)
slot print_timing: id  3 | task 31811 | 
prompt eval time =     332.50 ms /    83 tokens (    4.01 ms per token,   249.62 tokens per second)
       eval time =    4452.79 ms /   161 tokens (   27.66 ms per token,    36.16 tokens per second)
      total time =    4785.29 ms /   244 tokens
slot      release: id  3 | task 31811 | stop processing: n_tokens = 42368, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 31974 | processing task, is_child = 0
slot update_slots: id  3 | task 31974 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 42288
slot update_slots: id  3 | task 31974 | n_tokens = 42208, memory_seq_rm [42208, end)
slot update_slots: id  3 | task 31974 | prompt processing progress, n_tokens = 42224, batch.n_tokens = 16, progress = 0.998487
slot update_slots: id  3 | task 31974 | n_tokens = 42224, memory_seq_rm [42224, end)
slot update_slots: id  3 | task 31974 | prompt processing progress, n_tokens = 42288, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 31974 | prompt done, n_tokens = 42288, batch.n_tokens = 64
slot init_sampler: id  3 | task 31974 | init sampler, took 8.03 ms, tokens: text = 42288, total = 42288
slot update_slots: id  3 | task 31974 | erasing old context checkpoint (pos_min = 4135, pos_max = 5158, size = 24.012 MiB)
slot update_slots: id  3 | task 31974 | created context checkpoint 8 of 8 (pos_min = 41344, pos_max = 42223, size = 20.635 MiB)
slot print_timing: id  3 | task 31974 | 
prompt eval time =     333.08 ms /    80 tokens (    4.16 ms per token,   240.18 tokens per second)
       eval time =    1812.54 ms /    63 tokens (   28.77 ms per token,    34.76 tokens per second)
      total time =    2145.62 ms /   143 tokens
slot      release: id  3 | task 31974 | stop processing: n_tokens = 42350, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 32039 | processing task, is_child = 0
slot update_slots: id  3 | task 32039 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 42371
slot update_slots: id  3 | task 32039 | n_tokens = 42288, memory_seq_rm [42288, end)
slot update_slots: id  3 | task 32039 | prompt processing progress, n_tokens = 42307, batch.n_tokens = 19, progress = 0.998490
slot update_slots: id  3 | task 32039 | n_tokens = 42307, memory_seq_rm [42307, end)
slot update_slots: id  3 | task 32039 | prompt processing progress, n_tokens = 42371, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 32039 | prompt done, n_tokens = 42371, batch.n_tokens = 64
slot init_sampler: id  3 | task 32039 | init sampler, took 6.51 ms, tokens: text = 42371, total = 42371
slot update_slots: id  3 | task 32039 | erasing old context checkpoint (pos_min = 40010, pos_max = 41033, size = 24.012 MiB)
slot update_slots: id  3 | task 32039 | created context checkpoint 8 of 8 (pos_min = 41344, pos_max = 42306, size = 22.582 MiB)
slot print_timing: id  3 | task 32039 | 
prompt eval time =     338.05 ms /    83 tokens (    4.07 ms per token,   245.53 tokens per second)
       eval time =    2064.68 ms /    75 tokens (   27.53 ms per token,    36.33 tokens per second)
      total time =    2402.73 ms /   158 tokens
slot      release: id  3 | task 32039 | stop processing: n_tokens = 42445, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.999 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 32116 | processing task, is_child = 0
slot update_slots: id  3 | task 32116 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 42434
slot update_slots: id  3 | task 32116 | n_tokens = 42371, memory_seq_rm [42371, end)
slot update_slots: id  3 | task 32116 | prompt processing progress, n_tokens = 42434, batch.n_tokens = 63, progress = 1.000000
slot update_slots: id  3 | task 32116 | prompt done, n_tokens = 42434, batch.n_tokens = 63
slot init_sampler: id  3 | task 32116 | init sampler, took 6.69 ms, tokens: text = 42434, total = 42434
slot print_timing: id  3 | task 32116 | 
prompt eval time =     242.14 ms /    63 tokens (    3.84 ms per token,   260.18 tokens per second)
       eval time =    3348.13 ms /   122 tokens (   27.44 ms per token,    36.44 tokens per second)
      total time =    3590.27 ms /   185 tokens
slot      release: id  3 | task 32116 | stop processing: n_tokens = 42555, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.975 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 32239 | processing task, is_child = 0
slot update_slots: id  3 | task 32239 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 43526
slot update_slots: id  3 | task 32239 | n_tokens = 42434, memory_seq_rm [42434, end)
slot update_slots: id  3 | task 32239 | prompt processing progress, n_tokens = 43462, batch.n_tokens = 1028, progress = 0.998530
slot update_slots: id  3 | task 32239 | n_tokens = 43462, memory_seq_rm [43462, end)
slot update_slots: id  3 | task 32239 | prompt processing progress, n_tokens = 43526, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 32239 | prompt done, n_tokens = 43526, batch.n_tokens = 64
slot init_sampler: id  3 | task 32239 | init sampler, took 6.23 ms, tokens: text = 43526, total = 43526
slot update_slots: id  3 | task 32239 | erasing old context checkpoint (pos_min = 40389, pos_max = 41412, size = 24.012 MiB)
slot update_slots: id  3 | task 32239 | created context checkpoint 8 of 8 (pos_min = 42438, pos_max = 43461, size = 24.012 MiB)
slot print_timing: id  3 | task 32239 | 
prompt eval time =    1860.80 ms /  1092 tokens (    1.70 ms per token,   586.84 tokens per second)
       eval time =    1683.50 ms /    59 tokens (   28.53 ms per token,    35.05 tokens per second)
      total time =    3544.30 ms /  1151 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 32239 | stop processing: n_tokens = 43584, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 32300 | processing task, is_child = 0
slot update_slots: id  3 | task 32300 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 43605
slot update_slots: id  3 | task 32300 | n_tokens = 43526, memory_seq_rm [43526, end)
slot update_slots: id  3 | task 32300 | prompt processing progress, n_tokens = 43541, batch.n_tokens = 15, progress = 0.998532
slot update_slots: id  3 | task 32300 | n_tokens = 43541, memory_seq_rm [43541, end)
slot update_slots: id  3 | task 32300 | prompt processing progress, n_tokens = 43605, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 32300 | prompt done, n_tokens = 43605, batch.n_tokens = 64
slot init_sampler: id  3 | task 32300 | init sampler, took 8.41 ms, tokens: text = 43605, total = 43605
slot update_slots: id  3 | task 32300 | erasing old context checkpoint (pos_min = 40508, pos_max = 41495, size = 23.168 MiB)
slot update_slots: id  3 | task 32300 | created context checkpoint 8 of 8 (pos_min = 42560, pos_max = 43540, size = 23.004 MiB)
slot print_timing: id  3 | task 32300 | 
prompt eval time =     336.52 ms /    79 tokens (    4.26 ms per token,   234.76 tokens per second)
       eval time =    1743.21 ms /    62 tokens (   28.12 ms per token,    35.57 tokens per second)
      total time =    2079.73 ms /   141 tokens
slot      release: id  3 | task 32300 | stop processing: n_tokens = 43666, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 32364 | processing task, is_child = 0
slot update_slots: id  3 | task 32364 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 43686
slot update_slots: id  3 | task 32364 | n_tokens = 43605, memory_seq_rm [43605, end)
slot update_slots: id  3 | task 32364 | prompt processing progress, n_tokens = 43622, batch.n_tokens = 17, progress = 0.998535
slot update_slots: id  3 | task 32364 | n_tokens = 43622, memory_seq_rm [43622, end)
slot update_slots: id  3 | task 32364 | prompt processing progress, n_tokens = 43686, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 32364 | prompt done, n_tokens = 43686, batch.n_tokens = 64
slot init_sampler: id  3 | task 32364 | init sampler, took 6.10 ms, tokens: text = 43686, total = 43686
slot update_slots: id  3 | task 32364 | erasing old context checkpoint (pos_min = 40595, pos_max = 41573, size = 22.957 MiB)
slot update_slots: id  3 | task 32364 | created context checkpoint 8 of 8 (pos_min = 42642, pos_max = 43621, size = 22.980 MiB)
slot print_timing: id  3 | task 32364 | 
prompt eval time =     337.41 ms /    81 tokens (    4.17 ms per token,   240.07 tokens per second)
       eval time =    2800.54 ms /   102 tokens (   27.46 ms per token,    36.42 tokens per second)
      total time =    3137.95 ms /   183 tokens
slot      release: id  3 | task 32364 | stop processing: n_tokens = 43787, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 32468 | processing task, is_child = 0
slot update_slots: id  3 | task 32468 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 43758
slot update_slots: id  3 | task 32468 | n_tokens = 43686, memory_seq_rm [43686, end)
slot update_slots: id  3 | task 32468 | prompt processing progress, n_tokens = 43694, batch.n_tokens = 8, progress = 0.998537
slot update_slots: id  3 | task 32468 | n_tokens = 43694, memory_seq_rm [43694, end)
slot update_slots: id  3 | task 32468 | prompt processing progress, n_tokens = 43758, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 32468 | prompt done, n_tokens = 43758, batch.n_tokens = 64
slot init_sampler: id  3 | task 32468 | init sampler, took 6.09 ms, tokens: text = 43758, total = 43758
slot update_slots: id  3 | task 32468 | erasing old context checkpoint (pos_min = 40675, pos_max = 41653, size = 22.957 MiB)
slot update_slots: id  3 | task 32468 | created context checkpoint 8 of 8 (pos_min = 42763, pos_max = 43693, size = 21.831 MiB)
slot print_timing: id  3 | task 32468 | 
prompt eval time =     300.90 ms /    72 tokens (    4.18 ms per token,   239.28 tokens per second)
       eval time =    2822.48 ms /   102 tokens (   27.67 ms per token,    36.14 tokens per second)
      total time =    3123.38 ms /   174 tokens
slot      release: id  3 | task 32468 | stop processing: n_tokens = 43859, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 32572 | processing task, is_child = 0
slot update_slots: id  3 | task 32572 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 43841
slot update_slots: id  3 | task 32572 | n_tokens = 43758, memory_seq_rm [43758, end)
slot update_slots: id  3 | task 32572 | prompt processing progress, n_tokens = 43777, batch.n_tokens = 19, progress = 0.998540
slot update_slots: id  3 | task 32572 | n_tokens = 43777, memory_seq_rm [43777, end)
slot update_slots: id  3 | task 32572 | prompt processing progress, n_tokens = 43841, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 32572 | prompt done, n_tokens = 43841, batch.n_tokens = 64
slot init_sampler: id  3 | task 32572 | init sampler, took 6.11 ms, tokens: text = 43841, total = 43841
slot update_slots: id  3 | task 32572 | erasing old context checkpoint (pos_min = 41037, pos_max = 42060, size = 24.012 MiB)
slot update_slots: id  3 | task 32572 | created context checkpoint 8 of 8 (pos_min = 42835, pos_max = 43776, size = 22.089 MiB)
slot print_timing: id  3 | task 32572 | 
prompt eval time =     342.26 ms /    83 tokens (    4.12 ms per token,   242.51 tokens per second)
       eval time =    7022.58 ms /   248 tokens (   28.32 ms per token,    35.31 tokens per second)
      total time =    7364.84 ms /   331 tokens
slot      release: id  3 | task 32572 | stop processing: n_tokens = 44088, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 32822 | processing task, is_child = 0
slot update_slots: id  3 | task 32822 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 44483
slot update_slots: id  3 | task 32822 | n_tokens = 43841, memory_seq_rm [43841, end)
slot update_slots: id  3 | task 32822 | prompt processing progress, n_tokens = 44419, batch.n_tokens = 578, progress = 0.998561
slot update_slots: id  3 | task 32822 | n_tokens = 44419, memory_seq_rm [44419, end)
slot update_slots: id  3 | task 32822 | prompt processing progress, n_tokens = 44483, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 32822 | prompt done, n_tokens = 44483, batch.n_tokens = 64
slot init_sampler: id  3 | task 32822 | init sampler, took 6.48 ms, tokens: text = 44483, total = 44483
slot update_slots: id  3 | task 32822 | erasing old context checkpoint (pos_min = 41174, pos_max = 42143, size = 22.746 MiB)
slot update_slots: id  3 | task 32822 | created context checkpoint 8 of 8 (pos_min = 43506, pos_max = 44418, size = 21.409 MiB)
slot print_timing: id  3 | task 32822 | 
prompt eval time =    1341.92 ms /   642 tokens (    2.09 ms per token,   478.42 tokens per second)
       eval time =    2646.11 ms /    95 tokens (   27.85 ms per token,    35.90 tokens per second)
      total time =    3988.03 ms /   737 tokens
slot      release: id  3 | task 32822 | stop processing: n_tokens = 44577, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 32919 | processing task, is_child = 0
slot update_slots: id  3 | task 32919 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 44964
slot update_slots: id  3 | task 32919 | n_tokens = 44483, memory_seq_rm [44483, end)
slot update_slots: id  3 | task 32919 | prompt processing progress, n_tokens = 44900, batch.n_tokens = 417, progress = 0.998577
slot update_slots: id  3 | task 32919 | n_tokens = 44900, memory_seq_rm [44900, end)
slot update_slots: id  3 | task 32919 | prompt processing progress, n_tokens = 44964, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 32919 | prompt done, n_tokens = 44964, batch.n_tokens = 64
slot init_sampler: id  3 | task 32919 | init sampler, took 6.68 ms, tokens: text = 44964, total = 44964
slot update_slots: id  3 | task 32919 | erasing old context checkpoint (pos_min = 41344, pos_max = 42223, size = 20.635 MiB)
slot update_slots: id  3 | task 32919 | created context checkpoint 8 of 8 (pos_min = 43876, pos_max = 44899, size = 24.012 MiB)
slot print_timing: id  3 | task 32919 | 
prompt eval time =     909.10 ms /   481 tokens (    1.89 ms per token,   529.09 tokens per second)
       eval time =    9546.91 ms /   337 tokens (   28.33 ms per token,    35.30 tokens per second)
      total time =   10456.01 ms /   818 tokens
slot      release: id  3 | task 32919 | stop processing: n_tokens = 45300, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 33258 | processing task, is_child = 0
slot update_slots: id  3 | task 33258 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 45119
slot update_slots: id  3 | task 33258 | n_tokens = 44964, memory_seq_rm [44964, end)
slot update_slots: id  3 | task 33258 | prompt processing progress, n_tokens = 45055, batch.n_tokens = 91, progress = 0.998582
slot update_slots: id  3 | task 33258 | n_tokens = 45055, memory_seq_rm [45055, end)
slot update_slots: id  3 | task 33258 | prompt processing progress, n_tokens = 45119, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 33258 | prompt done, n_tokens = 45119, batch.n_tokens = 64
slot init_sampler: id  3 | task 33258 | init sampler, took 6.57 ms, tokens: text = 45119, total = 45119
slot update_slots: id  3 | task 33258 | erasing old context checkpoint (pos_min = 41344, pos_max = 42306, size = 22.582 MiB)
slot update_slots: id  3 | task 33258 | created context checkpoint 8 of 8 (pos_min = 44276, pos_max = 45054, size = 18.267 MiB)
slot print_timing: id  3 | task 33258 | 
prompt eval time =     509.59 ms /   155 tokens (    3.29 ms per token,   304.17 tokens per second)
       eval time =    3568.63 ms /   127 tokens (   28.10 ms per token,    35.59 tokens per second)
      total time =    4078.22 ms /   282 tokens
slot      release: id  3 | task 33258 | stop processing: n_tokens = 45245, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.999 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 33387 | processing task, is_child = 0
slot update_slots: id  3 | task 33387 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 45182
slot update_slots: id  3 | task 33387 | n_tokens = 45119, memory_seq_rm [45119, end)
slot update_slots: id  3 | task 33387 | prompt processing progress, n_tokens = 45182, batch.n_tokens = 63, progress = 1.000000
slot update_slots: id  3 | task 33387 | prompt done, n_tokens = 45182, batch.n_tokens = 63
slot init_sampler: id  3 | task 33387 | init sampler, took 6.33 ms, tokens: text = 45182, total = 45182
slot print_timing: id  3 | task 33387 | 
prompt eval time =     249.22 ms /    63 tokens (    3.96 ms per token,   252.79 tokens per second)
       eval time =    6109.13 ms /   216 tokens (   28.28 ms per token,    35.36 tokens per second)
      total time =    6358.35 ms /   279 tokens
slot      release: id  3 | task 33387 | stop processing: n_tokens = 45397, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.999 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 33604 | processing task, is_child = 0
slot update_slots: id  3 | task 33604 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 45246
slot update_slots: id  3 | task 33604 | n_tokens = 45182, memory_seq_rm [45182, end)
slot update_slots: id  3 | task 33604 | prompt processing progress, n_tokens = 45246, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 33604 | prompt done, n_tokens = 45246, batch.n_tokens = 64
slot init_sampler: id  3 | task 33604 | init sampler, took 7.67 ms, tokens: text = 45246, total = 45246
slot update_slots: id  3 | task 33604 | erasing old context checkpoint (pos_min = 42438, pos_max = 43461, size = 24.012 MiB)
slot update_slots: id  3 | task 33604 | created context checkpoint 8 of 8 (pos_min = 44373, pos_max = 45181, size = 18.970 MiB)
slot print_timing: id  3 | task 33604 | 
prompt eval time =     263.96 ms /    64 tokens (    4.12 ms per token,   242.46 tokens per second)
       eval time =    1945.34 ms /    69 tokens (   28.19 ms per token,    35.47 tokens per second)
      total time =    2209.30 ms /   133 tokens
slot      release: id  3 | task 33604 | stop processing: n_tokens = 45314, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 33674 | processing task, is_child = 0
slot update_slots: id  3 | task 33674 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 45649
slot update_slots: id  3 | task 33674 | n_tokens = 45246, memory_seq_rm [45246, end)
slot update_slots: id  3 | task 33674 | prompt processing progress, n_tokens = 45585, batch.n_tokens = 339, progress = 0.998598
slot update_slots: id  3 | task 33674 | n_tokens = 45585, memory_seq_rm [45585, end)
slot update_slots: id  3 | task 33674 | prompt processing progress, n_tokens = 45649, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 33674 | prompt done, n_tokens = 45649, batch.n_tokens = 64
slot init_sampler: id  3 | task 33674 | init sampler, took 6.48 ms, tokens: text = 45649, total = 45649
slot update_slots: id  3 | task 33674 | erasing old context checkpoint (pos_min = 42560, pos_max = 43540, size = 23.004 MiB)
slot update_slots: id  3 | task 33674 | created context checkpoint 8 of 8 (pos_min = 44561, pos_max = 45584, size = 24.012 MiB)
slot print_timing: id  3 | task 33674 | 
prompt eval time =     870.32 ms /   403 tokens (    2.16 ms per token,   463.05 tokens per second)
       eval time =    1865.10 ms /    66 tokens (   28.26 ms per token,    35.39 tokens per second)
      total time =    2735.43 ms /   469 tokens
slot      release: id  3 | task 33674 | stop processing: n_tokens = 45714, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.960 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 33742 | processing task, is_child = 0
slot update_slots: id  3 | task 33742 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 47527
slot update_slots: id  3 | task 33742 | n_tokens = 45649, memory_seq_rm [45649, end)
slot update_slots: id  3 | task 33742 | prompt processing progress, n_tokens = 47463, batch.n_tokens = 1814, progress = 0.998653
slot update_slots: id  3 | task 33742 | n_tokens = 47463, memory_seq_rm [47463, end)
slot update_slots: id  3 | task 33742 | prompt processing progress, n_tokens = 47527, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 33742 | prompt done, n_tokens = 47527, batch.n_tokens = 64
slot init_sampler: id  3 | task 33742 | init sampler, took 6.68 ms, tokens: text = 47527, total = 47527
slot update_slots: id  3 | task 33742 | erasing old context checkpoint (pos_min = 42642, pos_max = 43621, size = 22.980 MiB)
slot update_slots: id  3 | task 33742 | created context checkpoint 8 of 8 (pos_min = 46439, pos_max = 47462, size = 24.012 MiB)
slot print_timing: id  3 | task 33742 | 
prompt eval time =    3222.12 ms /  1878 tokens (    1.72 ms per token,   582.85 tokens per second)
       eval time =    7320.97 ms /   253 tokens (   28.94 ms per token,    34.56 tokens per second)
      total time =   10543.09 ms /  2131 tokens
slot      release: id  3 | task 33742 | stop processing: n_tokens = 47779, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.961 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 33997 | processing task, is_child = 0
slot update_slots: id  3 | task 33997 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 49465
slot update_slots: id  3 | task 33997 | n_tokens = 47527, memory_seq_rm [47527, end)
slot update_slots: id  3 | task 33997 | prompt processing progress, n_tokens = 49401, batch.n_tokens = 1874, progress = 0.998706
slot update_slots: id  3 | task 33997 | n_tokens = 49401, memory_seq_rm [49401, end)
slot update_slots: id  3 | task 33997 | prompt processing progress, n_tokens = 49465, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 33997 | prompt done, n_tokens = 49465, batch.n_tokens = 64
slot init_sampler: id  3 | task 33997 | init sampler, took 6.89 ms, tokens: text = 49465, total = 49465
slot update_slots: id  3 | task 33997 | erasing old context checkpoint (pos_min = 42763, pos_max = 43693, size = 21.831 MiB)
slot update_slots: id  3 | task 33997 | created context checkpoint 8 of 8 (pos_min = 48377, pos_max = 49400, size = 24.012 MiB)
slot print_timing: id  3 | task 33997 | 
prompt eval time =    3391.16 ms /  1938 tokens (    1.75 ms per token,   571.49 tokens per second)
       eval time =    5119.13 ms /   178 tokens (   28.76 ms per token,    34.77 tokens per second)
      total time =    8510.29 ms /  2116 tokens
slot      release: id  3 | task 33997 | stop processing: n_tokens = 49642, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 34177 | processing task, is_child = 0
slot update_slots: id  3 | task 34177 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 49580
slot update_slots: id  3 | task 34177 | n_tokens = 49465, memory_seq_rm [49465, end)
slot update_slots: id  3 | task 34177 | prompt processing progress, n_tokens = 49516, batch.n_tokens = 51, progress = 0.998709
slot update_slots: id  3 | task 34177 | n_tokens = 49516, memory_seq_rm [49516, end)
slot update_slots: id  3 | task 34177 | prompt processing progress, n_tokens = 49580, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 34177 | prompt done, n_tokens = 49580, batch.n_tokens = 64
slot init_sampler: id  3 | task 34177 | init sampler, took 15.07 ms, tokens: text = 49580, total = 49580
slot update_slots: id  3 | task 34177 | erasing old context checkpoint (pos_min = 42835, pos_max = 43776, size = 22.089 MiB)
slot update_slots: id  3 | task 34177 | created context checkpoint 8 of 8 (pos_min = 48618, pos_max = 49515, size = 21.057 MiB)
slot print_timing: id  3 | task 34177 | 
prompt eval time =     433.81 ms /   115 tokens (    3.77 ms per token,   265.09 tokens per second)
       eval time =   10725.33 ms /   370 tokens (   28.99 ms per token,    34.50 tokens per second)
      total time =   11159.14 ms /   485 tokens
slot      release: id  3 | task 34177 | stop processing: n_tokens = 49949, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.970 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 34549 | processing task, is_child = 0
slot update_slots: id  3 | task 34549 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 51089
slot update_slots: id  3 | task 34549 | n_tokens = 49580, memory_seq_rm [49580, end)
slot update_slots: id  3 | task 34549 | prompt processing progress, n_tokens = 51025, batch.n_tokens = 1445, progress = 0.998747
slot update_slots: id  3 | task 34549 | n_tokens = 51025, memory_seq_rm [51025, end)
slot update_slots: id  3 | task 34549 | prompt processing progress, n_tokens = 51089, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 34549 | prompt done, n_tokens = 51089, batch.n_tokens = 64
slot init_sampler: id  3 | task 34549 | init sampler, took 10.09 ms, tokens: text = 51089, total = 51089
slot update_slots: id  3 | task 34549 | erasing old context checkpoint (pos_min = 43506, pos_max = 44418, size = 21.409 MiB)
slot update_slots: id  3 | task 34549 | created context checkpoint 8 of 8 (pos_min = 50001, pos_max = 51024, size = 24.012 MiB)
slot print_timing: id  3 | task 34549 | 
prompt eval time =    2693.95 ms /  1509 tokens (    1.79 ms per token,   560.14 tokens per second)
       eval time =    9380.54 ms /   320 tokens (   29.31 ms per token,    34.11 tokens per second)
      total time =   12074.49 ms /  1829 tokens
slot      release: id  3 | task 34549 | stop processing: n_tokens = 51408, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 34871 | processing task, is_child = 0
slot update_slots: id  3 | task 34871 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 51180
slot update_slots: id  3 | task 34871 | n_tokens = 51089, memory_seq_rm [51089, end)
slot update_slots: id  3 | task 34871 | prompt processing progress, n_tokens = 51116, batch.n_tokens = 27, progress = 0.998749
slot update_slots: id  3 | task 34871 | n_tokens = 51116, memory_seq_rm [51116, end)
slot update_slots: id  3 | task 34871 | prompt processing progress, n_tokens = 51180, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 34871 | prompt done, n_tokens = 51180, batch.n_tokens = 64
slot init_sampler: id  3 | task 34871 | init sampler, took 7.33 ms, tokens: text = 51180, total = 51180
slot update_slots: id  3 | task 34871 | erasing old context checkpoint (pos_min = 43876, pos_max = 44899, size = 24.012 MiB)
slot update_slots: id  3 | task 34871 | created context checkpoint 8 of 8 (pos_min = 50384, pos_max = 51115, size = 17.165 MiB)
slot print_timing: id  3 | task 34871 | 
prompt eval time =     399.51 ms /    91 tokens (    4.39 ms per token,   227.78 tokens per second)
       eval time =    7747.53 ms /   261 tokens (   29.68 ms per token,    33.69 tokens per second)
      total time =    8147.04 ms /   352 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 34871 | stop processing: n_tokens = 51440, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 35134 | processing task, is_child = 0
slot update_slots: id  3 | task 35134 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 51579
slot update_slots: id  3 | task 35134 | n_tokens = 51180, memory_seq_rm [51180, end)
slot update_slots: id  3 | task 35134 | prompt processing progress, n_tokens = 51515, batch.n_tokens = 335, progress = 0.998759
slot update_slots: id  3 | task 35134 | n_tokens = 51515, memory_seq_rm [51515, end)
slot update_slots: id  3 | task 35134 | prompt processing progress, n_tokens = 51579, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 35134 | prompt done, n_tokens = 51579, batch.n_tokens = 64
slot init_sampler: id  3 | task 35134 | init sampler, took 7.36 ms, tokens: text = 51579, total = 51579
slot update_slots: id  3 | task 35134 | erasing old context checkpoint (pos_min = 44276, pos_max = 45054, size = 18.267 MiB)
slot update_slots: id  3 | task 35134 | created context checkpoint 8 of 8 (pos_min = 50491, pos_max = 51514, size = 24.012 MiB)
slot print_timing: id  3 | task 35134 | 
prompt eval time =     876.85 ms /   399 tokens (    2.20 ms per token,   455.04 tokens per second)
       eval time =   64054.07 ms /  2144 tokens (   29.88 ms per token,    33.47 tokens per second)
      total time =   64930.91 ms /  2543 tokens
slot      release: id  3 | task 35134 | stop processing: n_tokens = 53722, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.614 (> 0.100 thold), f_keep = 0.096
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 53722, total state size = 1283.736 MiB
srv          load:  - looking for better prompt, base f_keep = 0.096, sim = 0.614
srv        update:  - cache state: 13 prompts, 5792.906 MiB (limits: 8192.000 MiB, 64000 tokens, 233930 est)
srv        update:    - prompt 0x55a5f0b7a5c0:    7162 tokens, checkpoints:  8,   347.469 MiB
srv        update:    - prompt 0x55a5f1d40020:    7615 tokens, checkpoints:  8,   361.914 MiB
srv        update:    - prompt 0x55a5f08766f0:   21813 tokens, checkpoints:  8,   712.311 MiB
srv        update:    - prompt 0x55a5e9d8fee0:    7620 tokens, checkpoints:  8,   330.328 MiB
srv        update:    - prompt 0x55a5f253e010:    1645 tokens, checkpoints:  1,    74.475 MiB
srv        update:    - prompt 0x55a5f0eef780:    1393 tokens, checkpoints:  2,    83.268 MiB
srv        update:    - prompt 0x55a606fb61a0:    1819 tokens, checkpoints:  5,   128.385 MiB
srv        update:    - prompt 0x55a5ef774150:    3893 tokens, checkpoints:  6,   216.460 MiB
srv        update:    - prompt 0x55a5ef97d560:    4629 tokens, checkpoints:  8,   285.658 MiB
srv        update:    - prompt 0x55a5f1e7ee30:    5461 tokens, checkpoints:  8,   295.084 MiB
srv        update:    - prompt 0x55a62d43ef60:    7594 tokens, checkpoints:  8,   372.536 MiB
srv        update:    - prompt 0x55a5f0e5e010:   41056 tokens, checkpoints:  6,  1124.027 MiB
srv        update:    - prompt 0x55a6357da0f0:   53722 tokens, checkpoints:  8,  1460.989 MiB
srv  get_availabl: prompt cache update took 1182.24 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 37280 | processing task, is_child = 0
slot update_slots: id  3 | task 37280 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8371
slot update_slots: id  3 | task 37280 | n_past = 5138, slot.prompt.tokens.size() = 53722, seq_id = 3, pos_min = 52698, n_swa = 128
slot update_slots: id  3 | task 37280 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  3 | task 37280 | erased invalidated context checkpoint (pos_min = 44373, pos_max = 45181, n_swa = 128, size = 18.970 MiB)
slot update_slots: id  3 | task 37280 | erased invalidated context checkpoint (pos_min = 44561, pos_max = 45584, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 37280 | erased invalidated context checkpoint (pos_min = 46439, pos_max = 47462, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 37280 | erased invalidated context checkpoint (pos_min = 48377, pos_max = 49400, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 37280 | erased invalidated context checkpoint (pos_min = 48618, pos_max = 49515, n_swa = 128, size = 21.057 MiB)
slot update_slots: id  3 | task 37280 | erased invalidated context checkpoint (pos_min = 50001, pos_max = 51024, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 37280 | erased invalidated context checkpoint (pos_min = 50384, pos_max = 51115, n_swa = 128, size = 17.165 MiB)
slot update_slots: id  3 | task 37280 | erased invalidated context checkpoint (pos_min = 50491, pos_max = 51514, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 37280 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  3 | task 37280 | prompt processing progress, n_tokens = 2048, batch.n_tokens = 2048, progress = 0.244654
slot update_slots: id  3 | task 37280 | n_tokens = 2048, memory_seq_rm [2048, end)
slot update_slots: id  3 | task 37280 | prompt processing progress, n_tokens = 4096, batch.n_tokens = 2048, progress = 0.489308
slot update_slots: id  3 | task 37280 | n_tokens = 4096, memory_seq_rm [4096, end)
slot update_slots: id  3 | task 37280 | prompt processing progress, n_tokens = 6144, batch.n_tokens = 2048, progress = 0.733962
slot update_slots: id  3 | task 37280 | n_tokens = 6144, memory_seq_rm [6144, end)
slot update_slots: id  3 | task 37280 | prompt processing progress, n_tokens = 8192, batch.n_tokens = 2048, progress = 0.978617
slot update_slots: id  3 | task 37280 | n_tokens = 8192, memory_seq_rm [8192, end)
slot update_slots: id  3 | task 37280 | prompt processing progress, n_tokens = 8307, batch.n_tokens = 115, progress = 0.992355
slot update_slots: id  3 | task 37280 | n_tokens = 8307, memory_seq_rm [8307, end)
slot update_slots: id  3 | task 37280 | prompt processing progress, n_tokens = 8371, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 37280 | prompt done, n_tokens = 8371, batch.n_tokens = 64
slot init_sampler: id  3 | task 37280 | init sampler, took 1.94 ms, tokens: text = 8371, total = 8371
slot update_slots: id  3 | task 37280 | created context checkpoint 1 of 8 (pos_min = 7283, pos_max = 8306, size = 24.012 MiB)
slot print_timing: id  3 | task 37280 | 
prompt eval time =    7847.04 ms /  8371 tokens (    0.94 ms per token,  1066.77 tokens per second)
       eval time =   80920.42 ms /  3360 tokens (   24.08 ms per token,    41.52 tokens per second)
      total time =   88767.46 ms / 11731 tokens
slot      release: id  3 | task 37280 | stop processing: n_tokens = 11730, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.774 (> 0.100 thold), f_keep = 0.703
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 40646 | processing task, is_child = 0
slot update_slots: id  3 | task 40646 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 10659
slot update_slots: id  3 | task 40646 | n_past = 8248, slot.prompt.tokens.size() = 11730, seq_id = 3, pos_min = 10706, n_swa = 128
slot update_slots: id  3 | task 40646 | restored context checkpoint (pos_min = 7283, pos_max = 8306, size = 24.012 MiB)
slot update_slots: id  3 | task 40646 | n_tokens = 8248, memory_seq_rm [8248, end)
slot update_slots: id  3 | task 40646 | prompt processing progress, n_tokens = 10296, batch.n_tokens = 2048, progress = 0.965944
slot update_slots: id  3 | task 40646 | n_tokens = 10296, memory_seq_rm [10296, end)
slot update_slots: id  3 | task 40646 | prompt processing progress, n_tokens = 10595, batch.n_tokens = 299, progress = 0.993996
slot update_slots: id  3 | task 40646 | n_tokens = 10595, memory_seq_rm [10595, end)
slot update_slots: id  3 | task 40646 | prompt processing progress, n_tokens = 10659, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 40646 | prompt done, n_tokens = 10659, batch.n_tokens = 64
slot init_sampler: id  3 | task 40646 | init sampler, took 1.60 ms, tokens: text = 10659, total = 10659
slot update_slots: id  3 | task 40646 | created context checkpoint 2 of 8 (pos_min = 9571, pos_max = 10594, size = 24.012 MiB)
slot print_timing: id  3 | task 40646 | 
prompt eval time =    2594.23 ms /  2411 tokens (    1.08 ms per token,   929.37 tokens per second)
       eval time =    3706.93 ms /   161 tokens (   23.02 ms per token,    43.43 tokens per second)
      total time =    6301.16 ms /  2572 tokens
slot      release: id  3 | task 40646 | stop processing: n_tokens = 10819, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.841 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 40810 | processing task, is_child = 0
slot update_slots: id  3 | task 40810 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 12676
slot update_slots: id  3 | task 40810 | n_tokens = 10659, memory_seq_rm [10659, end)
slot update_slots: id  3 | task 40810 | prompt processing progress, n_tokens = 12612, batch.n_tokens = 1953, progress = 0.994951
slot update_slots: id  3 | task 40810 | n_tokens = 12612, memory_seq_rm [12612, end)
slot update_slots: id  3 | task 40810 | prompt processing progress, n_tokens = 12676, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 40810 | prompt done, n_tokens = 12676, batch.n_tokens = 64
slot init_sampler: id  3 | task 40810 | init sampler, took 2.45 ms, tokens: text = 12676, total = 12676
slot update_slots: id  3 | task 40810 | created context checkpoint 3 of 8 (pos_min = 11588, pos_max = 12611, size = 24.012 MiB)
slot print_timing: id  3 | task 40810 | 
prompt eval time =    2187.74 ms /  2017 tokens (    1.08 ms per token,   921.96 tokens per second)
       eval time =   25097.38 ms /  1065 tokens (   23.57 ms per token,    42.43 tokens per second)
      total time =   27285.12 ms /  3082 tokens
slot      release: id  3 | task 40810 | stop processing: n_tokens = 13740, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.931 (> 0.100 thold), f_keep = 0.923
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 41877 | processing task, is_child = 0
slot update_slots: id  3 | task 41877 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13611
slot update_slots: id  3 | task 41877 | n_past = 12676, slot.prompt.tokens.size() = 13740, seq_id = 3, pos_min = 12716, n_swa = 128
slot update_slots: id  3 | task 41877 | restored context checkpoint (pos_min = 11588, pos_max = 12611, size = 24.012 MiB)
slot update_slots: id  3 | task 41877 | n_tokens = 12611, memory_seq_rm [12611, end)
slot update_slots: id  3 | task 41877 | prompt processing progress, n_tokens = 13547, batch.n_tokens = 936, progress = 0.995298
slot update_slots: id  3 | task 41877 | n_tokens = 13547, memory_seq_rm [13547, end)
slot update_slots: id  3 | task 41877 | prompt processing progress, n_tokens = 13611, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 41877 | prompt done, n_tokens = 13611, batch.n_tokens = 64
slot init_sampler: id  3 | task 41877 | init sampler, took 2.64 ms, tokens: text = 13611, total = 13611
slot update_slots: id  3 | task 41877 | created context checkpoint 4 of 8 (pos_min = 12523, pos_max = 13546, size = 24.012 MiB)
slot print_timing: id  3 | task 41877 | 
prompt eval time =    1202.10 ms /  1000 tokens (    1.20 ms per token,   831.88 tokens per second)
       eval time =   15698.99 ms /   653 tokens (   24.04 ms per token,    41.60 tokens per second)
      total time =   16901.09 ms /  1653 tokens
slot      release: id  3 | task 41877 | stop processing: n_tokens = 14263, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.955 (> 0.100 thold), f_keep = 0.954
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 42532 | processing task, is_child = 0
slot update_slots: id  3 | task 42532 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 14250
slot update_slots: id  3 | task 42532 | n_tokens = 13611, memory_seq_rm [13611, end)
slot update_slots: id  3 | task 42532 | prompt processing progress, n_tokens = 14186, batch.n_tokens = 575, progress = 0.995509
slot update_slots: id  3 | task 42532 | n_tokens = 14186, memory_seq_rm [14186, end)
slot update_slots: id  3 | task 42532 | prompt processing progress, n_tokens = 14250, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 42532 | prompt done, n_tokens = 14250, batch.n_tokens = 64
slot init_sampler: id  3 | task 42532 | init sampler, took 2.68 ms, tokens: text = 14250, total = 14250
slot update_slots: id  3 | task 42532 | created context checkpoint 5 of 8 (pos_min = 13239, pos_max = 14185, size = 22.206 MiB)
slot print_timing: id  3 | task 42532 | 
prompt eval time =     918.46 ms /   639 tokens (    1.44 ms per token,   695.73 tokens per second)
       eval time =    4597.03 ms /   190 tokens (   24.19 ms per token,    41.33 tokens per second)
      total time =    5515.49 ms /   829 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 42532 | stop processing: n_tokens = 14439, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 42724 | processing task, is_child = 0
slot update_slots: id  3 | task 42724 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 14425
slot update_slots: id  3 | task 42724 | n_tokens = 14250, memory_seq_rm [14250, end)
slot update_slots: id  3 | task 42724 | prompt processing progress, n_tokens = 14361, batch.n_tokens = 111, progress = 0.995563
slot update_slots: id  3 | task 42724 | n_tokens = 14361, memory_seq_rm [14361, end)
slot update_slots: id  3 | task 42724 | prompt processing progress, n_tokens = 14425, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 42724 | prompt done, n_tokens = 14425, batch.n_tokens = 64
slot init_sampler: id  3 | task 42724 | init sampler, took 2.06 ms, tokens: text = 14425, total = 14425
slot update_slots: id  3 | task 42724 | created context checkpoint 6 of 8 (pos_min = 13423, pos_max = 14360, size = 21.995 MiB)
slot print_timing: id  3 | task 42724 | 
prompt eval time =     425.67 ms /   175 tokens (    2.43 ms per token,   411.12 tokens per second)
       eval time =    5234.18 ms /   217 tokens (   24.12 ms per token,    41.46 tokens per second)
      total time =    5659.85 ms /   392 tokens
slot      release: id  3 | task 42724 | stop processing: n_tokens = 14641, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 42943 | processing task, is_child = 0
slot update_slots: id  3 | task 42943 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 14633
slot update_slots: id  3 | task 42943 | n_tokens = 14425, memory_seq_rm [14425, end)
slot update_slots: id  3 | task 42943 | prompt processing progress, n_tokens = 14569, batch.n_tokens = 144, progress = 0.995626
slot update_slots: id  3 | task 42943 | n_tokens = 14569, memory_seq_rm [14569, end)
slot update_slots: id  3 | task 42943 | prompt processing progress, n_tokens = 14633, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 42943 | prompt done, n_tokens = 14633, batch.n_tokens = 64
slot init_sampler: id  3 | task 42943 | init sampler, took 2.75 ms, tokens: text = 14633, total = 14633
slot update_slots: id  3 | task 42943 | created context checkpoint 7 of 8 (pos_min = 13703, pos_max = 14568, size = 20.307 MiB)
slot print_timing: id  3 | task 42943 | 
prompt eval time =     412.37 ms /   208 tokens (    1.98 ms per token,   504.40 tokens per second)
       eval time =    9880.70 ms /   406 tokens (   24.34 ms per token,    41.09 tokens per second)
      total time =   10293.07 ms /   614 tokens
slot      release: id  3 | task 42943 | stop processing: n_tokens = 15038, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.980 (> 0.100 thold), f_keep = 0.973
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 43351 | processing task, is_child = 0
slot update_slots: id  3 | task 43351 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 14935
slot update_slots: id  3 | task 43351 | n_tokens = 14633, memory_seq_rm [14633, end)
slot update_slots: id  3 | task 43351 | prompt processing progress, n_tokens = 14871, batch.n_tokens = 238, progress = 0.995715
slot update_slots: id  3 | task 43351 | n_tokens = 14871, memory_seq_rm [14871, end)
slot update_slots: id  3 | task 43351 | prompt processing progress, n_tokens = 14935, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 43351 | prompt done, n_tokens = 14935, batch.n_tokens = 64
slot init_sampler: id  3 | task 43351 | init sampler, took 2.14 ms, tokens: text = 14935, total = 14935
slot update_slots: id  3 | task 43351 | created context checkpoint 8 of 8 (pos_min = 14100, pos_max = 14870, size = 18.079 MiB)
slot print_timing: id  3 | task 43351 | 
prompt eval time =     556.09 ms /   302 tokens (    1.84 ms per token,   543.08 tokens per second)
       eval time =     936.58 ms /    37 tokens (   25.31 ms per token,    39.51 tokens per second)
      total time =    1492.67 ms /   339 tokens
slot      release: id  3 | task 43351 | stop processing: n_tokens = 14971, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.955 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 43390 | processing task, is_child = 0
slot update_slots: id  3 | task 43390 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15642
slot update_slots: id  3 | task 43390 | n_tokens = 14935, memory_seq_rm [14935, end)
slot update_slots: id  3 | task 43390 | prompt processing progress, n_tokens = 15578, batch.n_tokens = 643, progress = 0.995908
slot update_slots: id  3 | task 43390 | n_tokens = 15578, memory_seq_rm [15578, end)
slot update_slots: id  3 | task 43390 | prompt processing progress, n_tokens = 15642, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 43390 | prompt done, n_tokens = 15642, batch.n_tokens = 64
slot init_sampler: id  3 | task 43390 | init sampler, took 2.92 ms, tokens: text = 15642, total = 15642
slot update_slots: id  3 | task 43390 | erasing old context checkpoint (pos_min = 7283, pos_max = 8306, size = 24.012 MiB)
slot update_slots: id  3 | task 43390 | created context checkpoint 8 of 8 (pos_min = 14554, pos_max = 15577, size = 24.012 MiB)
slot print_timing: id  3 | task 43390 | 
prompt eval time =    1055.33 ms /   707 tokens (    1.49 ms per token,   669.93 tokens per second)
       eval time =   50990.76 ms /  2053 tokens (   24.84 ms per token,    40.26 tokens per second)
      total time =   52046.10 ms /  2760 tokens
slot      release: id  3 | task 43390 | stop processing: n_tokens = 17694, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.857 (> 0.100 thold), f_keep = 0.884
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 45445 | processing task, is_child = 0
slot update_slots: id  3 | task 45445 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 18261
slot update_slots: id  3 | task 45445 | n_past = 15642, slot.prompt.tokens.size() = 17694, seq_id = 3, pos_min = 16670, n_swa = 128
slot update_slots: id  3 | task 45445 | restored context checkpoint (pos_min = 14554, pos_max = 15577, size = 24.012 MiB)
slot update_slots: id  3 | task 45445 | n_tokens = 15577, memory_seq_rm [15577, end)
slot update_slots: id  3 | task 45445 | prompt processing progress, n_tokens = 17625, batch.n_tokens = 2048, progress = 0.965172
slot update_slots: id  3 | task 45445 | n_tokens = 17625, memory_seq_rm [17625, end)
slot update_slots: id  3 | task 45445 | prompt processing progress, n_tokens = 18197, batch.n_tokens = 572, progress = 0.996495
slot update_slots: id  3 | task 45445 | n_tokens = 18197, memory_seq_rm [18197, end)
slot update_slots: id  3 | task 45445 | prompt processing progress, n_tokens = 18261, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 45445 | prompt done, n_tokens = 18261, batch.n_tokens = 64
slot init_sampler: id  3 | task 45445 | init sampler, took 2.79 ms, tokens: text = 18261, total = 18261
slot update_slots: id  3 | task 45445 | erasing old context checkpoint (pos_min = 9571, pos_max = 10594, size = 24.012 MiB)
slot update_slots: id  3 | task 45445 | created context checkpoint 8 of 8 (pos_min = 17173, pos_max = 18196, size = 24.012 MiB)
slot print_timing: id  3 | task 45445 | 
prompt eval time =    3253.70 ms /  2684 tokens (    1.21 ms per token,   824.91 tokens per second)
       eval time =    1396.39 ms /    55 tokens (   25.39 ms per token,    39.39 tokens per second)
      total time =    4650.10 ms /  2739 tokens
slot      release: id  3 | task 45445 | stop processing: n_tokens = 18315, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.936 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 45503 | processing task, is_child = 0
slot update_slots: id  3 | task 45503 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 19513
slot update_slots: id  3 | task 45503 | n_tokens = 18261, memory_seq_rm [18261, end)
slot update_slots: id  3 | task 45503 | prompt processing progress, n_tokens = 19449, batch.n_tokens = 1188, progress = 0.996720
slot update_slots: id  3 | task 45503 | n_tokens = 19449, memory_seq_rm [19449, end)
slot update_slots: id  3 | task 45503 | prompt processing progress, n_tokens = 19513, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 45503 | prompt done, n_tokens = 19513, batch.n_tokens = 64
slot init_sampler: id  3 | task 45503 | init sampler, took 3.67 ms, tokens: text = 19513, total = 19513
slot update_slots: id  3 | task 45503 | erasing old context checkpoint (pos_min = 11588, pos_max = 12611, size = 24.012 MiB)
slot update_slots: id  3 | task 45503 | created context checkpoint 8 of 8 (pos_min = 18425, pos_max = 19448, size = 24.012 MiB)
slot print_timing: id  3 | task 45503 | 
prompt eval time =    1683.33 ms /  1252 tokens (    1.34 ms per token,   743.76 tokens per second)
       eval time =   55258.06 ms /  2149 tokens (   25.71 ms per token,    38.89 tokens per second)
      total time =   56941.39 ms /  3401 tokens
slot      release: id  3 | task 45503 | stop processing: n_tokens = 21661, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.863 (> 0.100 thold), f_keep = 0.901
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 47654 | processing task, is_child = 0
slot update_slots: id  3 | task 47654 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 22613
slot update_slots: id  3 | task 47654 | n_past = 19513, slot.prompt.tokens.size() = 21661, seq_id = 3, pos_min = 20637, n_swa = 128
slot update_slots: id  3 | task 47654 | restored context checkpoint (pos_min = 18425, pos_max = 19448, size = 24.012 MiB)
slot update_slots: id  3 | task 47654 | n_tokens = 19448, memory_seq_rm [19448, end)
slot update_slots: id  3 | task 47654 | prompt processing progress, n_tokens = 21496, batch.n_tokens = 2048, progress = 0.950604
slot update_slots: id  3 | task 47654 | n_tokens = 21496, memory_seq_rm [21496, end)
slot update_slots: id  3 | task 47654 | prompt processing progress, n_tokens = 22549, batch.n_tokens = 1053, progress = 0.997170
slot update_slots: id  3 | task 47654 | n_tokens = 22549, memory_seq_rm [22549, end)
slot update_slots: id  3 | task 47654 | prompt processing progress, n_tokens = 22613, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 47654 | prompt done, n_tokens = 22613, batch.n_tokens = 64
slot init_sampler: id  3 | task 47654 | init sampler, took 11.46 ms, tokens: text = 22613, total = 22613
slot update_slots: id  3 | task 47654 | erasing old context checkpoint (pos_min = 12523, pos_max = 13546, size = 24.012 MiB)
slot update_slots: id  3 | task 47654 | created context checkpoint 8 of 8 (pos_min = 21525, pos_max = 22548, size = 24.012 MiB)
slot print_timing: id  3 | task 47654 | 
prompt eval time =    4094.65 ms /  3165 tokens (    1.29 ms per token,   772.96 tokens per second)
       eval time =    1473.61 ms /    56 tokens (   26.31 ms per token,    38.00 tokens per second)
      total time =    5568.26 ms /  3221 tokens
slot      release: id  3 | task 47654 | stop processing: n_tokens = 22668, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.922 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 47713 | processing task, is_child = 0
slot update_slots: id  3 | task 47713 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 24520
slot update_slots: id  3 | task 47713 | n_tokens = 22613, memory_seq_rm [22613, end)
slot update_slots: id  3 | task 47713 | prompt processing progress, n_tokens = 24456, batch.n_tokens = 1843, progress = 0.997390
slot update_slots: id  3 | task 47713 | n_tokens = 24456, memory_seq_rm [24456, end)
slot update_slots: id  3 | task 47713 | prompt processing progress, n_tokens = 24520, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 47713 | prompt done, n_tokens = 24520, batch.n_tokens = 64
slot init_sampler: id  3 | task 47713 | init sampler, took 3.66 ms, tokens: text = 24520, total = 24520
slot update_slots: id  3 | task 47713 | erasing old context checkpoint (pos_min = 13239, pos_max = 14185, size = 22.206 MiB)
slot update_slots: id  3 | task 47713 | created context checkpoint 8 of 8 (pos_min = 23432, pos_max = 24455, size = 24.012 MiB)
slot print_timing: id  3 | task 47713 | 
prompt eval time =    2643.68 ms /  1907 tokens (    1.39 ms per token,   721.34 tokens per second)
       eval time =    2695.87 ms /   103 tokens (   26.17 ms per token,    38.21 tokens per second)
      total time =    5339.56 ms /  2010 tokens
slot      release: id  3 | task 47713 | stop processing: n_tokens = 24622, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 47818 | processing task, is_child = 0
slot update_slots: id  3 | task 47818 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 24579
slot update_slots: id  3 | task 47818 | n_tokens = 24520, memory_seq_rm [24520, end)
slot update_slots: id  3 | task 47818 | prompt processing progress, n_tokens = 24579, batch.n_tokens = 59, progress = 1.000000
slot update_slots: id  3 | task 47818 | prompt done, n_tokens = 24579, batch.n_tokens = 59
slot init_sampler: id  3 | task 47818 | init sampler, took 3.74 ms, tokens: text = 24579, total = 24579
slot print_timing: id  3 | task 47818 | 
prompt eval time =     175.47 ms /    59 tokens (    2.97 ms per token,   336.24 tokens per second)
       eval time =   80223.43 ms /  2999 tokens (   26.75 ms per token,    37.38 tokens per second)
      total time =   80398.90 ms /  3058 tokens
slot      release: id  3 | task 47818 | stop processing: n_tokens = 27577, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.893 (> 0.100 thold), f_keep = 0.891
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 50818 | processing task, is_child = 0
slot update_slots: id  3 | task 50818 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 27538
slot update_slots: id  3 | task 50818 | n_past = 24579, slot.prompt.tokens.size() = 27577, seq_id = 3, pos_min = 26553, n_swa = 128
slot update_slots: id  3 | task 50818 | restored context checkpoint (pos_min = 23432, pos_max = 24455, size = 24.012 MiB)
slot update_slots: id  3 | task 50818 | n_tokens = 24455, memory_seq_rm [24455, end)
slot update_slots: id  3 | task 50818 | prompt processing progress, n_tokens = 26503, batch.n_tokens = 2048, progress = 0.962416
slot update_slots: id  3 | task 50818 | n_tokens = 26503, memory_seq_rm [26503, end)
slot update_slots: id  3 | task 50818 | prompt processing progress, n_tokens = 27474, batch.n_tokens = 971, progress = 0.997676
slot update_slots: id  3 | task 50818 | n_tokens = 27474, memory_seq_rm [27474, end)
slot update_slots: id  3 | task 50818 | prompt processing progress, n_tokens = 27538, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 50818 | prompt done, n_tokens = 27538, batch.n_tokens = 64
slot init_sampler: id  3 | task 50818 | init sampler, took 4.27 ms, tokens: text = 27538, total = 27538
slot update_slots: id  3 | task 50818 | erasing old context checkpoint (pos_min = 13423, pos_max = 14360, size = 21.995 MiB)
slot update_slots: id  3 | task 50818 | created context checkpoint 8 of 8 (pos_min = 26450, pos_max = 27473, size = 24.012 MiB)
slot print_timing: id  3 | task 50818 | 
prompt eval time =    4263.71 ms /  3083 tokens (    1.38 ms per token,   723.08 tokens per second)
       eval time =    1871.13 ms /    69 tokens (   27.12 ms per token,    36.88 tokens per second)
      total time =    6134.83 ms /  3152 tokens
slot      release: id  3 | task 50818 | stop processing: n_tokens = 27606, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 50890 | processing task, is_child = 0
slot update_slots: id  3 | task 50890 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 27604
slot update_slots: id  3 | task 50890 | n_tokens = 27538, memory_seq_rm [27538, end)
slot update_slots: id  3 | task 50890 | prompt processing progress, n_tokens = 27540, batch.n_tokens = 2, progress = 0.997681
slot update_slots: id  3 | task 50890 | n_tokens = 27540, memory_seq_rm [27540, end)
slot update_slots: id  3 | task 50890 | prompt processing progress, n_tokens = 27604, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 50890 | prompt done, n_tokens = 27604, batch.n_tokens = 64
slot init_sampler: id  3 | task 50890 | init sampler, took 3.96 ms, tokens: text = 27604, total = 27604
slot update_slots: id  3 | task 50890 | erasing old context checkpoint (pos_min = 13703, pos_max = 14568, size = 20.307 MiB)
slot update_slots: id  3 | task 50890 | created context checkpoint 8 of 8 (pos_min = 26582, pos_max = 27539, size = 22.464 MiB)
slot print_timing: id  3 | task 50890 | 
prompt eval time =     349.10 ms /    66 tokens (    5.29 ms per token,   189.06 tokens per second)
       eval time =   11547.78 ms /   434 tokens (   26.61 ms per token,    37.58 tokens per second)
      total time =   11896.88 ms /   500 tokens
slot      release: id  3 | task 50890 | stop processing: n_tokens = 28037, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.978 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 51326 | processing task, is_child = 0
slot update_slots: id  3 | task 51326 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 28214
slot update_slots: id  3 | task 51326 | n_tokens = 27604, memory_seq_rm [27604, end)
slot update_slots: id  3 | task 51326 | prompt processing progress, n_tokens = 28150, batch.n_tokens = 546, progress = 0.997732
slot update_slots: id  3 | task 51326 | n_tokens = 28150, memory_seq_rm [28150, end)
slot update_slots: id  3 | task 51326 | prompt processing progress, n_tokens = 28214, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 51326 | prompt done, n_tokens = 28214, batch.n_tokens = 64
slot init_sampler: id  3 | task 51326 | init sampler, took 4.16 ms, tokens: text = 28214, total = 28214
slot update_slots: id  3 | task 51326 | erasing old context checkpoint (pos_min = 14100, pos_max = 14870, size = 18.079 MiB)
slot update_slots: id  3 | task 51326 | created context checkpoint 8 of 8 (pos_min = 27150, pos_max = 28149, size = 23.449 MiB)
slot print_timing: id  3 | task 51326 | 
prompt eval time =    1075.13 ms /   610 tokens (    1.76 ms per token,   567.37 tokens per second)
       eval time =    1613.45 ms /    62 tokens (   26.02 ms per token,    38.43 tokens per second)
      total time =    2688.59 ms /   672 tokens
slot      release: id  3 | task 51326 | stop processing: n_tokens = 28275, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LRU, t_last = -1
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 51390 | processing task, is_child = 0
slot update_slots: id  2 | task 51390 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20465
slot update_slots: id  2 | task 51390 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 51390 | prompt processing progress, n_tokens = 2048, batch.n_tokens = 2048, progress = 0.100073
slot update_slots: id  2 | task 51390 | n_tokens = 2048, memory_seq_rm [2048, end)
slot update_slots: id  2 | task 51390 | prompt processing progress, n_tokens = 4096, batch.n_tokens = 2048, progress = 0.200147
slot update_slots: id  2 | task 51390 | n_tokens = 4096, memory_seq_rm [4096, end)
slot update_slots: id  2 | task 51390 | prompt processing progress, n_tokens = 6144, batch.n_tokens = 2048, progress = 0.300220
slot update_slots: id  2 | task 51390 | n_tokens = 6144, memory_seq_rm [6144, end)
slot update_slots: id  2 | task 51390 | prompt processing progress, n_tokens = 8192, batch.n_tokens = 2048, progress = 0.400293
slot update_slots: id  2 | task 51390 | n_tokens = 8192, memory_seq_rm [8192, end)
slot update_slots: id  2 | task 51390 | prompt processing progress, n_tokens = 10240, batch.n_tokens = 2048, progress = 0.500367
slot update_slots: id  2 | task 51390 | n_tokens = 10240, memory_seq_rm [10240, end)
slot update_slots: id  2 | task 51390 | prompt processing progress, n_tokens = 12288, batch.n_tokens = 2048, progress = 0.600440
slot update_slots: id  2 | task 51390 | n_tokens = 12288, memory_seq_rm [12288, end)
slot update_slots: id  2 | task 51390 | prompt processing progress, n_tokens = 14336, batch.n_tokens = 2048, progress = 0.700513
slot update_slots: id  2 | task 51390 | n_tokens = 14336, memory_seq_rm [14336, end)
slot update_slots: id  2 | task 51390 | prompt processing progress, n_tokens = 16384, batch.n_tokens = 2048, progress = 0.800586
slot update_slots: id  2 | task 51390 | n_tokens = 16384, memory_seq_rm [16384, end)
slot update_slots: id  2 | task 51390 | prompt processing progress, n_tokens = 18432, batch.n_tokens = 2048, progress = 0.900660
slot update_slots: id  2 | task 51390 | n_tokens = 18432, memory_seq_rm [18432, end)
slot update_slots: id  2 | task 51390 | prompt processing progress, n_tokens = 20401, batch.n_tokens = 1969, progress = 0.996873
slot update_slots: id  2 | task 51390 | n_tokens = 20401, memory_seq_rm [20401, end)
slot update_slots: id  2 | task 51390 | prompt processing progress, n_tokens = 20465, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 51390 | prompt done, n_tokens = 20465, batch.n_tokens = 64
slot init_sampler: id  2 | task 51390 | init sampler, took 2.93 ms, tokens: text = 20465, total = 20465
slot update_slots: id  2 | task 51390 | created context checkpoint 1 of 8 (pos_min = 19504, pos_max = 20400, size = 21.034 MiB)
slot print_timing: id  2 | task 51390 | 
prompt eval time =   28971.05 ms / 20465 tokens (    1.42 ms per token,   706.39 tokens per second)
       eval time =    5360.11 ms /   189 tokens (   28.36 ms per token,    35.26 tokens per second)
      total time =   34331.17 ms / 20654 tokens
slot      release: id  2 | task 51390 | stop processing: n_tokens = 20653, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 51590 | processing task, is_child = 0
slot update_slots: id  2 | task 51590 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20613
slot update_slots: id  2 | task 51590 | n_tokens = 20465, memory_seq_rm [20465, end)
slot update_slots: id  2 | task 51590 | prompt processing progress, n_tokens = 20549, batch.n_tokens = 84, progress = 0.996895
slot update_slots: id  2 | task 51590 | n_tokens = 20549, memory_seq_rm [20549, end)
slot update_slots: id  2 | task 51590 | prompt processing progress, n_tokens = 20613, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 51590 | prompt done, n_tokens = 20613, batch.n_tokens = 64
slot init_sampler: id  2 | task 51590 | init sampler, took 10.70 ms, tokens: text = 20613, total = 20613
slot update_slots: id  2 | task 51590 | created context checkpoint 2 of 8 (pos_min = 19756, pos_max = 20548, size = 18.595 MiB)
slot print_timing: id  2 | task 51590 | 
prompt eval time =     626.61 ms /   148 tokens (    4.23 ms per token,   236.19 tokens per second)
       eval time =   11018.65 ms /   350 tokens (   31.48 ms per token,    31.76 tokens per second)
      total time =   11645.26 ms /   498 tokens
slot      release: id  2 | task 51590 | stop processing: n_tokens = 20962, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.982 (> 0.100 thold), f_keep = 0.975
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 51942 | processing task, is_child = 0
slot update_slots: id  2 | task 51942 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20816
slot update_slots: id  2 | task 51942 | n_tokens = 20431, memory_seq_rm [20431, end)
slot update_slots: id  2 | task 51942 | prompt processing progress, n_tokens = 20752, batch.n_tokens = 321, progress = 0.996925
slot update_slots: id  2 | task 51942 | n_tokens = 20752, memory_seq_rm [20752, end)
slot update_slots: id  2 | task 51942 | prompt processing progress, n_tokens = 20816, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 51942 | prompt done, n_tokens = 20816, batch.n_tokens = 64
slot init_sampler: id  2 | task 51942 | init sampler, took 2.97 ms, tokens: text = 20816, total = 20816
slot update_slots: id  2 | task 51942 | created context checkpoint 3 of 8 (pos_min = 20304, pos_max = 20751, size = 10.505 MiB)
slot print_timing: id  2 | task 51942 | 
prompt eval time =     907.96 ms /   385 tokens (    2.36 ms per token,   424.03 tokens per second)
       eval time =   17773.42 ms /   620 tokens (   28.67 ms per token,    34.88 tokens per second)
      total time =   18681.38 ms /  1005 tokens
slot      release: id  2 | task 51942 | stop processing: n_tokens = 21435, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.971
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 52564 | processing task, is_child = 0
slot update_slots: id  2 | task 52564 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20966
slot update_slots: id  2 | task 52564 | n_tokens = 20816, memory_seq_rm [20816, end)
slot update_slots: id  2 | task 52564 | prompt processing progress, n_tokens = 20902, batch.n_tokens = 86, progress = 0.996947
slot update_slots: id  2 | task 52564 | n_tokens = 20902, memory_seq_rm [20902, end)
slot update_slots: id  2 | task 52564 | prompt processing progress, n_tokens = 20966, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 52564 | prompt done, n_tokens = 20966, batch.n_tokens = 64
slot init_sampler: id  2 | task 52564 | init sampler, took 4.29 ms, tokens: text = 20966, total = 20966
slot update_slots: id  2 | task 52564 | created context checkpoint 4 of 8 (pos_min = 20665, pos_max = 20901, size = 5.558 MiB)
slot print_timing: id  2 | task 52564 | 
prompt eval time =     690.97 ms /   150 tokens (    4.61 ms per token,   217.09 tokens per second)
       eval time =   13988.21 ms /   406 tokens (   34.45 ms per token,    29.02 tokens per second)
      total time =   14679.17 ms /   556 tokens
slot      release: id  2 | task 52564 | stop processing: n_tokens = 21371, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.956 (> 0.100 thold), f_keep = 0.981
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 52972 | processing task, is_child = 0
slot update_slots: id  2 | task 52972 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 21938
slot update_slots: id  2 | task 52972 | n_tokens = 20966, memory_seq_rm [20966, end)
slot update_slots: id  2 | task 52972 | prompt processing progress, n_tokens = 21874, batch.n_tokens = 908, progress = 0.997083
slot update_slots: id  2 | task 52972 | n_tokens = 21874, memory_seq_rm [21874, end)
slot update_slots: id  2 | task 52972 | prompt processing progress, n_tokens = 21938, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 52972 | prompt done, n_tokens = 21938, batch.n_tokens = 64
slot init_sampler: id  2 | task 52972 | init sampler, took 3.08 ms, tokens: text = 21938, total = 21938
slot update_slots: id  2 | task 52972 | created context checkpoint 5 of 8 (pos_min = 20977, pos_max = 21873, size = 21.034 MiB)
slot print_timing: id  2 | task 52972 | 
prompt eval time =    1805.15 ms /   972 tokens (    1.86 ms per token,   538.46 tokens per second)
       eval time =   27170.09 ms /   933 tokens (   29.12 ms per token,    34.34 tokens per second)
      total time =   28975.24 ms /  1905 tokens
slot      release: id  2 | task 52972 | stop processing: n_tokens = 22870, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.962 (> 0.100 thold), f_keep = 0.908
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 53907 | processing task, is_child = 0
slot update_slots: id  2 | task 53907 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 21573
slot update_slots: id  2 | task 53907 | n_past = 20758, slot.prompt.tokens.size() = 22870, seq_id = 2, pos_min = 21973, n_swa = 128
slot update_slots: id  2 | task 53907 | restored context checkpoint (pos_min = 20304, pos_max = 20751, size = 10.505 MiB)
slot update_slots: id  2 | task 53907 | erased invalidated context checkpoint (pos_min = 20665, pos_max = 20901, n_swa = 128, size = 5.558 MiB)
slot update_slots: id  2 | task 53907 | erased invalidated context checkpoint (pos_min = 20977, pos_max = 21873, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 53907 | n_tokens = 20751, memory_seq_rm [20751, end)
slot update_slots: id  2 | task 53907 | prompt processing progress, n_tokens = 21509, batch.n_tokens = 758, progress = 0.997033
slot update_slots: id  2 | task 53907 | n_tokens = 21509, memory_seq_rm [21509, end)
slot update_slots: id  2 | task 53907 | prompt processing progress, n_tokens = 21573, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 53907 | prompt done, n_tokens = 21573, batch.n_tokens = 64
slot init_sampler: id  2 | task 53907 | init sampler, took 3.11 ms, tokens: text = 21573, total = 21573
slot update_slots: id  2 | task 53907 | created context checkpoint 4 of 8 (pos_min = 20714, pos_max = 21508, size = 18.642 MiB)
slot print_timing: id  2 | task 53907 | 
prompt eval time =    1618.01 ms /   822 tokens (    1.97 ms per token,   508.03 tokens per second)
       eval time =   20357.86 ms /   723 tokens (   28.16 ms per token,    35.51 tokens per second)
      total time =   21975.87 ms /  1545 tokens
slot      release: id  2 | task 53907 | stop processing: n_tokens = 22295, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.971 (> 0.100 thold), f_keep = 0.967
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 54632 | processing task, is_child = 0
slot update_slots: id  2 | task 54632 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 22186
slot update_slots: id  2 | task 54632 | n_tokens = 21550, memory_seq_rm [21550, end)
slot update_slots: id  2 | task 54632 | prompt processing progress, n_tokens = 22122, batch.n_tokens = 572, progress = 0.997115
slot update_slots: id  2 | task 54632 | n_tokens = 22122, memory_seq_rm [22122, end)
slot update_slots: id  2 | task 54632 | prompt processing progress, n_tokens = 22186, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 54632 | prompt done, n_tokens = 22186, batch.n_tokens = 64
slot init_sampler: id  2 | task 54632 | init sampler, took 3.33 ms, tokens: text = 22186, total = 22186
slot update_slots: id  2 | task 54632 | created context checkpoint 5 of 8 (pos_min = 21423, pos_max = 22121, size = 16.391 MiB)
slot print_timing: id  2 | task 54632 | 
prompt eval time =    1352.05 ms /   636 tokens (    2.13 ms per token,   470.40 tokens per second)
       eval time =   13233.26 ms /   462 tokens (   28.64 ms per token,    34.91 tokens per second)
      total time =   14585.31 ms /  1098 tokens
slot      release: id  2 | task 54632 | stop processing: n_tokens = 22647, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.979
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 55096 | processing task, is_child = 0
slot update_slots: id  2 | task 55096 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 22454
slot update_slots: id  2 | task 55096 | n_tokens = 22165, memory_seq_rm [22165, end)
slot update_slots: id  2 | task 55096 | prompt processing progress, n_tokens = 22390, batch.n_tokens = 225, progress = 0.997150
slot update_slots: id  2 | task 55096 | n_tokens = 22390, memory_seq_rm [22390, end)
slot update_slots: id  2 | task 55096 | prompt processing progress, n_tokens = 22454, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 55096 | prompt done, n_tokens = 22454, batch.n_tokens = 64
slot init_sampler: id  2 | task 55096 | init sampler, took 4.25 ms, tokens: text = 22454, total = 22454
slot update_slots: id  2 | task 55096 | created context checkpoint 6 of 8 (pos_min = 21772, pos_max = 22389, size = 14.492 MiB)
slot print_timing: id  2 | task 55096 | 
prompt eval time =     859.17 ms /   289 tokens (    2.97 ms per token,   336.37 tokens per second)
       eval time =   12801.67 ms /   453 tokens (   28.26 ms per token,    35.39 tokens per second)
      total time =   13660.84 ms /   742 tokens
slot      release: id  2 | task 55096 | stop processing: n_tokens = 22906, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.979
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 55551 | processing task, is_child = 0
slot update_slots: id  2 | task 55551 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 22797
slot update_slots: id  2 | task 55551 | n_tokens = 22422, memory_seq_rm [22422, end)
slot update_slots: id  2 | task 55551 | prompt processing progress, n_tokens = 22733, batch.n_tokens = 311, progress = 0.997193
slot update_slots: id  2 | task 55551 | n_tokens = 22733, memory_seq_rm [22733, end)
slot update_slots: id  2 | task 55551 | prompt processing progress, n_tokens = 22797, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 55551 | prompt done, n_tokens = 22797, batch.n_tokens = 64
slot init_sampler: id  2 | task 55551 | init sampler, took 3.25 ms, tokens: text = 22797, total = 22797
slot update_slots: id  2 | task 55551 | created context checkpoint 7 of 8 (pos_min = 22164, pos_max = 22732, size = 13.343 MiB)
slot print_timing: id  2 | task 55551 | 
prompt eval time =     892.61 ms /   375 tokens (    2.38 ms per token,   420.12 tokens per second)
       eval time =    5856.32 ms /   206 tokens (   28.43 ms per token,    35.18 tokens per second)
      total time =    6748.93 ms /   581 tokens
slot      release: id  2 | task 55551 | stop processing: n_tokens = 23002, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 55759 | processing task, is_child = 0
slot update_slots: id  2 | task 55759 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 22948
slot update_slots: id  2 | task 55759 | n_tokens = 22797, memory_seq_rm [22797, end)
slot update_slots: id  2 | task 55759 | prompt processing progress, n_tokens = 22884, batch.n_tokens = 87, progress = 0.997211
slot update_slots: id  2 | task 55759 | n_tokens = 22884, memory_seq_rm [22884, end)
slot update_slots: id  2 | task 55759 | prompt processing progress, n_tokens = 22948, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 55759 | prompt done, n_tokens = 22948, batch.n_tokens = 64
slot init_sampler: id  2 | task 55759 | init sampler, took 3.40 ms, tokens: text = 22948, total = 22948
slot update_slots: id  2 | task 55759 | created context checkpoint 8 of 8 (pos_min = 22165, pos_max = 22883, size = 16.860 MiB)
slot print_timing: id  2 | task 55759 | 
prompt eval time =     568.45 ms /   151 tokens (    3.76 ms per token,   265.63 tokens per second)
       eval time =    1020.26 ms /    38 tokens (   26.85 ms per token,    37.25 tokens per second)
      total time =    1588.72 ms /   189 tokens
slot      release: id  2 | task 55759 | stop processing: n_tokens = 22985, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 55799 | processing task, is_child = 0
slot update_slots: id  2 | task 55799 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23053
slot update_slots: id  2 | task 55799 | n_tokens = 22948, memory_seq_rm [22948, end)
slot update_slots: id  2 | task 55799 | prompt processing progress, n_tokens = 22989, batch.n_tokens = 41, progress = 0.997224
slot update_slots: id  2 | task 55799 | n_tokens = 22989, memory_seq_rm [22989, end)
slot update_slots: id  2 | task 55799 | prompt processing progress, n_tokens = 23053, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 55799 | prompt done, n_tokens = 23053, batch.n_tokens = 64
slot init_sampler: id  2 | task 55799 | init sampler, took 3.29 ms, tokens: text = 23053, total = 23053
slot update_slots: id  2 | task 55799 | erasing old context checkpoint (pos_min = 19504, pos_max = 20400, size = 21.034 MiB)
slot update_slots: id  2 | task 55799 | created context checkpoint 8 of 8 (pos_min = 22165, pos_max = 22988, size = 19.322 MiB)
slot print_timing: id  2 | task 55799 | 
prompt eval time =     420.45 ms /   105 tokens (    4.00 ms per token,   249.73 tokens per second)
       eval time =    5574.83 ms /   200 tokens (   27.87 ms per token,    35.88 tokens per second)
      total time =    5995.28 ms /   305 tokens
slot      release: id  2 | task 55799 | stop processing: n_tokens = 23252, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 56001 | processing task, is_child = 0
slot update_slots: id  2 | task 56001 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23161
slot update_slots: id  2 | task 56001 | n_tokens = 23053, memory_seq_rm [23053, end)
slot update_slots: id  2 | task 56001 | prompt processing progress, n_tokens = 23097, batch.n_tokens = 44, progress = 0.997237
slot update_slots: id  2 | task 56001 | n_tokens = 23097, memory_seq_rm [23097, end)
slot update_slots: id  2 | task 56001 | prompt processing progress, n_tokens = 23161, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 56001 | prompt done, n_tokens = 23161, batch.n_tokens = 64
slot init_sampler: id  2 | task 56001 | init sampler, took 4.37 ms, tokens: text = 23161, total = 23161
slot update_slots: id  2 | task 56001 | erasing old context checkpoint (pos_min = 19756, pos_max = 20548, size = 18.595 MiB)
slot update_slots: id  2 | task 56001 | created context checkpoint 8 of 8 (pos_min = 22355, pos_max = 23096, size = 17.399 MiB)
slot print_timing: id  2 | task 56001 | 
prompt eval time =     529.57 ms /   108 tokens (    4.90 ms per token,   203.94 tokens per second)
       eval time =    1107.76 ms /    36 tokens (   30.77 ms per token,    32.50 tokens per second)
      total time =    1637.33 ms /   144 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 56001 | stop processing: n_tokens = 23196, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 56039 | processing task, is_child = 0
slot update_slots: id  2 | task 56039 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23266
slot update_slots: id  2 | task 56039 | n_tokens = 23161, memory_seq_rm [23161, end)
slot update_slots: id  2 | task 56039 | prompt processing progress, n_tokens = 23202, batch.n_tokens = 41, progress = 0.997249
slot update_slots: id  2 | task 56039 | n_tokens = 23202, memory_seq_rm [23202, end)
slot update_slots: id  2 | task 56039 | prompt processing progress, n_tokens = 23266, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 56039 | prompt done, n_tokens = 23266, batch.n_tokens = 64
slot init_sampler: id  2 | task 56039 | init sampler, took 3.39 ms, tokens: text = 23266, total = 23266
slot update_slots: id  2 | task 56039 | erasing old context checkpoint (pos_min = 20304, pos_max = 20751, size = 10.505 MiB)
slot update_slots: id  2 | task 56039 | created context checkpoint 8 of 8 (pos_min = 22355, pos_max = 23201, size = 19.862 MiB)
slot print_timing: id  2 | task 56039 | 
prompt eval time =     429.11 ms /   105 tokens (    4.09 ms per token,   244.69 tokens per second)
       eval time =    1481.76 ms /    53 tokens (   27.96 ms per token,    35.77 tokens per second)
      total time =    1910.87 ms /   158 tokens
slot      release: id  2 | task 56039 | stop processing: n_tokens = 23318, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.393 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 56094 | processing task, is_child = 0
slot update_slots: id  2 | task 56094 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 59143
slot update_slots: id  2 | task 56094 | n_tokens = 23266, memory_seq_rm [23266, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 25314, batch.n_tokens = 2048, progress = 0.428013
slot update_slots: id  2 | task 56094 | n_tokens = 25314, memory_seq_rm [25314, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 27362, batch.n_tokens = 2048, progress = 0.462641
slot update_slots: id  2 | task 56094 | n_tokens = 27362, memory_seq_rm [27362, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 29410, batch.n_tokens = 2048, progress = 0.497269
slot update_slots: id  2 | task 56094 | n_tokens = 29410, memory_seq_rm [29410, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 31458, batch.n_tokens = 2048, progress = 0.531897
slot update_slots: id  2 | task 56094 | n_tokens = 31458, memory_seq_rm [31458, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 33506, batch.n_tokens = 2048, progress = 0.566525
slot update_slots: id  2 | task 56094 | n_tokens = 33506, memory_seq_rm [33506, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 35554, batch.n_tokens = 2048, progress = 0.601153
slot update_slots: id  2 | task 56094 | n_tokens = 35554, memory_seq_rm [35554, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 37602, batch.n_tokens = 2048, progress = 0.635781
decode: failed to find a memory slot for batch of size 2048
srv  try_clear_id: purging slot 3 with 28275 tokens
slot prompt_clear: id  3 | task -1 | clearing prompt with 28275 tokens
srv  update_slots: failed to find free space in the KV cache, retrying with smaller batch size, i = 0, n_batch = 2048, ret = 1
slot update_slots: id  2 | task 56094 | n_tokens = 37602, memory_seq_rm [37602, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 39650, batch.n_tokens = 2048, progress = 0.670409
slot update_slots: id  2 | task 56094 | n_tokens = 39650, memory_seq_rm [39650, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 41698, batch.n_tokens = 2048, progress = 0.705037
slot update_slots: id  2 | task 56094 | n_tokens = 41698, memory_seq_rm [41698, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 43746, batch.n_tokens = 2048, progress = 0.739665
slot update_slots: id  2 | task 56094 | n_tokens = 43746, memory_seq_rm [43746, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 45794, batch.n_tokens = 2048, progress = 0.774293
slot update_slots: id  2 | task 56094 | n_tokens = 45794, memory_seq_rm [45794, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 47842, batch.n_tokens = 2048, progress = 0.808921
slot update_slots: id  2 | task 56094 | n_tokens = 47842, memory_seq_rm [47842, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 49890, batch.n_tokens = 2048, progress = 0.843549
slot update_slots: id  2 | task 56094 | n_tokens = 49890, memory_seq_rm [49890, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 51938, batch.n_tokens = 2048, progress = 0.878177
slot update_slots: id  2 | task 56094 | n_tokens = 51938, memory_seq_rm [51938, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 53986, batch.n_tokens = 2048, progress = 0.912805
slot update_slots: id  2 | task 56094 | n_tokens = 53986, memory_seq_rm [53986, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 56034, batch.n_tokens = 2048, progress = 0.947433
slot update_slots: id  2 | task 56094 | n_tokens = 56034, memory_seq_rm [56034, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 58082, batch.n_tokens = 2048, progress = 0.982060
slot update_slots: id  2 | task 56094 | n_tokens = 58082, memory_seq_rm [58082, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 59079, batch.n_tokens = 997, progress = 0.998918
slot update_slots: id  2 | task 56094 | n_tokens = 59079, memory_seq_rm [59079, end)
slot update_slots: id  2 | task 56094 | prompt processing progress, n_tokens = 59143, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 56094 | prompt done, n_tokens = 59143, batch.n_tokens = 64
slot init_sampler: id  2 | task 56094 | init sampler, took 8.43 ms, tokens: text = 59143, total = 59143
slot update_slots: id  2 | task 56094 | erasing old context checkpoint (pos_min = 20714, pos_max = 21508, size = 18.642 MiB)
slot update_slots: id  2 | task 56094 | created context checkpoint 8 of 8 (pos_min = 58055, pos_max = 59078, size = 24.012 MiB)
slot print_timing: id  2 | task 56094 | 
prompt eval time =   64626.87 ms / 35877 tokens (    1.80 ms per token,   555.14 tokens per second)
       eval time =    7143.48 ms /   221 tokens (   32.32 ms per token,    30.94 tokens per second)
      total time =   71770.34 ms / 36098 tokens
slot      release: id  2 | task 56094 | stop processing: n_tokens = 59363, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.974 (> 0.100 thold), f_keep = 0.384
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 59363, total state size = 1416.012 MiB
srv          load:  - looking for better prompt, base f_keep = 0.384, sim = 0.974
srv        update:  - cache state: 14 prompts, 7350.599 MiB (limits: 8192.000 MiB, 64000 tokens, 250515 est)
srv        update:    - prompt 0x55a5f0b7a5c0:    7162 tokens, checkpoints:  8,   347.469 MiB
srv        update:    - prompt 0x55a5f1d40020:    7615 tokens, checkpoints:  8,   361.914 MiB
srv        update:    - prompt 0x55a5f08766f0:   21813 tokens, checkpoints:  8,   712.311 MiB
srv        update:    - prompt 0x55a5e9d8fee0:    7620 tokens, checkpoints:  8,   330.328 MiB
srv        update:    - prompt 0x55a5f253e010:    1645 tokens, checkpoints:  1,    74.475 MiB
srv        update:    - prompt 0x55a5f0eef780:    1393 tokens, checkpoints:  2,    83.268 MiB
srv        update:    - prompt 0x55a606fb61a0:    1819 tokens, checkpoints:  5,   128.385 MiB
srv        update:    - prompt 0x55a5ef774150:    3893 tokens, checkpoints:  6,   216.460 MiB
srv        update:    - prompt 0x55a5ef97d560:    4629 tokens, checkpoints:  8,   285.658 MiB
srv        update:    - prompt 0x55a5f1e7ee30:    5461 tokens, checkpoints:  8,   295.084 MiB
srv        update:    - prompt 0x55a62d43ef60:    7594 tokens, checkpoints:  8,   372.536 MiB
srv        update:    - prompt 0x55a5f0e5e010:   41056 tokens, checkpoints:  6,  1124.027 MiB
srv        update:    - prompt 0x55a6357da0f0:   53722 tokens, checkpoints:  8,  1460.989 MiB
srv        update:    - prompt 0x55a606728910:   59363 tokens, checkpoints:  8,  1557.693 MiB
srv  get_availabl: prompt cache update took 1367.06 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 56334 | processing task, is_child = 0
slot update_slots: id  2 | task 56334 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23376
slot update_slots: id  2 | task 56334 | n_past = 22778, slot.prompt.tokens.size() = 59363, seq_id = 2, pos_min = 58339, n_swa = 128
slot update_slots: id  2 | task 56334 | restored context checkpoint (pos_min = 22355, pos_max = 23201, size = 19.862 MiB)
slot update_slots: id  2 | task 56334 | erased invalidated context checkpoint (pos_min = 58055, pos_max = 59078, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  2 | task 56334 | n_tokens = 22778, memory_seq_rm [22778, end)
slot update_slots: id  2 | task 56334 | prompt processing progress, n_tokens = 23312, batch.n_tokens = 534, progress = 0.997262
slot update_slots: id  2 | task 56334 | n_tokens = 23312, memory_seq_rm [23312, end)
slot update_slots: id  2 | task 56334 | prompt processing progress, n_tokens = 23376, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 56334 | prompt done, n_tokens = 23376, batch.n_tokens = 64
slot init_sampler: id  2 | task 56334 | init sampler, took 3.35 ms, tokens: text = 23376, total = 23376
slot update_slots: id  2 | task 56334 | created context checkpoint 8 of 8 (pos_min = 22651, pos_max = 23311, size = 15.500 MiB)
slot print_timing: id  2 | task 56334 | 
prompt eval time =    1317.18 ms /   598 tokens (    2.20 ms per token,   454.00 tokens per second)
       eval time =    4675.84 ms /   158 tokens (   29.59 ms per token,    33.79 tokens per second)
      total time =    5993.02 ms /   756 tokens
slot      release: id  2 | task 56334 | stop processing: n_tokens = 23533, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
