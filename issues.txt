# Multi‑Agent Project Issue Tracker

## 1. Inconsistent event types
`AgentProcess` uses plain dictionaries for events while the rest of the code imports and expects `AgentEvent` dataclasses. This mismatch can cause runtime errors and hinders type-checking. **Status: ✅ Fixed**

## 2. AgentProcess sends raw dictionaries
The outbound queue receives simple dicts, whereas the supervisor expects `AgentEvent` instances. Although the current policy accepts either, the inconsistency is confusing and fragile for future extensions.

## 3. Generic interjection message
The policy only signals whether an interjection should occur; the supervisor always replies with a fixed apology string. The specific error context is lost, and the policy's utility is limited.

## 4. Unused `_agent_target` helper in `SupervisorProcess`
`_agent_target` returns an empty dictionary and is never invoked. The agent is started directly with its arguments, making the helper redundant.

## 5. Missing persistence layer (`app/db.py`)
`ChatHistory` is referenced but the implementation file does not exist. Without persistence, chat history cannot be stored or retrieved, breaking the plan for Phase\u202f2.

## 6. Missing HTTP proxy (`app/server.py`)
The plan calls for a `/chat/{id}` endpoint that forwards requests to the Llama client. No such route exists, so integration tests that hit the proxy will fail.

## 7. Inefficient async handling in `AgentProcess`
`asyncio.run` is called for every incoming message, which repeatedly creates and destroys an event loop. This is unnecessary overhead and can block the process if many messages arrive.

## 8. Policy checks for non\u2011existent `token` field
`should_interject` examines the `token` key, but `AgentProcess` emits events with a `content` key. The check may never trigger, causing missed interjections.

## 9. Supervisor ignores policy\u2011provided messages
The policy currently returns a boolean only. The supervisor discards any message content, always sending the same apology string instead of a tailored response.

## 10. Graceful shutdown not propagated to agent
When the supervisor terminates, it does not notify the agent process. The agent may continue running, leading to orphaned processes.

## 11. Logging inconsistency
Agent logs to stdout; supervisor uses a logger. Outputs may intermix, making debugging difficult.

## 12. LlamaClient error handling
Non\u2011200 responses raise a generic `RuntimeError`. Tests may need to mock this scenario, but the current code does not expose a clear error path.