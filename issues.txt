Summary of problems with the chat/messaging flow

| # | Area | What’s wrong | Why it matters |
|---|------|--------------|----------------|
| 1 | Duplicate logging | `log_message` is called before, during, and after tool calls, writing the same assistant content three times (once for the streaming part, once for each tool result, once for the final full reply). | The DB ends up with spurious duplicate rows and the history view shows the same assistant turn multiple times. |
| 2 | Duplicate UI rendering | The assistant bubble is first filled with the streamed text, then overwritten with the final full reply (`placeholder.markdown(full_text)`). Tool‑call previews are written to the same placeholder but are immediately replaced by the final text. | The user sees a flicker and the tool‑call details are never shown. |
| 3 | Missing tool‑call preview | In `process_tool_calls` the tool preview is written with `placeholder.markdown`, but later the same placeholder is overwritten by the final assistant content. The preview is therefore lost. | The user never sees the “details” card that was intended to display tool results. |
| 4 | Tool‑call message construction | The assistant message that triggers the tool is built with `{"role":"assistant","content":None,...}`. While the OpenAI spec allows `content=None`, the message is never actually sent back to the model because it is immediately followed by a new placeholder for the next turn. | The model never receives the tool‑call message, so the tool‑call flow can break if the assistant tries to reference the tool result in the next turn. |
| 5 | Unnecessary “repo_docs” assistant message | `build_messages` adds `repo_docs` as an **assistant** message after the system prompt. This is semantically odd (repo docs are not an assistant reply) and can cause the assistant to treat them as a prior turn. | The assistant might reply to the docs rather than the user’s actual question, and the order of messages is distorted. |
| 6 | Inconsistent placeholder usage | `process_tool_calls` creates a brand‑new `st.empty()` placeholder for each tool‑call loop, but the original placeholder (`placeholder`) is still used for the final `markdown(full_text)`. The new placeholders are never cleared, leading to stale UI components. | UI clutter and potential confusion about which placeholder holds the current assistant content. |
| 7 | Potential API errors (content=None) | Some OpenAI SDKs require a string for `content`. While the spec accepts `None`, the local OpenAI‑compatible server may reject it, causing a run‑time error. | The entire chat flow could crash if the model rejects the tool‑call message. |
| 8 | Redundant tool‑call handling logic | `process_tool_calls` loops until `tool_calls` is `None`, but the logic inside the loop appends the same `full_text` to the cumulative string each time, and then the outer loop in `main` repeats the same call again. | This double‑processing can lead to duplicated assistant text in the final bubble and excessive API calls. |
| 9 | No error‑handling for tool‑call failures | If a tool raises an exception, the result is a string containing the error, but the assistant message still includes that string as a normal reply. | The user sees raw error messages intermingled with normal text, which is confusing. |